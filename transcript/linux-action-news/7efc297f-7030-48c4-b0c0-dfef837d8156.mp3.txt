Hello, and welcome to Linux Action News, our weekly take on Linux and the open source world.
This is episode 62, recorded on July 15, 2018.
I'm Chris.
And I'm Joe.
Hello, Joe.
We kick things off this week with Arch's turn in the barrel.
It appears there was malware found in the Arch user repository.
Not a huge surprise, really.
Well, actually, the surprise is that it's taken this long for malware to appear in the
AUR because anyone can upload software there.
So you would assume that people would have tried this before.
Yeah, you know, I wouldn't be surprised if there has been stuff in the past that maybe
just didn't get attention like things do now.
Also though, I do recall from my days of installing Arch that when you get to that point of installing
software from the AUR, they're pretty careful about walking you through how to build a package
from the AUR by hand.
So that way, you know how package builds work and you kind of know what to look out for.
So there may be a little more baked in vigilance in the user base of the AUR, possibly.
Yeah, but that assumes that people actually read the manual and pay attention to it.
Surely, most people just go through that once and then just, ah, it's fine.
I'll just trust it.
If there's a problem, there'll be a Reddit thread about it or something.
Okay, there's a little bit of that.
Yeah.
Plus there's also when you go to the AUR website, there's a comment section.
So you know, you always give that a scan too.
If anybody's in there shouting malware, you know, you move on.
But this obviously ties in with the recent stories about the Snap Store with the Crypto
Miner and Docker Hub as well.
Again, that was crypto mining.
This time it wasn't crypto mining, though, although it may have been laying the groundwork
for it.
It was just really a hardware survey, wasn't it?
A little bit like what Ubuntu have done, only without telling people this time.
Yeah, without the permission or the anonymity.
So there's those aspects to it.
But it is kind of funny to see that it just wanted machine ID, the output of uname-a,
your CPU information, output from the Pacman database of installed packages, and then the
systemctl list systemd units to figure out what you're running by default.
And that's all it wanted.
No big deal.
Send that up to a pastebin file.
That's it.
No big deal.
Yeah, but that was probably to ascertain what the best method to get crypto mining software
on people's machines was.
Oh, no, no, no, Joe, you completely misunderstand.
This was simply designed to give these users the best experience possible the next time
they install something from the AUR.
That's all.
But just for a little bit of the details here, Zactor appears to be the username of the AUR
who modified a package on June 7th.
The package, AcroRead, hmm, I wonder what that could be, was changed to run this script
and it set up a systemd unit to start itself up and do the collection in the background
for you automatically for your convenience.
But obviously that script that it's calling can be changed on the remote server at any
time to do whatever he wants it to do.
So yeah, clearly crypto mining was the plan here, I think.
But it does beg the question, what can we do about this long term?
If we're moving to this system of repositories that anyone can upload to or that are certainly
less curated than they traditionally have been with the repos, we need to put some safeguards
in place, don't we?
Or is it just the Wild West, like we have with Windows, or we have had it with Windows
in the past where it's just random executables downloaded from websites?
I don't know if they're comparable, like for example, snaps have confinement in most cases.
So this script wouldn't have been able to get to the system information because it wouldn't
have had access to that information.
So they may not be one to one comparable here, just like a Docker container only has access
to the things that are within a container.
So you can put malware in a container, but it doesn't get on the system unless there's
other exploits which it can chain on top of.
So in this particular case, it is a little more reflective of the earlier model that
the AUR represents.
I mean, it's been around for much longer than anything we just mentioned, Docker Hub or
the Snap Store or Flatpaks and Flat Hub.
It's been around for a very long time now.
And it's always been anyone can contribute.
That's sort of why it's called the Arch User Repository, they try to put it in the name.
And I don't necessarily think it means we need to fix it.
I just think it means that we have to continue education when you start to use any one of
those services.
And each one kind of has to be taken in its own way.
And that's why some people consider it dangerous to install things from the AUR.
I never was one of those people.
But all those people who always said it's dangerous can now point to this and say, hey,
look, I was right.
But I go back to my core point when we talked about Docker Hub and the Snap Store is it's
really up to the users that are installing the software to do the due diligence, to look
into it, and to just do a quick cursory check of basic things like the user account, the
user views, and in the case of the AUR, the package build file, and just do that cursory
work.
It doesn't take very long.
And it is so worth it because you could avoid something like this.
I think they're really worth it.
I think they're very worth it because they make software and free software in particular
more available to more people.
You just have to do that due diligence.
But hang on a second, you said that users need to be more proactive and everything.
But part of the appeal for me of Linux is that I can give it to someone like my mom
and just say, don't install anything other than from the GUI App Store and you'll be
absolutely fine.
But if you start then putting snaps and whatever into that GUI App Store and then trying to
tell people that they are responsible for it, that's where the line gets a bit fuzzy
for me.
I don't know if we're there yet.
Generally speaking, say you look at GNOME software on the Ubuntu desktop, the software
that gets featured there is hand-selected by staff at Canonical.
So there is a human there that is curating that carousel when you're in GNOME software,
for example.
So you give this to mom or a family member and they stick to the stuff that's advertised,
I think they're always going to be OK.
And that might just have to be the solution.
The end users, what they get is sort of a more curated experience.
But if you're going to the AUR, you're beyond the end user phase.
And then I think that's where you can say, all right, there's a little more onus on you
now.
You're opting to go to this more advanced, just like if you're using Docker Hub.
You're beyond the end user stage.
And so now, just like when you become an advanced car driver or a pilot or whatever, when you
advance something like that, there's more responsibilities you take on.
That's just how it works.
Yeah, and you say if you're using the AUR, if you're using Arch, you're beyond the end
user at that point.
And Hergros!
Yeah, I suppose, or Manjaro maybe.
But even then, if you're beyond, you know, maybe I shouldn't say this, but if you're
beyond sort of Ubuntu, Fedora even, then you're kind of getting into the enthusiast side of
things and then you kind of should be responsible for what you're installing, I suppose.
Well, something that end users won't be touching but machines will be deploying is this
new minimal Ubuntu that was released this week.
Yeah, another minimal Ubuntu.
I think there are two or three of them, so that's a bit confusing.
But this is an image that is designed to be run in the cloud, isn't it?
Designed to be spun up hundreds at a time by orchestration software.
And the whole point of it is to be slim, boot fast, but be Ubuntu underneath and have Snap
and Apt and you can build whatever system you want on top of it.
So it's kind of the best of both worlds.
And it's kind of an attempt to compete with the likes of Alpine Linux, isn't it?
Yeah, and that's why I'm glad we finally are seeing this.
Maybe even I'd say a little late, because it's exactly where Ubuntu needed to be about
a year ago.
So that way they could be really as part of where Alpine's at now.
However, they're still in a really strong position, so I wouldn't say it's too little
too late.
In fact, the results may have been worth the wait.
For the Docker Hub image, it's a 29 megabyte image.
That's remarkable, because you're really not missing out on anything.
You could apt-get install htop if you wanted to and have a much better process fewer.
Like it's real Ubuntu.
And that kind of goes to what I've been noticing about Ubuntu on a wider scale is they're not
going through these thousands of different product differentiating categories.
Like I'm starting to lose track right now over at the Red Hat camp.
You've got Red Hat, you've got CentOS, you've got Fedora Atomic, but now we've also got
Fedora Core OS, which isn't a big transition.
And then out there kind of outside all of this, you have Scientific Linux.
Like it's nebulous to me exactly what's going on, while at the meantime, I'm also using
Fedora Cloud and Fedora Server, and I don't know where that's going.
And then over on the OpenSUSE camp, it's really a mess in the SUSE area when you want to get
into Kubernetes or containerization or OpenStack.
There's different vertical stacks of SUSE for each one of those solutions.
Then you've got OpenSUSE, you've got multiple iterations of that, two of them, plus main
SUSE has two iterations, SUSE Enterprise for the desktop and SUSE Enterprise for the server.
It's mind-blowing.
But when you get to Ubuntu, there is one Ubuntu 18.04.
Now there's a mini version of it called Minimal, and there's the version you can install on
your desktop, and there's the version you can deploy on a VPS or on physical hardware.
It's all the same version.
It's all the same operating system.
There's one Ubuntu 18.04, just like there's one Ubuntu 16.04.
It's much easier to understand, and it feels like these other distros that have these different
vertical slices, these differentiators are really just a sell into different markets,
and it just adds confusion.
It feels like a model from the 90s that Microsoft created.
Well, Ubuntu was always about Linux for human beings, and that philosophy seems to have
continued into their cloud offerings, doesn't it?
Just keep it as simple as possible and just have one Ubuntu.
I suppose it gets a little more complicated with Ubuntu core, but certainly with stuff
like this, you could take this minimal image that is supposed to be competing with the
likes of Alpine, and you could, in theory, install a full Ubuntu desktop on top of it,
and it wouldn't be much different from what you can download as an ISO.
I was joking with Will about that on Late Night Linux, and he said, don't do that.
I'm almost tempted to do it.
I still haven't got around to it, but the point remains, doesn't it, that you just have
one Ubuntu, and that seems to be a very strong strategy.
Yeah, and so these images are 50% the size of the standard Ubuntu server image, and they
boot 40% faster, and I know people will write in, and they will say, well, how much faster
does it need to boot, guys?
At this point, it's pretty quick, but it was made really clear to me when I was having
a conversation with someone who works inside AWS, and he was talking about how they're
trying to shave down seconds off of spinning up thousands of instance at once.
They'll turn on 1,000 Ubuntu servers at once, and that boot up time makes a huge difference,
and if you do analysis of some postmortems from Netflix outages, the boot time of their
Linux servers, because it's thousands that have to wait and boot, really stacks up, and
it creates this massive outage window where they've had to engineer around this problem,
and so if Canonical can shave that boot time off the top, like just by default, when you
use this image, you're going to get a 40% faster boot.
That makes real-world differences to companies like Netflix and others that have infrastructure
on virtual systems.
But you do have to wonder, by the time you've built the other stuff that you need on top
of this image, whether you're going to still have that 40% saving.
I think it really depends on the workload, doesn't it?
Yeah, and it also depends on how you're using this.
These could be images that are inside containers, so they're sitting on a, you know, who knows
what base system, but these containers themselves can fire up faster when needed to respond
to customer demand.
That matters, too.
And you can build really specific systems, like think serverless.
You hear things like AWS Lambda tossed around.
It's a big hype right now.
In fact, we've done some experiments with just doing different things on the back end,
just spinning up a serverless infrastructure.
A week ago, I think it was, we talked about Rattlesnake OS, how they're building their
self-updating infrastructure around serverless on AWS Lambda.
Well, serverless is really just a way for you to execute a function, get a result back,
and move on.
And that's all powered by Linux systems on the back end spinning up instantly, creating
an environment for your code, executing it, delivering you the result, and then destroying
themselves.
That's all serverless is.
And the faster you can spin those up, the more requests you can take, and obviously
the more margins you make.
But then you go back to the Alpine issue.
Is this too late from Ubuntu and Canonical?
Have they already lost out to Alpine in this space?
Yeah, I think that is the big question that we just won't know.
We'll have to wait and see.
They have an ecosystem.
Developers seem to enjoy using Ubuntu on the desktop, laptop, and then on the server
and cloud.
So that may translate to adoption of Ubuntu Minimal for containers and for other deployments.
So maybe that momentum will carry this, but Alpine has quite a bit of momentum now as
well.
I think it's kind of up in the air.
Yeah, I think that that is a big part of it, having the same system on your laptop as that's
running in your container.
Just that familiarity with how everything works and the little differences between distros,
it makes it more attractive to me to stick with Ubuntu in the cloud.
So maybe this is enough for them, but I suppose we'll have to see.
But as we know, the cloud all runs on Python these days, and there's been a big shift over
at the project.
Its benevolent dictator for life has decided to step down.
Yeah, Guido van Rossum has had enough after all these years.
He's decided that he's going to remain a developer for the time being, but he's had enough of
being the leader.
Too much politics going on, and he's stepping down, and he's not naming a successor either.
He's just kind of saying, up to you guys, do what you want.
Yeah, that's actually literally what he's saying in his announcement on the mailing
list.
It's, you're on your own now.
Have at it.
This is really after what was a hell of a process to bring a new feature into Python
that was rather controversial.
And as all community discussions go, it got a little heated, especially these days, and
it's called the PEP572 mess.
You may have seen this go by, especially if you're an LWN subscriber or if you attended
Python Language Summit 2018 this year, where it was a significant topic of conversation.
The basic idea behind this PEP feature was a way to do assignments and expressions, which
makes writing some code constructs easier.
C has this, so does Go, but there was a lot of debate on if this feature needed to even
be in Python.
You know, there was a common feeling that we've been around for 28 years and we haven't
needed this feature.
There was also different camps on how the syntax should be implemented, some really
strong opinions on syntax.
Everybody really had an opinion on syntax.
And it may have gotten in the development channel a little earlier than it should have,
which upset some people, and it all led to a very voiceless conversation that at the
end of it appears to have left their benevolent dictator feeling like he needs a very long
vacation.
Do you think it's a knee-jerk reaction from him?
I know this dragged on for a little bit, but now that it's over with, just him almost mic
dropping at this point, surely after this long he could maybe just take a vacation for
a couple of weeks and then come back, rather than just say he's out and get on with it.
It just seems a little bit strange to me.
Yeah, I almost wonder if he feels like the position isn't necessary anymore.
He writes, I'm not going to appoint a successor.
And then he also writes, so what are you all going to do, create a democracy, anarchy,
a dictatorship, a federation?
He sort of points out that his opinion hasn't been as necessary over the last few years
and that the project has a certain amount of momentum and there's already kind of voting
going on on different things that maybe they can just figure it out.
I don't know, because if it was a total mic drop, he wouldn't then later on offer to mentor
people like he does and say he's going to stick around.
I think in a way he kind of handled it in the best way possible if he's totally done.
He got them through this controversial storm, got them on the other end of this thing, and
then once they're there and things have settled, he's saying, all right, I'm stepping away
now.
Like he could have left in the middle of it when he was probably peak upset, but instead
he waited until he got on the other end of it, things settled a bit, and then said, okay,
I'm leaving, I'll be around, I can do some mentoring, but I'm not the benevolent dictator
anymore.
There's no doubt that he's been responsible with it, but it does still strike me as strange
after all that time, but maybe he was kind of done with it already and this just pushed
him over the edge.
Yeah, I could see that, especially if you have a feeling like your position has been
less and less relevant over the years.
I could see it kind of coming to that, and maybe this is the best way for it to happen.
I'll be watching this with a lot of interest though, because this is a longstanding community
project that has a huge legacy and a lot of importance, and now what are they going to
do?
What are they going to do next?
Do they fall apart?
Do they form into something new?
Do we see massive changes?
Will there be a fork?
Like there could be some really interesting developments over the rest of this year with
Python.
Last,.ting.com, it's smarter than unlimited because you only pay for what you use.
So when you use less, you pay less.
The average Ting bill is just $23 per month per phone.
It's a fair price for however much you talk, text, and data you use.
Ting has nationwide coverage, CDMA, and GSM.
There's no contracts nor the termination fee, so you can try it out and rest assured that
for some reason it doesn't work for you, you're not stuck.
I love that too.
I have MiFi devices that I can turn off if I know I'm not going to be traveling for a
while.
It's a great system because if you don't want to, you never have to talk to a human being.
You can do it all through their really nice control panel, but if you prefer to talk to
a human being or you need to, they have great customer service.
They have support for some of the best phones because they have CDMA and GSM and a ton of
devices that you could probably bring with you, so check their BYOD page.
They have a lot.
And up on their blog right now, I'll point this out, this is really nice.
They have up like a term sheet.
It's not quite as generic as that, but they have up a bunch of different terms and definitions
for fiber optic networking, which has different things in it than traditional networking.
It's just a really handy post.
Start though by going to last.ting.com.
That supports the show and it gets you $25 off a device or if you bring one, it'll give
you $25 in service credit.
And then you just pay for what you use, a fair price for however much you talk, text,
and data you use.
last.ting.com.
Okay, so let's talk about Firefox, specifically for Android.
And is this good news?
Is this bad news?
I don't know.
It's entering a maintenance phase while they rebuild it from scratch on different technologies.
Yeah, the Android components technologies, which is a collection of Android libraries
that can be used to build browser-like applications, which probably means not Gecko.
So one part of me is a little concerned, but the Mozilla development team has been killing
it lately.
Like Firefox has been better than ever.
And so I kind of have faith that they know what they're doing here.
And it's nice that they will still be pushing bug fixes for critical bugs and security fixes
to the version of Firefox that's on Android.
So maintenance does mean security fixes for a bit.
Just no major new features, which is probably great for guys like you, Joe.
Yeah, I don't mind no new features, but most people do.
But what concerns me a little bit about this and makes me think that it might be bad news
is that you're going to have homogenization here.
It's like on iOS, there's a version of Firefox, right?
But it's not based on Gecko.
It's not really Firefox, is it?
It's just Mozilla wrapping their stuff around Apple technologies.
And you've got the same thing here with Android now.
They're going to use, albeit open source stuff from Android, but it's not going to be their
own thing, is it?
It's going to be just their brand stuck on a collection of existing Android technologies.
Maybe that's unfair because it's obviously going to take a lot more work than that sounds,
but it's not going to be as differentiated as it is now.
What doth make the browser you ask?
Is it the experience around the browser like password and bookmark sync and built-in features
like pocket and blocking of certain kinds of ads and tracking and maybe containers in
the future for different accounts, or is it the rendering engine, WebKit versus Gecko?
I would argue that it is not the latter.
I would argue that it is actually the experience around the web browser now, not so much the
actual rendering.
I don't think users care.
I think that's pretty obvious on its face.
And the reality is that when you use the components of the platform, you inherit the additional
benefits of new features that the platform provider creates.
In Apple's case, it's iOS, and in Google's case, it's Android, and they're consistently
making investments in that technology stack.
And also it means that you have to do a lot less testing, don't you?
If you're using the same rendering engine, you know that a website that works on Chrome
is almost certainly going to work on Firefox.
And as you say, then you've got the other added value there with the syncing and stuff.
So I do see the argument, but it just feels a bit sad to me.
It's not like Mozilla haven't got a few quid to spend on this, but I suppose they have
to divert their resources where they're required and where it makes sense to do so.
But it was always nice to have proper Firefox on Android.
And now it feels like we're not going to have that anymore.
I agree.
And it reminds us of the massive dominance that WebKit now has.
Well yeah, Chrome is just default everywhere, seemingly.
On Windows, Edge is just nowhere at this point, and Firefox is just trailing behind.
And even on Linux, how many people who use Linux on their desktop or laptop use Chrome
as their main driver?
Yeah, it's a good portion.
I mean, I think Firefox is still pretty well represented because it's the default still
on a lot of distros.
And I'll just note, too, I'm using WebKit as kind of shorthand for a lot of the WebKit-based
rendering engines like Google's own.
There's sort of a large category.
WebKit itself has kind of become rather fractured in the last five years, but it's still kind
of all the same beast.
And so when we had Trident and Gecko as sort of the last standout rendering engines now,
it seems like as long as Firefox remains relevant on the desktop, Gecko will still have an important
place.
But I think this is just Mozilla being practical here.
It seems that a Gecko-based standalone browser on the Android platform was either unsustainable
or just not popular enough to matter.
And so perhaps they can make this change and see an increase in users as a result, which
will make them a relevant player on the Android platform.
And that's good for everybody.
Well, I really hope so, but I'm not holding my breath, I'm afraid.
This next story stands out personally for me because it's like they ripped the carpet
out from underneath me.
I was about to go on the air Tuesday for Linux Unplug and cover ARM's new Get the Fax campaign
against RISC-V. And right as I was preparing to go on air, I realized they'd pulled the
whole thing down, but it started really as a shot across the bow.
Well, that's one way to look at it.
Another way is a very long-term death rattle maybe from ARM, looking over at what RISC-V
are doing and how that is an open standard and how it may eventually eat ARM's lunch.
It was very misjudged, there's no doubt about that.
And it really played their hand, didn't it?
Talk about not keeping your cards close to your chest.
It was basically them just admitting all the stuff they're worried about, wasn't it?
Yeah, they really try to raise five concerns before you go design your own system on a
chip.
They say that the portions that RISC solve by being open source really only solve a small
part of the overall problem and that when you're investing in a commercial processor,
it's more than just having access to the designs.
And they say RISC-V doesn't yet have a large developer ecosystem like ARM does, so that's
a disadvantage.
And there's risk of fragmentation with something that's open source.
They also point out that it's not very mature yet, at least not as mature as ARM is obviously.
And that there could be some greater design costs with RISC-V due to potential revalidation
if you have to modify the original ISA.
So just avoid the whole thing, ARM says, and stick with ARM because better to the devil
you know than the devil you don't.
Can you imagine Intel coming out with something similar about ARM?
I mean, maybe back in their scrappy days.
Maybe they'd be saying this kind of stuff in meetings, maybe with clients that are under
NDA or something, but I cannot imagine them even at any point saying this stuff publicly.
Yeah, that's why I was really ramping up to have a go at them on Tuesday.
But it appears there was some sort of internal staff revolt, as different outlets are calling
it, that prompted them to pull the page down before it really got very far.
Well, you can imagine how many internal emails must have been sent going, what are you doing
exactly with this?
Yeah, really, no kidding.
Miguel Itacaza on Twitter said, ARM's negative campaign against RISC-V can only backfire.
The Gnomon Xamarin co-founder also said, their points are kind of weak.
This was attempted before against open source, and all it achieved was egg on people's faces.
And that's exactly what's happened here.
It's classic.
You go after open source because you try to say it's fragmented, it's hard to predict,
go with us, we're safe, we're commercial, it just always comes across as looking petty
and looking defensive.
And what do you think about how they backtracked on it by just pulling the website down, and
now there's just a blank page there?
I thought that was great.
Like just nothing.
Nothing to see here.
Nope.
Nothing ever here.
Don't worry about a thing.
And unfortunately, archive.org didn't manage to cache the page.
So I think it might be lost to history apart from the odd screenshot here and there.
But I don't know, I think that probably it was a good strategy to just pull it down and
pretend that it hadn't happened, rather than a big apology or anything that's just going
to drag it out.
Because we're talking about it now, but we'll probably, or certainly a lot of people will
have forgotten about it in another few months, I would have thought.
Yeah, but now we definitely know it's on their radar, and they're a little worried about
it.
Yeah, it's rattled their cage, hasn't it?
And that's good.
It's made RISC-V more legitimate as a architecture, isn't it?
Maybe so.
I don't think ARM's going anywhere.
So I don't think they have to worry.
But you know, there may be a portion of their market that they end up losing to RISC-V as
it starts to bear fruit.
So they really should be kind of concerned.
I think there's legitimacy to it.
Yeah, I mean, this is not going to affect their, at least for the time being, their
snapdragons and stuff in the high end smartphones and the clusters in the data center.
This is the IoT stuff, the real low power, low level stuff where RISC-V can potentially
compete with them.
And that is often the bread and butter of a company, isn't it?
We talk about the flagships, and that's the exciting stuff.
But really, it's the low cost stuff and low power stuff that they're pumping out loads
of that actually makes them the money.
Yeah, it's the fight for IoT is what it is.
It's the fight for the future revenues of the IoT revolution.
Yeah, and you have to be forward thinking because maybe RISC-V will get to a point where
it can compete with snapdragons and stuff at some point.
And they don't want to just be snoozing like Intel have been doing for the past 10 years.
Debian caught our attention this week when they joined KDE's advisory board.
Looks like they're also joining other distributions like Ubuntu and OpenSUSE.
Yeah, yet more people embracing KDE and Plasma.
You've been going on about it long enough, and obviously, Debian must have been listening
to the shows, eh?
Yeah, I'm sure that's what it is.
You know, KDE has really been a great platform on Debian for a long time, and so they've
had a strong relationship for a long time.
And I think the two projects really consider this formalizing that relationship.
In fact, the Debian project leader Chris Lam wrote, the KDE Plasma desktop environment
is fully supported within Debian, and thus the Debian project is extremely excited to
be formally recognizing the relationship between itself and KDE, especially how that will greatly
increase and facilitate our communication and collaboration.
I wonder what this means in terms of the Debian defaults, because for a long time Gnome was
a default, then they changed to XFCE briefly, and I was cheering that decision.
But I wonder, does it mean maybe we might get Plasma as a default in the Debian installer?
Well, we are all sliding into that Wayland future, Joe, so maybe.
Maybe they're thinking down the road at some point they'll want something that's really
feature complete on Wayland.
But in the meantime, I just see it as a formalizing of something that's probably been sort of
unofficial for a long time.
If it led to Plasma as the default on Debian, I would be 100% for that.
That sounds like a wicked good combo.
Well, they could do a lot worse than Plasma as default.
I've grown to really respect what they've been doing, and it's not quite enough to drag
me away from XFCE at this point, but it gets more and more attractive every time I look
at it.
And if something like that were to ever happen, or anything else that does happen in the world
of Linux and open source, you know where to catch it every single week, and you can do
that by going to linuxactionnews.com slash subscribe for all the ways to get new episodes.
And you can go to linuxactionnews.com slash contact for ways to get in touch with us.
And you can support the whole network over at our Patreon page, patreon.com slash jupitersignal.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
I'm at Chris Ellis.
I'm at Joe Ressington.
Thank you for joining us, and we will see you next week.
See you later.
