1
00:00:00,000 --> 00:00:09,680
Hello, and welcome to Linux Action News, Episode 234, recorded on March 30th, 2022.

2
00:00:09,680 --> 00:00:10,680
I'm Chris.

3
00:00:10,680 --> 00:00:11,680
And I'm Wes.

4
00:00:11,680 --> 00:00:12,680
Hello, Wes.

5
00:00:12,680 --> 00:00:14,360
Let's do the news.

6
00:00:14,360 --> 00:00:20,260
And we start with the story that was sent into the show by far the most this week.

7
00:00:20,260 --> 00:00:28,180
The recently refreshed Rolling Remix of the Ubuntu Desktop, codenamed Rolling Rhino.

8
00:00:28,180 --> 00:00:32,520
This new Remix builds on the work our friend Martin Wimperis kicked off, although that

9
00:00:32,520 --> 00:00:35,960
was mostly on a lark, if I recall, right, Chris?

10
00:00:35,960 --> 00:00:36,960
It seemed.

11
00:00:36,960 --> 00:00:41,520
So, you know, Wimpy was really on this a little while ago.

12
00:00:41,520 --> 00:00:42,520
Others have talked about this.

13
00:00:42,520 --> 00:00:47,520
I mean, I actually kind of feel like this idea of a rolling Ubuntu has been popping

14
00:00:47,520 --> 00:00:53,680
up in one form or another for years, maybe since 1804 shipped.

15
00:00:53,680 --> 00:00:57,160
I feel like it's been in the conversation, at least in the background.

16
00:00:57,160 --> 00:01:02,560
I think this idea just appeals to some hardcore Ubuntu users who love Ubuntu as a base, love

17
00:01:02,560 --> 00:01:07,320
that environment, but they just want the freshest package as possible.

18
00:01:07,320 --> 00:01:11,680
Maybe they're an enthusiast, maybe they're a developer, something like that.

19
00:01:11,680 --> 00:01:17,660
The Rolling Rhino website describes the project as the following, quote, Rolling Rhino Remix

20
00:01:17,660 --> 00:01:23,000
is an unofficial Ubuntu flavor which converts the Ubuntu operating system into a rolling

21
00:01:23,000 --> 00:01:26,040
Linux distribution that tracks the development series.

22
00:01:26,040 --> 00:01:31,160
The project also highlights the primary tool they've created to help smooth this whole

23
00:01:31,160 --> 00:01:38,000
new rolling process out, quote, the main tool we've created is Rhino Dash Update.

24
00:01:38,000 --> 00:01:43,120
It will ensure that system updates are ran smoothly and extends the capabilities of what

25
00:01:43,120 --> 00:01:45,640
apt is able to provide.

26
00:01:45,640 --> 00:01:48,480
Well, that sounds fascinating.

27
00:01:48,480 --> 00:01:51,560
And yeah, at this point, apt might need a little help if it's going to be doing some

28
00:01:51,560 --> 00:01:53,200
radical new package promises.

29
00:01:53,200 --> 00:01:54,200
Yeah, yeah.

30
00:01:54,200 --> 00:01:55,200
Huh.

31
00:01:55,200 --> 00:01:56,200
That's a good point.

32
00:01:56,200 --> 00:01:59,000
I wonder what's this is probably something I'm going to throw in a VM to be honest with

33
00:01:59,000 --> 00:02:00,000
you.

34
00:02:00,000 --> 00:02:01,880
I was debating it up until this point.

35
00:02:01,880 --> 00:02:06,240
And then when I saw that tool, I'm like, hmm, nope, gonna give this a go because it sounds

36
00:02:06,240 --> 00:02:07,640
really handy.

37
00:02:07,640 --> 00:02:11,520
It's also nice to see that this has the blessing of our buddy Wimpy.

38
00:02:11,520 --> 00:02:15,400
He's been helping with this renewed effort, it seems filing some bug reports, responding

39
00:02:15,400 --> 00:02:18,760
to team questions, obviously, giving the okay to use the project name.

40
00:02:18,760 --> 00:02:21,440
So you know what, I'm all for this.

41
00:02:21,440 --> 00:02:22,960
I think this is great to see.

42
00:02:22,960 --> 00:02:26,400
I'm really glad this has a couple of developers behind it.

43
00:02:26,400 --> 00:02:29,320
Now I hope they continue and I hope that team grows.

44
00:02:29,320 --> 00:02:34,280
And even though I don't suspect that I'm the target user, because I like probably a lot

45
00:02:34,280 --> 00:02:37,740
of Ubuntu users, I've just kind of adapted to that release model.

46
00:02:37,740 --> 00:02:41,920
So if I deploy Ubuntu on a system, that's probably a box, I don't expect is going to

47
00:02:41,920 --> 00:02:43,640
change very often.

48
00:02:43,640 --> 00:02:47,840
So the end user that I see this is probably going to be the most suitable for would be

49
00:02:47,840 --> 00:02:53,240
a developer, a developer who's likely trying to target the next iteration of the Ubuntu

50
00:02:53,240 --> 00:02:54,240
platform.

51
00:02:54,240 --> 00:02:59,320
And in that scenario, I could see this being a very handy release, and potentially one

52
00:02:59,320 --> 00:03:04,520
that's worth keeping around in a VM by us enthusiasts, just to see where Ubuntu is going.

53
00:03:04,520 --> 00:03:10,240
I use Rhino, by the way.

54
00:03:10,240 --> 00:03:16,880
Continuing off my remarks from the last chapter, and maybe I should be running it on AMD hardware,

55
00:03:16,880 --> 00:03:22,200
at least at this rate, Michael Larble over at Ferronix continues to be hot on the trail

56
00:03:22,200 --> 00:03:29,440
of new AMD Linux positions, writing this week that AMD is recruiting more engineers to better

57
00:03:29,440 --> 00:03:37,440
support the Linux platform, and also develop support for Compute Express Link under Linux.

58
00:03:37,440 --> 00:03:42,660
We've really been watching AMD kind of take a whole corporate level commitment, like the

59
00:03:42,660 --> 00:03:48,920
entire corporate stack, a commitment to Linux and Linux support over the last year and a

60
00:03:48,920 --> 00:03:50,200
bit.

61
00:03:50,200 --> 00:03:54,640
And this is good to see because AMD is part of the Compute Express Link organization,

62
00:03:54,640 --> 00:03:57,380
part of that group that is pushing that standard.

63
00:03:57,380 --> 00:04:01,880
So it's kind of important that some of the key members of that standard are putting their

64
00:04:01,880 --> 00:04:04,860
money where their mouth is and supporting Linux development.

65
00:04:04,860 --> 00:04:08,320
And that's exactly what we're seeing with these new AMD positions.

66
00:04:08,320 --> 00:04:12,800
And by the way, if you're not familiar, the Compute Express Link is an industry supported

67
00:04:12,800 --> 00:04:18,480
cache coherent interconnect for CPUs, memory expanders and accelerators, you know, basically

68
00:04:18,480 --> 00:04:21,720
all the plumbing you might need to make things go fast.

69
00:04:21,720 --> 00:04:31,460
And it's backed by the CXL Consortium, which calls itself an open industry standard group.

70
00:04:31,460 --> 00:04:35,080
Don't you just love it when a good thing keeps getting better?

71
00:04:35,080 --> 00:04:38,620
Wire Plumber 0.4.9 is now out.

72
00:04:38,620 --> 00:04:43,640
And it properly exposes surround sound support to those Linux games that support Dolby 5.1.

73
00:04:43,640 --> 00:04:48,440
Yeah, a little disappointed if you go and invest in that surround sound system and then

74
00:04:48,440 --> 00:04:50,400
Linux breaks it.

75
00:04:50,400 --> 00:04:55,680
It looks like actually the fix landed in Wire Plumber approximately a month or so ago.

76
00:04:55,680 --> 00:05:02,000
And it was the relaxation of format parsing within the SI audio adapter module that actually

77
00:05:02,000 --> 00:05:05,460
appears to be the thing that fixed the issue.

78
00:05:05,460 --> 00:05:08,120
This latest release has a whole lot more than that though.

79
00:05:08,120 --> 00:05:13,860
I mean, there's the sort of usual crash stability improvements, but it also addressed a kind

80
00:05:13,860 --> 00:05:18,500
of nasty race condition within the Zoom desktop app, which could have resulted in your audio

81
00:05:18,500 --> 00:05:21,720
sharing to fail, which that's never a great impression.

82
00:05:21,720 --> 00:05:26,840
It also adds Brave and Edge and Vivaldi and Telegram all to the Bluetooth auto switch

83
00:05:26,840 --> 00:05:30,980
application list, which should be a pretty smooth little experience.

84
00:05:30,980 --> 00:05:37,320
But then there's just a whole bunch of other fixes and improvements.

85
00:05:37,320 --> 00:05:38,880
Linode.com slash LAN.

86
00:05:38,880 --> 00:05:43,240
Go there to get $100 in 60 day credit on a new account and you go there to support the

87
00:05:43,240 --> 00:05:44,240
show.

88
00:05:44,240 --> 00:05:47,640
Linode is cloud computing made simple, affordable and accessible to all.

89
00:05:47,640 --> 00:05:51,120
It's what we use for everything we've built in the last two and a half years and it constantly

90
00:05:51,120 --> 00:05:52,120
gets better.

91
00:05:52,120 --> 00:05:56,440
I just did a free upgrade to their new MVME storage and it's blazing fast.

92
00:05:56,440 --> 00:06:01,520
So take advantage of our $100 offer and deploy Linode on your own and experience what it

93
00:06:01,520 --> 00:06:02,520
can do.

94
00:06:02,520 --> 00:06:04,960
Kick the tires and support the show.

95
00:06:04,960 --> 00:06:10,140
Linode.com slash LAN.

96
00:06:10,140 --> 00:06:11,140
And thanks to Ting.

97
00:06:11,140 --> 00:06:12,140
Linux.ting.com.

98
00:06:12,140 --> 00:06:18,720
I've been a Ting customer since 2013 because they offer great nationwide coverage on the

99
00:06:18,720 --> 00:06:25,000
big duopoly carrier networks, but at a price and with customer support, nobody can touch.

100
00:06:25,000 --> 00:06:29,320
Ting was recently named the number one carrier by Consumer Reports in 2021.

101
00:06:29,320 --> 00:06:33,960
There's a plan for everybody starting around $10 a month and up from there and every plan

102
00:06:33,960 --> 00:06:39,160
gets access to Ting's award-winning customer service and nationwide LTE and 5G coverage

103
00:06:39,160 --> 00:06:40,680
and no contracts ever.

104
00:06:40,680 --> 00:06:46,840
So go to linux.ting.com.

105
00:06:46,840 --> 00:06:51,640
And we wrap things up this week with a series of impressive updates from the Linux kernel

106
00:06:51,640 --> 00:06:52,640
team.

107
00:06:52,640 --> 00:06:57,920
Let's start with a problem that I'm sure impacts just about everyone listening.

108
00:06:57,920 --> 00:07:04,240
You have gosh darn so many NVMe disks that Linux takes too long to shut down.

109
00:07:04,240 --> 00:07:09,520
Well apparently some people do have that problem, including the folks at Google who wrote into

110
00:07:09,520 --> 00:07:11,740
the mailing list, quote,

111
00:07:11,740 --> 00:07:16,960
Some of our machines are configured with many NVMe devices and are validated for strict

112
00:07:16,960 --> 00:07:19,480
shutdown time requirements.

113
00:07:19,480 --> 00:07:24,840
Each NVMe device plugged into the system typically takes about 4.5 seconds to shut down.

114
00:07:24,840 --> 00:07:32,400
So a system with 16 such devices takes approximately 80 seconds to shut down and reboot.

115
00:07:32,400 --> 00:07:37,700
It's rough, you know, 16 NVMe disks, it's just rough.

116
00:07:37,700 --> 00:07:41,580
The register actually does give us some context on this problem they write.

117
00:07:41,580 --> 00:07:45,180
The problem is that the kernel's drive shutdown function is synchronous.

118
00:07:45,180 --> 00:07:50,440
For each drive it waits for the shutdown command to complete before carrying on to the next.

119
00:07:50,440 --> 00:07:55,100
The new kernel patch does exactly the same thing, but changes the way that the calls

120
00:07:55,100 --> 00:07:57,640
are issued to be asynchronous.

121
00:07:57,640 --> 00:08:02,680
It issues the call to the first drive, then immediately moves on to the next, and it works

122
00:08:02,680 --> 00:08:08,560
its way down the list when they all return the desired status, the job is done.

123
00:08:08,560 --> 00:08:12,800
Well while we save up to buy some more NVMe disks, let's take a look at the upcoming

124
00:08:12,800 --> 00:08:17,760
Linux 5.18 release, which is shaping up to be another barn burner.

125
00:08:17,760 --> 00:08:23,520
And one area that's getting a kick in the pants is 64-bit ARM support, adding a shadow

126
00:08:23,520 --> 00:08:26,880
call stack, thanks to the work of Alibaba.

127
00:08:26,880 --> 00:08:31,120
Yeah, the shadow call stack is an instrumentation pass, that's what they call it, and it's

128
00:08:31,120 --> 00:08:36,120
currently only implemented for ART64 systems, but it protects programs against the return

129
00:08:36,120 --> 00:08:40,600
address overwrites, which is essentially, I guess, a stack buffer overflow.

130
00:08:40,600 --> 00:08:45,200
Yeah, it works something like this, when the compiler sees code that's calling into

131
00:08:45,200 --> 00:08:51,480
another function, it first emits code that creates a separate, quote, shadow call stack,

132
00:08:51,480 --> 00:08:55,440
and then saves the function's return address to that shadow call stack before continuing

133
00:08:55,440 --> 00:08:57,160
on.

134
00:08:57,160 --> 00:09:01,280
Once whatever function that was being called is complete and has done its work, the compiler

135
00:09:01,280 --> 00:09:07,180
ignores whatever return address is on the real call stack, and instead uses that value

136
00:09:07,180 --> 00:09:13,120
it sneakily stored on the shadow stack to jump back to the calling original function.

137
00:09:13,120 --> 00:09:14,920
Why bother to go through all this work?

138
00:09:14,920 --> 00:09:19,960
Well, the idea is that if anyone malicious on the system tampered with the real call

139
00:09:19,960 --> 00:09:24,520
stack, which, you know, that's the first place you'd look, it doesn't actually interfere

140
00:09:24,520 --> 00:09:27,320
with the intended control flow.

141
00:09:27,320 --> 00:09:31,960
Sticking with 5.18 for just a bit longer, support for Intel's hardware feedback interface

142
00:09:31,960 --> 00:09:37,920
landed in the thermal subsystem, and the Linux 5.18 power management updates that have landed

143
00:09:37,920 --> 00:09:38,920
look noteworthy.

144
00:09:38,920 --> 00:09:45,080
Yeah, it seems that both AMD and Intel have received important piece-date improvements

145
00:09:45,080 --> 00:09:46,600
this time around.

146
00:09:46,600 --> 00:09:50,820
And in conjunction with some other bits of work, this should give the OS more governance

147
00:09:50,820 --> 00:09:55,720
over the power state the system is in, as well as the idle states of the CPU, all of

148
00:09:55,720 --> 00:10:01,080
which should work together to provide more efficient power usage, and hey, maybe better

149
00:10:01,080 --> 00:10:02,640
battery life to boot.

150
00:10:02,640 --> 00:10:05,120
Now, it's not all good news in 5.18.

151
00:10:05,120 --> 00:10:11,400
It seems our collective cries to save the once great Ryzer FS have not been heard.

152
00:10:11,400 --> 00:10:13,640
Or there were just no calls.

153
00:10:13,640 --> 00:10:17,840
Either way, it seems there is now consensus among the upstream kernel developers to deprecate

154
00:10:17,840 --> 00:10:20,080
Ryzer FS.

155
00:10:20,080 --> 00:10:25,280
Given that there are no notable users of it any longer, the code is barely maintained,

156
00:10:25,280 --> 00:10:29,320
and it's hard to come up with a single legitimate reason to keep it, especially when you have

157
00:10:29,320 --> 00:10:33,120
modern alternatives like ButterFS and XFS.

158
00:10:33,120 --> 00:10:37,360
So the plan is to treat it as deprecated and then formally remove it from the mainline

159
00:10:37,360 --> 00:10:40,800
kernel in 2025.

160
00:10:40,800 --> 00:10:44,280
So long Ryzer FS.

161
00:10:44,280 --> 00:10:46,760
Don't worry though, it's not all bad file system news.

162
00:10:46,760 --> 00:10:50,560
There's some good news this time around, at least for XFS users.

163
00:10:50,560 --> 00:10:51,560
We hope.

164
00:10:51,560 --> 00:10:54,320
The XFS file system changes.

165
00:10:54,320 --> 00:11:00,640
Now it's not actually in 5.18, those changes are mostly bug fixes, important as those are.

166
00:11:00,640 --> 00:11:06,560
But after the 5.18 cycle is complete, it seems that there are some major changes potentially

167
00:11:06,560 --> 00:11:07,560
planned.

168
00:11:07,560 --> 00:11:11,280
Yeah, this came to light after a comment by the XFS maintainer Derek Wong.

169
00:11:11,280 --> 00:11:17,600
He writes, Dave Chinner will be taking over as the XFS maintainer for one release cycle,

170
00:11:17,600 --> 00:11:25,160
starting from the day 5.18 RC1 drops until 5.19 RC1 is tagged, so that way Derek can

171
00:11:25,160 --> 00:11:31,760
focus on starting a massive design review for the online repair feature.

172
00:11:31,760 --> 00:11:37,040
That could be pretty big, so we'll have more details on that when it gets closer.

173
00:11:37,040 --> 00:11:41,840
Our final story today is one we've been following for a bit of time, with an excellent update

174
00:11:41,840 --> 00:11:44,520
this week from LWN.

175
00:11:44,520 --> 00:11:49,640
Back in mid-February, LWN first reported on the plan to unite the two kernel devices that

176
00:11:49,640 --> 00:11:55,860
provide random numbers, effectively making one just a pointer to the other.

177
00:11:55,860 --> 00:12:01,200
And that change made it as far as the mainline during Linux 5.18's merge window, but it was

178
00:12:01,200 --> 00:12:04,380
actually quickly reverted when problems were found.

179
00:12:04,380 --> 00:12:09,600
So it may be possible, LWN reports, that this unification work will continue someday, as

180
00:12:09,600 --> 00:12:15,440
they put it, but for now there's just production environments that need their random numbers

181
00:12:15,440 --> 00:12:20,280
early on in the boot process and can't wait for the entropy to be available or rely on

182
00:12:20,280 --> 00:12:22,860
that Linus jitter dance.

183
00:12:22,860 --> 00:12:25,160
What is the Linus jitter dance, you ask?

184
00:12:25,160 --> 00:12:26,160
Well, fair question.

185
00:12:26,160 --> 00:12:31,120
Well, for several years now, it's a procedure that's been used during boot time to take

186
00:12:31,120 --> 00:12:36,580
advantage of CPU execution time differences to initialize the pool of random numbers in

187
00:12:36,580 --> 00:12:38,120
less than a second.

188
00:12:38,120 --> 00:12:43,880
It basically uses difference in code execution speed of repetitive operations due to just

189
00:12:43,880 --> 00:12:49,680
the sort of inherent unpredictability in modern CPUs, you know, from things like caches, branch

190
00:12:49,680 --> 00:12:52,080
prediction, that kind of thing.

191
00:12:52,080 --> 00:12:57,320
That actually sounds really clever, but a day after the code was merged, a bug report

192
00:12:57,320 --> 00:13:03,360
came rolling in reporting, quote, a large number of QMU boot test failures for various

193
00:13:03,360 --> 00:13:09,240
architectures, and the submitter noted that the common denominator in those boot hangs

194
00:13:09,240 --> 00:13:14,280
was one error message, and it read, quote, saving random seed.

195
00:13:14,280 --> 00:13:18,560
During the user's troubleshooting, they tracked the issue down to that new unified random

196
00:13:18,560 --> 00:13:24,320
number device generator and noted that when they reverted that change, the problems went

197
00:13:24,320 --> 00:13:25,320
away.

198
00:13:25,320 --> 00:13:29,660
You know, it can be tricky on things in data centers or yeah, especially virtualized situations

199
00:13:29,660 --> 00:13:33,880
where you just don't have access to a lot of real physical devices with unpredictable

200
00:13:33,880 --> 00:13:35,880
behavior.

201
00:13:35,880 --> 00:13:41,260
So for now, the kernel team is keeping things the way they've always been, and the generator

202
00:13:41,260 --> 00:13:45,000
unification must wait for another day.

203
00:13:45,000 --> 00:13:49,420
But all that said, it does seem like there's more thought and work going into Linux is

204
00:13:49,420 --> 00:13:54,980
random number generation systems these days, and that's got to be a good thing.

205
00:13:54,980 --> 00:14:00,640
I am impressed with the amount of energy and focus all these different deep layers of the

206
00:14:00,640 --> 00:14:05,560
kernel are getting and we've been talking about device drivers rewritten in rust, critical

207
00:14:05,560 --> 00:14:11,040
power support for the different primary CPU platforms, this AMD stuff coming in the file

208
00:14:11,040 --> 00:14:12,880
system improvements.

209
00:14:12,880 --> 00:14:15,680
Every level in there seems like it's getting some attention right now.

210
00:14:15,680 --> 00:14:20,640
And that's just so impressive for a project the age and size of the Linux kernel.

211
00:14:20,640 --> 00:14:23,320
We'll keep an eye on all those developments and everything else happening in the world

212
00:14:23,320 --> 00:14:26,480
of Linux and open source news and keep you posted.

213
00:14:26,480 --> 00:14:31,380
So make sure you get every single episode by going to linuxactionnews.com slash subscribe

214
00:14:31,380 --> 00:14:33,840
for all the ways to get new episodes.

215
00:14:33,840 --> 00:14:38,940
And don't forget linuxactionnews.com slash contact for ways to get in touch.

216
00:14:38,940 --> 00:14:42,920
If you'd like to get Linux action news ad free become a member at Jupiter.party and

217
00:14:42,920 --> 00:14:47,240
get all of the network shows ad free with all of their extra special content.

218
00:14:47,240 --> 00:14:52,600
Either way, we'll be back next week with our take on the latest Linux and open source news.

219
00:14:52,600 --> 00:14:53,600
Thanks for joining us.

220
00:14:53,600 --> 00:15:23,200
And that's all the news for this week.

