Hello, and welcome to Linux Action News, episode 184, recorded on April 11th, 2021.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
There's been some impressive progress towards an important milestone for getting Linux up
and running on the Apple M1, and some indications that full desktop support might be achievable.
But last week, the co-maintainer of the ARM SoC kernel tree merged the Apple M1 branch
into Linux Next, which is the staging area for code expected to land in the next kernel
merge window.
And that also means that it's not yet accepted by Linus.
And it's months from shipping if he does accept it.
But at this time, as we record, there is no indication or reason to suspect that Linus
will reject this.
In fact, it seems quite the opposite that he will accept it.
And it's a mind bending initial set of patchwork that's been contributed by Hector Martin
and his team at Asahi Linux.
I think that's how you say it.
This new branch includes basics to get the Apple M1 systems booting.
But also in there is that brand new bootloader the team built to make this possible that
accommodates USB oddities and whatnot that we covered in a previous episode of Linux
Action News.
Now don't get too excited once you've got it booted up, Asahi's environment only has
a serial and frame buffer console for access right now.
But this is important work to actually get future drivers developed.
We reached out to Hector Martin for comment.
And he said,
I want to emphasize that what we upstream just gives you a serial console, but it represents
figuring out a lot of deep platform details about the ports, changes to core kernel code
and settle several technical questions that required a lot of back and forth, including
things like what the bootloader is responsible for versus what Linux is responsible for.
As we've talked about before, there's a lot of work and conversation that has to go in
before you get this kind of stuff merged.
Asked about the next steps for M1 support, Hector said,
So the next step is drivers and I expect that it will get a lot quicker than most people
might think after we spent three months on just getting a serial console working.
Hector Martin is already sending in the M1 IOMMU driver for review and we are working
on PCIe bring up and we found Linux code that matches the controllers in other SOCs.
Hector also relate to us that he and the team are dedicated to shaving all the required
YACs to get this thing to be a high quality port.
Clearly they care a lot about this.
There's a lot of pride, I think, involved in the work and they want to see the shine
if it's possible.
Yeah, he pointed to a couple of examples of abandoned Android platforms where they have
just created this unmaintainable code dump that is just essentially a fork of Linux.
That's not what they're going for at all here.
They want something that's long term and maintainable and I think they're going to get there at
this stage.
I'm cautiously optimistic.
I'm confident that we're going to get a text based Linux booting on this thing that you
could use to say rescue hardware and do data recovery and security forensics.
I think we're really close to that and that's going to be valuable just as Apple begins
to sell millions of these devices and professionals need these tools available to them.
So Hector Martin and his team are going to do a service, even if they never get the graphical
environment going here, it will be a use case.
But I am actually getting cautiously optimistic they're going to go all the way.
I mean, it's obviously not time to buy an M1 Mac right now with the intention of running
Linux on it, but it seems like it's going to be possible more than ever right now.
Yeah, I mean, for his part, Hector Martin seems pretty confident that he's going to
be able to get a fully working desktop on the M1 sometime this year.
In response to Michael Larable over at Ferronix, who had doubted the project would reach that
milestone, Hector responded with just challenge accepted.
And what might also be a positive sign with this is that as the Asahi team has moved along,
they don't really seem to be running into a lot of artificial barriers from Apple.
Maybe I'm wrong, but it kind of seems that in some respects, like how firmware gets loaded,
how much stuff is handled in the hardware, it might be simpler to get this going on the
ARM side than it was on the on the x86 version.
Isn't that funny?
And the opposite of what you would expect is in some cases, the hardware is doing the
like the firmware blob loading for you, the OS doesn't even have to touch it.
And you almost wonder if there if there isn't some fire to the smoke about rumors that Apple
is running Linux in the bowels to internally test hardware in the early development stages.
Apple very well may have a few M1 test systems running Linux in-house because it seems like
they haven't gone out of their way to lock this out at all.
In fact, they just simply haven't done anything to make it work, but they also haven't tried
to prevent it.
And if you think about it, if Apple was running Linux down in the skunk labs, would they say
a word about it or would they keep mum so that way people didn't ask them GPL questions?
But additionally, if I were Apple and I saw the roadmap of the M platform, I think I'd
want to run these in my own iCloud data center.
There's got to be obvious efficiencies to some of the ML stuff that's built into the
chip, but also just running their own gear in their own hardware and having more confidence
in supply chain security and also the performance and power savings when you're running your
data center off a solar system, which they do with their Nevada data center.
And I know they use Azure and they use AWS and they use Akamai quite a bit, but they
also have a ginormous data center with actual physical hardware in it.
And you'd think they'd want to rack up their own M systems instead of continuing to buy
x86 boxes.
And if they're going to run that in a data center, it's probably going to be running
Linux, at least on some of them.
Yeah.
I mean, Amazon, Microsoft, Google that are all already building their own custom ARM
systems for the data center.
You could really understand why Apple might want to do the same.
Really though, this story is just getting started before Linux 513 comes out with these
initial patches, which should be sometime around June.
You can expect kernel 512 as early as this week or sometime in late April or early May.
We'll see either way.
It's got loads of exciting new features and we'll have those details whenever it ships.
Well speaking of Linux 513, also very likely for inclusion in that release is a new PCIe
host controller driver for the much anticipated Psi 5 High 5 unmatched board system.
The unmatched has 16 gigs of RAM.
It has USB 3.2.
It has one PCI express 16 slot that is operating at 8x speed and one MVME slot and gigabit
ethernet.
And might you be able to get your hands on one of these?
Well, the pre-order page from Mouser Electronics, which will be one of the potential suppliers
anyway, is currently indicating they're expecting the High 5 unmatched to arrive sometime around
the end of May.
And that means that by the time people actually start receiving those units, this new PCIe
host controller driver will be shipping pretty soon.
Or maybe already have shipped to end users.
That's pretty exciting.
And if you want to take part and try this thing out, the pricing remains at $665.
Linode dot com slash LAN.
Go there to get a $100 60 day credit towards your new account and of course support the
show.
It's easy.
Linode dot com slash LAN.
$100 means you can actually kick the tires.
Linode is the largest independent cloud computing provider.
It's where we host everything for JB 3.0 and they make it easy no matter what skill level
you're at to get up and going.
And they have all the different distros you could possibly want to choose from to host
on.
If you run into any trouble as well, Linode has outstanding, amazing 24-7 customer support
by phone or ticket.
All with hundreds of guides and tutorials to help you get started.
In fact, in the notes, I'll link a guide to covering how to secure PHP MyAdmin.
I get it.
It's a useful tool and I've worried about it too.
That's what's great about their guides.
They give you some peace of mind running this stuff in production.
Linode is easy to use and has a powerful cloud dashboard and you can kind of grok if you're
a longtime Linux user that the people that run and build Linode are Linux users too.
And their S3 compatible object storage is so useful you'll find hundreds of uses for
it.
And then they have great features like cloud firewall, simple one click application deployment,
super fast networking and much, much more.
That's why you just got to go check it out for yourself.
Try one of those one click app deployments, something like that and just see what we've
been talking about, because Linode is truly fantastic and the only way I would host things
today.
So sign up today at linode.com slash LAN.
Get a $100 60 day credit towards your new Linode account and of course support the show.
That's linode.com slash LAN.
When Firefox 88 is released later this month, it'll finally be making the long anticipated
switch to using Web Render as the default rendering engine on Linux.
This is that final piece of all of the performance we were promised with Project Quantum back
in like Firefox 67 timeframe.
This is though, this is one of those updates where it's impressive depending on how you
have your system configured and the kind of hardware that you might have in your box.
Interestingly, Web Render actually comes out of Mozilla's work on Servo and first made
an appearance in Firefox way back in Firefox 67, which was released on May 21st, 2019.
But of course, this was behind a config option and was not the default.
You had to go into about config and set gfx.webrender.all to true before you could play with any of this
new shiny.
And Chris, you'll be pleased because of that Servo heritage, yes, Web Render is written
in Rust.
That's right.
A lot of our, a lot of Rust and its progress is actually kind of tied back to Servo.
So it's, it all comes together.
And also kind of in the Firefox vein, we have a link in the show notes for you.
Have you ever noticed that extensions just seem to work better under the Fox?
Well, it turns out there actually may be several technical reasons why extensions are better
under Firefox.
The uBlock Origin developer wrote a post that kind of goes over some of these highlights,
and a couple of them stood out to us.
Yeah, one of the reasons that uBlock Origin just kind of does better on Firefox is it
has a better ability to unclog third party servers that use CNames to make it look like
their first party, so called CName unclogging, but really just means uBlock Origin is better
able to figure out where you're going and then if it needs to, it can block it, which
means you get more blocked sites.
There's just a whole list, like the ability to filter HTML before it's passed and parsed
by the browser, improvements about the way Firefox brings extensions up.
But the one that struck me, because I'm sure this affects a lot of extension developers,
is the Firefox version of uBlock Origin makes use of WebAssembly code for like the core
filtering paths.
That's just not the case with the Chromium based ones, simply just because of creating
a smoother user experience in the Chrome Web Store, and if they wanted to use WebAssembly
code for the filtering code pass, they'd have to ask for an additional permission at install.
It would reduce the amount of deployments they get because other plugins don't do this,
and so they don't do it, and it takes a slower path on Chrome, and it's just kind of an example
of something that's both technical and political that makes it just not as ideal to develop
an extension for Chrome.
It's just because there's so many dang users that people do it, but I have noticed this
with the Fox.
I've noticed it seems like extensions that I use in both browsers do work better in Firefox,
and it's got to be some of this.
Yeah, you know, Mozilla has a long history of being the extension forward browser vendor,
so I think they've just figured out some of the things that you need, where the right
hooks should go, but really this is just the excuse maybe you needed to give Firefox a
try again.
We'll talk about more future desktop Linux stuff.
One of the challenges about our Wayland futures, it means sometimes we're actually introducing
fragmentation and multiple implementations to do something, and that is exactly what's
happening around extended display identification data, which is information that Linux can
use to learn more about monitors that are connected, and currently there's no de facto
EDID parsing library for Linux, and so what we've ended up with, as you are probably fearing
right now, is multiple implementations, and most Wayland compositors are just rolling
their own solution.
Now this extended display identification data, that's the good stuff that the kernel needs
to learn everything about your monitor or monitors, and then it passes that along to
user space and offers various metadata for the different tools to set up your displays.
But the problem that we have today is the various tools that we do have in user space,
they need more information.
They need metadata about high dynamic range, refresh rate, all kinds of additional things,
and so they're implementing their own solutions to this, and it's not consistent.
A prominent Wayland developer is suggesting that instead of exposing all of that parsed
information from the kernel directly, there should instead be a unified Linux EDID parsing
library, that hypothetically at least would be a free desktop.org hosted project, MIT
licensed, offer, you know, a way to use it from C of course, and probably just take one
of the existing EDID parsing libraries, sort of flesh it out, make it work, and hopefully
the standard.
That I think is the clever aspect to this, is take something that already exists that
people are kind of comfortable with, and then modify it as needed to solve the remaining
edge cases, and this would cut down on code duplication across Wayland compositors, and
really solve differences that might end up being frustrating to end users, and kind of
make it a more unified experience.
This is early, the call was made on the Wayland mailing list just recently, and is currently
up for discussion, but we'll keep an eye on this one.
Before we leave the world of graphics, and with the crazy high prices of GPUs right now,
we wanted to pass along a neat little tool that might help you get a lot more out of
your existing NVIDIA cards.
It's called VGPU Unlock, and what does it unlock?
Well VGPUs, or virtual GPUs, which normally are only supported on a few Tesla cards, but
if you happen to have the right GeForce or Quadro card that shares the same underlying
physical chip as the Tesla, it turns out that's just a software limitation, and now there's
software that tries to fix this.
And really, it's a fascinating deep dive into how NVIDIA pulled this off, and how these
intrepid hackers worked around NVIDIA's handcuffs.
If you'd like to learn more and get the technical nitty gritty details, we'll have a link in
the show notes.
Thanks
20 gigs a month there's a perfect ting plan for you and every ting plan gets
access to tings award-winning customer service with nationwide multiple LTE and
5g networks for you to choose from and the freedom of no contracts ever and
with these three great networks you can choose from you pick the one that has
the best coverage in your area but it also means likely the phone you got
today will work with ting if you like your phone bring it ting will give you
$25 in service credit when you go to linux.ting.com check your current phone
create an account and pick the plan that's right for you they got a wizard
that guides you through all of it and then boom ting sends you a SIM card you
pop that in your device and you're rocking on ting in minutes you'd be
amazed how much you can just manage through tings dashboard and all through
their website and cutting your phone bill has never been easier with ting
mobile's brand new plans get it all at linux.ting.com back in January we told
you about the challenges the KDE community was facing with the release of
Qt 6 but if you don't recall the important detail is that Qt projects
licensing model means long-term supported releases and updates to those
well those go commercial only once there's a new development release out
that meant Qt 5 support in particular went proprietary and behind a paywall
when Qt 6 was released now you might think what's the problem here just jump
ship and start using Qt 6 but unfortunately Qt 6 is still a work in
progress in missing some essential features which makes any porting efforts
kind of difficult and that is why most if not all KDE applications are still
using Qt 5 that's why back in January we did hear that news we went well how is
this going to impact all of KDE and in particular my beloved plasma desktop how
are they gonna manage this because clearly they still need time before
plasma desktop and all of the other KDE projects and lots of Qt applications
are ready for Qt 6 there's still work they need to do with Qt 5 but as time
goes on with Qt 5 there's gonna be security fixes that need to be patched
in or just general bugs that have to be fixed and the Qt company will not be
releasing those so what were they going to do that was really the big question
we were left with and now we have an answer because this week the KDE project
announced their Qt 5 patch collection quote as Qt 5 support is drawing to a
close and we shift to Qt 6 we need to ensure that KDE products are as reliable
as ever to this end KDE will be maintaining a set of patches with
security and functional fixes so that we can enjoy good KDE software still based
on Qt 5 until our software is reliably based on Qt 6 it's good to see the KDE
project do this because it kind of is smoothing out the nuances if you will of
Qt licensing in a way that doesn't really impact the wider community I
think they're I think they're going out of their way to be intentional about
calling this a a patch collection don't call it a fork it's not a fork of Qt 5
it's a it's a gentle collection of patches that will just maintain alongside
of Qt 5 and that's that's a smart way to go about it because it kind of keeps
this on the DL it's not this bold statement that we're going our own way
it's just this simple humble we're gonna have our own nice little collection I
mean it's a complicated relationship to manage here right KDE and plasma they're
big users of the Qt framework and that is a relationship they have to keep
managing they want to keep benefiting from the open source but here they're
also kind of stepping up because you know many open source developers
themselves including they can't afford to pay that paywall there's no budget
for that they got to do something and here's the band-aid before we go a quick
update on that adorable Linux powered helicopter on Mars named ingenuity we
were expecting a possible test flight today as we record followed by about a
13-hour delay in finding out the results of that test flight unfortunately
however NASA has chosen to reschedule the ingenuity Mars helicopters first
experimental flight to no earlier than April 14th that's because during a
high-speed spin test on the rotors on Friday the command sequence controlling
the test ended early due to a watchdog timer expiration you know these things
go wrong it's experimental that's true I mean that's what they're trying to
catch right now yeah this occurred just as they were transitioning from the
flight computer to the pre-flight flight mode and so there's this watchdog timer
that oversees the command sequence and then alerts the system to any potential
issues it detects yeah really it just helps the system stay safe by not
proceeding if an issue is observed and working as planned and you need those
kinds of fail-safe when you're a million miles from home right now the helicopter
team is reviewing the telemetry they've got to see if they can diagnose and
understand what went wrong following that we'll get a rescheduled full-speed
test yep nobody ever said space travel was easy but we'll be keeping an eye on
that story because we're nerds and love the idea of a Linux powered helicopter
flying on the surface of Mars so be sure to get every episode because you don't
want to miss that go to Linux action news comm slash subscribe for all the
ways to get new episodes like what we're doing or want to let us know about a
Linux news story we missed hey just head on over to Linux action news comm slash
contact for ways to get in touch and don't miss your celebratory 400 beer
Stein for Linux unplugged we have a special beer mug at la plug dot beer for
a limited time we'll be back next Monday beers in hand with our weekly take on
the latest Linux and open source news thanks for joining us and we will see
you next week
