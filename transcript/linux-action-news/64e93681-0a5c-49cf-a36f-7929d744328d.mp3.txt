Hello, and welcome to Linux Action News, episode 173 recorded on January 24th, 2021.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
It's a new year, and with it come new Red Hat Enterprise Linux programs.
If you recall, last year, on December 8th, Red Hat announced a major shift in how CentOS
is delivered, from trailing rail development to leading it.
Not yet public, but in the works at the time, was an expansion to their developer program
that makes current versions of Red Hat Enterprise Linux free to use in production on up to 16
hosts.
Yeah, this week, Red Hat announced they are expanding their existing developer program
so that individual developer subscriptions for RHEL can be used in production for up
to 16 systems.
You will need to sign in to the RHEL account system, and you will have to download it from
there and, of course, have your system plugged into that to receive updates.
But Red Hat promises this isn't a sales program, and they say that no sales representative
will follow up.
An option will exist, though, within the subscription to easily upgrade to full support, but that's
all up to you.
It seems kind of odd that they're wrapping this up into their developer program.
I don't really know of other vendors that wrap developer accounts into production licenses.
I think just that alone might cause large-scale, serious companies to kind of look at this
and stay away, maybe stay a little skeptical.
And the elephant in the room here that everybody thought of when they read this, which seemed
obvious on its face, is that they should have announced this when they announced the change
to how they're producing CentOS.
Leading that story with RHEL going free to more people and expanding how you can get
access to RHEL would have obviously softened the blow about the change to CentOS's support
cycle and switching focus to Stream.
Instead, this ends up feeling reactionary and really too little too late.
And what's worse is we know, based on Red Hat's phrasing, but also to multiple people
we've talked inside Red Hat to, we know that these plans to make RHEL available to more
people for free were in the works before the CentOS changes were made public.
But now in the shadow of what feels like just having the deal changed on us, they're announcing
a new deal and it leads one to suspect that the deal could just change again.
It feels like you're on borrowed time, a fact which they kind of addressed with some statements,
but not really simply saying, we're going to try to keep it as long as possible.
We're making it sustainable.
It feels like they're asking us to trust them again after they've just broken the trust.
And it really doesn't seem like 16 hosts is enough.
Yeah, I'm not quite sure what environments this makes sense for.
I mean, I can imagine some small businesses maybe, but in that case, I'm not sure what
exact benefit they're getting using RHEL.
I mean, RHEL's not bad and it can work quite nicely, but the old version of CentOS could,
Stream probably could, or Rocky Linux could, or even Ubuntu LTS.
Because let's be honest, so you and I before the show, I was talking about an old client
of mine.
It's a doctor with three nurses and an occasional doctor that comes in and works out of the
other office.
They need one server.
And the Ubuntu support model is perfect for them because they can deploy Ubuntu LTS, which
is the industry standard for long-term support versions of Ubuntu.
And if there is a day in which they needed support, it sort of has this on-demand support
structure where you can go from no contract to contract.
And that appeals to them because they can defer, defer, defer until the day they need
it.
With RHEL, you're going to have to kind of maintain a relationship.
You're going to need to sign in.
You're going to need to keep the system plugged into the RHEL dashboard.
You're going to have to make sure that when they discontinue support for this version,
you upgrade because there'll be no extended support for developers.
And you're also going to have to be willing to consider yourself a developer to even get
access to this for this one small business.
You have to pretend like you're a developer now.
Yeah, that's kind of the weird part.
I mean, it certainly makes sense in general.
I like the program.
I like also that they're including, if you are paying for RHEL, you now get more developer
licenses on top of that for free.
But these are all things that made more sense in the reverse order.
You just can't unsee that once you're aware of it because in some sense, the whole latest
CentOS development feels that way where CentOS Stream, yeah, makes sense.
We should have a place where RHEL is developed, having more access for developers, people
who want to learn RHEL, who want to start playing it, set up a nice home ladder or maybe
a small business where the admin admins a lot of RHEL and it just makes sense for them
to do so.
That's all great.
But if CentOS had just remained, if it had never been acquired, it's almost like we've
had to go through all of this drama and just confusion to get back to a slightly improved
version of what we had before.
Yeah.
I mean, at least these CentOS alternatives are truly community ran.
So I think over time as they produce and as long as they produce consistently, they'll
gain a level of trust that maybe a corporation just can't get anymore.
But I think what they're missing here is this developer program is missing out on a huge
use case for CentOS and that's large volume deployments where the infrastructure is not
the primary revenue generator, but a tool to generate revenue.
Think of a web host, a VPS at scale.
When you look at the web stats, which are available to us, 19% of web servers currently
run CentOS.
Think about that for a second.
It's only second to Ubuntu.
If Red Hat has no solution for these large deployment customers that put them in the
sales funnel, well, Rocky Linux or someone else will.
That's the key thing here is CentOS, instead of being used as a sales funnel strategy to
move people into RHEL or other Red Hat products, or here's a crazy idea, sell one-off support
packages for CentOS like Ubuntu does.
I know wild, right?
Instead of doing something like that that would have funneled customers into the Red
Hat sales department, what they're doing now is they're just not addressing a large portion
of the CentOS user base.
When you look at how many web servers run CentOS, it's clear that there's a lot of large
scale deployments and they're going to look at the 16 host limitation and say, all right,
well, we're not even going to consider that.
I can't help but think to an old employer of mine who all the application VMs were running
Ubuntu, but the actual virtualization hosts were all on CentOS.
That might be a place where Stream doesn't fit or they might not have been comfortable
with that, but it was also an environment where the business was not... They were never
going to pay for RHEL.
You were never going to convince people upstairs that that was worth it.
I don't know what they've done.
I've not spoken to them, but I've got to imagine it's Ubuntu LTS now.
Well, I mean, yeah.
If you want something that is still supported for five years that doesn't... They're never
also going to get away from that rolling concept, even though it's just as rolling probably
as Ubuntu LTS is.
Yeah, it has minor updates inside a major release update.
If we consider that rolling all of a sudden, then we've just changed the definition of
rolling, but that branding will not ever be removed from CentOS Stream.
Rocky Linux will come in with its, quote unquote, bug for bug compatibility as this built from
RHEL source RPMs alternative that's maintained by a nonprofit backed community.
It is so perfectly addressing the need that CentOS filled, and oh, by the way, they're
working on a tool to convert CentOS installs to Rocky Linux.
It seems clear to me that Rocky will fill that position just fine for a lot of people,
or something like Rocky, like the Cloud Linux solution.
Yeah, absolutely.
And you know what, Wes?
Maybe that's just fine.
People have their community backed enterprise distribution that they can use at scale and
that they trust, and RHEL's development, like you were saying, moves out into the open.
And what seems clear to me is those involved with CentOS's development felt some sort of
change needed to happen.
There's always been some kind of inherent conflict of interest between RHEL sales and
CentOS.
You know, why are you selling this super expensive thing over here and essentially giving it
away over here?
It obviously wasn't sustainable.
And when you weigh the contributions that Red Hat has made to the Linux community, calling
it invaluable isn't doing it justice.
It's been fundamental to the success of Linux in so many ways.
What Red Hat has done has been fundamental.
So if this change is what they felt needed to happen to make that contribution level
sustainable and resolve that conflict of interest, put CentOS in a way that's sustainable in
their development chart, you know, when they look at it now, they have CentOS leading RHEL
and Fedora at the base of all of it.
So if you're a fan of Fedora, if you're a fan of CentOS, this essentially enshrines
them in the development process of Red Hat Enterprise Linux and brings the development
of Red Hat Enterprise Linux out into the open and makes the whole kit and caboodle, the
whole package dependent on Fedora's future development.
So in a lot of ways, it does a lot of good things and the community is stepping up to
offer a solution and I feel confident that the Cloud Linux solution and Rocky Linux will
be shipping well before the end of life date for standard CentOS.
We have until the end of this year and these projects are on track and I suspect Stream
will remain a great distribution for a lot of people and then Rocky and others will fill
that gap.
The only loser we're really going to have in all of this besides the sysadmins who have
to burn their time worrying about this is the Red Hat sales department because they're
going to lose a huge part of their sales funnel, but at the same time, they've at least resolved
this internal conflict.
Yeah, I think you're right to say that there is a conflict there.
Clearly, there were two minds within Red Hat that wasn't sitting comfortably.
So if this is what it took to get to a new steady state for a while, I think you're right
to point out that Red Hat's doing a lot of great stuff.
That investment is not going anywhere.
Neither are the source tarballs that they continue to publish that fuel the efforts
of things like Rocky Linux.
So if we've just got a new structure, a new organization, in some ways, maybe we'll look
back on this as just the nature and sort of the power of open source development.
Yeah, and maybe even, this is a little bold, but maybe even a necessary change.
From the server to the desktop, in a development status update for Ubuntu 21.04, the team has
revealed that they'll be skipping the next GNOME release and sticking instead with 3.38.
What's old is new again, Wes.
I'm having a bit of deja vu here.
When Ubuntu announced it was switching back to GNOME from Unity in April of 2017, we pondered
how long it would take until this might happen.
And as we thought then, just like it kind of looks like now, it would take a confluence
of perfectly reasonable reasons, which is exactly what's happened here.
The Ubuntu team has reasoned that the new shell might not be fully ready in the next
release.
It's a big undertaking, probably going to take some time to work that out.
They are unsure what the impact will be on their custom desktop and extensions.
They can't guarantee what that experience will be like, and because we're already well
into the development cycle, it's a moving target.
And they suspect there's likely going to be some design questions they have to resolve,
and what they consider non-trivial code changes to make things work with GNOME 40.
And of course that other big-ticket item, GTK4.
As Ubuntu desktop developer Sebastien Bachur pointed out, Debian will have it packaged
in time, at least it seems, but the team feels GTK4 stability is just unknown right now.
And the team suspects it will take a couple of GNOME release cycles to fully transition.
Yeah, and that's just the reality right now.
They are for themselves mid-release cycle on the Ubuntu release.
So it's a big load, and they have the time now to just smooth that out over the next
couple of Ubuntu releases.
Instead of eating it all now and then having things potentially change on them, they can
release, let another development cycle of GNOME land, and they can work it into a future
Ubuntu, and they still have time before the LTS lands.
Yeah, you know, it does make me think this is sensible, because Ubuntu is, you know,
it's more than just the GNOME desktop.
It's the Ubuntu desktop.
They've got their own feel, they've all got their own fit and finish there, and it's primarily,
you know, used by a lot of folks as a workstation to get work done.
You don't really want that changing and breaking all the time, so it makes sense to be careful
if we're going to have anything close to what you get on like the Apple side of the house.
It's nice to see some thought going in and not just, well, they updated, should we?
I joked about deja vu though, and I have to say, it kind of reminds me of the bad old
days where Ubuntu would be shipping an older version of GTK or GNOME, and it would make
life a little bit more frustrating for those of us that wanted to install and use the latest
stuff.
And it kind of reminded me of a time where it felt like Ubuntu on the desktop was behind
a little bit.
You know, I can't help but reconnect with some of those old feelings, even though the
situation is totally different.
Like, this is a pretty big design change, and if anything, distributions like Ubuntu
and a few others are kind of there to insulate their users, and they absorb some of that
upstream and smooth it out before it hits their users.
It's exactly the role they should be playing, and yet I can't help but feel this slight
tinge of disappointment.
Yeah, I think maybe you should have always expected or not gotten unused to this, I guess
I'm saying.
I have memories of the same, and it was kind of like, yeah, all right, this isn't exciting,
especially when you are like us and are sort of clued in and are following updates and
all the exciting developments happening and improvements in these desktops.
But hey, that's what you have Arch for, or really, that's what you have Fedora for.
Yeah, and if anything, this just makes it in a way more fun to try the different distributions,
because for a bit here, they'll be more differentiated than ever.
You do wonder how this impacts the downstream Ubuntu derivatives that don't necessarily
have the same opinion or perhaps ship their own desktop environment and would like GTK4,
but my gut tells me probably most of the downstream derivatives are kind of grateful for a little
bit of stability for a bit before the transition to GTK4, because if everybody can get up to
the most current GTK, if they can use this release cycle to get current on a lot of things,
it'll make the transition to 4 easier.
And so I have to think this gives the derivatives a little bit of a chance to take a breath
of air and get some work done.
But I acknowledge that it's essentially a choice being made out of their control.
It's kind of like the deal.
Like if you're going to ride on Ubuntu's coattails, this is sometimes the deal you get.
And it does sound like there'll be Debian packages available.
So perhaps there's a route of escape there for distros that really want the latest GNOME.
It also makes me think maybe you just need the GNOME version of Neon.
You mean GNOME OS, Wes?
I think I do.
linode.com slash LAN.
Go there to get a $100 60-day credit and support the show.
A big thank you to Linode for supporting this here program.
They're our cloud hosting provider.
I chose Linode about two years ago, and I've been using them every day since, and I've
just really expanded on that.
I've grown to trust them and deploy all of our backend services on Linode.
And with that $100 credit, you can really get started.
I mean, they have systems that are as cheap as $5 a month, but why not play around in
their configurator and really build yourself something neat?
Deploy a game server in seconds with a lot of the settings pre-configured in the deployments
just right there in the screen.
You set the options you want and hit go.
And what I really love about Linode is their passion for Linux.
That's what got them into this game back in 2003.
They've been doing this basically since cloud computing was a thing.
They started three years before AWS, and yet they're still crushing them on the price.
And unlike some of the entry-level hosting services that lock you into their platform,
Linode gives you full backend access to customize and control your servers to fit your need.
And that has come in handy for me several times.
Love it.
So go to linode.com slash land, get that $100 60-day credit, and see what I've been talking
about.
They're independently owned, and they're founded on a love for Linux, and that has influenced
so many of their decisions over the years.
And now they're dedicated to offering the best way to virtualize anything you need for
a cloud computer.
Maybe it's a website, a personal site, or maybe it's the backend infrastructure for
your business.
That $100 credit will give you an idea of what it's capable of.
Go over their documentation and try out their fantastic human-powered support.
You can do a lot with that $100 60-day credit, so go to linode.com slash land.
That's linode.com slash land, and a big thank you to Linode for sponsoring Linux Action
News.
On a blog post titled Doubling Down on Open Part 2, posted January 14th, Elastic announced
changes to the license for Elasticsearch and Kibana, changing from the Apache 2.0 license
to the server-side public license and the Elastic license.
If you're not familiar, Elasticsearch is a distributed, multi-tenant-capable, full-text
search engine with a powerful HTTP-based REST API and the ability to ingest schema-free
JSON documents, which, especially when paired with its sister project Kibana, an open-source
data visualization dashboard, it provides a flexible data storage and analysis platform
that has seen wide-scale deployment across a huge number of industries.
And this is really what we're seeing here is a bigger meta-story that's been going on
for a few years, and this show has been covering it.
Open-source projects that become massively successful, they create, in some ways, industries,
they have to start tweaking their license in reaction to AWS hoovering up their customers
and monetizing their work.
You know, it's an interesting sort of tack-on problem to the fact that AWS just dominates
hosting these days, right?
I've often sort of wondered, and we've taken advantage of some services, things like Nextcloud,
maybe Hosted Matrix, or Home Assistant comes to mind in this case, where you just, you
have an open-source project you love, you want to use it and leverage it, but you don't
want to manage the server side, so you're happy to pay someone to do that for you.
But in the AWS case, well, they're already the default, so when they also offer everything,
of course that's where businesses are going to go, and that just means it's harder if
you're going to try to sell it on your own on the side.
Yeah, if you're an all-in AWS organization and you need to deploy something like Elastic
Search, it's just a no-brainer to go with the one that AWS offers.
I mean, you don't have to go set up a whole separate relationship and sign contracts and
I mean, maybe you don't have to do all of those things, but it's a whole separate thing
when you've already got an Oedipus account.
Everyone in the organization is familiar, and you just click another button.
And this week, AWS announced they're forking Elastic Search.
AWS says Elastic Search is no longer open-source software.
As they put it, they are now, quote, stepping up to provide a truly open-source Elastic
Search alternative.
And Amazon also let us know that they're always prepared for open-source projects to get angry
with them.
Adding in their post, when AWS decides to offer a service based on an open-source project,
we ensure that we are equipped and prepared to maintain it ourselves if necessary.
Their forks of Elastic Search and Kibana will be based on the latest Apache version two
licensed code bases, version 7.10, and they plan to publish new GitHub repositories in
the next few weeks.
The AWS team also pushed back on being the villain in this story.
Quote, Elastic knows what they're doing is fishy.
The community has told them this.
It's also why they felt the need to write an additional blustery blog on top of their
initial license change blog to try to explain their actions as AWS made us do it.
Most folks aren't fooled.
We didn't make them do anything.
They believe that restricting their license will lock others out of offering managed Elastic
Search services, which will let Elastic build a bigger business.
Elastic has a right to change their license, but they should also step up and own their
decision.
It's interesting how much the step up language is being used here and how bluntly AWS is
just coming at this as this has evolved over the years where they've kind of been caught
off guard.
Now they're just coming out with all guns blazing, essentially saying we're prepared
for open-source projects to flake on us.
We're stepping up to provide something that's truly free.
And they try to play like this underdog who is compensating for cranky open-source projects.
And I'm just, I don't buy that image.
It seems so obviously self-motivated.
Oh yes, absolutely.
Now I will say Amazon has been doing better in the open-source community the last few
years.
You know, they have, I think in a real sense stepped up at least in some areas.
Now that changes a lot depending on which area we're talking about.
And there's some spicy language and feelings on both sides here.
And I can certainly sympathize with Elastic, the folks who have done a lot of stuff out
in the open-source world, tried to build at least open-source based or open-core for a
while type of product, which generally the community tends to like and found themselves
struggling to make a sustainable business because of the elephant in the room of everyone's
just running it on Amazon.
But at the same time, it's hard to argue that this license change, I mean, the OSI isn't
fond of this license, right?
So there is a sense that the community, rightly so, feels you're changing the essence of what
this is.
The deal has been changed a little bit.
That is where Amazon is 100% right.
And from their perspective, they are just now executing on what they're legally allowed
to do with anything that's Apache licensed.
And in this post, they cite the many several occasions where they submitted code upstream.
So it's not like they weren't contributing here.
They were actually contributing upstream to the project.
And I guess that'd be my comment to kind of underscore what you said is we have seen AWS
do more of that investing in engineers and investing essentially in the output of code
that goes back upstream to these projects.
And I feel like as this story, this meta story has evolved over the last few years, that's
an area where Amazon has actually quote unquote stepped up.
It is interesting to consider some of these new anti-AWS based licenses because at least
for the stuff we're doing at JB or personal use, it wouldn't necessarily affect me.
I'm not worried about being sued by Elastic over it and we're not selling a managed service
or anything like it of the essential parts of Elasticsearch.
But there's a new license with new verbiage and not a bunch of court cases to let you
know how that's going to be interpreted.
So I can certainly see why this would create a lot of uncertainty for other businesses
who are selling some kind of service.
Maybe it's not just a new face on Elasticsearch or Cubana, but it's heavily used.
How integral is that?
Where do you draw the line?
Elastic has published some additional blog posts and updates to FAQ pages and the like
to try to clarify that because it's clearly upsetting some people.
But if you had an open source, a quote unquote proper open source version, wouldn't you just
use that?
Xencrypt, who now provides TLS certificates to more than 235 million websites, has announced
a successful database upgrade.
And as you might expect at their scale, a database upgrade is anything but trivial.
Their certificate authority software, Boulder, uses MySQL style schemas and queries to manage
subscriber accounts and the entire certificate issuance process.
It's designed to work with a single MySQL or MariaDB or Percona database at the backend.
They currently use MariaDB with the InaboutDB database engine.
To hear them say it, running a certificate authority against a single database is done
just to minimize complexity.
Keep things simple, only a few places where it can go wrong because, well, you really
don't want to get this process wrong.
Yeah, it keeps, as they put it, the maintenance burden low.
But obviously one consequence of this design is that their database machines need to be
pretty powerful.
I mean, they acknowledge that eventually they may need to shard or break up the single database
into multiple databases.
But so far, they claim hardware advances have allowed them to just avoid doing that.
Their old hardware before the upgrade was a dual socket Xeon E5 2650 box with a total
of 48 threads and a terabyte of RAM and 24 3.8 terabyte Samsung SATA SSDs.
Now they have some new stuff.
Oh, yeah.
The new hardware is based on two AMD EPYC 7542s with a total of 64 cores, 128 threads,
and now two terabytes of RAM with 24 6.4 terabyte Intel NVMe SSDs along for the ride.
Yeah, now that's a big deal.
See, going with those EPYC CPUs provides a hundred and twenty eight PCI lanes, which
enables them to put in 24 NVMe drives in one single machine.
If you want to geek out more on these server performance charts and details, it's really
worth visiting their post, which we'll have linked in the show notes.
They clearly show a big performance improvement for Let's Encrypt with Headroom for Growth,
which is great.
And they also talk a bit about their adoption of OpenCFS and how they optimized it for NVMe
drives.
All of it is fascinating.
Datadog.com slash Linux Action News.
Datadog is end-to-end application monitoring.
They're the unified monitoring and analytics platform.
I mean, really for complete visibility into the performance of your applications, you
need telemetry data, traces, metrics, and logs that describe the activity across your
entire stack.
But if you're using multiple monitoring tools, your data can end up in silos, making it difficult
to troubleshoot issues that affect the user experience.
Datadog lets you quickly analyze the performance of your Linux servers in real time with customizable
dashboards that troubleshoot Linux issues in seconds with a unified view of your metrics,
your traces, and your logs all in one place.
And with the Datadog clipboard, you can streamline the performance, so check out investigation
outages by capturing relevant views of your infrastructure and applications all in one
place.
In one shot time, get the big picture.
And they have turnkey integrations for over 400 technologies to just get going.
You can even use Datadog to monitor the key metrics of a Linux box right alongside proprietary
and open source applications, the entire stack.
So start your Datadog trial today by visiting datadog.com slash Linux Action News.
You start your free trial, create one dashboard, and you can get a free Datadog t-shirt.
So that's datadog.com slash Linux Action News.
Create a dashboard, get some free swag, and unify your monitoring.
A big thank you to Datadog for sponsoring this here episode of Linux Action News.
And a big thank you to everybody for visiting datadog.com slash Linux Action News.
Developers at ARM virtualization company Corellium have managed to get Ubuntu 2004
up and running on the new Apple Silicon Mac Mini.
This certainly got a lot of attention when the developers started tweeting pictures of
the Raspberry Pi version of Ubuntu desktop running on an M1.
The networking was made possible using a dongle.
And as you might expect, the GPU work here, well, is minimal.
It's essentially just a frame buffer.
It's no acceleration.
So that's still a sticking point.
Corellium has worked on getting Linux working on the A14 chip that can be found in some
iPads, I believe.
So they had a bunch of code that was pretty much baked for the A14.
So it wasn't a big transition to get it up and running on the M1.
The only kind of negative thing about it is they've just kind of been sitting on this
code for this entire time.
And then they kind of have one developer who's now putting it up on GitHub.
And it seems kind of like it's more of a product that they have that they're utilizing now
to make a big splash.
And I say that because in background, in a conversation I was having with Hector Martin,
he had talked to me about how one of the ways they may strategically try to raise awareness
for their project is by doing exactly what Corellium just did.
He kind of even laid out that the way you go through it, the way you take the pictures
up on Twitter and post them, like he had the whole thing as a way to raise awareness for
the project.
A marketing media strategy.
And of course, we're talking about Asahi Linux project.
He launched to try to do this, so there's a little bit of maybe some thunder being stolen
here.
It at least felt a little dicey on Twitter for a few moments.
It's probably not going to help them raise funds.
It's not going to get them any more patrons for a bit.
I mean, not that it's going to steal from them, but what it kind of came across as is
Corellium was like, hey, look at us.
It actually even tweeted this.
We had a free day, so we got it up and running on the M1.
But they really haven't interfaced directly with the kernel community as far as we can
tell yet.
And we don't really know if they have any actual plan on following through with being
a normal contributing member of the kernel community, or if this is just sort of a code
dump.
We'll see.
I mean, at the moment, it's just one guy doing the work to take all of this upstream and
try to clean it up.
And at the end of the day, the Ashi Linux project can't really touch this unless it's
legally safe.
And so it's sort of like one of these situations where, okay, good job.
You got it working.
Now upstream it.
And if it passes those tests, then we can really use it.
In the meantime, this is actually a bit of a marketing stunt.
Unless you want to get a Mac that has no graphics acceleration that requires dongles for basic
functionality.
I mean, that's kind of what a Mac is already.
But really, who buys a really expensive M1 Mac to have very poor functionality?
And I think what Corelium is doing is they're kind of capitalizing on people not understanding
the nuances of what it takes to get this system up and running to get attention for their
commercial products.
Yeah, it is hard to downplay that aspect.
I think Hector Martin and Asahi Linux had been trying to take things definitely slower,
step by step, trying to do things right, making sure things could be upstream.
But also, I think have done a surprisingly good job of setting expectations from the
beginning.
Whereas you're right, these kinds of announcements, flashy announcements for Corelium, despite
some impressive work, I mean, their blog post about how they did it and some of the technical
details is definitely interesting and it's some hard and impressive work.
But yeah, no one's going to, this is not usable by any stretch of the means.
You've got a proof of concept working and that's what you should have said.
Yeah, and they say they're aiming to upstream as much of the work as possible.
That's going to be what matters long term.
You know, I have seen a few mailing lists posts go by, it does look like there's some
healthy discussions.
I haven't seen, you know, nothing's been merged, of course, far too early for that.
But I see Hector Martin's name in there providing some good feedback to you.
So hopefully the end result here is that patches fly, conversation happens and eventually good
code gets merged.
On the GPU front, it is worth mentioning that the developer we've covered in the past who's
working with the Yashii Linux project has put another update on their blog and it appears
that progress is happening.
They've actually been able to draw a triangle using the GPU on the screen.
Well, while that is a minor in the grand scheme of things, it's a very important first step.
They're drawing triangles now on the M1 GPU.
And the debate continues if this time is a good investment or not.
But I kind of feel like that's a side debate because it's clearly happening regardless.
Yeah, I'm not these people's manager.
I don't get to tell them how to spend their time.
So all I can do is sit here and wait and hope.
Well talking about ARM devices, the Raspberry Pi Foundation has a real tiny announcement.
It's a Pico.
It's a little Raspberry Pi Pico board for four dollars.
It has a custom dual core ARM processor running at a hundred and thirty three megahertz, two
hundred and sixty four kilobytes of RAM and twenty six GPIO ports, which include three
analog inputs, a micro USB port and a temperature sensor.
It doesn't come with Wi-Fi or Bluetooth, though.
But I mean, again, it's four dollars if you want to run something on that shiny new Raspberry
Pi Pico.
It's actually quite easy.
You plug your device in your computer using the micro USB port, then you boot up the Pi
Pico while holding down a button and the device will just appear on your computer as an external
drive, copy over your programs and away you go.
Now something I noticed that is really pretty neat is that in addition to C, you can use
Micro Python as your development language.
It's a Python inspired language for microcontrollers.
And I don't know about you, Chris, but my C++ is a little rusty.
And as I know you love to see, Wes, they have tons of good documentation, a data sheet and
a lot more.
We'll have links in the show notes at LinuxActionNews.com slash 173.
And while you're over there, check out the subscribe page for all the ways to get new
episodes.
And of course, the contact page for ways to get in touch.
And pro tip, check out Linux Unplug 390 for an in the trenches discussion of Elasticsearch.
As for us, though, we'll be back next Monday with our weekly take on the latest Linux and
open source news.
Thanks for joining us and we will see you next week.
