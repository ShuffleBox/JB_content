Hello and welcome to Linux Action News, episode 171 recorded on January 10th, 2021.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
And let's start with a story we previously covered on Linux Action News 143, which is
that LTS versions of Qt aren't going closed source.
Now, it's actually finally happening.
As you might expect, this has gotten a lot of upset in the community, even though we
did know this was coming.
It's kind of important.
Qt has become really important.
I mean, not only is it the basis for the Plasma desktop, but in general, it's an application
framework that's available under an open source and a commercial license.
And it was around a year ago that the Qt company stated its plan to make the LTS releases commercial
only, along with some other changes designed to encourage open source users to contribute
or or buy a license.
Yeah, we learned more about this in a mailing list post from a senior VP over at the Qt
company who wrote that with Qt 6 released and the first patch release coming soon, it's
time to enter the commercial only LTS phase for Qt 5.15 LTS.
All the existing branches remain publicly visible, but they will be closed for new commits.
Now, closing happened on the 5th of January, and they've actually set up a separate internal
repository for any cherry picks and changes that need to go in.
But you'll need a commercial license to get to that.
So in addition to getting the full releases of these additional like 5.15.3 upcoming LTS
patch release, you can also go get individual commits if you need to and if you've paid.
Now, the source code to Qt 5.15 is out there.
It came out in May of 2020.
It remains available for developers to use, but the Qt company themselves won't be making
future additions available for free.
That doesn't mean that open source maintainers can't fix a bug or a security issue that comes
along.
But it does mean until they adopt Qt 6, we essentially have double the work for fixing
bugs.
And I think the core issue here is that essentially Qt 6 doesn't support many of the add on modules
that can be found in 5.15.
There's a lot of cleanup work and refactoring that's still intended to be done for Qt 6
as well.
So it's not really in a state where developers are going to want to adopt it, especially
for something like Plasma.
And much like when Qt 5 came along, it wasn't until like 5.2 or 5.3 that the Plasma desktop
actually started adopting it.
You'll probably see the same thing here.
It's going to take Qt 6.2 or 6.3 before developers are really comfortable maintaining it.
And that means in the meantime, Wes, unless I'm misunderstanding something here, they're
essentially just running on unsupported quote unquote version of Qt.
Well they have to support it themselves at least.
Right.
That's that's the choice is while you're working on getting to the next major release, which
has perhaps some breaking changes, just some new updates, some missing stuff you've got
to provide filler for, you also have to decide, well, am I just not touching anything that
I'm currently running on?
Or are there bugs that need to be fixed?
And if so, that's additional time taken away from development to catch up with the new
major release.
So you've got to wonder, maybe this time around, it'll take even a little longer.
Yeah, so it's not an ideal situation for developers.
For end users, I don't think it's going to really impact you much.
The desktop environment and application developers are going to pretty much insulate you from
this transition.
And one nice thing is Qt 5.15 does a lot of the early work to get your application or
whatever it might be ready for Qt 6.
So if in the meantime, developers spend that time just getting up to Qt 5.15, which is
the current last five series, if they just get in to just decent shape with 5.15, they're
going to be in a really good position to transition to Qt 6 when the community does decide to
make that transition because that early legwork will have been done.
This is all definitely new.
You can tell that in some of the tones on the mailing list and just in the fact that
there are so many unknowns.
Now I'm sure we'll be reporting on this again in future Qt releases.
Switching over to the GNOME and GTK side of the Linux desktop, there's been a lot of feedback
and criticism about changes coming in GNOME Shell 40.
Alan Day has authored a blog post that we will have a link to in the show notes that
addresses a lot of the comments, a lot of the concerns, and shows the latest development
snapshot of what they're working on.
And it's probably worth visiting the show notes for this link if you're interested because
there's a video in bed.
And I think he's really trying to address all of the criticism and kind of explain the
rationale as best he can.
And I think he won me over.
Reading through this, Wes, I feel like the GNOME team is listening and is even kind of
changing what they had planned a little bit to address some of the feedback.
Yeah, I mean, to quote Alan, a good portion of the comments that we've had about the design
reflect concerns about existing workflows being disrupted.
We understand these concerns, and an effort has been made to limit the scale and disruptiveness
of the updated design.
And as a result, the changes that are being introduced are actually quite limited.
Everything about the shell remains the same, except for the overview.
Right.
And he also touches on that they're improving the touchpad gestures, so if you have a laptop
with a touchpad, you'll be able to navigate the GNOME Shell better.
The personalized app grid that's coming, the fact that app icons will be in the window
overview, and they've improved the app titles just in general in GNOME 40, which will show
the full title now when you're hovering over its launcher.
You bring all these improvements together, and I really like what he's talking about.
But here's the fundamental difference between GNOME and Plasma.
If this was a Plasma change, they'd take this feedback in and they'd say, all right, we're
just going to leave both options available.
We're going to default to this new behavior.
But if you already have it set the old way, or you want to set it that way, that's just
fine with us.
And honestly, I think I prefer that.
It is nicer from a user experience perspective.
I get that, right?
You don't have to change.
You don't have to keep up with it.
But on the other side, it can be a major pain, and we also all love to complain when things
go wrong, when things crash, or just when the new features we really do want are delayed
in development, and keeping things nice and trim and, you know, focusing on one way of
doing it.
And that certainly simplifies.
Yeah, I definitely understand.
And it's less like quality testing they have to do and whatnot, because there's different,
you know, there's less code pass, there's less ways for things to be displayed on the
screen.
And it's simpler overall.
I mean, I grok all of that.
But with open source software, I feel like in some cases, we don't always have to make
these dramatic all but all or nothing changes.
If we could rally the support for supporting both ways, and people are willing to contribute
their time, it would be nice if there was a facility or a way for the project to entertain
the idea.
It's not like corporate software development, where everything has to, you know, equal a
certain return on value.
And you can only have so many developers on a project, because otherwise, they're not
getting enough return on that.
And with open source, it's not that way at all.
You could have people that just want to keep something alive, or just want to have a certain
work.
I mean, that's why Mat√© exists in the first place, right?
And it just seems like we could have that flexibility, and it feels like maybe the plasma
project would be a little more willing to consider that.
But you do open yourselves up to who's going to maintain that, right?
And perhaps if internally, if in the regular contribution community, there were a push
for that, then perhaps you could have that argument.
Right now, Alan notes that, well, they're not planning on supporting keeping it around
the old design at all, mostly because of the work.
So perhaps if people stepped in to contribute that work, that could change.
But there could be community extensions, everyone's favorites.
They do say that they're happy to work with extension developers to help make this happen.
Maybe keep something like a vertical dash of your desktops on the side instead, or where
your icons are.
Those all seem like plausible options.
That's a pretty solid compromise.
If they're willing to be essentially even just non-hostile towards an extension developer,
reverting the behavior, if they don't take that as a slight or an insult to their design,
that's a pretty big win.
And that kind of facilitates what I said, somebody who has the passion could make that
extension and maintain it and problem solved.
I like that they're at least open with the idea.
Also, if you are a crazy user like me and you have a couple of vertical screens, it
appears that they're doing work to make sure all of this new stuff, the overview stuff,
works just fine on vertical displays as well.
I was happy to see that because people have given them a hard time for being so touched
focused.
But when you look at some of these design decisions, it actually seems like it's going
to make it work a lot better as a desktop show.
I think that might be a side benefit of keeping things simple, too, is it's clear here that
they're doing a lot of testing and thinking and exploring and all of that is time constrained.
Where we go from here, though, is they're going to develop this in a branch with the
new design, open it up to testing, have a quote unquote intensive period of bug fixing
and evaluation prior to any UI freeze, somewhere in about a month's time.
So more to come soon.
Linode dot com slash land, go there to get a one hundred dollar 60 day credit towards
a new account and go there to support the show.
Linode is our cloud hosting provider and just this weekend we spun up a brand new instance
and I think this one could have some real mileage.
At first we just wanted to test PeerTube 3.0.
New release came out.
We're going to talk about it in the show and we wanted to have some hands on experience.
Linode makes it so simple to do this kind of thing.
We had an Ubuntu LTS 2004 machine deployed in probably about three minutes and then you're
up and going with an SSH session pretty quick after that.
We deployed the software and within moments, really, from just from idea to execution,
we're done.
And when you start to use it, you start realizing this has some potential and Linode makes it
really easy for even a group like us who may have some traffic on an instance like this
to easily manage it.
They have node balancers to help with the traffic.
Additionally, Linode has object storage.
So we can use object storage with PeerTube to only use as much space as we need to host
the video files we currently have.
Instead of having to carve off like some big 40 gig or 80 gig or let's be honest, terabyte
volume storage and we just pay for it all the time, we can use object storage, which
is a great S3 compatible way to store your files online and of course Linode supports
that.
Linode.com slash LAN.
That gives you the $100 60 day credit and then you can really cook with some gas because
like a basic rig is like five bucks a month and they go all the way up from there to multiple
GPUs and dedicated CPUs.
But every machine has super fast SSDs.
They have 11 data centers around the world.
We chose to deploy in Dallas, so it's a nice central location in the US for our PeerTube
instance.
And I trust Linode because they're the largest independently owned cloud provider.
They started in 2003 as one of the first companies in cloud computing, three years before AWS
and other enterprise providers.
And I love them because they've supported the Linux ecosystem for a long time.
Events, projects and even these here humble podcasts, they're dedicated to offering the
best virtualized cloud computing.
If it runs on Linux, it runs on Linode.
So thanks to Linode for running all of the Jupiter broadcasting workload, our new backend
infrastructure and for hooking our audience up with a $100 60 day credit when they go
to Linode.com slash LAN.
Well, that didn't take long.
Early work is already underway on reverse engineering the Apple M1 GPU.
Alyssa Rosenzweig, who is known for her work on reverse engineering ARM GPUs, and in particular
her work working on Panfrost, the open source driver stack for some Mali GPUs, well, she's
recently taken an interest in Apple's latest graphics chip.
This work is really being focused around the Ashi Linux project, which is Hector Martin
and his team's effort to create a distribution for the Linux that supports the M1 out of
the box.
But ultimately, their goal is to create a Mesa driver for the M1 GPU and upstream all
of their code.
So things would just work?
Wow, that would be nice.
It would.
Yes.
Because could you imagine Linux on that without a GPU?
No, I mean, I guess maybe a server.
Anyway, after getting a Mac OS environment set up that was friendly enough for reverse
engineering, because, you know, turns out the Mac OS kernel, not the Linux kernel, you
got to do things a little bit differently over there, Alyssa was able to get poking
around at shader binaries.
Some early takeaways from that work are that the Apple M1 GPU is scalar for all bit sizes,
hardware scheduling is being used, and that it looks like it is a super scalar architecture.
And that, by and large, most of the cleverness is actually in the hardware design and not
in some super magic optimizing compiler that Apple's got, which hopefully is good news
for her further efforts.
Right.
It doesn't mean they have to come up with all those tricks in software, if they can
just get the hardware working, it should be decent performance.
So that work for the Ashi Linux project is up on GitHub right now.
I was in conversation with Wendell from Level One Techs and of course, Level One Linux recently
about his thoughts on the state of graphics on Linux.
And I wanted to get his take on the effort being put in to get the GPU for the M1 platform
functional under Linux.
This is what he had to say.
I mean, OK, ARM is exciting, but we're jumping the gun here a little bit.
Save that effort.
Just put it in the jar, put it in a bottle and wait until real ARM, not Apple's sort
of beer goggles ARM comes out, because ARM is amazing.
And if Apple did it like I mean, technically, Microsoft did it first, but Apple did it first
correctly, which was we want to build a laptop that's a genuinely good user experience.
Microsoft, I'll tell you exactly what the problem is.
I can sum it up for you because they did ARM first, Windows RT.
The only thing Microsoft was thinking was, wow, we can make a really cheap Windows device.
We can mass produce these.
We can print these like money.
It's going to be great.
They weren't thinking about a good user experience.
Yeah.
And you're saying that's the part Apple got, right?
Yeah, that's the part that Apple was relentlessly focusing on because it's the operating system
tied with ARM.
And so that level of dedication, that zeal, that, you know, insane focus on positive user
experience.
I think once we've got that hardware in ARM for mass consumption, which is coming, good
performant ARM, then the enthusiasts can adopt that and we can build whatever, because it
just seems folly to me to try to reverse engineer something that somebody doesn't want to be
open with because they're constantly going to kneecap you.
They're constantly going to undermine your efforts and it's like, oh, this, you know,
this piece of hardware is amazing.
I want to run my own software on it.
We've seen exactly how hostile Apple is to that in the iPhone ecosystem.
We don't have to guess.
We don't have to hope that they're going to do the right thing.
We already know that they have no interest in participating in the open source ecosystem.
They are open source hostile when you look at licenses like the GPL.
We should not in any way try to do anything with their hardware that, you know, they don't
sanction for that reason because it's, it ultimately potentially is wasted effort.
And if that effort were put towards something better for the ecosystem, something like what,
you know, the pine people are doing, it would be a much better effort for the overall community,
I think.
If you want more Wendell, well then join us for this week's Linux Unplugged episode 388,
where Wendell goes in depth on the future of Linux on the Intel platform.
Speaking of graphics on the Nvidia side of things, it appears Nvidia is getting prepared
to support hardware accelerated X Wayland.
X Wayland is what makes it possible for traditional X11 type applications to run under a Wayland
session.
And now an Nvidia developer has submitted a merge request to the X server GitLab titled
support for hardware accelerated rendering and proprietary Nvidia driver for X Wayland,
which seems to be pretty clear what that is intended to do.
It's two patches that are included in there that also work in tandem with an upcoming
Nvidia proprietary driver.
They'll work to enable GL and Vulkan rendering with X Wayland.
Once that driver is out, this code should just work with that driver and things should
just start working automatically.
It's interesting to see Nvidia's efforts here, you know, they'd previously done some other
work trying to improve Wayland support last December.
And also this month, a different Nvidia engineer made some contributions to Mesa.
So clearly there's stuff going on behind the scenes.
As for the performance of these recent changes, though, well, they expect it to be on par
with native X11, at least based on benchmarks so far.
Although there is an annoying extra copy required for windowed applications, but the impact
doesn't appear to be significant and you shouldn't see it for most full screen applications.
Which covers a lot of games, really.
It sure does.
And so there's that, there's the aspect of being able to play games on Nvidia hardware
under Wayland that obviously matters.
But there's also just the preservation of software, software that maybe has a GPU component
that's designed for X11 that the developers never rewrote to support Wayland or whatever
the case might be, which is probably going to be a considerable amount of applications.
It's really nice to know that Nvidia users with that proprietary GPU driver, some of
whom have to use it for their workloads, will have access to the software with full acceleration
still.
I think this is a really big step.
It's taken a long time for Nvidia to get here, but with probably within between now and the
end of spring or beginning of summer, we're going to have a just works out of the box
experience.
It's great to see it coming.
Datadog.com slash Linux Action News.
Datadog is great.
They're the unified monitoring and analytics platform that gives you comprehensive visibility
into your cloud, hybrid and multi-cloud environments.
You can quickly analyze the performance of your Linux servers in real time with beautiful
customizable dashboards.
In fact, go to their website just so you can see these dashboards.
It makes it easy to troubleshoot Linux issues in seconds with a unified view of your metrics,
images and logs all in one place.
The Datadog clipboard lets you streamline performance and outage investigations by capturing
relevant views of your infrastructure and applications across the entire stack in one
place.
And they have just turnkey integrations for over 400 technologies.
And you can even use Datadog to monitor just key Linux metrics alongside with data from
the rest of your stack to get full visibility into the health and performance of your entire
infrastructure.
So start a Datadog trial today by visiting datadog.com slash Linux Action News.
You start your free trial, you create one dashboard and you'll get a free Datadog t-shirt.
So that's datadog.com slash Linux Action News.
Create that dashboard and get that free t-shirt and go there to support the show and our sponsor.
Keeps our humble podcast free for listeners like you.
So thanks to Datadog for sponsoring the show and thanks to all of our listeners who visit
datadog.com slash Linux Action News.
A free, decentralized, federated and peer-to-peer video platform just had a major release.
That's right, PeerTube version 3 is here and it had one new feature that really caught
our eye.
Very excited to see live stream support officially land.
It's a minimalist and efficient peer-to-peer live stream system that seems to be working
pretty great.
We have test footage live streaming to about a dozen people right now and they're all over
the world.
From right here in the US of A on the West Coast to the Netherlands, people are streaming
this and uploading individual chunks of the stream to each other.
Yeah, it's really quite neat.
It uses web torrents so it takes some pressure off the creator, hey in this case us, so our
upload could be a little bit less and then everyone watching the video can share chunks
with folks who haven't got quite as far as they have.
It's impressive that this all works live.
It's so great too because we haven't thrown a ton of resources at it.
We have a two-core CPU, four gigs of RAM, Linode running this and we were actually able
to sustain two streams, two live streams at the same time, just barely and if you're just
using it as a PeerTube instance on its own, it takes storage for the videos and it takes
the CPU when it's transcoding them to the various formats, but once everything's done
and it's just sitting there, it's not a big impact.
It actually is going to be pretty straightforward for open source projects like Debian to have
a YouTube in a box.
It's like old YouTube.
It's nice, clean and simple.
It has your video feed, it has subscriptions, it has trending videos.
You can even get an RSS feed for your subscriptions and it has all of the basic features of YouTube,
but in this case, it could be DebianTube and it's just Debian stuff and it's their project
videos and past conference videos and talks and maybe even walkthroughs and then when
there's a Debian conf, you know where to go because you go to the DebianTube and it really
is a YouTube in a box and the setup, well, I mean, just a few minutes.
Yeah, not a big deal.
I mean, we were kind of using on what's been our standard in Ubuntu LTS and then pretty
much everything in Docker and while I don't know that it was officially supported, it
was least documented in their community area of documentation, a lot of good documentation
for getting set up.
So there was a Docker compose file pretty much ready to go with a little customization
or they've got some very nice robust docs if you want to go the classic way that's built
on robust technologies like Postgres and Redis and TypeScript.
So it seems like a lot of good things in there.
Comes with a nice configuration with Let's Encrypt, of course.
So really once we got DNS pointed, everything was up and running in no time.
And if you've ever done a live stream on YouTube or even if you haven't, it's pretty straightforward.
You go to publish video and one of the options now is just a live tab.
You click on that and it gives you the RTMP server information.
It gives you the key to use and you put that in, what we did was OBS on Linux and hit start
streaming.
That's really all there is to it and the main difference between using this and something
like Twitch or YouTube besides the fact that it's totally free, decentralized and completely
under your control is that it's a little slower because if you think about how this is working,
the server is doing the bulk of the encoding but then that work is then shared amongst
the client.
So first you have to wait for the server to receive the signal, then the server has to
transcode that and send that out to the clients and then the clients send that out to their
peers and so it just takes slightly longer and the latency can be somewhere in our testing
between 25 seconds to maybe as much as a minute depending on how long the stream has been
going.
You know, honestly, that's not a deal breaker.
It's nice to have low latency.
Maybe that'll be something that improves in future releases.
This is kind of brand new but pretty much no hiccups.
I mean, we had a decent little stream going.
I had several of them right here on my own laptop and I can even change resolutions to
a different transcode, you know, down from 720 to 360.
Worked pretty well.
But again, it features that kind of thing you can do on YouTube where you stream and
then when you're done, the stream is still available for playback automatically.
That's great for talks and all of the conferences that have gone online.
I could see it being useful in all kinds of education sectors, you know, you're delivering
it right now.
Now it's automatically backed up, ready to go for watching later.
Totally could be killer for education in schools.
They could even run it on their own LAN, have it behind the firewall.
It's just their stuff.
You can brand it and you can theme it as a plug-in system.
I mean, I'm really, really impressed with how far they've gotten in just three releases.
Every single release has been really remarkable and this one is just absolutely up there.
We're setting one up.
We're playing with different ideas and how we could use it as a podcast network because
I've got a few ideas, if nothing else, just like a way to have a canonical archive where
things haven't been pulled down by YouTube.
It's pretty exciting because I remember when we first started doing the very early live
streaming at Jupiter Broadcasting, it required that the end users all had flash.
Oh, those were the dark days.
Yeah, and there was so many weird ways to try to get it working.
And now we're at a point in time where you can get a YouTube in a box that also supports
live streaming and it's remarkable.
And really, you don't have to have incredible horsepower to throw at it.
Of course, that's going to scale depending on how many videos and how many users you
have.
But the PeerTube project has knocked it out of the park.
It's really great to see this.
And they say now they're going to focus on refinement in version 4 and they think they
have a few things that they want to make a little more streamlined and they want to bring
a little more user customizing like features in there and stuff like that.
They say centralized platforms give a little power over the display of videos, newest,
most viewed, just that category, the look of the platform.
Those might all be functionalities that we could change in maybe PeerTube v4.
I don't know.
But yeah, you're right.
We could add more branding, make it a little more of our own or change some of the fundamental
behavior of how videos get ranked, say.
You never know.
Maybe one day we'll have a Jupiter tube.
You never know.
But what I know is you should check out LinuxActionNews.com slash subscribe for all the ways to get new
episodes of this here show.
And we love hearing from you, LinuxActionNews.com slash contact for all the ways to get in touch.
Hey, what are you doing on Monday's 5pm Pacific, 8pm Eastern?
Because you should be listening to Coder's Happy Hour, the new time slot, improved time
slot for Coder Radio.
Grab a robe, maybe a beverage.
Join us there.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
Thanks for joining us.
And we will see you next week.
