Hello, and welcome to Linux Action News Episode 112, recorded on June 29th, 2019.
I'm Chris.
And I'm Joe.
Hello, Joe.
Good to be connected with you.
So many stories to jump into this week.
Let's start with a brand new fresh Raspberry Pi 4 that was announced just really kind of
a few hours after our episode went live last week.
Dang it.
Yeah, no, this shouldn't have happened.
We reported a few months ago that there was going to be no Raspberry Pi 4 this year at
all.
And then suddenly, boom, it shows up.
Not only did it show up, but it showed up with a skew that I am very happy with at the
higher end.
Of course, the starting price is $35, but at the higher end, it's $55, US greenbacks,
and you can get it with four gigabytes of LPDDR4 RAM now.
Yes, that is exactly what I wanted.
Well that and gigabit Ethernet, I am very excited about dedicated Ethernet now as well.
Those two things alone, I feel like game changers for the Pi, but I believe you actually have
gotten your hands on one.
Yeah, I got hold of the four gigabyte version, which apparently is quite rare, but I found
a site, someone linked me to it that was selling it.
I was not confident it was going to actually turn up, but it did a couple of days later.
I did have to buy a power supply with it, which actually I'm grateful for now because
it really does need the three amp power supply to run it.
This is a power hungry beast now.
Instead of being based on the 40 nanometer silicon, this time it's 28 nanometer, so it's
not the very latest technology, but it is significantly improved.
As a result of that, not only is the RAM faster and DDR4 now instead of two, it is just a
much faster machine.
There's no doubt.
Just general browsing and just everything you do with it is faster.
So I'm curious about two things really, Joe.
Let's start with the first one.
New set of adapters required, right, because you've got micro HDMI, USB-C, as you kind
of alluded to, so it's a new set of cables.
How did all that go fiddly?
Did you have to go pick stuff up?
Well, I was forced to buy the power supply with it, so that was taken care of, and I've
got other USB-C cables and chargers and stuff, so I wasn't too worried about that.
It's got two micro HDMI outs now, so you can run two monitors, and I just got the Amazon
Basics micro HDMI to HDMI cables for like Â£5.60 or something for the pair.
So I just consider that part of the cost of it, really.
They're pretty short, though.
They're only three foot, but I have got a coupler if I need to make it longer, but so
far it's not been an issue.
I'm happy to see USB-C, to be honest.
It's worth a new power adapter as far as I'm concerned.
The second thing I'm wondering, this is a lot faster of a chip.
In fact, they're claiming it's 3X the performance they're claiming.
It's desktop performance grade that has to equal in more heat.
When you're consuming more power, you've got a faster processor.
Did you get a sense of heat output, and especially when it was under load, did you get a sense
of how hot it was getting?
Dangerously hot, I'm afraid.
That's the downside of this.
Everything else is great, but the heat is a real issue.
I would not feel comfortable giving this to my little nephew to play with unsupervised.
Maybe if it was in a case, I would, but...
You think he'd burn himself?
I think there's a real risk of it.
He's pretty sharp and switched on, but I'd be at least keeping one eye on him to make
sure he didn't touch it.
You cannot hold it for more than a couple of seconds before it starts to burn your fingers.
It's funny that the 3B Plus I noticed was hotter than the 3B, and this is one step up
in terms of temperature.
The whole thing gets hot, and specifically the CPU.
It needs cooling.
It's funny, I was listening to the Friday stream from last week, and you guys were talking
about your first PCs on there, and how originally they didn't even have heat sinks, and then
they started to have heat sinks, and then, wow, this one's got a heat sink and a fan,
and that was kind of a big deal.
I think we're getting there now with these pies.
I think we're going to get to the point where you're going to have to use some sort of active
cooling on it.
Perhaps, yeah.
And maybe even if it's not officially recommended, you might find that enthusiasts just start
doing it, you're already starting to see them do it with the previous models.
One difference here now from way back in the day, like we were talking about in the Friday
stream, is there is active thermal management and active downclocking.
This, as they say, is really designed for bursty performance, which is really their
way of saying after a little bit of high performance time on the CPU, we have to start clocking
down a bit.
Let's not forget, not only does this have a faster quad-core 64-bit ARM Cortex A72 CPU
in it, but along with all of that is their faster graphics, which is now using a real
full OpenGL stack, in part, thanks to some really fresh software they're shipping on
these new pies.
Yeah, there's a new version of Raspbian that goes along with this, and it's based on the
upcoming release of Debian, which is Debian 10 Buster, which is pretty much ready to go
that.
I think we're going to be reporting on the release of that in the next couple of weeks
probably.
And it generally feels pretty stable and pretty good.
There's a few little rough edges here and there, but in some fronics benchmarks, it
is that little bit faster, I think about 3% faster on a 3B plus at least.
It looks like Michael didn't get a hold of one, but it feels all right, this new version
of Raspbian, but I think that there's a bit of a way to go.
If you look at the earlier versions of Raspbian when they came out, it's come such a long
way.
And with this new hardware and the new system on a chip, there's a lot of work has had to
go into it.
And I think a bit of the polish still needs to happen.
So I'm hoping that with updates over the next few months, it's going to significantly improve.
I would imagine.
The official launch date of Debian Buster is July 7th.
So they are a couple of weeks ahead.
That said, keep in mind, it's been frozen Buster for a couple of months, I believe now.
And they've been testing Buster on the new Raspberry Pi internally since January of 2019.
So they've had a really good go at it.
They're pretty confident shipping it to end users, but I suspect you're right, Joe.
In a couple of weeks after Buster shipped, there's probably going to be a round of updates
for Raspbian that sort of brings it up with fixes or other little tweaks that I'm sure
will be discovered as more and more users start to use this.
Because not only do you have the upcoming release of Buster, which will put it in the
hands of a lot more people, but you're also just going to have a lot more users now using
the Raspberry Pi 4 with this version of Raspbian, they'll discover things, submit them upstream,
and there'll be a natural round of fixes that'll come from this.
It's kind of nice to see them pushing it forward.
And to be clear, the reason why they really went all in on Buster is for that OpenGL video
driver that's now being used by default.
And the development of that driver has been taking place upstream in the most recent version
of Debian.
And they looked at backboarding it to stretch, but they thought, you know, our effort is
better spent getting Buster up to production because it's so close already.
And that's what they decided to do.
They weren't sure if Buster would land before the new hardware or not to when they made
that decision.
It was sort of up in the air.
I'm glad to see it.
And the early reports are good.
I ordered one.
I ordered the whole desktop kit of the four gigabyte model because they're really talking
about using this on the desktop when I thought, let's give it a go.
Let's see what it's like.
I'm going to go in with reasonable expectations, but it's nice to see this update because if
they get close to desktop performance, maybe kiosk performance, or perhaps nice Kodi media
center performance, I'd be a pretty happy customer.
I know there's other devices on the market that have reached this level of performance,
but it's nice to see a Raspberry Pi that's really competitive now.
Do you know what I mean?
Oh, yeah, definitely.
One thing I was a bit disappointed about was that it doesn't boot from USB.
I was confused for a little while trying to make it work.
Is it my cable?
Is it this monitor?
What's going on?
But then I looked in the comments for the original post on the Raspberry Pi blog.
And yeah, Eben is commenting there that he says, at present, we only support booting
from SD card.
We will support booting from USB and network in due course via an upgrade to the onboard
SPI flash.
So yeah, a bit of a disappointment there, but hopefully that will be coming soon because
it's USB 3.
And if you've got a fast USB flash drive or USB 3 SSD, you could potentially have a really
fast boot experience.
So you can still do it now by moving partitions around and stuff, but it'd be nice to be able
to just stick USB stick in and just have a really simple, fast boot.
I believe him when he says it'll come because when it does arrive, you can see a lot of
people taking a USB 3 SSD of any size they want and making that the primary boot disk
for Raspberry Pi and essentially having as much storage as a desktop PC.
That's the exciting thing.
In the meantime though, you could have a pretty high performance SD card, a boot from that
and then use the attached storage.
And the nice thing is with the Raspberry Pi 4, the USB 3 bus is its own dedicated USB
bus now.
You're not competing for resources with the network anymore.
So using real storage is an option.
So it'd be nice to see it, but there's ways to make it work in the meantime.
Yeah.
And I've installed Samba on it with just a spinning drive that is USB 3 that's reasonably
fast.
Bear in mind that I was transferring from that to my other NAS box, which is not built
for performance at all.
It was built for budget and I was getting three to four to maybe 500 megabits a second
of a ethernet.
So I wasn't pushing it to the gigabit, but I'm sure that you probably could push it a
bit closer if the other end was faster.
Yeah.
I bet we'll see some projects based around this to turn them into NAS's and all kinds
of stuff.
I mean, that's what I'm going to do with mine.
I'm going to play around with that.
Maybe I can make a solid state NAS in the RV or something that's potentially fanless.
We'll see about that.
In the meantime, I'll spend my time waiting for my Raspberry Pi 4 by checking out the
new reinvented Firefox preview, at least for Android.
Yeah.
They call this a preview and it kind of doesn't really have a proper name yet.
And really it's a replacement for Firefox Focus, which was their really stripped down
browser, which is still available, but it's kind of been parked and shelved and there's
no active development on it anymore.
And it's kind of splitting the difference between Firefox Focus and regular Firefox.
It's faster and leaner, but it has far more features than Firefox Focus.
And I feel like it could potentially compete.
It's a little bit rough around the edges, a bit buggy at this point, but it is only
a preview.
It's really for enthusiasts and people wanting to test it for bugs and developers and stuff.
So my expectations were pretty low going into it, but I was kind of pleasantly surprised
by it.
Although I was annoyed that the tabs are at the bottom rather than at the top where they
belong.
I would be willing to bet that's going to change.
A lot of people will have that feedback.
I'm glad you got a chance to try it because I did actually bring my Android device with
me on the trip to try out stuff, but did not get a chance.
I'm down in Texas right now.
But I did read through this and I noticed a couple of things that jumped out at me.
And so I did some digging and you're right, Joe.
There is a real emphasis on this not being quite production ready yet.
In fact, if you read through their announcement, they refer to it as A, a preview, B, a pilot
and C, available for early adopters.
So they're really trying to make it clear this isn't for everyone.
But I'll tell you one of the features that jumped out at me, and then I want to talk
about the performance.
But just feature wise, I was really kind of lukewarm to this bundles idea that they have.
They call them collections in this browser, but different browsers have done this concept
before.
And I kind of looked at the way they've done these collections of different websites and
I get it now.
In their example, they show a morning routine collection or perhaps your favorite place
to go plan for trips or shopping for clothes.
And they bundle all those sites together in one like easy to execute group, also easy
to share with other users.
And that I kind of dig, like news bundles I could see us using, but that's kind of neat.
So I'll be playing around with it pretty soon.
I might give it a couple of weeks to bake, but let's talk about the performance here
just for a moment.
This is powered by something we've covered on the show before and we're kind of unsure
where it was going to go.
And now we really have a clear answer.
This is running GeckoView, Firefox's new mobile browser engine.
That's the same high performance engine that focus is already using.
And on the Mozilla blog, they say implementing GeckoView paves the way for a complete makeover
of the mobile Firefox experience.
They say all major browsers today are based on blink on Android and reflective of Google's
decisions about mobile.
This is GeckoView engine ensures us and our users independence, that's some bold talk
about GeckoView.
Like this is GeckoView is turning out to be like a key part of their Android strategy
of their reinvention on Android.
Well, it's like quantum on the desktop, isn't it?
It's the basically the only alternative to Chrome and Chromium based browsers now.
And they've realized that that's what differentiates them and then just go in with it.
Yeah, they even kind of talk about how this is their take on quantum for Android.
Like we're going to do what we did for the desktop now on mobile.
They're going to make it faster at a code level, but they also say they're going to
make it faster by designing it to be a little more efficient at a usability standpoint.
And then for the rest of 2019, they're directing their efforts into optimizing the Firefox
experience on Android.
This is of course the mobile teams focus.
And they say in order to have a strong foundation for the next generation of mobile Firefox
browsers, we're going to put all of our efforts into GeckoView.
And that's also at the expense of, like you mentioned earlier, focus going on hold for
a bit or I guess potentially indefinitely, and then maybe being eventually replaced by
this new effort.
We don't quite know yet.
They're not necessarily spelling it out yet.
No, but it certainly looks like focus is going to go away, I think.
Yeah, that would be my inclination from it.
And I think what you're going to end up with is like you said, something that splits the
difference and makes for a pretty good browser.
And along with overall Firefox improvements, one of the things that's landing in Firefox
69 is a random password generator, which is nice because a lot of the other major browsers
offer that now.
So when you get a prompt to create a password for our website, it will suggest something
that's randomly generated and then in theory, I would imagine, offer to save it for you.
Yeah, I think this is long overdue really.
So good to see them doing it.
Yeah.
Well, something Microsoft feels is overdue is getting in on that insider circle of Linux
distros that know about those security problems before the rest of us.
Yeah, Microsoft employee Sasha Levin has applied to join the Linux distros mailing list, which
as you say is where the various distros communicate and coordinate on security disclosures before
the rest of us find out.
And Microsoft are kind of claiming that they deserve to be part of this now because they
have got WSL2 and Azure Sphere, which are proper distros.
So yeah, let us in please.
You would think something called the Linux distros list was something else.
But nope, this is where they discuss these security issues.
And from that standpoint, I can kind of see Microsoft point, I think this is probably
legit.
You see, there's eight different criteria in which you must meet to get access to this.
Like they're different ones like actively maintain a Unix like operating system distro
with substantial use of open source components.
Like Joe said, they argue the WSL2 does that, that Azure Sphere does that.
They also argue that products like Azure HD Insight, their Kubernetes services and other
things on Azure make them a public provider of access to Linux based distributions.
So they also meet another criteria.
There's other things in here.
Like I said, eight different criteria.
Once they get accepted in theory, they would then get access to these discussions that
are crucial for getting an early heads up on coordinating and handling the deployment
of fixes before they're made public.
Once they're made public, then they go on a mailing list called OSS security, which
you would think would be the mailing list they talk about security issues that are private,
but is in fact the one where they talk about public security issues.
So there's two different mailing lists.
And right now they only have access to the public one.
So they've submitted Sasha on behalf of Microsoft, all those different criteria, he's got an
answer for all of them.
Just word noting, he is endorsed by Greg KH, who I think people probably know who Greg
is.
He's longtime contributor to Linux kernel.
He maintains the LTS branch.
He's Linus's number two.
And the reason why he signed off on Sasha is quite simply, if you just glance at the
change log for the more recent Linux kernels, Sasha's all over it.
He's been contributing to Linux kernel pretty steadily recently.
And so he's obviously got the attention of Greg and he is giving Sasha his blessing.
So I think it's probably pretty likely they're going to get in and it makes sense.
They've got cloud infrastructure that's running user loads, powered by open source and Linux.
They should probably stay safe and secure.
Yeah.
And as the register points out, it really does complete their transformation almost
from back in 2001, calling Linux a cancer to here we are 18 years later, and they're
taking part in some of the low level stuff like this.
So I don't know, maybe Microsoft have changed.
Let's see what the YouTube comments say about that.
They love it when you say that.
Yeah.
But speaking of the kernel, when Google Plus went away, suddenly Linus had nowhere to
post and a bunch of the other kernel people.
So they decided to start people.kernel.org.
Following the different kernel developers on Google Plus was quite literally for me
the best thing about Google Plus and the thing I missed about Google Plus when it went away.
So it is really great to see people.kernel.org pop up.
Now there's already a place where you can follow a lot of the kernel developers.
That's planet.kernel.org.
It's an aggregator of a bunch of different blogs.
The difference here with people.kernel.org is it's focused on Linux related development
topics, whereas the other is sort of just their blogs, whatever they're talking about.
This is just the kernel development stuff.
And it's kind of one of our secret sauces here that's made a little easier for everyone
now is we go out and individually follow these developers and sort of aggregate their blogs
to watch for news.
And now they're doing it for everyone.
So it's people.kernel.org if you want to follow just Linux related topics of different kernel
developers.
And as you'd expect, it is an ActivityPub enabled federated platform powered by write
freely and some nice hosting by the folks at write.as.
So that's pretty cool.
And you'll be able to see the individual blogs that are on topic.
Yeah.
And unlike planet.kernel.org, they've actually configured the SSL cert properly.
Really?
I hadn't noticed that.
I only follow the feed, so I've never really gone to the website.
Yeah, I haven't for a while, but I've just checked it now.
And yeah, it's misconfigured, unfortunately.
It's pretty cool.
Like I went I've been going there for the last couple of days because I saw this announcement
earlier in the week and was following it since then.
And it's really technical.
Like if you get into like the really geeky low level stuff, this is it.
This is really great.
And you can get an idea a little flavor of the different kernel developers like you can't
do this with other operating systems.
So it's so cool.
Yeah.
And all running free software as well, which is cool.
So it's kind of the silver lining to Google Plus going away.
Following up to one of the notable topics from last week, we did get a statement as
expected from Canonical on the support for 32-bit i36 packages for Ubuntu 1910 and Ubuntu
2004 LTS.
Yeah, and they did the U-turn that we were kind of expecting, but hoping they wouldn't.
And so they are going to support a limited number of 32-bit packages to make stuff like
Steam and Wine work, which I suppose it was just inevitable, wasn't it really?
Yeah.
You got to give Canonical one thing.
They make a strong stance and then they typically will listen to the feedback and it may take
them a while, but they eventually reverse course or compromise.
You can look at Upstart and SystemD, Unity to Gnome.
I mean, just the list goes on and on.
And this is another example.
They say we'll put in place a community process to determine which 32-bit packages are needed
to support legacy software and can add to that list post-release if we miss something
that is needed.
Let's stop here for a second because in the end, I think what we ended up with is a pretty
workable compromise.
Instead of having to manage and maintain hundreds of 32-bit libraries, perhaps they will limit
that problem domain down to 30 or 40, which not only makes it more sustainable, but keeps
the end users happy and their partners happy.
Like Valve, it's kind of a great compromise because it's way easier than maintaining hundreds
of libraries while also keeping end users and partners happy.
Like everybody wins.
Yeah, but they did have plans and ideas for how to solve this problem in another way.
And it feels like just pressure from the community has forced them to just do it the way the
community wants rather than pushing forward using containerization and snaps and other
technologies, newer technologies.
They are just going to keep supporting at least some of these old I386 packages, which
it just feels like a bit of a backwards step to me to do that.
It feels like they need to move on, but I suppose people's games are very important
to them.
There's quite a lot of feedback about our stance on this, and obviously, Canonical got
even more than ours, way more, and I suppose they were going to have to do this.
But this means that it could be 2030 by the time they stop supporting 32-bit I386 packages
for people who are paying.
That's an awfully long time.
It is.
And as part of this process in our research, we went back to the original announcement
of the 64-bit transition to just sort of try to take the temperature of what it was like
going from 32-bit to 64-bit.
And on linux.com, which we have linked in last week's Linux Unplugged, there is an interview
with some kernel developers in there, and they're clearly talking about this as a temporary
transitional technology.
Oh, the 32-bit supports there, but it's really just while we move into 64-bit, and they talk
about it like it's a temporary thing.
And so it's kind of funny to think if that was in 2001, and Canonical may end up supporting
that until 2030s, that temporary transition will have been a 30-year transition around
there, some 29, 28-year transition.
It's like when you do construction work on a house, and you just have a temporary thing
there, and then you just end up stuck with it forever, because it's just more hassle
than it's worth to sort it out.
Just that pipe, we'll just temporarily run it along the surface or whatever, and we'll
sort it out later, and then 30 years later, it's just there all rusty and stuff.
And that's pretty much what we've got here.
I want to talk about Valve's response here in a moment, because they also posted a statement.
But just to wrap this up, I do kind of think this is a pretty nice compromise.
So I think it's not, in the end, that bad of a solution.
I do still believe that we already have existing technology that could have solved this problem.
It is possible today to install a 64-bit-only Linux distro, and then add a Steam Flatpak
that includes 32-bit support.
And you can play the game.
I mean, that's technology that exists today.
Yeah, but someone has to build those 32-bit components though, right?
Oh, sure.
But that's being done today already.
Like, it's happening.
So we have the technology, I guess is what I'm saying, is it's a possibility.
Steam could also have just included more in their runtime, which they talk about in a
little bit in their post.
I think, ultimately, what made me think this is not necessarily a bad idea to try to work
these old 32-bit subsystems and libraries out is the messaging from Canonical.
It's been extremely subtle, but it's there every time they talk about this.
Even in their latest statement, they write, there is a real risk to anybody who is running
a body of software that gets little testing.
The facts are that most 32-bit x86 packages are hardly used at all.
This means fewer eyeballs and more bugs.
They in different ways have tried to say, without having to scare people, we feel we
are shipping vulnerable software that isn't getting properly checked out and tested.
And as a platform vendor, we think this is bad, but they don't want to come out and say
we're shipping vulnerable software because that looks really bad and we get them a lot
of crap, but they have to kind of also communicate to their end users at the same time.
We're really worried about the security of this.
We think you should know that.
That's been completely overlooked in this entire thing.
Yeah, it's not necessarily about it being vulnerable.
It's about it being potentially vulnerable.
It's about simply not knowing because there's not enough testing.
Well, we do know for a fact that they are vulnerable from Spectre and Meltdown type
attacks because no one's ever backboarded the mitigations to that to 32-bit.
Yeah, but that is quite an extreme example, isn't it?
Sure, but it is an example of a very well-known, extremely publicized vulnerability that hasn't
made it back to 32-bit.
And so you got to wonder if maybe other things that are a little less known, maybe didn't
get as much publicity, also aren't getting fixed.
I would bet that's true.
Yeah, I remember once there was a bug in Ubuntu that stopped mumble working and that was after
a kernel upgrade.
But the 32-bit kernel upgrade had no effect on it and it still worked perfectly well.
And so there are clearly differences between 32-bit and 64-bit x86 and who knows what they
are because if hardly anyone is using 32-bit, then there could be all sorts of bugs.
Maybe they're just bugs like I was talking about there with mumble where it just doesn't
work and just crashes or whatever, or maybe they are security issues.
There's just no way of knowing.
Something that's a bit interesting, again, the last episode of Linux Unplugged where
we talked about this, we did a breakdown of what happens on a Linux box when you launch
a 32-bit application on a 64-bit system.
You think it's, oh, it loads one or two libraries.
It's actually extremely complicated, including libraries and components that get loaded that
you may never use, kernel subsystems that get activated the entire stack all the way
down.
There are ramifications.
And I think it's interesting, I never knew it myself until we looked it up and wasted
a full breakdown in the last Linux Unplugged.
Yeah, I was going to say we looked it up.
You mean Wes looked it up.
Yeah.
Yeah.
Or I think I looked it up and said, Wes, this is really complicated.
Could you break this down for us?
He's good at that.
Well, Valve also made a statement.
Now, the same individual that tweeted that, oh, we have to drop support for Ubuntu, this
is outrageous, posted an update as an official statement on the Steam Community website.
And he goes into some background here and mentions the fact that Steam already bundles
a lot of the dependencies needed by 32-bit games, but it currently relies on some key
components being available on the host system, a 32-bit GLIB C, an ELF loader, MESA, and
the NVIDIA graphics driver libraries, to just name a few.
He says, we've been investigating ways to avoid these system dependencies for a while
now by looking into light containerization and other approaches.
So this is something Valve apparently has already been looking at.
But the issue is that they wouldn't have it ready by the 1910 release time.
And that's where the upset came from, because it'd either require a fundamental rushing
or a fundamental change in the Steam runtime, either one they weren't happy with in a short
time period.
He touches on as well as the response mentioning not recommending Ubuntu to Steam users.
Steam currently, he says, really kind of pushes users to use Ubuntu.
And there may be some changes to that, sounds like, in the future.
He writes, there's technical and non-technical reasons behind their concerns, but the bottom
line is that we would have to drop what we're doing and scramble to support 1910, and that
was the main issue.
Well, something that jumped out at me is towards the end of the post where he says, the Linux
landscape has changed dramatically since we released the initial version of Steam for
Linux.
And as such, we are rethinking how we want to approach distribution support going forward.
And then he says that there are several distributions on the market today that offer a great gaming
experience, such as Arch, Manjaro, Pop OS, Fedora, and many others.
So that feels like a fairly thinly veiled threat to Canonical, that if you don't play
the game with us, then we're going to start recommending a different distro.
Yeah, or we're going to start recommending all of the distros.
Perhaps some sort of containerized version of Steam would do just that.
The end result would be good, I think, for all Linux users.
I thought it was funny that he mentioned Arch and Manjaro, which are both sort of the same
code base, essentially.
And then Pop OS, which is based on Ubuntu.
The only thing that was really its own unique standout distro in that list was Fedora, which
only just recently got easier to install the NVIDIA driver and flat pack up Steam.
I mean, it works great now, I'll grant you.
That's only a recent development.
But in the case of some past attempts at distributing Steam on some of these platforms, they've
come up with their entire own packaging scheme, which I imagine Valve wouldn't be really a
huge fan of either.
So it is, it's a weird kind of thinly veiled attempt to throw shade at Canonical.
I went through the history of this individual's Twitter feed, Pierre's, and he doesn't seem
to be overall super satisfied with Ubuntu as a platform.
You can see him complaining about the way PPAs are distributed.
You can see him complaining that there was a regression that happened upstream, but Canonical
didn't catch before it landed in Ubuntu.
There seems to be other factors at play.
In fact, even in this post, he writes, there are technical and quote, non-technical reasons
behind our concerns.
That's a shame.
You know, my personal experience is Canonical is a pretty easy company to work with.
And they're pretty accommodating.
In fact, they'll work pretty damn hard to accommodate a partner like Valve.
But at the end of the day, if Valve can come up with a way to distribute Steam that makes
it essentially a common Steam runtime across all distributions and works really well, that's
a win for all Linux users, Ubuntu users, Manjaro users, even Puppy Linux users.
Yeah, and Flatpak seems to be the obvious solution or snap, but given the hostility
towards Canonical, it seems unlikely that it'd be a snap.
But yeah, if they could get a really great Flatpak that worked across all the distros,
then everyone would be happy.
It would be a more appropriate way to distribute Steam because you can't really expect all
the different distributions across all the different hardware to really have a specific
set of host libraries like they do now.
It's really kind of created a hot mess.
It's created all these different Steam solutions and all of these arch wiki posts and forum
posts and everywhere where people are trying to figure out how to get certain 32-bit games
to work.
It's good if you are in a certain track of Linux.
You know, if you're on one of these distributions he mentioned or you're on mainline Ubuntu,
you really don't have any problems or even Fedora now.
But there are distros, especially ones that are maybe a little more technically modern.
Maybe they only ship 64-bit.
Those distributions, it has been a challenge in the past and you can't necessarily rely
on the host operating system to even have the libraries in the path Steam expects them
to be in.
So they do need to fix this problem and you really got to come up with a way to use Linux
as the platform to deliver your product.
That's how you have to treat it.
And I think that's where they're going.
It'd be nice to see them do it without having to throw shade.
We'll see.
We'll see how future posts go.
Yeah, we'll keep following it and everything else in the Linux world.
And you probably want to follow that too.
So go to linuxactionnews.com slash subscribe for the ways to get all the future episodes.
And let us know what you think about these stories or feedback for the show, linuxactionnews.com
slash contact for ways to get in touch.
And just a couple of items of note, we recently did a study group on understanding burnout.
It was a really good one.
Major Hayden from Red Hat joined L and we had some great contributions from the Mumble
Room.
That'll be up on our YouTube channel, youtube.com slash Jupiter Broadcasting.
Highly recommend that to everyone out there who's ever struggled with some burnout.
Another note, this upcoming Linux Unplugged that'll be out in a few days as you're listening
to this is all about our experience with PCI pass through.
It's so awesome.
Even if you're not currently thinking about it, I encourage you to listen because it's
a new way to distro hop and run Windows, Linux, and Mac OS all at once.
So check out Linux Unplugged coming up soon.
Yeah, I'm going to listen to that tomorrow while I edit it.
We'll be back next Monday with our weekly take on the latest Linux Diamond Source news.
I'm at Chris LAS.
I'm at Joe Rissington.
Thank you for joining us and we will see you next week.
Take care, bye-bye, see you later.
