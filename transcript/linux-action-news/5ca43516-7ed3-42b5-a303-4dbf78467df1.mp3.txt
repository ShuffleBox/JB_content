Hello, and welcome to Linux Action News, episode 129, recorded on October 27, 2019.
I'm Chris.
And I'm Drew.
Well, hello, Drew.
That wasn't the plan, was it?
No.
Turns out Joe has a little illness going on and he won't be joining today.
Some con cred, as it always happens when you travel to events in the winter.
So we wish him a quick recovery, and in the meantime, we kick things off with really great
news out of the GNOME Foundation.
They're taking the fight to the patent troll.
They've filed defense against the patent troll going after Shotwell.
That's absolutely right.
And just as a reminder to everybody, they are being sued for patent infringement by
Rothschild Patent Imaging LLC.
Yeah, they need the money.
Everybody knows that.
Right.
Of course.
But Rothschild did offer them a settlement offer for somewhere high in the five figures,
but GNOME actually turned it down.
This is the part that really kind of gets me fired up.
And I'm really grateful for the GNOME Foundation here.
They write on their blog, quote, this would have been simple to do so, i.e. accept that
compromise.
But they go on to say, it would have caused less work, it would have cost us less money,
and it would have provided the foundation a lot less stress.
But it also would be wrong.
Agreeing to this would leave the patent live and allow it to be used as a weapon against
countless others.
They conclude by saying, we will stand firm against this baseless attack, not just for
GNOME and Shotwell, but for all free and open source software projects.
Yes.
And I think this is really the right move and is a good example to set for the free
software community in general.
Now granted, not everybody has the kind of pull and weight that the GNOME Foundation
has to be able to fight this sort of thing.
But since they do, they're doing the right thing here.
Well, I think that's why it's important that they are the ones to take this fight on.
I don't know how much weight and pull they do have.
And I think that's why it's important that when we talk about these things, we mentioned
they have set up a legal fund, not just for this, but future fights as well.
The software conservancy is getting behind them like there is things lining up, but it's
not a sure thing yet.
And we really want to see this thing succeed because if the GNOME Foundation, heaven forbid,
were to fail, this Rothschild patent imaging sham LLC would be emboldened to move forward.
They started with barbecue restaurants and small little chains in Florida, and now they're
moving on to the internet and going after anything that uses this vaguely defined image
transfer metadata patent.
It's weak on the very grounds.
So there's a good shot here that the GNOME Foundation can win this fight, but they have
to have the finances, they have to have the backing to do it.
And so that's why I feel like anytime we talk about this, we're going to put a link in the
show notes for the Patent Troll Defense Fund because it's not just for GNOME, it's not
just for Shotwell, it's for future open source projects because it will not stop here if
this patent troll wins.
And the way that the GNOME Foundation is fighting this is Neil McGovern has instructed their
legal counsel at Sherman and Sterling to file the following papers, a motion to dismiss the
patent outright as invalid, an answer to the claim, which they don't even think that they
should have to file but are filing anyways, stating that Shotwell and Free Software in
general is not even affected by this patent, as well as a counterclaim just in case Rothschild
tries to drop the suit once they see that the GNOME Foundation is going to fight it.
I love this because what they've done here is they've recognized that these people didn't
do their homework properly and they don't even have a valid case here.
So this third, this counterclaim, this third paper they've filed to make sure they can't
just tuck and roll and try to get out of this and then go after somebody who doesn't do
their homework is the masterstroke of this procedure.
It really shows you that they've been thinking about this.
And also, it sends a signal.
It sends a signal to this horrible, twisted patent troll marketplace that you just can't
go after free software like this, that these foundations will seek legal counsel and they'll
go after you for it.
They'll hold you to the fire.
Yes, and the GNOME Foundation even goes so far as to say, we want to send a message to
all software patent trolls out there.
We will fight your suit.
We will win.
And we will have your patent invalidated.
Well, I'm happy to say they are making good progress to their goal of 125,000.
I suspect they're going to need a lot more than that.
But so far, as we record this episode of Linux Action News, they have raised 80,000 US greenbacks
and they're close to tipping to 81,000.
So we'll put a link in the show notes again.
I think this is something that matters a lot.
And maybe we can get them to that goal of 125.
I'm looking at this.
I'm thinking there's no, you can't, you can't do this for $125,000.
But this is a good start.
So let's get them to at least that goal.
Yes, absolutely.
And also throwing a little bit of weight behind them.
You've also got the Software Freedom Conservancy, Debian and the Document Foundation, all pledging
to stand with the GNOME Foundation, which I think is great as a show of support.
Well, I think Will Cook has our support.
He was the director of engineering for the Ubuntu desktop, but he has left Canonical.
That's right.
He's moving over to InfluxDB, which is an open source time series database solution.
And Martin Wimperis is going to be taking over his spot.
Yeah, that's great for Will and it's also really great for Wimpy.
I can't think of anyone better to take on this new role.
And I think it'd be nice to kind of look back over some of the things that Will accomplished
because the last five years of the Ubuntu desktop have been some of the most significant
change we've witnessed.
Absolutely.
They have really come out of the gate strong with all of those releases.
And that was after some would say a little bit of a slump in quality.
I think Will really brought Ubuntu up to where it needed to be.
And the last few releases especially have just been of exceptional quality, if you ask
me.
There was a couple of pivotal moments for Will under his leadership of the Ubuntu desktop
that I recognized.
Number one was he opened up a dialogue with the wider community.
He kind of stepped outside the Linux bubble and said, what do you want in a Linux desktop?
And a lot of them came back with, we want the GNOME shell.
We want sane defaults.
We want this, that and the other thing.
And then he took that data and he went to Mark Shuttleworth and the whole team had a
conversation and we saw the announcement that they'd be transitioning from Unity to GNOME
shell, that they'd be essentially implementing all of these highly requested things that
the community wanted.
And he was there during that transition, but not only that, he was there during the investment
into GNOME shell to make it so smooth, so much more stable, so much more professional
grade than it was at the time they adopted it.
All of the changes that they have made in the past few months even have been pushing
GNOME way farther than I thought possible.
It has become such a great experience and such a joy to use that I think it's actually
starting to win a lot of people back.
I think I like the way this is being done.
The 1910 release got out.
It was a solid feature packed release.
And now Will's doing a nice transition and a handoff here.
He sought through some of the most challenging times of the distribution and got it to this
point where it's better than it's been, I mean, probably ever.
It's legitimately probably the best desktop they've ever shipped.
And we've been able to say that now for, like you mentioned, a few releases.
It's just been progressively getting better and better.
At the same time, that doesn't mean that we don't need to change things up a bit.
If you look at where they're going, they're going in a direction that's more professional
grade.
It's a development workstation.
They're working more with OEMs like Dell and they're taking their input and they're really
focusing the product.
At the same time, Microsoft is a big part of the story now, not only just with Azure,
but also with the Windows subsystem for Linux.
And that is something that Canonical is starting to take more seriously.
We may see that develop into its own official branch of the Ubuntu project.
And I think it's interesting as Wimpy takes on this desktop lead role, he's not just taking
that on, but he's also taking on the management for the Windows subsystem for the Linux.
Canonical is internalizing that.
And I think it shows not just a recognition that that's a legitimate platform, but it's
truly a recognition of how important the developer is for the Ubuntu platform and specifically
the Ubuntu desktop.
And that's why I think this is the perfect timing.
It will really turn this thing around and now Wimpy can take it and bring it to that
next phase.
And he may be one of the most uniquely positioned people, not just at Canonical, but in the
open source community to pull it off.
I completely agree.
He is definitely a person who has the leadership skills and the engineering background to really
do this.
Between his work with the MATE desktop and being so focused on SnapCraft and packaging
formats, he really knows what it takes to get something off the ground like this.
And he's also excellent at taking user feedback and implementing it into his work.
I really can't think of anybody else who would be better suited to this position right now.
Yeah.
So just a big congratulations to both Will and Wimpy from the team here at Jupiter Broadcasting.
And I think it's just going to make for a better product for end users.
So really just pretty happy all around about this and look forward to 2004.
It better be good now.
If he doesn't knock this out of the park, he's got five years to live it down.
It's true though.
Oh man.
At the same time, I'm super excited for him.
But then when I think about that, I'm like, oh, that's a tough spot to be in.
Well Firefox has some new features.
Keep an eye out for version 70 because when it lands, some new features come front and
center to tell you just what a good job it's doing.
I've actually already got this on my desktop.
It landed for me today in the Fedora repos.
And honestly, the new panel is really slick.
It is so good looking.
Yeah, I mean, really, this is one of the things I think that makes PyHole such a great project
is you get these great, nice looking visualizations of all of the hard work it's doing for you
and it kind of makes it click.
It really is actually actively protecting you.
Right.
So not only is it showing you the metrics of how many trackers it's blocking, but it
also integrates with lockwise as well as Firefox monitor to show you not just your password
statistics, but also if you've set up monitor with your email address, it will even show
you how many breaches your email address has been involved in directly in that same panel.
And my understanding is it will flag future breaches as well.
So they have an analogy here that kind of actually works, but you'll have to just sort
of be a little forgiving.
They say, in some ways, a browser is like a car where the engine drives you to the places
you want to go and a dashboard tells you the basics, like how fast you're going or whether
you need gas.
But just like the car dashboard these days, it's telling you more and more.
And so they sort of see the browser is playing this role.
They want to bring three key things to the surface.
They want you to see how many times enhanced tracking protection has blocked an attempt
to tag you with a cookie.
They also want you to be aware of any potential future data breaches like we were just talking
about.
That's the Firefox monitor that works in conjunction with the have I been pwned database.
And then lastly, they really want you to consider using lockwise, manage your passwords and
sync them across your devices.
You get a brief idea of how many passwords you have, you get an overview of if they're
like complicated enough.
And in theory, you can work in conjunction with Firefox monitor to flag you and tell
you, hey, hey, you're using passwords that are on the public internet.
You better change those.
It also has some nice features for generating passwords.
So when you will go to sign up for a website or go to refresh a password, it will actually
prompt you to ask you, hey, do you want to go ahead and create a randomized password
for this and have me store it for you, which I think is a really killer feature and helps
people to remember that it's there and that they should be using it.
Well, yeah.
I mean, anybody listening to this goes, well, you know, bit warden or last pass or insert
name of password manager that does that for me already.
Well, good job.
You.
Yeah, you've done a good job.
You've got a password manager.
Turns out, though, the rest of the world hasn't really caught up yet, unfortunately.
And so this is sort of bringing it to the masses.
I like that about it.
But I think really, if you were to take one thing away from version 70 is the data visualization.
It really just shows you in a very kind of understandable, readable way how fricking
bad the web is, you know, like, holy crap, like, and I've been running this, too.
I also got the same update you did just just for my morning prep for the show.
And I'm I'm in the hundreds already.
Oh, absolutely.
The news sites are almost the worst in some cases.
Yeah.
I mean, they want to connect to Facebook, which thankfully, Firefox is already blocking
due to its Facebook container ization, which I love also, you know, they want to pull your
Google Analytics, they want to pull your Twitter traffic, they want to they want to pull everything
about you that they can.
And not only can that slow the pages down, it's also, you know, a little privacy invading.
Kind of tangentially related to this, there was some further details on Firefox's DNS
over HTTPS implementation.
And I think in an attempt to sort of alleviate some concerns around Cloudflare primarily.
Yes, for one, they are coming right out and saying, we are not entering into any kind
of financial agreement with Cloudflare.
None of this has anything to do with any money.
Beyond that, Cloudflare has also signed a contract that states that they are meeting
the privacy requirements that Firefox has set forth.
And they've agreed that neither party is allowed to make money by monetizing the data pulled
from any DNS requests.
So overall, I think that they are doing a pretty good job to alleviate the concerns.
Now I think a lot of people are still going to be really wary of Cloudflare in specific.
But Mozilla has also stated that they're working with more resolvers to try and get them to
sign that same contract that Cloudflare signed and get them into their trusted recursive
resolver program.
I think that would be a very good move on their part that would do substantially more
to alleviate people's concerns than just sort of reiterating what we kind of already knew
about their Cloudflare agreement.
Granted, some of this is new details, but a lot of this was sort of implied through
Mozilla's blogs already.
And I think what we see happening to Cloudflare is both good and also unfortunate.
I think the community is taking all of the bad lessons learned about Google and all of
the great things Google said about doing no evil and all of that, and they're taking all
of it, internalizing that and just preemptively applying it to Cloudflare before they even
get to the position to abuse power.
People are sick of it.
At the same time, I think it's a good thing because lesson learned, good on us.
We won't be fooled twice.
But it's unfortunate because Cloudflare is not Google, and they have not done the same
things that Google has done.
And we should judge each in their own based on their own actions.
And if we were to go by the actions here, it would seem that Cloudflare is really playing
ball with Mozilla from the complying with their privacy standards to no financial transactions
involved with this.
There's no monetizing of data that's in the agreement.
All of that really should be satisfying most of us.
That's a pretty unprecedented level of agreement that you don't typically see with these kinds
of companies, and Mozilla should be recognized for achieving that.
But it hasn't really satiated that overall concern that I think has been baked into us
from companies like Google and probably Facebook.
Yeah, I think you're right.
But let's move on to a little bit of the technical details about how they're utilizing DOH.
For one, if DOH fails, it will drop back to standard basic DNS to fulfill a query.
So it's not like DOH is just going to start breaking things left and right.
And beyond that, they're also providing a method for sites to state, hey, we don't work
with DOH.
DOH breaks our functionality.
Can you please fall back to DNS before even trying DOH?
So sites can actually break out of that and say, no, no, no, we don't want DOH.
Please give us standard DNS, and Firefox will attempt to accommodate that.
And some other use cases involving that same strategy are things like parental controls.
So if you're using something like Umbrella or some other kind of parental DNS overlay,
Firefox should automatically detect it by using a canary domain and then fall back to
standard DNS because clearly you have made a decision to use something to implement parental
controls.
Same thing with enterprise policies.
If it detects enterprise policies, again, it will automatically disable DOH and fall
back to standard DNS so as not to break your enterprise local DNS settings, which I think
all of those are the right move, especially coming out the gate.
Yeah, those don't sound bad.
I think in particular, all of those will come down to let's see it in action because auto-detecting
based on a canary list is useful, but it's sort of like antivirus that's only based on
pattern detection.
You only will be able to detect the known things, and if somebody stands up a new project
or somebody creates their own system for their LAN, it may or may not detect those things.
We'll just have to wait and see.
It perhaps will accommodate, but we don't know.
I have been using DOH in my day-to-day usage for months, maybe month and a half, two months,
essentially since we started talking about it regularly here on the show, and it's been
unnotable.
It wasn't until I recently had an issue where my PyHole box was blocking some domains, at
least I suspect that was happening, and I couldn't resolve them, and I didn't know why,
and so I turned on DOH and it started working.
Now that would seem to indicate to me that Firefox's DOH implementation failed to auto-detect
that I was using PyHole intentionally and still let me resolve those sites, which yay
for me, I wanted to get to those sites, but doesn't seem to speak well for the overall
implementation.
Perhaps it is yet to be fully implemented.
Well and they do have a kill switch too.
So if you're an administrator and you're rolling out say like Firefox to an enterprise, you
can go ahead and preemptively disable it in about config, and if you're a general user,
you can manually disable it in the browser under the preferences by going to the network
settings under general, and there's a really easy checkbox, enable or disable DOH right
there, and it will let you pick your provider, granted there's only one right now, but the
functionality is already there to change.
Yeah, there's only one now, and that's how I turned it on.
I opted in so that way I could have some experience when I talk about this on air, because I do
manage DNS.
I use DNS very intentionally on my LAN and I want that to work when I want to connect
to a local box, I just want to use its friendly name.
So I've been trying it out and I like to try to hold the two things separately.
There's the technology implementation and then there's the policies and politics around
the implementation, the avoiding surveillance, all of the other things like perhaps cloud
flares issues.
There are two separate issues, the tech and the politics, and as far as I'm concerned,
the tech is useful, and so as long as I can continue to run my own DOH servers and I can
choose my own provider or add my own custom entry or turn it on or turn it off, I say
it's a great thing to have in the browser, because there are situations where your local
DNS sucks, and having reliable, fast, secure, signed DNS is a good thing, and you could
just go turn it on with a single freaking checkbox and you can turn it off with another
click of that same freaking checkbox, and I think that makes it a good thing in my book.
Well one thing that you can opt out of, at least for now, is GitLab Telemetry.
They announced recently that they were going to start adding JavaScript-based code that
would run in a user's browser to pull telemetry data and submit it back up to GitLab via a
third-party platform called Pendo, but they're backtracking a bit on this.
This is a fascinating story, and when you read their original post, at least what remains
of it, you can tell they're really kind of approaching this from a very trepidatious
standpoint.
This is an ugly truth of software as a service.
You need data.
You need metrics.
You need to know what parts of your platform you're losing people, what parts of your platform
are the best, and where you can improve or fix things in between, and without metrics
of what your users are clicking on, how long they're spending in areas, where they bail,
where the transaction fails, without those metrics, you don't know where to improve.
You build something, you get thousands, hundreds of thousands, millions of users in some cases,
and then you're blind as to what they're doing on the platform.
Imagine that scenario.
That sounds frightening.
You'd just be guessing, going by instinct, well I feel like we ought to improve this.
This is essentially the situation GitLab found themselves in, and so they thought, well,
let's think about this.
Let's be real reasonable here.
I know what we'll do.
We'll get more data on how users are using GitLab, and they had a nice plan.
They do something real minor, just a little JavaScript snippet like Drew said, something
real simple.
They'd be real transparent about it in their privacy statement, and they may also put it
out in different versions of GitLab, just so they get that data as well, but don't worry.
If you turn on Do Not Track, we'll respect it, and it's all going to be fine.
Well, like so many things like this, the internet didn't respond so well, and there may have
been some parts of this official post that got removed later on too, which is a little
suspicious.
Including impressive financial results for our shareholders was the piece that got removed.
Now I want to give you the context here because it's important.
The original line read, on one hand, we value results, including impressive financial results
for our shareholders, and we believe an open core model is the best path to achieve that.
It also means making our products better as fast as possible for our customers and users.
Now what's important there is that they're pulling out that information about wanting
to provide financial results, which essentially reads as, we're going to monetize this data
that we are pulling out of your browser.
Not a good look.
No, I think that's not what they intended.
What they, I assume, were trying to convey was almost like this triumphant, we're going
to give impressive results to our shareholders because of our open core approach.
Our open core approach will bring them great dividends, and that's an important metric
for us because open source making money is important to us.
I think that was the intention of the statement, but man does it not read like that at all.
Oh yeah, I totally agree.
I think this is essentially them saying through improvements to the product, we're going to
have more users and show better return on our professional paid product, but whoever
wrote this copy made a whoopsie.
I think they were trying to be bold.
Also you could interpret that as impressive financial results equals sustainability, which
is important for a product like this in the developer ecosystem.
I kind of understand the somewhat backwards logic that led to that line being in there,
but imagine Drew as well.
This was proofread by a handful, at least maybe even a dozen people.
This wasn't just something a guy wrote up and then posted on the web.
This is something that they really as a group thought, yeah, this is the way to get this
message across that open core and open source can make money.
The whole situation just looks bad and then to back out of the data collection both doesn't
really solve the problem and also just punts it down the road and they'll have to get back
to this at some point.
They do need these metrics.
They really should just come up with a way to bake them in that isn't offensive to the
end users and I couldn't tell them how to do that, but when you read their post, I read
something that comes across as trepidatious, lots of couching, lots of telling you why
this is the best scenario that they've come to and how they're going to try to do it right
and how they're going to try to be transparent and then you give it a few days and they immediately
turn around and they say, okay, we're not going to do it.
I mean, we're going to do it, but we're not going to do it right now.
We're going to give it a rethink.
They even mentioned that a lot of the pushback was because some of the code that would be
running in users' browsers is closed source and the reason for that is a lot of these
third-party telemetry scripts, like the really good professional ones, are proprietary and
using software as a service rather than something that they would bake into their site in order
to save some money, save some engineering time, they'd probably have to hire somebody
to do that particular work.
It makes sense from a business perspective to go ahead and outsource that, but I mean,
especially when you're talking about a community that writes source code and shares source
code, they're not super into having closed source code run in their browser.
I also don't think GitLab needs to participate in these chickenshit closed source tracking
systems that are designed to create bogus stats for an industry that lives off of hype.
They don't need to play that game.
They can write their own checks and I suspect that this was the result of trying to achieve
a certain set of goals about trying to reach certain metrics in performance, in stability,
in bug fixing, and in financial performance and after the group got together and had a
nice good group think on it, this was their solution to solve that problem and now this
has put a big red flag up and now they're going to, as a group, have to rethink it and
I would bet you their second take on this is going to be much more palatable.
Well I hope so because I like the GitLab project.
I think it's a good project and I think it's got some legs, but I would be remiss if I
didn't bring up, hey, this is like a month after they announced a $268 million Series
E round of funding.
It's got to be at least partially connected to that.
Yeah, that is a little bit coincidental.
On their blog they write, our plans for the funding are straightforward.
GitLab will invest to make all of our DevOps platform offerings, including monitoring security
and planning, best in class so we can enable our enterprise customers continue to bring
products to the market faster.
That's a great goal.
How do they know where their product is currently lacking?
How do you make it best in class without data telling you where the problems are?
Where as they might say in the biz, the friction is.
Without the ability to identify that friction and lower that friction, they can't make it
the best in class.
You can easily see how you go from, well we've just taken on $268 million in Series E funding,
all of these A, B, C, D and E funders want data.
We want to be best in class.
We have a goal to be best in class by 2023 because as they write, we think the market
will triple by then and they want to be positioned.
Okay, you've got three years.
How do you get there?
Well, the old school way would be to solicit user feedback.
But as many projects have shown time and time again, a lot of times you end up with the
vocal minority really calling the shots then and you're not really seeing how your average
user is utilizing a platform.
So yeah, they're going to need this telemetry to really hit that goal.
Yeah, they need to do it at scale too because I couldn't even guess at how many people individually
use GitLab but their number for organizations which could have hundreds of thousands of
users in some cases, 100,000 organizations use GitLab today.
It's companies like Delta Air, Goldman Sachs, Ticketmaster, Nvidia and obviously a heck
of a lot more.
You need to understand where they're having problems because a lot of times when they
hit an issue, they just bail.
They just move on.
They just do something else, have somebody else fix it.
They don't go on a forum and complain.
They don't start a Reddit post.
They don't fill out a bug report.
They move on with their day.
And without data, you can't capture those events at scale.
And I'm not sitting here advocating for tracking especially using closed source tracking software.
That's not the way to do it.
But at the same time, I can completely empathize with their position and with the fact that
they have real serious questions being asked by their financers and they got to answer
those.
They just have to be able to strike that balance.
Good luck to you GitLab.
I really hope you find a good solution that's really going to make some other people happy.
I don't know if it's going to involve bringing some people in-house and developing your own
telemetry systems or working with Pendo to maybe open source some of their current JavaScript
to make it a little more palatable but yeah, you're going to need it and I wish you the
best of luck.
Yeah.
I like you think it's a really important project and want to see it continue and I like both
those suggestions either do it in-house or work with one of those offensive proprietary
solutions and make it less offensive.
Maybe even open source it.
I bet if there's a company out there that could have some sway, it's GitLab.
Google also has seen some much improved stats around Project Treble and how it is improving
user adoption of Android OS updates.
So as a reminder, Treble started with Oreo 8 and it is a way to kind of modularize Android
so that you've got this generic system image underneath and then vendors can build their
sort of skins on top of it rather than having to modify the entire system image just to
get your branding and all of the apps that you want to preload on there, which would
then make it much more difficult to upgrade in the future because then you have to rewrite
all the code for the new version.
Treble circumvents that by making it more modular system and it wasn't until Android
9 and now 10 launched that they were really able to get some metrics on it and those metrics
have been pretty stellar.
Right.
You get it in one release but then you don't really even start to see the fruits of that
labor until the following release but then because of the delay cycle in the OEMs, it's
actually the release after the following release where you really start to see it take traction
and anecdotally, some of us have noticed it.
The Essential phone was announced with Android 10 right away.
Yaomei also announced a phone on the same day that Google did running Android 10.
OnePlus started its beta program on the same day as well and also it's worth mentioning
the OnePlus 7T has launched with Android 10 already loaded on board.
This is all thanks to Treble.
Ya, and not only that, other larger manufacturers who are usually really slow to update have
really stepped up their game and are saying that they're aiming to release Android 10
on several of their devices by the end of the year.
There's a bit of system magic that's happening here.
We can talk about the way they've broken things off into different modules but really by having
this base system that is signed by Google that is being updated independently, it has
enabled not just the OEMs that we like to talk about all the time but even the ROM community
as well.
The ROM community can use these generic system images to function kind of the same way that
the OEMs are in that they can use that base system image to layer on top of it with the
goods that they want and ship them out to any phone that was launched with Oreo or Pi
so long as it has an unlocked bootloader.
Like so many things in Android there always are a few caveats but it is nice to just have
a story like this where the situation is improving and there's data to show it's improving.
So often with Android the story has always been, well you'll never get that update.
That's finally starting to shift.
It's going to take a few more phone cycles to really be in that perhaps possible utopia
but we're clearly seeing data that shows we're on that way.
We're on the path, Drew, you know?
Like it's finally happening.
Oh yeah and I'm pretty excited for it and you know Google hasn't just been putting all
their eggs in the trouble basket.
They've also been collaborating with silicon manufacturers to help them enable the jump
to Android 10 as well.
Ah yes us iOS users will have one less thing to feel superior about soon but I think it's
worth it and I'm happy for it really.
I'd love to see these updates roll out more frequently.
Not so happy about how things are looking though for Disney Plus on Linux.
They're much talked about streaming service.
Well it's not just Linux though.
It's any device that doesn't support the strictest version of Widevine DRM enforcement.
Widevine has three possible security levels and Disney Plus is using the absolute most
strict level meaning that anything functioning at those two lower levels can't connect to
it.
My understanding is that Netflix and other platforms use the same technology but they
just dial it down.
They don't have it at maximum abuse mode.
Well they do and they don't.
They support the maximum mode but if your browser or device is not capable of utilizing
that maximum mode they will drop down.
So instead of getting a full HD or 4k resolution you'll get something a little lower but it'll
still play.
I see.
And now Linux and Android only support the very lowest level which is only software encryption
which means that while you can watch videos in Linux or on Android with a little bit of
a neutered resolution it's still going to work but with Disney Plus not allowing that
fallback there's just no possibility to use it at all.
It's funny because you can almost make money on a bet that says when a company doubles
down on DRM there will be so many online versions of that content to then meet the demand.
You know what I mean?
They're almost guaranteeing piracy of their content doing this.
How can they not understand that?
And with a company as big and as influential as Disney is you really think they would but
users are still getting this error 83 and when contacting customer service they sometimes
don't even know what this error 83 is.
So part of me wonders how prevalent it is and how many people with these unsupported
devices have signed up for Disney Plus but at the same time part of me knows that they're
aware of it and either it's really low on their radar or they're not sure how to fix
it because it's been over a month since these reports started rolling out.
Well who's to say?
I recognize that people that want to watch streaming content on their PC are not the
majority regardless of platform Mac or Windows or Linux.
Most people are on a set top box or they're on mobile or maybe a tablet and I appreciate
that fact but there is like this category of us who have multiple screens.
We work all day at our desk and sometimes it's a very monotonous kind of work you know
a Netflix binge or something like that of a show that's not like crazy important but
you kind of want to watch.
It's perfect for that and I could easily see catching up on Disney content because it's
not just Disney cartoons it's everything that monster owns and that would be nice to have
on the desktop and that will create a demand which will lead to piracy and the way around
that is to make it easily accessible legally to paying customers and when you fail to do
that there's a lesson the internet teaches companies over and over and over again.
Like somebody should create a podcast that just tracks how many times this happens and
how companies have to learn this lesson over and over again and now Disney's going to learn
it.
People's media servers their Kodi boxes will be stuffed full of Disney Plus content and
it won't be via a streaming add-on that they've keenly developed for Kodi.
Let's just put it that way.
Well and you mentioned set top boxes there I think that's going to be the predominant
way for people to really stream the service just like with many of the other services.
So that's the target use case and to their credit Disney Plus does have apps available
for both the Android ecosystem and the Apple ecosystem to be able to stream their content.
So if you have something like an NVIDIA shield that is Android based you're not left out
in the cold but there is something to be said for smart TVs that have Linux baked in to
be able to run content without an external set top box.
Disney needs to cater to that market as well and the way to do that is through Linux.
There are more and more TVs that are running things like web OS that aren't Android based
that perhaps Disney will want to stream to so maybe they will need to reconsider their
support of the Linux platform sooner than later.
There was some sort of indication that they are working on the problem but it's really
early days for the service.
They're not transparent on the process and there's been no updates or any progress in
the last month so I'm betting it's a back burner kind of thing.
So it's something to be aware of if you're thinking about subscribing to the Disney Plus
streaming service that you may not be able to watch it on your Linux box for a long time.
Maybe that's not an issue for you.
You've got a set top box no big deal or maybe it is and we wanted you to be aware of it.
That's just sort of the bottom line right now.
Well if anything changes with this story or any of the other stories that we've covered
we'll be sure to bring you an update right here on Linux Action News.
Check out linuxactionnews.com slash subscribe for all the ways to get new episodes.
And we love your feedback, ideas, even corrections linuxactionnews.com slash contact for all the
ways to get in touch.
Also be sure to check out Linux Headlines, linuxheadlines.show every single weekday.
All of the important things happening in the Linux world in three minutes or less.
And if you're interested in coming to work with us at Linux Academy you can find our
job postings at jobs.lever.co slash linuxacademy.
That's right.
Lots of great positions.
Come work with us.
It's a pretty great place to work.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
I'm at Chris LAS and I'm at Drew of Doom.
Get better Joe.
Thanks for joining us and we'll see you next week.
