Drew, you're just so good. So handsome!
Aw, why thank you.
It's true. I know.
Have you seen the way his hair sort of floops to the front?
I was just gonna say, he's got that adorable hair thing going on.
It's just, you read my mind. You read my mind.
Like a giant bunny ear, but for a person.
Hahaha!
Hello, friends, and welcome into 3.73 of your weekly Linux talk show.
My name is Chris.
My name is Wes.
Hello, Wes.
You brought a posse with you today.
I don't know if we have enough seats for all these fine people.
Well, we have a huge show, so, you know, we need a crew.
It's time for an in-studio audience for this one.
This episode is brought to you by a cloud guru, the leader in hands-on learning.
The only way to learn a new skill is by doing.
That's why ACG provides hands-on labs for cloud Linux servers and much more.
Get your hands cloudy at a cloud guru dot com.
Drew, hello.
I'm impressed you managed to find a seat in here today.
I know.
It is so crowded in here.
I think we're breaking some ordinances, aren't we?
Oh, for sure.
But, you know, ever since we hit 3.70, Wes has always rolled with the posse now.
This is the new Wes, so we're going to make it work.
But you like my hat, so no complaints.
That's true.
And I like that you guys are all color matched.
That does actually work.
Look pretty good.
Before we get into the stories, though, we have to bring in our virtual lug.
Time appropriate.
Greetings, mumble room.
Hello.
Hello.
Hello.
Hello.
Woody.
Bienvenido.
Hey.
Rocking 27 people in that virtual lug today.
Good to see all of you.
Hello.
I am thrilled about today's show because not only do we have some fantastic community news
that we're going to get into, but then Wes and I had a lot of fun messing around with
Linode last night and setting up a couple of servers to just hammer ButterFS Send and
ZFS Send versus R-Sync.
And today what we want to do is just give you a plain explanation of what these technologies
are and why it's an example of something that these newer file systems offer and how you
can use it.
But does it really matter when you have R-Sync and you can use R-Sync with any file system?
We'll talk about that.
And it was fun last night.
I mean, Wes stayed up a lot later than I did.
I'm an old man.
I had to go to bed by 11, but we were building these systems and then attaching these disks
and then setting up ZFS and then setting up ButterFS and then throwing data between them
and all in the name of podcasting.
And let me assure you, all of our pools were named after Star Trek engineers.
All right.
Well, let's get into the community news first, though.
This is just great for the LVFS project.
A certain kind of milestone, I mean, you know, numbers are arbitrary, but early this week,
Richard Hughes from LVFS announced that they have provided the 20 millionth firmware update
out to a machine.
Now, here's the thing, though, is it actually could be a lot more than that, Wes, because
there's systems that are behind Nets that just entirely mirror all of LVFS.
So that's all one update.
Yeah.
Yeah.
It really kind of all started, Richard writes on his blog, because of the Colorhug firmware.
And if you have one of those Colorhug devices, in a way, you kind of helped start the whole
LVFS thing off.
Yeah.
I mean, he writes, my experience building open hardware devices really pushed me to
make the LVFS free for all, mostly on the logic that I wouldn't have been able to justify
even a $100 per year subscription and certainly making the service free in all respects meant
that it was almost risk free for companies to test the service.
That's key, right?
Because now the LVFS analyzes uploaded firmware for security problems and it keeps millions
of devices up to date.
And here at Linux Unplugged, we keep reporting on how many new hardware manufacturers are
adopting LVFS because of this open model.
Yeah, it's pretty neat.
And it's not without some lacks still, I think I'd still, there's still some devices I have
that I'd love to see updates, but it's just an assumed now at this point when I get a
new device, which I have, by the way, I don't think I've mentioned this on the show, have
I, Wes?
No, you have not.
So I don't know if Dell just listened to last week's show and realized that they could
probably get me or if they just happen to send this anyways and me being in the laptop
market right now is just a coincidence, they have sent me a review unit of a Dell Precision
5750.
Oh, that's a mean looking rig.
Look this thing up.
As configured, it's $4,900 and in the review, I'll get into why.
Wait, wait, what?
Yeah.
Uh-huh, yeah.
And Dell has put some serious R&D into cooling.
So they have laptop Xeons in this thing that they can run at high speeds because of the
cooling system they've put into this, as well as a super high end graphics card.
I'm trying it out still.
I'm going to try it for a little bit, get past the honeymoon stage, throw a few different
distros at it, run it through its paces and all of that, and I'll give you a report, but
this is so clearly aimed right at whoever would be like kind of that developer market
that might be buying a MacBook Pro.
This is Dell's answer that it's thin.
It's got chamfered edges.
It's got four USB-C ports plus an SD card reader, and it's got much upgraded speakers
compared to what are normally shipped into Dell that it clearly seems like they're trying
to match what the MacBook Pro has in audio quality.
And then just the specking on this thing, which I'll get into in the review, is just
absolutely insane.
And it's obviously Dell saying, hey, by the way, if you heard about this ARM transition
and everything that you target in the cloud runs on x86 and you'd rather just get a Linux
box that could replace your MacBook Pro, have you seen the Dell Precision 5750?
It's really crazy.
I mean, between the like just the really hot RAM and the screen, there's a lot to like
here, right?
Yeah, yeah.
It has screaming RAM in this thing, too.
That's yeah, that's one of the other things they did.
You know, I just know that this thing, it's going to be supported by LVFS now, and that's
a pretty sweet position to be in because I could put Fedora 33 on that thing and I'm
not, I could put PopOS on that, which is going to be kind of particularly ironic, or I could
leave 1804 is what it ships with right now.
And they're all going to get supported with LVFS.
It's pretty nice.
There's other things in the works.
Few hints.
He also gives a notable mention to Logitech, who's done literally millions, shipped literally
millions of firmwares.
Kind of an early adopter, too.
And he gives specific thanks to Lenovo, they've really worked well with the project.
But there's other details in here, too, that I think are worth the click in the show notes
if you guys care about the project.
Some good stuff in here.
It's really neat to see this.
What I really liked about this post by Richard was just, you know, last year he presented
a talk and his slide was, well, LVFS is just a website that runs cron jobs, right?
At the end of the day, it has, you know, it's basically new packaging infrastructure.
But someone in the crowd told him, you didn't just create a website.
You changed an industry.
And that's it, right?
Like, LVFS feels like a pipe dream.
It feels like the kind of firmware updates that we wish we could have in the free software
community.
And yet, it's 2020.
Here we are.
By and large, we have them.
Now, this next story, I don't know, maybe it's going to appeal to millions.
Maybe it's only going to appeal to just me.
But the Zen project is officially porting its hypervisor to the Raspberry Pi 4.
You got to, you know, you got to have the four.
So to be precise, it's really...
Four.
Yeah.
Well, it comes down to some of the hardware components in there.
And this idea kind of bubbled up, what?
Not too long ago?
Yeah.
Well, the idea to do an official port bubbled up from the Zen community, you know, as it
will, and then reached the desk of George Dunlap, chairman of the Zen Projects Advisory
Board.
Dunlap mentioned the idea to an acquaintance who works at the Raspberry Pi Foundation.
Okay, friends in high places.
And was told that around 40% of pies are sold to businesses, rather than hobbyists.
And Chris, I mean, I think at this point, the number of pies in your RV alone, well,
that's a small business, right?
Hmm, you know, now that I'm independent again, I wonder if I could claim it's a business
expense.
Yeah, I mean, I'm doing some serious business with my pies.
And they're now actual production devices, so much so that I could even eventually see
myself being convinced to run a Raspberry Pi in the studio, which is my highest level
of production grade.
We're getting close.
Yeah.
Now, here's the nutty thing, though.
30 million ARM-based pies have been sold as December 2019, and it looks like if you go
by what has been released by the foundation, the Raspberry Pi sales are running at like
a brisk 600,000 plus a month as of April 2020.
The register has a really good piece on all of this that goes through a lot of the details.
And the thing is, Wes, there is some similarities to the Raspberry Pi and the x86 systems that
Zen has run on that made it possible, but then there was also some complications as
well.
Yeah, I mean, the Raspberry Pi 4 system on a chip uses a regular GIC 400 interrupt controller,
which Zen supports out of the box.
And I know, I know, especially here at Linux Unplugged, we're all about KVM, but Zen has
been there for literally decades.
And it's, I mean, it's fair to say it's huge in the hypervisor space.
So the fact that you can just support the interrupt controller on this board, you can
use it for virtualization, that's no small feat.
Yeah, it's a pretty big deal.
Now, the thing is, it's not just that easy.
They had to do a deep dive into the belly of the memory allocator and Linux's address
translation layers.
Better them than us.
Well, no kidding, right?
And then later on, they had to figure out how to handle DMA and physical address conversions.
They had to solve all kinds of problems, but you can read them for yourself.
But the upshot of it is that they're all kind of coming together to land in Linux 5.9.
So by Linux 5.9, when that ships, we could have a fully working Zen hypervisor on the
Raspberry Pi 4 just out of the box.
Now don't get too excited though, Chris.
Linus Torvalds, in his infinite wisdom, has released Candidate 7 and suggested maybe another
cycle of testing will be needed before a full version release.
So it might be just a little while before the official Zen on Pi is able to be deployed.
But it's coming.
Yeah.
And for those of you that can't wait, Project Eve, which is the Linux Foundation's OS for
the IoT network edge devices, will soon publish details on their GitHub page detailing how
you could kind of get it going sooner.
But at the end of the day, I think this is actually a bigger deal for industry that are
developing applications than it really is for guys like us.
That said, I have given virtualization a bit of a poke on the Pi 4 and it's horrible, horrible
right now under KVM.
I mean, just because a thing is possible does not mean you should be doing it and it would
not be usable in any sense of the meaning.
But if they could get something with Zen and I could run a super low end base OS with Zen
on there and then I could have a few VMs, that would give me a sense of security.
Because being production grade also means easy to restore, easy to back up, or at least
there's a straightforward process.
And I don't really have that with the Pis right now beyond DDing the SD cards or something
like that.
Yeah, something gross.
Yeah.
So, anyways, it's great to see it.
Well, let's talk about a little more powerful hardware.
We've got ThinkPads and Dells, oh my, this week.
Let's start with the new XPS 13 and the developer edition, which is what Dell calls the version
preloaded with Ubuntu, has been announced right alongside the new XPS 13.
Now this is based on the Tiger Lake 11th Gen Intel laptop CPU.
They're going to ship with Ubuntu 2004 and Thunderbolt 4.
How about that for fancy?
What?
How does that work?
And isn't it just USB?
I mean, I think what happened is the USB became Thunderbolt, essentially, they've merged into
one Ultra Bolt, maybe, either way, if it's fast, I'm happy.
There's some interesting details in here like fast RAM and going up to 32 gigs.
It'll be available in the US and Canada starting September 30th.
And then they're going to roll it out across European countries to participate with Dell.
The price was not yet announced, but here's the thing in this announcement that I thought
was noteworthy.
The hardware, it looks great.
It's just it's what you expect now from the XPS 13 and they just impressively keep delivering
every single iteration.
And that remains true.
But this thing in here I thought was cool and perhaps a good data point for us to observe.
This is Dell, they write, based on their input from our developer community, we've also added
functionality to allow Windows XPS 13 users to switch their system from Windows to Ubuntu
2004 with a free software tool that Dell is making available, even if they did not originally
purchase the developer edition.
You can set it up so that both operating systems run side by side or that just Ubuntu takes
over completely.
That's got to be a big deal, right?
That they've made a tool to do this?
That is something.
I mean, they're invested at this point, Linux is a thing they're shipping and representing
in their hardware.
I mean, they start with based on input from our developer community.
So I guess this is something that they've gotten from their customers.
This is enough customers either requested or attempted this and contacted support or
whatever the story is, the number, the data metric was high enough for the leadership
or whoever it is at Dell to decide this is worth investing in.
That's got to be noteworthy and that's pretty exciting.
So I mean, the machines look great, too.
I think that's a nice note for our audience just in that consumer choices matter.
If you and your purchasing department perhaps are interested in hardware like this, Dell
seems to be listening.
Our original XPS 13 that I bought forever ago is still going strong, still going strong
in the Fisher household.
That's not to be outdone by Lenovo.
Lenovo is increasing the number of PC and laptops they sell preloaded with Ubuntu.
We talked about how they recently announced some Fedora systems.
And at that time, there were Ubuntu systems on Lenovo devices that you could buy if you
had like a business sales rep window that you could go through to get those machines.
But it seems that barrier is being removed and then they're just cranking up the machines
they support.
Oh, yes, that news builds on that certification program for big companies.
But now there's a comprehensive range of ThinkStation and ThinkPad series laptops that are available
to buy or at least will be from the Lenovo website, most coming preloaded with Ubuntu
2004.
That's a lot of machines and desktops, it's not just laptops.
So that's pretty great.
A lot of nice work systems to choose from right there.
And I hope that means that maybe more businesses could offer some of these systems to their
staff.
Maybe they're already a Dell shop or a ThinkPad shop.
It's just nice to see that integration with IT departments, especially in the age of Apple
embraces ARM and all kinds of custom system on a chips like, you know, the bog standard
x86 platform where you can just run whatever you want.
It's still going surprisingly strong.
Yeah, and in a way, when the hardware kind of reaches a point where the CPUs aren't changing
much and the, and all of that, a way that they can start to differentiate and reach
a new market is by offering Linux.
And it's not like a huge market, but it is something they can do to the machine that
differentiates.
And something tells me the people who are interested in that, well, they're willing
to spend the money.
Lenovo.com slash unplugged, go there, sign up and get a $100 credit towards your new
account for 60 days.
Linode is the world's largest independent cloud for developers founded in 2003 and they're
in 11 global markets with over 800,000 customers, 100% independent.
They launched three years before AWS.
Linode.com slash unplugged, get a $100 credit.
Wes and I use the heck out of Linode for the unplugged program.
And that's actually kind of how it started for me.
Two years ago, I thought I need to have a cloud for my own personal stuff that's separate
from my work stuff because I needed to have that divider now.
I no longer owned all of that, I needed to have my own account.
So I knew of Linode of course, because I've seen them at many of the events I go to, they're
active participants in the community, they have developers on staff who contribute upstream.
So I had seen their name a lot and I knew about Linode, so I thought, okay, I'll go
try them out.
And I had actually known a few developers who had written into Coderadio who told me
they host their stuff on the node.
So I'd gotten over the years, a picture and a snapshot, but I was using a different provider.
You guys might be familiar with who that was, but I thought for myself, I'll try it Linode.
That was two years ago.
And then it just kind of built from there.
I started doing it for my own systems, when I needed like an SSH jump post or something.
But then as we started to go independent again, it just was obvious to build out the infrastructure
on Linode.
We just prefer it.
The Linux ethos is it's baked into the way you just configure the systems and the access
you get and the options you have there.
But just all of it, like I created a volume last night, just as an example, I created
a volume last night and attached it to one of our systems.
It immediately just comes up with a nice little hover over of, here's the command you run
on Linux to mount it with the exact path here.
If you want to format it to a different file system, run this command.
They just, they know what the next step is because they use these systems themselves.
They make it simple to deploy infrastructure and you can rely on it.
We've been running a brand new matrix server on it flawlessly.
And with 11 data centers worldwide, you're going to find something that works for you.
They have shared plans that start as low as $5 a month.
Then of course they have dedicated CPU and GPU systems that are fast and powerful.
And every system has crazy fast networking.
That's one of the reasons why we're doing this test that we're about to talk about on
Linode because we wanted to just blast files as fast as possible at each other.
And so we set up two Linodes to do it.
And you get root access to your server along with their API.
So you get full control.
Let's start by going to linode.com slash unplugged.
That gets you a $100 60 day credit for your new account and it supports the show linode.com
slash unplugged.
And thanks to Linode for supporting the unplugged program.
We had dropped some hints in the past that Microsoft was attempting to support Linux
GUI applications via WSL.
And now we've got some interesting details on how X11 and Wayland applications are going
to work.
And we even saw some demos of good old GIMP running under WSL on Windows 10.
And we have a picture, a literal picture, which we have linked in the show notes for
you, that shows how all of this is going to come together.
And the secret sauce seems to be that Microsoft is doing what just about every other open
source desktop is doing.
And yeah, get this, they're writing their own Western implementation and it's actually
kind of clever.
In a nutshell, what we're doing is we're taking Western, we're taking this RDP backend and
we're extending it to teach it how to basically do remote application.
So instead of remoting the desktop, we remote individual window and then we can take those
window and integrate them with the rest of the Windows desktop.
And of course, they have to do the good old GIMP demo, which is always sort of cliche,
but proves a good point to that, hey, look, complex multi window application is working
on desktop.
Like, okay, all right, well, there's no arguing, you obviously have X apps going.
Right?
I mean, can you edit images?
Well then, you pass the test.
Now how are they doing all of this?
This is the interesting thing and they say, and we'll have a link to the Xorg Developers
Conference presentation.
It's a long presentation, it's like a big old one.
The Xorg Developers Conference ran September 16th through the 18th and this was one of
many presentations that was given there.
XTC?
Yes, that's right, XTC.
Thank you.
Yeah, it's got a cool logo too, which looks like the X logo, which is cool because it's
got an X.
They are modifying and upstreaming changes to free RDP to do all kinds of cool things,
including create PulseAudio syncs, pull that in and push it all to the standard Microsoft
RDP client.
And inside the guest, we're also running a PulseAudio server that's hosting our RDP sync
and RDP source for audio in and audio out.
And we forward those over to our compositor where we're running the RDP backend, but we're
running a greatly enhanced RDP backend.
We added support for things like multiple multi-mon.
So now you can go run all of this in multiple monitors and as the monitor comes and go,
the application will see the monitor comes and go.
I did support for things like cut and paste and things like this over the RDP channel.
So we start essentially to have an RDP server that is fully functional, that allows you
to do almost the same thing that you can do, say, remoting into a Windows box.
And if you go by the diagram that they have, it's free RDP that they are doing this to
and they say they're upstreaming the changes.
I think this is so cool in a number of ways.
Okay, there's the large Microsoft sort of, you know, stand out in the corner.
We'll get to that later.
But just that RDP is the thing that they invented and Weston is the thing from the Linux world
with these like abstractions first design and that you can merge these two so nicely
and have an upstream first mentality to make this all work.
I think that's Linux winning to quote Linus, right?
Yeah.
Like that's Microsoft having to give over and say like, look, this is the way we should
design this.
This is how we should tie our system in.
Even if you guys over in the Linux world haven't even decided that you're all ready to move
over to the Wayland Weston world.
Yeah, we're there.
Yeah, it's remarkable the effort they continue to put into WSL.
I mean, they could have stopped at WSL one.
I remember a time when there were other layers you could put on a Windows system that are
like WSL.
Like they had they actually had a Unix compatibility layer in the past that was on NT four that
you could install.
Right.
I mean, that's kind of what became WSL v1.
When they announced WSL v1, I thought, okay, that's what it's going to be like based on
what I've experienced with their compatibility layers in the past.
This is where it'll stop.
And, you know, they'll patch it and keep it up to date, etc, etc.
That'd be a compatibility layer into their own NT proprietary world.
Boy, is that not what's happened?
Is that not what's happened?
It's like not what's happened at all.
No, it's 2020 and Microsoft is shipping like a regular new Linux kernel.
Yeah.
So let's jump ahead to an email we got in from Chris Thompson.
He says, is Microsoft going to ditch Windows and Linux wins the desktop war?
One can dream, true or not, but the day may come.
And he links to a register article, which we have in the show notes.
But that register article is really about a story that Joe and I touched on in Linux
action news this Sunday.
And that was that Eric Raymond predicted that Windows would essentially co-opt Linux and
that Windows would turn into a compatibility layer, a proton-esque compatibility layer
that runs on top of a Linux kernel, and that eventually developers would start targeting
Linux and the compatibility layer would become just a option for old applications or old
third-party applications.
And that essentially you'd see a flip of what we have today, that you'd have the reverse
instead of a Windows desktop with a Linux compatibility layer, it's a Linux desktop
with a Windows compatibility layer.
Boy, I don't know.
I mean, I think there's still a lot to be said about controlling your own kernel, right?
I mean, they've got a lot of say here and as much as you hear the Microsoft folks playing
very nicely with upstream, and again, we should emphasize that, we really should.
But there's also still a lot in the proprietary world when you're running your own cloud and
when you control the dominant desktop operating system, you can choose when or when not to
play those games because it's your own kernel, they've got their own abstractions and they've
figured out how through Hyper-V, et cetera, to host Linux really well.
So I think they're in a surprisingly a very good point and if anything, they're in a better
spot now from rejecting Linux as a cancer to embracing Linux where they need it, right?
And where not, they've still got their own whole NT stack for the next generation of
Xbox and when they want it in Azure, they've got Linux-based switch hardware.
Yeah, that's how I see it too, Wes.
Eric Raymond makes the argument though that on a longer timetable, you know, maybe a decade
or something, the economic pressures will just kind of force Microsoft to shed their
historical tech legacy and just enjoy the cost benefits of having other developers create
software and he makes the case that you're already seeing this right now.
There's evidence today for you to witness this and that is the release of Edge for Linux.
He says that that shows you what Microsoft is doing is they're taking free or open source
software and they're packaging it up and saying, look, world, we've made this business safe.
The adults have come into the room, they've taken this and they've packaged it up.
Yeah, those kids and crazy doctors over at Google came up with this web browser but what
we've done here is we've gone and given it the Microsoft audit.
We've gone through it and we've added some features that we think make it better for
your business and oh, by the way, you can centrally manage this via group policy and
actor directory.
We think it's going to be great and now you can run it on Linux too and Microsoft saved
themselves a decade of work in investing in a new web browser engine like Triton and instead
were able to adopt Blink and Chromium and just essentially switch over to Edge in like
a year and hit the ground running and he argues that as a company, they're going to look at
that return and say, well that's clearly what we have to just do for the desktop now too
because Azure is really our long play.
I really don't see this argument.
For one, Edge is not exactly the first thing that Microsoft has put out even with a GUI.
No kidding.
Like we've had SQL, PowerShell, VS Code, Teams, all kinds of things have been coming over
to Linux.
It's not like this is some, oh my God, they're suddenly releasing software for Linux.
No, they've been doing it for a while.
This is not really something to start shouting from the rooftops about and I really don't
see the momentum going towards having a switch to Linux as a base.
I just don't see it.
There is way too much investment in the enterprise space and yes, I know that they're pushing
people towards the cloud for as many services as possible, including Active Directory, including
Exchange, all of it is trying to go towards the cloud, but I want people to keep in mind
that we have entities like the US government who are still paying them to support things
like Windows 95.
That's not going away anytime soon.
These big on-prem deployments are huge money makers for Microsoft and they're not just
going to turn away from that and they're not going to tell their clients, hey, switch over
to this thing where Linux is now your base and we're going to support all your stuff
via a compatibility layer.
It's fine.
That doesn't fly from mission critical.
It just doesn't.
I completely agree here.
I think Microsoft has never been in a better position not to need to do this and additionally,
there's going to be one clear tell that you have to see before this is ever going to happen
and if you don't see this, then you don't need to worry about it and that is in some
shape or form, DirectX is either open source or released for Linux or whatever because
there ain't no way Microsoft is abandoning DirectX.
It's a huge part of their strategy and the only way they could do a transition like this
is if they battle tested DirectX in a transition like that.
All the hardware vendors would be utterly upset if Microsoft switched from a Windows
NT kernel to Linux for two reasons.
The first is switching to a Linux kernel means that they would have to constantly work at
their drivers and have to potentially mainline it, which that's a lot of work.
Well, we've been lucky so far with the way that things have gone for the vast majority
of hardware vendors.
We were bootstrapped by people reverse engineering drivers and then it got to a point where there
was this kind of critical mass in certain sectors that led to people starting to do
it kind of first, then putting it and then other people taking that work and then mainlining
it themselves, but you rarely ever see the actual vendors themselves directly contributing
to the Linux kernel to add new drivers.
That just doesn't really happen very often, even today, and basically if the surefire
way for Microsoft to ruin all their relationships with all their hardware partners is to say
that we're moving to a Linux kernel and you have to do this.
Yeah, they'd be asking them to flush years of work.
It's not just the years of work.
It means that they actually have to care.
See the biggest problem with Windows drivers and one of the reasons why it was so notorious
for what 15 years or so is that when you make a Windows driver, you're building it against
a stabilized interface that you can that Microsoft guarantees for X period of years.
Well, once they build the driver, they don't have to care about it.
With the exception of graphics drivers, almost no drivers get updates after they're initially
made and released.
Yeah, fair that that does not work in the Linux world at all.
It seems like every time some big new piece of Microsoft, something XYZ on Linux happens,
this conversation comes up again and an edge, I think for those of us who have been around
a long time, represents a pretty strategic move because we're familiar with how Microsoft
leveraged Internet Explorer in the past, and so it invokes maybe an even a deeper analysis
of this topic, but I think the fundamentals remain the same.
I was pretty optimistic when I read that article, I was pretty optimistic and I said, why not?
But now I hear Drew and also the arguments of made.
I want to say these are really good arguments, and if you know that thing behind Windows,
all the relationship they have with their hardware vendors and everything that sounds
pretty obvious.
So it was really interesting to hear these arguments right now.
So thank you, Neal and Drew.
I think maybe the argument comes up because there is some logic to it like it would make
it would be great for Linux in the sense that a lot of games would come and it would mean
that the Linux user base and the underlying utilities that were all GPL would remain.
And it would mean the unification of developer support and that could be great, like there's
a lot of pros to it, if not a lot of risks.
But it seems obvious that Microsoft would also reap from a lot of benefit of not having
to do the plumbing and the other elephant of the room here that we all are not really
saying out loud is no doubt Windows is a horrible rat's nets.
It's just got to be just a mess of technical debt.
Sounds like you've been looking at the recent Windows XP source code leak, Chris, because
oh boy, there's some embarrassing comments.
No better way to fall asleep at night, but let's talk about something that we can get
our hands on today.
Fedora 33 beta landed a little bit earlier today.
And the nice thing is it was a little delayed, but there's a pro in that the final version
of GNOME 3.38 landed in this beta, so we can actually get some beta testing on that.
Gives a little more time for us to kick the tires on ButterFS as well, which is I think
probably the most notable new feature landing in Fedora 33.
And it seems like things are looking pretty good.
It's in good shape.
I noticed that you haven't mentioned Nano as the default text editor.
You bastard.
That's my silent win right there, Wes Payne.
That's my silent win.
The Nano army is out there, and we just do favors for each other in different parts of
the community silently.
Really we should say things like that swap on Zram, link time optimization.
These are all things that Fedora always does and advances the state of the Linux desktop
because they care, right?
They integrate upstream changes between Linux, the kernel, between GNU and GCC, between LVM.
They make it all work, and we all benefit.
I've been doing like Linux podcasts for like 14 years.
So it kind of takes something special to get me to look forward to reviewing and testing
a distribution.
And some of them, it happens still, thankfully.
And this is definitely one of them.
2004 was one of them.
I'm looking forward to 2010, but I'm really looking forward to Fedora 33 because they're
pushing the envelope, much like 2004 did with CFS.
This is here now with ButterFS and just equally exciting.
And there's something so great about that, to be following this every single day on a
weekly basis for 14 years and still get excited by this stuff.
It shows you how hard these teams really are working on this.
So we're definitely going to review this one on the show.
I can't wait.
How about a little housekeeping, tidied up around here, a few things you should probably
know about.
I'm going to suggest you consider upgrading to the Jupiter Broadcasting All Shows feed.
You can search for the All Shows feed in your podcast catcher or we have a link in the show
notes or a link on the JP site.
There's things in the works.
A lot going on now that we've gone independent and we're, I don't want to say specifics,
but there may be some new stuff and I don't want you to miss it.
The All Shows feed is a great way to get this show, get Linux action news, self-hosted when
it comes out.
There's Koda Radio back on the air that lands every single week.
There's good stuff in the All Shows feed and one spot to get it all.
And when something new comes out, if it does come out, I mean, who knows?
But if it does, that's where it would be.
And if you're looking out there to reach the perfect audience, Jupiter Broadcasting has
some sponsor opportunities in October, it could be a great fit.
Email me chris at jupitabroadcasting.com and let's talk about it.
There could be something there.
I think this could be an opportunity for the community to reach out to other community
members.
chris at jupitabroadcasting.com.
All right, we got really nerdy for this one, Wes.
We got really nerdy and in a way, it was really great to once again go through the process
of setting up a blank system.
This is a temporary system, guys, so we went with Arch because it's simple, clean, lean
and mean.
Okay, wait, wait.
What?
Can I just say this time, this one time, I didn't pick Arch, that was you.
I SSHed into this box and you had picked Arch.
Yeah.
And also, I kind of freshened up the place for you and put on fish shell for you, so
you know.
Which was so nice.
Yeah, I take care, but don't you think for this kind of build where you're trying to
get what you want, modern file system version, you just create a couple of devices, one's
ZFS, one's ButterFS, one's extended for you, so there's a few devices.
I mean, I think we've accepted Arch as the modern Gentoo slash Linux from scratch alternative
where you want to integrate all the upstream changes all at once without the Fedora, important
people like Neil and Carl who tested it first, will just test it and do a worse job.
I've got a new thought technology for you when it comes to Linux distros.
Are you ready for this one?
Arch is my learn and burn distro.
Learn and burn.
You set it up.
You update it.
You make some mistakes.
Well, like after today's episode, I mean, we're not going to keep these two systems
running.
We'll just, we'll literally just delete them.
So you know, for this, it kind of makes sense.
Anyways, back on track.
What we wanted to play around with was a feature that is truly fantastic about these new modern
file systems.
And that is either ButterFS send and receive or ZFS send and receive.
You may have heard these mentioned before.
We wanted to talk a little bit about what they are, what they can do for you, and kind
of the differences between those and say R sync.
So how about in the context of backups, Wes, maybe that's a good place to start.
We've been playing with ButterFS.
We've been playing with ZFS for really a long time.
And we have a lot of small files that change.
So we started thinking about what's a good test case to use for backing these things
up.
And right off the get go, Chris, you set these systems up over at Linode.
ZFS had a bit of a detractor, right?
Yeah.
So looking at this from a standpoint of one disk or two disks, and we want to use this
send and receive to do backups, there is the gotcha that you don't really just format a
disk with ZFS.
You don't just do makefs.zfs and point it at your disk or partition and say, go for
it.
Oh, no.
With ZFS, at least, you have to create a pool to get started.
Honestly, this has been a really fun example of when and where do you use file systems,
right?
Because, okay, so we want to talk about send and receive, right?
We want to talk about backups, talk about copy and write, incremental backups, and where
it made sense.
And I think we've been flirting with, at Linux Unplugged, some of the advantages or disadvantages
of ButterFS and ZFS combined, right?
Because we live in a Ubuntu 2004, or, honestly, 1604 world, where you have ZFS, but we also
live in a world where Chris sets up a Linode Arch server, and you have to compile the ZFS
module from scratch.
And in that world, ButterFS is a lot simpler, right?
I mean, okay, did you not tell me last night, I'm going to set up the ButterFS file system.
Can you set up the ZFS file system?
Yeah.
I just didn't want to mess it up for the test, and with ButterFS, I just did the MakeFS,
BTRFS, pointed at the device, and I can essentially take advantage of things like compression
and snapshots immediately without having to create a pool and setting up any kind of form
of RAID.
While both file systems offer some of the features we're about to talk about, that's
one thing to consider, and I think the point we're trying to drive home is, if you're on
a laptop or you're on, say, a VPS with a single disk, it may be a more appropriate use case
for ButterFS, despite what everybody's going to say about it being scary and dangerous.
If you're in a scenario where you have a large pool of disks, and you have essentially this
desire to have the file system and the operating system be separate, and they don't intertwine,
ZFS is a much better solution there.
Well, maybe not much better, but it's definitely maybe a better use case for ZFS there.
But at the end of the day, they both have this ButterFS, or ZFS send, and on the other
side receive command that allows you to essentially shoot snapshots over the network to another
system running ButterFS receive or ZFS receive, and then replicate that snapshot onto the
file system, which, once it's there, you could treat as a mount, and you could actually mount
it.
I mean, there's a lot of options you have there, and it's R-Sync at the actual file
system level.
Is that too crude of an explanation?
Well, maybe R-Sync plus plus, right?
How so?
Well, okay.
So, we started things off with a split partition setup on our two Linode machines, where we
had an ext4 partition, a ButterFS partition, and a ZFS partition, right?
And we copied the same data set over to each.
And okay, yeah, this was a super nerdy data set.
It was for machine learning.
It's basically a bunch of JPEGs of fruit.
Yes.
Honestly, it's fruit.
It's apples.
It's kiwi.
It's pineapple.
It's all the things that you might want to eat.
Is that a banana, or are you just happy to see me?
Oh, I'm very happy to see you.
Continue on, sorry.
And we set up a script to maybe make this a little more obvious than it needs to be.
We had a Python script set up that would just modify a few pixels in each picture.
You know, they have white backgrounds.
We changed that background to black.
And that's where R-Sync kind of fails.
And ZFS and ButterFS, with their copy-on-write technology, really come to the forefront.
Because if you think about copy-on-write, it's an advanced technology, but it makes
a huge difference.
Because a lot of our storage systems, well, you overwrite in place, right?
You update a file, you just write over the same file.
But with copy-on-write, you only copy if you have to make updates.
And that means with ButterFS and ZFS, when you take snapshots, when you have new subvolumes,
you only store the delta changes.
Whereas R-Sync, well, it needs to go check all of the files that might exist, rehash
them, and figure out what differences actually need to get sent over the wire.
I've heard of use cases where you can use ZFS or ButterFS and over long distances.
There's ways to accommodate that, too.
It's not necessarily a replacement, one or the other, for R-Sync or for the file system
send and receive functionality.
But think of it as this way, everybody, is it's kind of just baked in now.
So when you have a system that has ZFS or ButterFS versus Extended 4, which I'm not
trying to convince anybody to switch, but with Fedora 33 just around the corner, canonical
investing a bunch of work into ZFS, I'm trying to paint a picture for why it's necessary.
Well, that's just it.
Honestly, one of the best aspects of this little experiment that we did, Chris, was
kind of feeling out, like, what does it feel like to use a ZFS system or a ButterFS system
for serious data retention?
So here's the setup we had.
We've got this large data set of images.
We ran a Python script to modify one pixel in each image, and then synced the changes
both via R-Sync and Extended 4, ZFS, and ButterFS, and wanted to figure out, how does that feel?
What does it look like?
And what are the actual transfer rates?
And that actually was sort of where I think you and I did some of our most speculation
is I honestly expected R-Sync to kind of own this, because this is like its thing, I thought,
for sure.
It's its thing, yeah.
But what's fundamental about this is it's integrated the file system layer, and it is
aware of the blocks.
It's aware of the snapshots.
It's just a more integrated tool.
And surprise, surprise, I think in most cases, after your initial sync especially, right,
it sends much faster via file system than R-Sync.
No kidding.
OK, so we should clarify here.
We're using bitmaps, so we're updating exactly one little pixel in that bitmap.
We're just changing it from a white background to a black background.
Not a big deal.
But you could imagine that you've got a large corpus of legal texts or backgrounds
for your website.
It doesn't really matter, but you've got a small incremental update that you need to
sync to a large number of data sets.
A good real world example is Facebook, right?
They've got a huge number of containers they run in production, all powered by ButterFS.
You might update a few packages as your Fedora release comes due, and you've got a few
more updates, right?
You don't want to download each of those individually on each server.
You'd like to just diff the delta, send the delta, and update it.
Yeah, and to that point, Wes, as we saw in that talk that was given by a Facebook developer,
oh no, it was the ButterFS developer who works at Facebook.
He mentioned that they distribute updates to the Facebook website via ButterFS file
system send and receives.
I mean, they can actually just replace portions.
Well, yeah, right?
I mean, to give Docker due credit, they support ZFS and ButterFS as backends because they
support copy and write fundamentally.
So when you want to make a copy, instead of actually overriding in place, you make a new
copy and you change it there.
And that means these file systems can figure out which blocks have changed without having
to do a full differential sync like our sync might do.
This really showed up when we were testing this out because our sync took a full 20 seconds
to go figure out like, oh, all of the images that you had, well, they each had one tiny
bit flipped.
ZFS and ButterFS, they took less than a second to figure out the same thing because they've
got file system smarts.
And of course, that speed advantage just scales the more you're trying to move around and
the more that it's on the file system.
Exactly.
I mean, really, we're doing the minimal level here, right?
We've got like this machine learning initial training data set where it's just a lot of
really nice looking strawberries.
But once you start doing some real stuff, or you've got backups going for years, right?
Where, okay, yes, the presentation from your college days doesn't change a lot.
But maybe you've got some to-do lists, some stuff that does have a little more churn,
is in the complete override in the last five years.
Project files.
Yeah, exactly, Chris.
We know.
You haven't still updated those servers.
That's true.
That's exactly the stuff.
It just sends in the most efficient way possible.
And honestly, it was a really good comparison between where ButterFS is as a enterprise
file system and ZFS.
Yeah.
And I think maybe the folks in the enterprise, I could see how people with an enterprise
mindset would look at ButterFS if they're not familiar with it and go, oh, that's more
of a hobbyist file system.
I don't think it's a fair accusation anymore.
Really, it's funny how many times we've been working with both these file systems for this
show.
And now I just clearly walk away from this going, oh, yeah, okay, I see this use case
for ButterFS that I use it for, and I have a use case for ZFS too.
And that's why I just use both now.
But I'm curious about the differences that you notice in terms of, did you really notice
any speed or any kind of real performance difference between ButterFS and ZFS?
I know it's not a huge workload, but it's a couple of gigs.
Yeah.
I think our training set here was approximately 2.4 gigs of just lovely fruit bitmaps that
we had going.
ZFS by default uses LZ4, at least if you install on Arch, ZFS on Linux with LZ4 compression.
But ButterFS, well, you've got to enable that.
Yeah.
That's kind of what I would expect, though.
I was actually surprised to learn that it was turned on by default, but I think that's
just because Upstream has kind of determined that that's the more...
But here's where that doesn't matter.
You've still got to do your initial sync, right?
So if you want to go listen to self-hosted, you should, because Alex has some great stories
about syncing some of his backups over to his parents' place across the pond in London.
I've done similar.
If you've got big data sets, the initial sync is still going to take a long time because
you've got a lot of bits to send.
What matters is the delta.
And when you've got a fancy copy-on-write file system, you just don't have to worry
that much.
So the crux of our test here at Linux Unplugged was that we modified every file with a few
pixel changes.
Our sync, it basically resynced the entire data set.
Both ZFS and ButterFS, despite the initial slowness maybe that you might contribute to
ButterFS on the initial files end, neither of them took longer than a second to update
all files.
That's a pretty big difference then.
So there's a huge speed difference.
They both offer compression.
What about encryption with ButterFS?
Okay, so now we get into real-world administration details.
Chris, I think it's fair to say that setting everything up, you kind of like ButterFS a
little bit more.
As a traditional Linux sysadmin who just over time I have learned I like things that are
built into the OS that are tools like just kernel-supported stuff.
And ButterFS to me works like a file system I'm familiar with.
I can just go make FS on a disk and it just is there and it's already installed when I
get going.
All I have to do is just install the programs if they're not already installed and it's
just supported in the kernel.
There's no DKMS module I had to worry about.
So those things, and actually not just those things, I got to be honest, the other thing
that really appeals is I'm very commonly working on VPS nows and a VPS system generally has
maybe two disks at most but often just one disk.
And you're pretty abstracted from like whatever that real hardware is, right?
You're not talking to the disk, you're talking to like a network interface.
And ButterFS just seems perfect in that scenario where ZFS, if I owned the box and I had direct
access to the physical machines and I was writing ZFS to the actual disk and ZFS was
managing the actual physical disk and the RAID and it was all top to bottom controlled
by ZFS, I think that would be a pretty good ZFS scenario, especially more than a couple
of disks.
But with ButterFS on my laptop or on a VPS, it just seems to work a lot simpler.
While I don't have a solution for ButterFS encryption today, I know it's coming and I
know I prefer the ButterFS administration style.
It doesn't mean our NAS here in the studio is going to switch off of ZFS though.
I'm not doing that.
No, of course not, well, so that's what's interesting is that it really feels like ButterFS
has a great default, right?
You have a mixed usage file system, maybe you've got some sub volumes that, you know,
they're archival, they're backups, they're things like that.
And then you've got other ones that are just sort of ext4 plus plus, whereas ZFS, you've
got to commit, right?
It doesn't just slot into the sort of Unix layering system, it doesn't slot into how
you manage any of the other volumes.
When you do a df-h grep cfs, well, you get the data set name, not the actual partition
number, right?
So it just doesn't play nice with some of how you might use the Linux system as an admin.
But at the same time, it's a standalone enterprise system and some of the biggest wins it has
are resumable send and receive, built in support for compression, and recently, native encryption.
So if you just want to send some snapshots, you want to catch things up on the other side,
ButterFS is the easiest way to go.
And I didn't actually expect this conversation to kind of go into this, but it is sort of
the logic for ButterFS, and maybe with Fedora 33 around the corner, it's on our minds.
But I'll also say this, and it's not as silly as it used to sound, but you're not going
to run ZFS on a Raspberry Pi.
And remember that number we just talked about have been 30 million Pis sold.
And that number is based on April data, so it's more than 30 million.
And you can run ButterFS like a champ on my Raspberry Pi at least.
You sure can.
So I think there's a lot of use cases for it still.
And so I think we've made our case.
There's obviously a lot of reasons why it's pretty great.
The send and receive functionality, though, is something that I really encourage people
play with once they start switching over to these file systems, whichever one it may be,
because this could change your backup game a little bit.
And think about it from an application restoration standpoint.
You could have a container host or a VM host, and you snapshot and you ButterFS or ZFS send
that and put it on another machine that's a hot standby.
Mount it as a sub volume, get going, spin the containers right back up, zero downtime.
It was kind of fascinating to see how much of a difference it was between ButterFS and
ZFS.
So like on our little test setup over at Linode, I was taking snapshots on ButterFS, I was
taking snapshots on ZFS, and in the ZFS world, it was like sort of a logical entity, right?
I had a data set, I would take various snapshots.
They wouldn't show up on the file system.
No, of course not.
Those were like logical entities that existed within ZFS.
But in the ButterFS world, those all existed, like you had to pre-plan stuff so that you
had like a top layer namespace that you would take snapshots underneath.
And if you want to do a send or receive in ButterFS, you got to make sure that those
snapshots are read only.
In ZFS, well, they're always read only.
That's good and bad because you get a little more flexibility depending on that and how
you think about these things.
It's just fascinating.
You can do the same thing on both.
I think ZFS has more maturity by far in the sense of encryption, native compression, and
resumability for send and receive.
But ButterFS has the advantage that it's just sort of built into a modern kernel you might
use.
That's true.
And you could turn on compression and take advantage of that.
And you could just not use any of these features.
You don't even have to use copy on write, and you just get a pretty decent file system
for your laptop.
I think that's what has me so excited about this.
This is what an enterprise grade file system does, is it has this kind of functionality.
And I've watched over the years as it's sort of been lacking on these Linux workstations.
We sell these machines supposedly for developers, but they have a file system that has the functionality
of the 90s or actually even the 80s.
Meanwhile, Windows has shadow copies and NTFS and with granular permissions.
I'm not a huge NTFS fan, but I have to admit they seem to have kept it in decent shape
over the years for what it is.
People has APFS, which offers not as many features as these nicer file systems that
we have, but definitely more than extended four has.
And it's just kind of expected on a workstation for the file system to have a workstation
grade functionality.
And now just by installing Ubuntu 2004 or by installing Fedora 33 in the near future,
you get this stuff and you never have to touch it, but it's there if you want it.
Along with a bunch of other really cool stuff that's built into these that we haven't even
touched on today.
But the send and receive functionality specifically is worth a little more attention.
Maybe it's a little early now, but we want to get it in front of you.
So that way when you start using a distribution with these file systems, if you don't already,
you can kind of see some of the advantages.
And we also want to arm you with actual knowledge about this file system, ButterFS that's built
into Linux and try to give you some counterpoints to what you'll always hear about ZFS and how
great it is.
It's not that it's a bad file system or it's not that it's a good file system.
It's different use cases and there are advantages to both.
And I hope we've made that point and I hope that we've given you kind of that ammo so
when you're in those conversations, at least for yourself, you know what the reality is,
is that not one file system is the answer to all, but the situation's getting better
for all Linux users over time.
And pretty soon I hope that it's the default on all Linux desktops, but that's just crazy
Chris.
And then we have some feedback we should probably get to because we're going to be going on
forever if we keep talking about file systems.
I don't know what it is, but we love talking about file systems.
Thomas writes in with a question about to do apps and this is something we need to talk
about because otherwise we just talk about file systems all day and I got to keep on
track.
So to do app is perfect.
And he says, you recently covered GNOME or I'm sorry, GNOME to do, which got me going
down a rabbit hole.
Thanks so much.
I'm looking for more to do applications.
I've settled on D task for now or DS task after trying task warrior and the gnome to
do list.
And I've also tried to do.txt for the CLI stuff and I've tried task book.
Wow.
I'd love to hear more about to do apps.
Is that something you've covered before on self hosted or luck?
If not, I'd like to hear more about it.
Well, I decided Thomas, we'd probably cover this one because I just kind of went all in
on to do list.
And so I thought maybe I'd talk about to do list a little bit.
You know, I've been using to do list as well.
I started looking at it again when they announced a quote unquote native Linux app.
That's always kind of, okay, it also works great on my phone.
It works on my watch, it works on the web and it now it works on desktop Linux and they
added support for Trello like project boards along with to do lists and they have support
for sharing those to do lists with other folks like the wife and I have one for the RV that
we just put stuff on individually and you know, I have a bunch for work on there and
I found it to work pretty well for me.
It's not the prettiest to do app, I gotta be honest, but it is super functional.
It has an API for days.
The integrations with to do list are just mind bending.
It's just mind bending.
And on top of all of that, it seems like it's going to be around for the long haul.
I've watched them for a couple of years.
They seem pretty solid as a company.
They seem to be iterating at a pretty decent pace and adding decent features and the more
I drill into the application, the more I find that it does like I have this situation where
I have to again call back to Verizon wireless and so I just keep all of these notes for
every time I call these these people and I try to get them to cancel my line, I get it.
I have it right in there and I have all the details in my call notes and I find that to
be super handy.
Plus it supports a lot of plain English stuff for scheduling and whatnot and the mobile
apps decent too.
So I recommend to do list any anybody in the mumble room have suggestions for to do app
that works for them.
Super productivity is one that I've started using.
I got a reference to that from another podcast and that was it.
I'm kind of amazed at how it makes things better.
It's not just doing to dues and note taking and stuff like that, but it also integrates
with managing issue tracking workflows and stuff like that.
It might be a little bit more developer centric than to do as it is, but it's it's certainly
starting to help me out a little bit in balancing like what I'm trying to keep track of and
what I'm supposed to do and things like that.
Nice.
And the name was again.
Super productivity.
Nice.
That sounds like it.
That sounds like one worth looking into as well.
Drew, do you have one that you use any kind of like to do list management at all?
Yeah, I do.
But I like mine to be super duper simple.
I don't think that a to do app needs to have a whole bunch of bells and whistles.
So I actually just use Google task and it works great for me.
Wow.
I thought it'd get killed, but it seems like it's sticking around.
They seem to be integrating it more and more with different aspects of the Google app suite.
So I think it's in for the long haul.
Well, there's a couple of ideas right there.
And if you have any others and you're screaming them at us right now, you can always throw
them in the telegram group.
Go to broadcasting.com Telegram, join up and tell us about them.
I'd like to know.
I'd like, you know, we get if we get a batch of them, we could always do a little to do
pics special.
I suppose I want to say thank you to our core contributors.
Those of you that are supporting the show, we really appreciate it.
You're making the show possible and you get more show.
You have a choice.
You get the fully uncut live stream with all of our mistakes, but also a lot more content.
Too much content.
Is there ever too much Westpain?
Really?
No, probably not.
No, no, you can never have enough Westpain.
And there's two options for you.
You have the limited ad feed, which is fully produced, the fully edited show with the nice
mix and all of that, just with limited ads, or you get that full live version.
Thank you for making the show possible.
And if you're interested in supporting the unplugged program, if you want to become a
member, you can go to Linux unplugged.com and if you look right along the top there,
we have the links to send you over to our core contributor page and you can sign up
and then you get the feeds for the extra content and support the show.
Also over on the website, along with all the show notes, we have our matrix server info.
If you've been wondering about that and our mumble server info, if you'd like to join
us on a live stream, we do this show on Tuesdays at noon Pacific, 3pm Eastern, but get it converted
at your local time at jupiterbroadcasting.com slash calendar.
All right, Mr. Westpain.
See you next week.
Same bat time, same bat station.
Wait, do we have a bat signal?
I thought it was a penguin.
I think it's Twitter.
You know, when we just tweet that we're live.
You're right.
It's a at Linux unplugged, right?
Yeah.
That's the new bat signal, I think.
It's got to be.
Or the telegram group.
Cause I often post it in a telegram group.
So that's, that's another way to know when we're going live.
Thank you everybody for tuning this week's episode of the unplugged program links for
the topics and stories we talked about and information about the file system features
we've been going on about linuxunplugged.com slash three seven three.
Thank you so much for tuning into this week's episode of the unplugged program and we'll
see you right back here next Tuesday.
So, Hey drew, Hey Chris, Hey drew.
If I wanted to throw an audio job at this Dell for a review, is it possible to script
a Reaper series of actions so that I could import audio, process audio, render audio
or encode audio and then just run it over and over again?
Uh, maybe, you know, getting into the scripting thing isn't something that I've done a ton
of.
I picture you sitting in front of Reaper and you're kind of like just like executing all
kinds of automations and you're, you've got like a VR headset on and like a Nintendo power
glove and hence stuff is just like flying on the screen.
The power glove is key.
I was actually picturing drew with like one of those duck hunt, uh, you know, those orange
guns that you see.
The little light gun.
Oh yeah.
They're shooting at mistakes and they're getting cut.
