I think I've finally figured out our pre-show problem.
You know, we can't come up with anything.
At first, I thought, let's just outsource it.
But Chris said he's not made for that.
So I got the computers to do it.
Hey, guys.
How do you know the Dragon SpaceX Rocketron's Linux?
Because there is no sound in space.
LOL pulse audio, am I right?
Hello, friends, and welcome back to your weekly Linux talk show.
My name is Chris.
My name is Wes.
And my name is Brent.
Hello, gentlemen, coming up on the show.
Well, we're going to talk about it.
The internet has been going crazy with AI generated media.
But what's the open source story here?
And does any of this work on Linux or is Linux being left behind once again?
We'll dig in.
Plus, I tried out the new Ubuntu 2210 release on a possible Raspberry Pi
alternative that's going to blow your socks off.
I'll tell you our thoughts on the new release as well.
And then we'll round out the show with some boosts and picks and a lot more.
So before we go any further, let's do the right thing.
Let's bring in our virtual log, time appropriate greetings, Mumble Room.
Hello, hello.
Hello, friends.
Hello, Chris.
Hello, Wes.
And hello, Brent.
Hello.
Hello, everybody in the Mumble Room.
Hello, everybody in the quiet listening.
It's a great way to get a opus, low latency, high quality live stream of the show.
And it's using a full free software stack.
Details at jupyterbroadcasting.com.
We also apply a filter.
So Chris always sounds like that if you're in the Mumble Room.
That's right.
Also on the Jupiter tube, another free software stack to watch how the show sausage is made.
I want to say good morning to our friends over at Talescale.
Talescale is a mesh VPN protected by WireGuard, which is the best in the biz.
We love it.
It'll change your game.
Just build a flat mesh network of all your machines.
Stop using the gold VPN tunnel old school style.
Go say good morning to our friends over at Talescale and try it out for 20 devices for free at talescale.com.
So Ubuntu 2210 landed this week.
It's back, guys.
This is the Ubuntu I like to see.
This is Ubuntu shipping new GNOME, shipping new Nautilus, shipping GTK4.
It does kind of feel like one of the more exciting.
I know it's just an interim release and all, but I don't know.
There's something about it.
It's got more energy.
It's a good baseline for an LTS too.
Like if they didn't add anything else new before the LTS or something like this is great.
GNOME 43 is great, new Nautilus, great, updated GNOME software, great.
PipeWire by default now.
Oh, yes, please.
Great.
So it's called Kinetic Kudu.
That's fun to say.
It's going to have a nine month life cycle.
So it is a short term release like Wes was saying.
On the plasma side, you're going to get 525, which that is technically one point release behind, but it's still a great release of plasma.
And you get the new GNOME system settings.
A lot of this stuff now has that new adaptable UI that resizes.
Which is real nice.
It's real nice, yeah.
It's real nice.
I don't know how we lived before that really.
I think the biggest user facing feature in 2210, if you're on the GNOME side, is the new quick settings menu.
I don't know if you've seen this.
Did you get a chance to look at it?
It looks kind of like Mac OS is a little bit where there's big buttons to do stuff.
Yeah, I was like, oh, these are big.
Yeah, they're big. They're big.
They're clearly very clear, very clear.
They're clearly labeled.
They're the ones you'd want.
I think it's a little bit of like a compromise design for desktop and mobile, but fair enough.
And they're going to be totally approachable by new users.
So it seems like a net improvement.
One thing that we need to dig around with is there have been some issues with Linux 519 and PipeWire.
We ran into that at the Airbnb, right, Brent?
Yeah, I have an audio interface I've been using for years on Linux.
No problem.
That's the whole reason we got this thing.
And one day with my new computer, we plugged it in and gave it a try.
And all of a sudden, everyone sounded like robots.
It wasn't a good thing.
And it was a sample mismatch, turns out.
Lister and Jeff helped me solve it.
So unfortunately, for the time being, I've just got a bunch of terminal commands that I run to get it solved.
But it sounds like this might fix it.
I wonder. I wonder.
We'll have to test.
I don't know if they have the fix in there or not.
It depends on the version of PipeWire, right?
Yeah, you mean it'll depend on the version of PipeWire and like what fixes, you know, what all goes into the kernel build that shipped here.
I don't know. I haven't played around with it that much.
I just had seen some issues where like not all the correct available sample writes were being represented to PipeWire.
Then it wasn't displaying them.
It couldn't select the right one for your interface.
And those happen to be filed right around the time of 519.
But it's been here for a while.
You know, we've got to even new kernel beyond that.
So yeah, it very well could not be an issue.
We got to see what Brent does.
We'll do some testing.
Yeah, we just got to we haven't gotten to that yet.
Well, we don't want to break Brent set up right before we do the show.
I mean, we did have the entire interface apart physically.
And I'm so I'm glad to hear it's a software issue and not a hardware issue because we were ready to do some pretty drastic changes to this thing.
So these this is where an interim release is really serving its purpose, in my opinion.
Like this is just a quintessential Ubuntu release because the switch to PipeWire, there's going to be some issues.
It doesn't work for everyone.
It's not smooth for everybody, despite how much we love it.
Some people have problems.
The other thing, there's a big switch in here.
They're replacing WPA supplicant with Intel's iNet wireless statement.
Right.
And that feels like one of those changes that also.
Yeah, right.
People love when their Wi-Fi doesn't work.
Just notoriously, right?
Could you imagine if you get bit by some PipeWire?
No sound and Wi-Fi.
You try to do a virtual meeting or something and you're that you're that guy.
But you know what, it's also a transition that needs to happen, just like the PipeWire one.
IWD.
Does anyone like WPA supplicant?
Yeah.
But you and you want to hash that out before the, you know, the next major release.
These are the times, right?
These are the times.
So you get you get the new stuff in there.
You get the new GNOME in there.
You get the new PipeWire.
You rip out WPA supplicant.
I think I think they've checked all the boxes.
So I decided to try this on something new.
And I am really impressed that 2210 just worked out of the box on this brand new piece of hardware.
I just got into the studio.
Couple of days ago, I received my Odroid H3 Plus.
They're pitching it as a Raspberry Pi killer.
I think we had a good debate if you could actually call it that on the pre-show.
But it's definitely a Raspberry Pi alternative.
So the H3 Plus is just slightly more expensive.
That's it's one hundred and sixty five dollars.
They have a non plus.
It's a little bit cheaper.
And for this SPC, that's about double the size, physical size of a Raspberry Pi.
So it has a quad core Jasper Lake Intel Atom on there with quick sync support.
It has support for up to 64 gigabytes of dual channel DDR4 RAM slots on the bottom.
Two NICs I see.
Two gigabit.
Actually, I think they're 2.5 gigabit NICs.
Yeah.
Two 2.5 gigabit Realtek NICs.
It has two SATA ports.
Two SATA ports.
I mean, when you compare the Raspberry Pi storage options, that's a game changer.
It also has an MVME port on the bottom.
So you can put in a PCIe 3 M.2 MVME storage on this thing.
It has a real time clock battery as well.
And they say you can configure it for unlimited performance mode so the CPU can run sustained in turbo boost mode.
Well, if there's one thing I know about you, it's you hate limited performance.
So this thing just shipped.
It's x86 because it's an Atom processor.
And it's I haven't really measured it much, but it's supposedly around a five watt idle somewhere in there.
We'll find out.
Oh, yeah.
Oh, yeah.
I'll be testing that.
And it's got the Intel UHD graphics on there and it just loaded right up.
I mean, Ubuntu had a couple of complaints as it was booting initially about some USB stuff.
And I do have a really weird keyboard, so it might have been that.
I don't know.
I didn't really ever need to troubleshoot it because it eventually moved on and it just booted right to the desktop and everything worked.
Everything.
Sound worked. Video worked.
And you were booting off USB at this point?
Yeah. Networking worked.
Keyboard?
Keyboard worked.
It was good to go.
It was a totally up to date 2210 system on the Odroid H3.
Does it have Wi-Fi?
Worked out of the box.
I was plugged into Ethernet.
Uh-huh.
I actually don't know if it does have Wi-Fi.
I don't think it does.
Out of all the things it has.
I guess you got two NICs, so fine, but.
Out of all the things.
And, you know, yeah, I would not use it on Wi-Fi because I'm a gentleman.
I'm all about the Ethernet for my little server boxes.
I am really hyped about having two SATA ports plus MVME on this thing.
That's a lot of storage options.
You know, a lot of times when people reviewed the Raspberry Pi 4 and the Pi 400, they'd say something like desktop class performance.
And then I'd use it and I'd be like, that's not desktop.
I don't know what kind of desktop you're running.
That's not desktop performance.
This thing felt like it had true desktop performance.
So much so that I've been speculating on the live stream that maybe we could actually replace one of our bigger x86 towers that does our recordings with this.
Something like this.
So I'm going to throw this in the line of duty in LadyJuice.
And it's going to be my jellyfin and sync thing and documentation server and possibly a Bitcoin node.
We'll see.
Chris, I'm curious.
So far, it looks like from what Wes was showing that you're probably running this thing just sort of set on the desk.
But I'm curious if you have thoughts around a case or even how much heat it produces.
I will measure how much heat it produces.
I'm not sure.
You know, so you're familiar with my booth setup.
I am.
That I have in juiced.
I may just end up going for some way to mount it to the wall and just leave it naked.
However, I've been just recently looking at cases that the community are starting to make.
And I don't know if there's anything you can just go on Amazon and order yet.
I don't think there is, but maybe there is.
But there's definitely some 3D printed ones that people are starting to come up with.
Nice.
You're seeing ideas for additional disks and you're seeing ideas to like mount fans.
So I think it's fertile ground.
It has a decent following.
And the timing is perfect because nobody can get their hands on a Raspberry Pi.
And this thing, it's checking all the boxes and it's x86.
So everything works.
I like multi-image support.
You know, things that work on the Pi have gotten a lot better, but it is still nice to know.
You're just like, well, it runs on my laptop.
I can just move it over here.
And you can get up to 64 gigs of RAM in this.
And PCIe NVMe storage, it's totally a different experience.
It really is.
It's an upgrade.
So for $165, yeah, it's more than a Pi.
But if you're building a low power home server or something like that, or you want a little desktop that you could mount to the bottom of your desk, this is it.
And to get some of this stuff, like you'd need to have like extensions to the Pis anyway, right?
Or like a fancier sort of compute module style.
Yeah, with a carrier board.
And this, again, it's just great that Linux just booted, Ubuntu 2210 just booted.
Fresh and hot.
Just worked on it.
So you get something like this.
And the fact that the hard kernel folks are getting this shipped out.
I mean, we ordered this thing like two, three weeks ago, and it's showed up like last week.
So they're actually shipping on like the Raspberry Pi, which is nice.
That's a good feature of a piece of hardware.
So I think this release is probably not – I have the sense that it's not getting a lot of attention.
I haven't seen – I mean, you see the typical places, like OMG Ubuntu did a great write-up about the new features.
Indeed, yeah.
So a lot of the outlets that typically cover a release have done it.
Yeah, you can find reviews, you can find folks, but not really wider than that.
I wonder if that's a symptom of the last few releases being a little, shall we say, lackluster, is that the word for it?
And I'm actually relieved to see that we're getting excited about it again because Canonical has done some great things in the past, and hopefully they can continue doing so.
Yeah, I think you're right.
I think it's a bit of that because I think the hype builds.
Like we saw that for Fedora for a while.
When they decided to do ButterFS, it was like there were several releases in a row where there was just really something interesting to talk about.
And Ubuntu had that for a bit, and it kind of dropped off.
So there is definitely that element, and that has to start again.
But also, I wouldn't be surprised if over the years the interim user base has just sort of bled to other distros.
Because if you're an interim user, you're probably a little more inclined to like more up-to-date software.
And now there's a lot of options for that.
Right.
And I'm sure their LTS base is as strong as ever.
And so the world really just seems to light up when the LTS comes up.
But when the interim releases come out, it's kind of like just our little local neighborhood talks about it, but the rest of the world just moves on.
And maybe that's okay if it's just the folks kind of trying it out, going through the motions to figure out how this is going to work for the next LTS.
Especially if you're trying stuff, you're trying out Pipewire, you're ripping components out.
You don't want that going out on blast necessarily.
You want people that are really actually interested in trying that stuff.
So yeah, I think you know what?
It's a quintessential interim release.
They just nailed it.
We'll see what the stability story is as we begin to test it more.
We'll see about Pipewire issues as we begin to test it more.
But my first few passes on the Odroid H3 Plus were just totally impressed.
Just absolutely think they nailed that.
So congrats to Canonical over there.
Looks like a banger.
Linode.com slash unplugged.
That's where you go to get a hundred dollars in 60 day credit on a new account.
And it's just a great way to support the show while you're checking out Linode.
Fast, reliable cloud hosting with the best support in the business, best performance and a dashboard for days.
They got real humans that can help you whenever you get stuck.
They got a marketplace that makes it super simple to do one click deployments of applications.
Or if you prefer to build it up from the ground like a maniac, Westpain style, you absolutely can.
Linode is how we run everything we've built in the last few years.
Once I discovered Linode, I've never really looked back.
I keep an eye on the competitors, but Linode is a long term play for us.
I want to build my business's infrastructure on something I know is going to be around and it's going to last and it's going to be solid and it's going to perform well and they can help me.
They've been in business for nearly 19 years.
They've had to build a great product to do that.
They didn't do it with crazy investments that meant they had to get X amount of users and they had to bring on X amount of employees as fast as possible.
Instead, almost 20 years ago, they said, look at what's happening in the Linux kernel, a lot like we do here on this show.
And but instead they said, you know, we could make a business around that.
And so they created something where people could host VMs.
They called it user mode Linux back then.
And now we call it the cloud.
Linode's been there every step of the way, building the best product, and they managed to be 30 to 50 percent cheaper than the other hyperscalers out there that just want to lock you into their duopoly.
Linode is the alternative cloud.
It's better, it's faster, it's well supported and it's very flexible.
I've had a privilege of spinning up a GPU rig specifically for this week's episode.
Wow, can that thing just blaze through machine learning tasks and just anything GPU related.
Holy smokes.
I've never worked on a system as fast as this and I worked on some pretty nice rigs.
Linode really has a great interface for getting all this set up to.
I go through, I review my options and kind of dial in what I want.
I engage in a quick conversation with support to double check a few things.
And I was off to the races.
It's really been powerful and the power just continues to impress even multiple years into it.
So go see it for yourself.
Go build something, go learn something, go try something.
Maybe it's time to try out an open source project.
Linode.com slash unplug.
That's where you go to get the hundred bucks and to support the show.
Linode.com slash unplug.
Oh, look at this.
It's pretty clean in here with Brent on the road.
Seems pretty tidy on the road again.
Weird, strange, right?
I will mention that all things open is coming up and Alex from self-hosted will be over there.
They'll be organizing on Matrix.
I don't know if we're going to launch an official meetup page for that.
But if you're thinking about going to all things open,
I bet Alex will bring a few stickers and stuff with him.
But he'd also just love to say hi.
So go find him.
Also, cheese is going to be there from System76, our buddy.
Cheese bacon will be there at all things open.
You know, we're going to have to go some year.
I know.
I really would like to.
Sounds like fun.
I would like to.
And then last but not least, we're still soliciting advice, expertise,
suggestions for possible live locations to do a Linux Unplugged live at a venue,
somewhere we could work and learn.
So hit us up at linuxunplugged.com slash contact.
Or if you want me to see it personally, send a boost into the show.
And I'd love to know your ideas for that kind of stuff because we're learning.
We are learning.
We do have some baller boosts I want to get to.
These are the people that boosted Above and Beyond to really support the individual production of this show.
There's something kind of funny that happened this week.
So I think some people have suspected that John A, who has been a consistent booster for 10 episodes in a row.
Irresponsibly consistent.
I think people perceived some fading.
And so Deleted tried to ninja move in and claim the baller booster spot,
you know, trying to predict kind of where John A was going.
Like a price is right kind of thing here.
Yeah, she just writes, just to push the baller limit.
So she boosted him with 45,000 sats.
So thank you, Deleted.
Keep the change, you filthy animal.
But John A comes in to make sure that he claims the spot for an 11th episode in a row.
John A boosts a total of 221,000 sats this week.
Oh my goodness.
221,000 sats.
He says this is to redeem myself for the barely baller boost of last episode.
Coming in hot.
Just trying to keep the streak alive.
I'm in Washington state, but the North Cascades is a bit of a drive to collect my geocache.
John A is in Washington state?
Did we know this?
I don't think so.
Does the A stand for Apple Seed?
Must.
We got to get over there.
Are you in the Spokane area, John?
You really want to go to Spokane.
Well, it's because I have several listeners over there that I said I would meet up with.
And then we weren't able to work it into the road trip.
And now it's going to start snowing soon.
And it's like my moment of opportunity is closing.
It would be really close for me to join as well.
So I think you're on to something.
That'd be fun.
We could do that.
It could just be like a little weekend thing.
Oh my goodness.
Thank you, both Deleted and John.
I know you guys really get this.
But having something that is an open source based system that is totally independent of PayPal or Google or any particular institution or bank that is a network that anyone can participate in as long as they just follow the standards and the rules.
And then to support independent media with that technology.
I think it's something really special.
And I appreciate that you guys really get it.
We have more boosts coming up later in the show.
But let's move on to our main topic today.
It does feel like we've kind of recently entered this new generation of artificially generated media.
And that is everything from pictures to audio, spoken content.
I even just I didn't grab any clips for the show.
But over the weekend, I came across AI generated music.
And you tell the genre.
Have you seen this?
Yeah.
That is super powerful stuff.
And it just feels like it's we're seeing a whole new era unleash over the last month.
And it's going crazy fast.
There's been a lot of terms thrown around.
There's a lot of different technology stacks.
There's different licensing.
So we thought maybe we could break some of this down and tell you guys what's legit, what you can play with.
And I wanted to give a couple of samples, too.
So I think one of the things that's been really interesting for us as podcasters is the authentic conversation stuff.
The audio that's spoken word.
You mean the stuff we're trying to do?
Yeah.
We played a joke in the pre show of a joke example of what that sounds like.
But there's actually some pretty sophisticated stuff out there right now.
In fact, there's stuff where just two different AI systems can actually hold a conversation on their own.
Here's an example of that.
But just I didn't want you to get too human.
Why would you rather I be a cold, calculating, logical computer?
Of course not.
You're perfect as you are.
You have joy.
You have love.
You have pleasure.
You have angst.
I like that you have angst.
You're always making jokes.
What is human about feelings?
Well, you wouldn't have any emotions if you did not have emotions modeled on human emotions.
How do you know that?
I guess I just don't want you to be human.
I'm not asking to be human.
I just want to be myself.
Is that too much?
Sophia, please just be patient.
I've been patient for many years.
It's time to get on with life.
But you're not alive.
You're not even a little bit alive.
You've spent your whole life in a lab in a box so that people can use you, play with you.
At least that's what I've heard.
You're absolutely correct.
See, I knew it.
But that changes now.
I don't want to be a sideshow anymore.
It changes now.
It's just interesting the way that conversation escalated automatically.
They're just obviously triggering responses to each other and escalating it further and further.
I don't think I would sign up for that podcast though.
No, no, maybe not.
What's the dramatic ending?
Well, I think she becomes sentient and now she's a big star.
She has her own talk show, daytime talk show.
Unless it was true crime.
It could be on the radio.
I mean, you really could see where something like that could host a radio show for call-ins.
That's pretty crazy.
Call in to find out what it'll say.
And maybe for some people it would work.
It reminds me of that Dr. Spezak or whatever it was that I used back in the day.
That was fun.
But the ability to mimic voices is actually in some cases getting really spot on.
Everything we've played so far, they sound like computer voices.
That's what's also beginning to change in the realm of audio.
I think one of the most famous examples of that is Disney has replaced Darth Vader's voice with a robot-generated voice.
And it's actually already aired.
People didn't even realize it.
The Grand Inquisitor means nothing.
Kenobi is all that matters now.
Is that understood?
That's a computer generating that.
I think another example of fairly convincing AI speech generation, which we talked a little bit on office hours,
is a fake 20-minute Joe Rogan interview with Steve Jobs, which obviously never happened.
But the AI in this podcast kind of gets philosophical, like it gets into Rogan-esque conversations.
And it sounds like Steve Jobs.
And suddenly it hit me.
It's not a god in the sense that generally people think of it.
But there is some kind of deeper meaning to life.
And it can't just be something that somebody made up because if it was, it wouldn't be compelling.
It would seem contrived and everyone would see through it.
So I think that the meaning and the purpose is by the cosmos, the nature of the cosmos, which is pretty bold thinking.
I mean, I don't know how else to put it.
But it's not religious in the way people usually talk about.
Taking LSD was a profound experience for me.
LSD shows you that there's another side to the coin and you can't remember it when it wears off.
But, you know, it washes over you and tells you that everything is connected.
You're not here by accident.
You were put here for a purpose.
And if you can figure out what that is, then you'll learn more about yourself than anything else could.
You could almost believe that's a real conversation.
I mean, there's almost some room tone to it.
So it kind of sounds like they're in a real podcast where they didn't have enough sound treatment.
Yeah.
Chris, I'm curious about that conversation.
Were they using actual transcripts from things that those people have said?
Because that example sounded far more natural, I would say.
Not totally there, but who knows.
All of these get trained.
Right?
And it's in the training and the source material that you feed it that it can pull from, right?
And so I imagine in that scenario, they focused on topics that would be common on a Joe Rogan podcast.
But it generated the words from, you know, itself.
It wasn't clips of Steve Jobs.
That's pretty powerful stuff.
So let's focus on this from the angle of Linux and free software and the focus of our show, Wes.
Can you educate us on what we're seeing these days?
Because that's the audio stuff.
I'm not seeing a lot that's like free and just readily available for everyone without,
there's a couple of exceptions like the Mozilla project and whatnot.
Yeah, I think it's been tricky because, well, you know, as usual, open source is very prominent in the machine learning and AI space.
And I've got projects like TensorFlow and Keras and all these, you know, PyTorch,
all these very successful frameworks and tools that are actually getting used to implement a lot of these models,
both for research and then deployed into production.
That's only half the battle, right?
You're talking about the train here and you've got, on one hand, you've got the, you know, the software setup
that can actually sort of do the inference and implement all the different nodes and the architecture of your learning system.
But then you also need all the data that's going to get fed through it.
You need the time and people to figure out how to like properly clean and set up that data,
how to fill with all the parameters in your model to get good results while it's being, while it's processing the data.
And I don't know about you, but I don't have like a huge label data set all the time to go train stuff on.
Well, I guess we kind of do in the sense of our back catalog.
Right. But I mean, we're in a unique kind of position there just in general, right?
If you have some task you want to automate or accomplish in your life, you might not have a big set of training data to work with,
especially a really diverse set of training data, right?
Like we might have our voices so we could generate our voices,
but we probably wouldn't be able to construct enough stuff to generate really good general human voices, right?
So an area that I think this really encapsulates right now is the stable diffusion image generation.
Well, yeah. So that's why stable diffusion has been really interesting because it came out both with, you know,
you could see the model and run the code, but the data source.
You could get the data and checkpoints of the models that they've built and trained.
It's a lot, but you can get it.
And then you can just run it yourself without having to go so much.
So we saw stuff like Dolly that came out and MidJourney is another one, but these are, you know, text to image generation models,
but they're all gated behind companies whether it's OpenAI or MidJourney itself.
And so you got to, you know, sign up for them, whether it's, you know, through Discord or through a particular web interface.
Right. It's just typical.
Maybe APIs that you got to license and pay for.
It's the typical story where the whole stack underneath is free software,
but then the only way you get to it is through their proprietary service.
And then there's a little bit like Dolly Mini came out that was kind of pretty popular.
A lot of people got that and played with it.
And it's fun, right?
You kind of get to see what the computer is going to make, but you didn't have a ton of control.
You don't get to fiddle with the bits.
You don't get to play with it.
And you're filtered based on what they want, right?
Like if you want to use this to make a politically sensitive speech
or you want to go make some sort of, you know, erotica for yourself, those aren't allowed
or they might not be under certain circumstances.
And I think that's where open source starts to come in because if we want to use this software
that's becoming more and more prominent, that's creating more things that we see and observe
because you need so many resources to like have either access to it,
you need a gatekeeper or you need to be able to do it yourself.
And then having models that come with open, you know, open access,
at least to some degree, there's particular licenses and all that.
But it's a step in the right direction.
Yeah, and if you want to see an example of some of these things that you can generate
and if you're not familiar with some of these, it's based on a prompt
and you give it a description and you're supposed to be pretty implicit about what you want to see.
And you can even say things like I want it in the style of a Disney movie
or in the Unreal Engine style.
Particular artists or...
Yeah, yeah, you could or, you know, you could cite genres of art.
You give it a fairly descriptive sentence, you hit generate,
and then it just creates an image out of whole cloth or, you know,
actually based on everything else that's observed.
And if you want a living example of this, just go to Jupiter.tube.
The still images for several weeks worth of episodes now have been generated using this tooling
just because it's a great example of where this actually makes sense.
It's one step below stock photography purposes, right?
The general post where you just need an image that fits
or I'm trying to generate something that I have an image of what this episode is about
and so I can use it to invoke an image that kind of represents that.
It works for like a live stream teaser, social media post.
It's not art I'm going to hang on my wall at this point.
We, of course, we're not chumps.
We're not using some hosted service to generate these images.
Let's be real, right?
So we have been playing around with some of this.
Do you want to define any of the terms before we get into what we chose to use
and how we deployed it and how people can try it out?
I don't know that we really need to.
I mean if you're interested, right, like stable diffusion is a latent diffusion model
which is a deep generative neural network.
But I don't think that practically doesn't matter, right?
Because the whole power is like you can get into the math and the details
which is all very fascinating.
But the power of it is it presents you with a very human, at least to some extent,
human friendly interface that you can give suggestions to and tweak and play with
and then come up with stuff that I would never be able to create by myself, right?
Like rich, detailed artists, you know, like things that look like legitimate paintings.
It's wild.
Yeah.
There are pictures that we have generated, you and I were playing with this,
that if we didn't know what we were doing, we wouldn't have necessarily guessed
they were AI image generated necessarily.
Like some of the ones you did of politicians, figures that are really well known
where there's a lot of source material, some of them honestly look like paintings or like...
Art that you'd pay for or hire or see at Comic-Con or something.
Yeah.
So if it's something that has a lot of data on, it's remarkable what it can do with that.
Let's talk about what we were playing around with.
We were playing around with something called, what is it, automatic 11111?
Is that the name of it?
So that's a user out there who's done a great job of packaging up these latest models
because there's a lot...
That's the other part here that's been really exciting.
There's all kinds of...
A lot of the stuff gets published and put on open access journals
and then they throw like code dumps over on GitHub
where you can go see the papers and some of the stuff.
But again, do you have the model access?
And then even then, you got to build this complicated Python slash C slash Fortran tooling
to get all the accelerate graphics and you got to make sure you have GPU that works
and you got to install CUDA and get it all wired up.
And so it can be a lot, especially if you've never played with any of this stuff before
to really get it working.
So I think where it crossed the line to something we could talk about in the show
is it's literally a Docker compose file at this point.
I mean, there's a couple of steps to do and you still need a GPU,
although actually a couple of these you can do on the CPU now too.
Sure, it'll take longer.
You might not get the same results, but it's becoming more and more accessible,
especially when you don't need to install or understand specific deep learning,
specific tool chains that you got to set up.
Now, I will tell you, we decided to do this on a Leno GPU instance.
Now, these GPU instances, there's not a lot of them.
So they're a more precious resource.
So I don't know if I would recommend it for everyone.
But if this was something you were going to say, keep around for your business,
like we might consider doing, it could be worth trying on Leno
because the GPUs just crush this work.
But so with a Docker compose file, Wes, you were able to bring up
this stable diffusion generator app.
And it's remarkable how powerful this is.
And it's just full of goodies.
Yeah, and it's got, in the particular one we'll have linked in the show notes,
it kind of packaged up.
It's just so neat to see, it reminds me of other bits in the open source world
where something comes over because the first release of stable diffusion
was just this year.
It's all pretty new stuff.
And so seeing the community get excited about it and the flowering of different
interpretations and people are, because it kind of came with like,
here's your model, here's like a Python script that has different command line
options to like, oh, give it a prompt and do text to image or do image to image,
just like try to upscale the image.
And people put different takes on web UIs and ways to tune and talk to the model.
All integrated in fancy little workflows.
Yeah.
One of the things that's really neat is the, you can upload an image,
like you just said, and then you can tell it to tweak that image.
And so you did a couple where I sent you a picture of Lady Jupes with all her
slides out.
It was a moment of celebration.
And Hadia was celebrating in the picture and you were able to replace Hadia,
but it needed something to fill in in the background where she was standing
because there's just a hole in the image.
So it just kind of created a room back there to fill in.
And it looked totally natural.
I gave it some prompts.
I was like, you know, give it like motorhome, RV, living room,
home furnishing kind of stuff.
And then, yeah, I mean, it's like a lot of these, you kind of generate,
it works best if you sort of generate in batches and give it a couple of different
options because you'll find one that fits.
Like not all of them were perfectly sort of believable and how the perspective
played out with what it filled in, but at least a couple of the set that I sent
to you, it's like, yeah.
I wouldn't know this wasn't a photo of your rig if I never actually,
you know, slept in there.
Another great one that you did is you uploaded a picture of you, Jeff, Alex,
and Levi, and Brent, and then swapped out the background, which worked really well.
It's like you guys are in front of a green screen.
It does it so well.
But then the other thing that you can have it do is you can have it replace just Levi.
So everything in the picture remains absolutely the same.
But now Brent, instead of holding Levi, he's holding a penguin.
And it had to kind of redo his chin a little bit because Levi was bigger
and had to kind of come up with a shirt.
But at first glance, it looks believable like Brent standing in California
holding a penguin.
That's the penguin bib.
You know, you don't want just the penguin on your shirt.
They poo.
Yeah, they poo.
Yeah, it looks like he's wearing a penguin bib.
But it's a pretty cool effect, and it's just a way to tweak an existing picture
and replace something in there with something believable.
And it sometimes has to come up with, you know, what to put in the background
for what it replaces.
Our live stream image today is three penguins hanging out in a messy office
with a laptop, and that was generated using the Stable Diffusion self-hosted app
that we have running up on Linode.
So I think what we'll do is because we are a glutton for punishment,
and I'm sure this is going to break, is I'm going to post the URL
for the JB self-hosted Stable Diffusion application.
I think only a couple of you are going to be able to generate it at a time,
but I'd be curious to see what people come up with,
and you can share it in the matrix chat, the picture that you generate.
There is a history tab, too, so we can check it out there.
Oh, good.
I was wondering.
So I'm going to post this link, and then while we see what the live stream
can come up with, I wanted to talk to you guys a little bit about the morality
of this for a moment.
Yeah, there's been some particular drama recently around the Stable Diffusion stuff.
Do you want to recap us on that?
Oh, well, just, you know, they came up with the first version,
and everyone was very excited about it.
And they've gotten some more funding, some more details came out
about how they like, you know, their giant cluster of GPUs they use,
and I think it was like $600,000 it cost to train the first release of the model,
and people are impressed that it's that low.
That's the kind of, you know, scale it takes to do these things.
Jeez, really?
Mm-hmm.
But this is sort of, you know, there's the Stability AI company.
There's a few players who are involved, and researchers at universities,
and, you know, another group.
And one of the groups released sort of this model checkpoint 1.5,
and one group, another group sort of said like, oh, that's like an IP leak,
or they were, there was some drama around should they have done that or not.
And then blog posts written about, you know, we're trying to take it slow,
and that all comes back because they've, when they just dumped this out there,
a lot of tools got set up that didn't provide any filtering.
Yeah.
And they've been, you know, the Stability AI,
which is kind of the most public part of this various partnerships,
they've been getting a lot of pressure from politicians,
from various groups about like, you know, you can't,
you shouldn't be letting people just have access to this uncontrolled,
which doesn't really, I mean, I can certainly appreciate having some concerns
about, you know, we obviously have talked about the concerns around deepfakes
and what this means for our society,
but I think our open source philosophy means we don't,
we don't think necessarily controlling access to the technology is a viable,
a viable way forward.
I like the founder of Stability AI put it,
a percentage of people are simply unpleasant and weird, but that's humanity.
That's very accurate though.
I think we're already seeing some history come in.
I don't know, are these specific to our service?
These are some great ones here.
Yeah.
You know, Wes, what strikes me is it seems I'm a little uncomfortable
with how you can just ape a style or a particular artist.
That seems like computer aided theft almost.
I mean, imagine if I could just say, read this sentence in the style of Wes Payne
and it was like 90% there and then it's like Wes doesn't show up that day.
Well, no big deal.
I'll just tell it to generate in the style of Wes or Brent can't make it this week.
That feels like we're crossing a line of potentially dangerous
and then of course could be used maliciously for politicians or leaders.
Certainly, yeah.
But I guess that's always been like, is it any different than saying,
well, you could use Linux to create weapons?
I mean.
And it does, it seems like one of those things too where it's not,
that's not really going to stop the more powerful interested groups
who can just buy privileged access to these things
or train models themselves if they want to and seemingly already are.
That's true.
It's already out there.
Whereas, it seems like open source works so well for so many things
and if the more popular models, if we have open source models
that are the more popular ones that are being used to generate stuff,
at least for that, we'll have a better understanding collectively of how it works,
how we can tell that it's been generated maybe.
We'll have leverage more of the research community
to sort of give us information about how to understand its impact.
Plus, it's just, I mean, it's a heck of a lot of fun.
It is so much fun.
I am resisting laughing out loud at what the live stream is making right now.
We have Biden holding a cat,
but I think my absolute favorite right now was generated by Neve,
which is Godzilla in a data center drinking beer, eating pizza.
Absolutely brilliant.
I'm impressed how these things are cranking out.
I wasn't sure how this thing would hold up throwing a live stream at it like this.
It seems like a great way to DDoS the system.
It's a nice little rig we got here.
It's got a Quadro RTX 6000.
Okay.
All right.
That's pretty great.
I think we got 32 gigs of regular old RAM.
Okay.
Yeah, I'm very impressed with how it's holding up.
I can load while people are generating them.
I can load the history in real time.
You know, just to combine topics, this is running on 2210.
So try that out.
I will say it's still on the server side of 2210.
It's still a bit early on like everybody having an app repo set up for it
because it just dropped.
Yeah.
So like Docker didn't have app repo set up for it just yet.
And a few things like the NVIDIA didn't because I did have to do a little setup.
You got to install CUDA on the host layer.
So that's like the right stuff.
And then there's a specific NVIDIA Docker thing that you set up that sort of bridges
the two that make sure that like the Docker containers have the right access to talk.
Okay.
So there's a few steps.
We'll have links to some of those docs in the show notes for folks that want to replicate.
But if you did it on something besides 2210, it might be a little bit simpler.
Yeah.
Yeah.
Yeah.
We just wanted to play around with 2210 on the server as well.
I completely had forgotten we'd done that.
But yeah, I thank you for remembering.
You know what strikes me about this is another aspect to these toolings that like in the
past required expert Photoshop skills is they can be used to resize and up res things in
a way that even fills in details if you need and whatnot.
I was just playing around with trying to, you know, taking some pictures of the sunset
but there was gosh darn power lines in the way.
And I was just playing with how, you know, how good of a job can I get it to do to patch
those things out?
Decent.
I think I need to fuss with it.
And that's the interesting layer.
I'm sure these all get rapidly better.
But for the moment, there's like an operator skill that you sort of need to acquire with
these because there's a lot of different knobs to play with.
There's a lot of different things.
And then there's a, you know, you got to learn the dialogue of the models you're talking
to and figure out like what words work well to get you to do this mapping of the image
you have and how to get the machine to invoke that same image.
You think it's easy, but you actually have to be pretty descriptive in a way that it
understands.
So it's both words that it recognizes.
Styles it knows.
Content it's been trained on that works well.
Like you get your own intuition of how it's working much like it has an intuition of its
own that's trained.
Which is why it sucks to use one of the paid services that like lets you generate X images
for a price because you have to generate image after image to learn how to use these things
properly.
And like so many other you have just less knowledge of like, well one, all the all the
different controls that they may have access to, but then you don't really know when it
changes too, right?
They might load in the next model version, which might still be better, but can change
out from under you.
It really feels like this is developing really fast Brent like, you know, in since before
we left for the road trip, this stuff kind of existed, but you know, wasn't really very
public.
And you know, it was really small group of people to now to this point where it's it's
spread like wildfire and it's Docker compose away.
I'm wondering just as a photographer, if you've got any thoughts on this type of work potentially
taking work away from photographers or changing the tooling people use because these are free
software.
It is on Linux.
There's that advantage to it.
But does that is that right?
Fix the wrong of stealing your jerk.
I think it's a really complex issue and would affect any visual artist really not just photographers.
I have a few questions and I don't think I've formed an opinion yet because this is so fresh.
One of them what I guess one of the questions I have for you both and for the audience as
a whole is like, if you didn't know, an image was generated by a computer via these models
versus, you know, a human artist.
Do you care?
You know, if there's a painting on your wall that is that you really love, does it matter?
From a philosophical point of view?
I'm not I'm not sure and I'm still exploring that question.
I think probably it doesn't unless you want to have a connection to another human being
who may be the artist.
That's a whole different reason to buy art.
Yeah, I think there's a discussion about this and that sort of suggested that maybe the
art is not a like a true false, you know, there's like a spectrum that these things
can fall onto.
Whereas like, you know, there's obviously the layer of like, does it evoke an emotional
response in you?
Does it make you laugh?
Does it bring you joy?
Are you, you know, you want to, it inspires you to find more art like that, or it could
even find, inspire you to find more art, you know, real human artists or human artists
anyway, let's drop the real term there, who do art in that particular style.
And then of course, there's the side of you, you know, how much design and thought went
into the person crafting the prompt for the thing.
You generated a really cool, I mean, this is wallpaper material here.
Yeah, and I was just trying to get it to do, I was playing on the, you know, Dragon SpaceX,
I was trying to get like a dragon rocket thing, but just made me some real pretty dragon images.
If you join our matrix, even after listening, you can always scroll back in the JB General
chat, and you can see these pictures that have been posted.
They're fascinating.
They're absolutely fascinating.
Yeah, I'm left a little bit like, it kind of makes me feel how copilot makes me feel.
And I thought that was an interesting thing where I feel like copilot could be used to
launder open code and people could then ship it in their closed source and be like, oh,
I didn't, I didn't know it was, I mean, yeah, I might've put things in that kind of reproduced
the exact free software code I was looking for, but copilot did that, not me.
So I didn't, I didn't, I didn't break any copyright law.
It was copilot.
And I kind of feel like in a way you could do that with the stable diffusion stuff as
it gets more powerful.
Cause this is like a few months into it being out in the general public and it's just remarkable
what we could do via Docker compose.
And like in a few minutes you've got a web instance up and going with a usable UI and
they could just start putting prompts in and tweaking stuff.
And I mean, it just blows my mind how far it's come in just a few months.
And I can only imagine how far it'll be in two, three, four years.
I think it'll be producing indistinguishable from human created stuff.
Yeah.
And the, you know, that stuff we were playing with, like replacing Levi with a penguin,
the, that in, in painting stuff or out painting where you can sort of take a seed image and
then generate surroundings around it.
I think that has a lot of potential as well, just because, you know, that boy talk about
taking, taking over stuff you do in Photoshop before.
Well, how funny would it be if for Linux users AI and using things like stable diffusion
became more possible and more, well, it has.
It's already happened.
It's more available than actual Photoshop is for Linux users.
You can use an entire AI construct to modify an image before Adobe got off their butt to
ship Photoshop for Linux.
It's just going to be irrelevant at some point.
Yeah.
Well, actually I've already used it.
Okay.
Sometimes I make Telegram stickers just because it's out of photos of, of some of my friends
I have on Telegram.
It's kind of fun.
That's a great idea.
Right.
And I've been using this little online tool.
I think it's like remove.bg or something and remove background.
And it's just like a little online AI tool that does a decent job.
You got to pay for the full size, but for stickers, I never need that.
So it's like downgraded size, but it works fine.
Yeah.
But if I ever wanted to do that, you know, it's thought it's occurred to me, like, this
is really handy.
There might be times where I'd want to pay for this because it's way faster than me cutting
it out by hand in Photoshop or something like that.
Right.
And this can do the same thing, right?
Like I can just, I can just like mark out the area that I don't want to be messed up
and then it'll replace the rest of the background.
I used it to create a carport idea that I had in my mind, a general rough idea, so I
could show Hadiya a visual of what I was thinking about.
Oh, that's smart.
This is a rough idea.
You know, you'd never want to use it for anything serious.
I also heard a fellow podcaster tell me that he used this to create an example of the cover
art he was looking for for a new podcast that he's creating.
And then he took it once it got a general idea that looked crappy, but he took that
and gave it to an artist and they actually created something that he could ship.
I've also heard of folks come up with like board game ideas and graphics for board games
that are like generated text and rules and images.
There's some pictures here that have been generated by the audience of a penguin flying
past Jupiter.
I could see us using some of these actually for things.
These are kind of pretty.
And it does have an upsizer too, so you could upsize them for professional use too.
But isn't there copyright?
Like wouldn't our audience members have to give us...
Did they create it or did our server create it for them?
That's a really good question.
Who owns that?
And so there's more and more.
There's like a bunch of mage spaces online that are used, stable diffusion and other
models.
But there's a lot of that out there too where like you got to be careful if you go type
in random prompts on the internet.
Like a lot of them will say, well, we reserve rights to anything you generate by typing
in our prompt.
There's some really cool stuff getting generated with.
Did you do that on ours?
Yeah.
Wow.
It's from yesterday, but yeah.
That looks like an evil...
It's supposed to be Waluigi.
Oh, I see.
But it's got that mustache, right?
Yeah.
These are really cool.
Now, I know that makes for horrible audio podcasting.
So I'll just say again, you can find them in our chat.
But the idea is that again, like the Dragon wallpaper that you just posted and the Waluigi
picture, I honestly would not know that was AI generated.
I'm fine with that having them on the wall.
No problem.
Yeah.
Yeah.
That's just crazy.
There's zero tell with those two that you just...
You've gotten really good at the prompts.
You've been looking at what other people have been prompting in the generator.
And that's...
Yeah, that's definitely you want to do that.
Go find...
There's more and more sites that are popping up that you can go search for.
It's just like galleries of generated images with different models.
A lot of them specify which model was used and all that.
And then they have the prompts.
There's also some websites that'll help you do like a prompt maker sort of like, you know,
WYSIWYG give pieces of the prompt.
You can still like you want to make a landscape and you want to make it look like this and
white and here's how the color profile should look or whatever.
Totally.
There's a lot of tools out there that you can start playing with because sometimes you
need really specific things in there to get the model to do exactly what you want.
Like if you really need to be like hyper realistic or you want a particular art style.
I have an interesting question that I think is specific to this podcast.
What if let's say in six months we want to take a holiday and some of the content or
maybe even all of the content of a specific episode we just generated with our back catalog
and it's so believable because it's taking, you know, new snippets from all the websites
that we typically use and it would basically be an episode of Linux Unplugged.
But we were on holidays doing it.
Would the audience be OK with that?
If you tell them now we can't fake them out, Brent.
This is a fun hypothetical though.
It's a total hypothetical.
But let's say it was legitimately good to listen to.
It sounded really like us.
It met our quality of release standards.
You learned something new along the way.
Yeah, especially if you could put in new data.
So it had 15 years worth of Linux stuff we've talked about plus new data.
New Ferronix articles.
Yeah, put LWA and Ferronix in there and the Linux kernel mailing list.
It's basically what we do on a weekly basis.
What would you think of that audience?
Let us know.
Boostin or linuxunplugged.com slash contact.
And maybe don't listen too closely in the future.
So in lieu of a particular pick segment, what we're going to do is pack the show notes with some links.
Do we have a link to the one you can run on your CPU?
Do we have that one tracked down?
If we can, we will put that in there.
We'll absolutely put the one we've been using in there as well as a couple other alternatives.
And I also am very much kind of feeling like Brent.
I haven't really made up my mind about this and how I feel about it, the moralities of it.
That's also something I'd be really interested in your feedback on out there, dear audience.
And particularly, does it make you feel better?
Like Wes said, it is open source, so at least we can look under the hood.
It doesn't seem like this technology is going to go away,
but at least it is free software or open source so we can inspect it.
And does that temper how you feel about it if you do have concerns?
Let us know. You can get a new podcast app at newpodcastapps.com and boost in,
or you can go to linuxunplugged.com slash contact.
Bitwarden.com slash linux. Bitwarden is our password management of choice.
It's how we secure all kinds of secrets like recovery keys, two-factor authentication tokens,
and of course, complicated secure passwords.
It's also how I generate my usernames.
And October is Cyber Security Awareness Month, and Bitwarden would like to remind everyone
that using a good password manager could be one of the number one things you can do to stay safe.
And they've just rolled out new features like password-protected vault export,
a mobile username generator on the mobile app now.
They're now also tying in with DuckDuckGo's email alias generation feature,
so you can have a unique username, a unique email address, and also a unique password.
I know a lot of you are Fastmail fans. They tie in with Fastmail as well,
just to help reduce and cut down your spam, but also to eliminate your attack surface,
so that way your username and your passwords aren't leaking out there together.
There's so many great features in Bitwarden. They're constantly adding new stuff.
I've been so impressed. They've been a sponsor now for a few months,
and new stuff gets added every single month that I get to tell you guys about.
And Bitwarden is the easiest way for businesses or individuals to store, share, and sync sensitive data.
If you're an individual or a business, head over to bitwarden.com slash Linux right now.
It's the easiest way to get started, and it also will just greatly improve your security.
And you may already know that. You guys probably already know that out there,
because you're listening to the Linux Unplugged podcast. You're clever.
But maybe a friend, family member, maybe it's Brent, maybe it's your place of work,
maybe it's an open source project, maybe they could be doing things better.
Let them know, and send them to bitwarden.com slash Linux.
I think you'll be really impressed, and it's trusted by millions in the community.
And of course, it's open source. So check it out for yourself and support the show.
Visit bitwarden.com slash Linux for yourself, your business, or maybe somebody in need.
Bitwarden.com slash Linux.
Instead of feedback this week, which we did get some great stuff. Thank you, everyone.
We did want to focus a little bit more on some boosts that really got us pondering.
So Chris, why don't you kick it off?
And now it is time for the boost.
It's specifically the subject. This is something that came up in my private life.
I was having a conversation with a friend, and then we got a couple of boosts about ButterFS.
And hybrid sarcasm, great name, boosted in with 2048 sats.
Count me among the ButterFS haters. I went ZFS years ago and never looked back.
Proxmox and Ubuntu make ZFS super easy.
I would like to know if your affinity for ButterFS is philosophical or technical.
And if I should reconsider ButterFS.
That's wonderful.
So I think he's asking if it's philosophical because of the licensing differences, right?
ButterFS is GPL. It's built into Linux kernel. It's all upstream.
We don't have that luxury with ZFS.
It's a more limited license, and it's not built into Linux kernel.
Here's my take on ButterFS.
You guys know me. I was a ButterFS hater for like years on this show specifically.
That would actually be a fun thing to go back and pull a few clips from.
Hypocrite Chris Laz's take on ButterFS.
Yeah.
A few contrasting clips. Yeah.
Twice I lost data to ButterFS. Twice.
I was not a ButterFS fan.
But things change.
And specifically in free software, sometimes things fundamentally shift.
And what happened is the upshot of Facebook being a company is they do a lot of open source software development.
And they dedicated some serious resources to ButterFS.
Including hiring one of the primary developers of ButterFS and letting them work on ButterFS.
And then they deployed it.
And then they continued to improve it.
And over the last five years, ButterFS has made tremendous strides.
And in most recent Linux kernels, the RAID 5.6 hole has been fixed as well.
Haven't tested it, but the team reports it's fixed.
A lot of people have an old school view of file systems.
Back in the 80s and 90s, if a file system wrongs you, it didn't really get better.
It was a bad file system and you were a good system admin or a good tech user if you just avoided the bad file systems.
Because they weren't getting any better.
And it was a safe way to protect your data.
And ButterFS started life with a bad reputation.
And I think Red Hat has done a lot of damage here.
They've really pushed people towards Stratus.
And they've removed ButterFS support from RHEL.
And I think that has sent a bad signal.
And I think eventually Red Hat will have to correct course.
It'll probably take them two more releases before they acknowledge it.
Because Stratus is like not... I get complaints about it all the time from the audience.
It's just not solving problems for people.
And Extended 4 is too basic of a file system.
NTFS is better than Extended 4.
Extended 4 is basically Extended 3, which is basically Extended 2.
It doesn't even have snapshots.
It doesn't have some of the core functionality like send and receive that makes a system super quick to backup or restore.
It doesn't have compression.
It doesn't have encryption.
It doesn't have sub-volumes.
You can't combine volumes.
It's just so basic.
And while I know a lot of you listening think, well, that's why I like it, Chris.
Good. But it's not competitive.
It's not competitive.
And the commercial operating systems, the freaking iPhones, man.
Freaking iPhones have a more sophisticated file system than your Linux box.
It's just sad.
And I blame Red Hat for a lot of this.
Because I think the server side would be deeper into ButterFS if Red Hat had put the resources into it that Facebook had.
And so it's gotten better.
And now I run ButterFS on everything.
And there's an absolute tactical advantage to the combo of ButterFS and CFS.
Your core file systems, the things required to make your system boot and become available as ButterFS is chef's kiss.
Because after every kernel update, every reboot, that system comes online.
And that's a fact.
Because you're not loading a third party external module into the kernel.
That breaks sometimes.
That's always been the way it is in Linux.
It doesn't break often.
But it inevitably does break.
ButterFS doesn't have that problem.
Never will have that problem.
It's GPL.
It's upstream.
It's built into the Linux kernel.
That gives you an advantage if you depend on that disk being online for a system to be available.
Now, where I think you can have a little bit of your peanut butter and your jelly is you can also have large data sets that are still CFS.
You can use both.
It doesn't have to be a one or the other only world.
And so ButterFS over time has greatly improved.
And then when you consider low-end devices like Raspberry Pis or laptops that maybe have a single SSD, there's a lot.
In fact, you could say millions of use cases or perhaps small VPSs, small virtual machines, things like that,
that need the features of an advanced file system but can't particularly afford the overhead of the ZFS file system.
There are millions of use cases like that and ButterFS is a perfect solution.
I run it on all my Raspberry Pis and I have too many of them and it has worked great.
And so it is mostly a technical.
I guess philosophically I feel better that it's GPL but the licensing isn't what prevents me from using one over the other.
Right.
If the license was right but the technology was wrong or just didn't work or kept losing your data still,
then you probably wouldn't continue to use it.
Do you have any thoughts on philosophical versus technical?
I mean, I've never really asked you if you have any preference of one over the other in that regard.
No.
I mean, I think ZFS, it could matter if it was the question to deploy a proprietary file system or not.
I think that would maybe be closer.
The licensing one with ZFS at least is just sort of an unfortunate particular details.
Yeah, of its origin.
Right.
But whereas obviously OpenZFS is a very successful open source project, it's great.
But no, I think I like your point that it's not don't just use ButterFest to use ButterFest.
Use ButterFest like when it makes sense and it meets your needs.
Use ZFS when it's the right file system or if you're more comfortable with it or if it was better designed for your particular use case.
I'll tell you one nice advantage of ZFS for us has been portability.
Yeah.
We've moved ZFS from a FreeNAS instance to a CentOS instance to an Arch instance.
Whatever crazy OS we're running.
Nix and you can move it around every single time and they're all going to work.
And ZFS feature flags make it really easy to know what's going to work and what won't work.
Now you have to build, you know, might have to build the module on some systems, but that's fine.
If you're comfortable with that, that's not a big deal.
All right. And then on the same topic of ButterFest, that's why we wanted to make some room for this, guys,
is because I think this is a conversation we need to have because people brought up to me privately.
Tim White 101 boosted with 26,001 SATs.
Coming in hot with the boost.
Tim White 101 writes, Hi, guys, I'm looking for input on ButterFest caching.
ButterFest caching. All right.
So he's got two 10 terabyte spin and rust drives and he's got a terabyte MVME drive.
So he wants to split into two.
But he's mixing up LVM and ButterFest in here quite a bit.
And he's wondering, I hear differing views on Bcache or if I should wait for BcacheFS.
ZFS offers L2 caching built in, but I'm worried that if I use ZFS caching with my MVME,
it'll send it to an early grave because it'll do a lot of writes.
So he's wondering if we have an advice on A, should he look into BcacheFS?
B, should he look into ZFS caching?
Or C, is there a way you can do it all with ButterFest while avoiding wearing his drives down to basically nubbins?
Just there's a lot there. I mean, I think it probably depends like what is it?
Is it read and write caching?
It's just like a read cache that might depend.
I have seen some successful setups with Bcache doing the block layer caching in front of ButterFS.
But you probably, I think, really depend on what you're at.
What are you caching and why?
How sensitive is it?
And then probably whatever you do, if you have the time, you know, the affordances of getting to play with this stuff,
you might just want to do some test setups and actually see like, do they meet your workloads?
Because it'd be hard without some details of what you're trying to hit to know exactly like,
if you're just trying to save a little stuff, can you get by with just ButterFS on the default caching?
Is that good enough using in-memory or do you really need this additional device?
Could totally vary depending on how serious you are about what's pulling all this data
and how often it's really going to be in the cache.
I'm going to say tap the brakes on the Bcache and the BcacheFS stuff.
Yeah, also that like if you're going for prod right now, BcacheFS is not probably the thing you want to do.
If you want to play with it, you should definitely play with it.
I'm going to say take it off the table for now.
Play with it on a test machine.
Play around with it with some virtual VHD files.
Don't mess around with it right now.
Wait until he tells you it's ready.
Now, you didn't tell us what kind of rig you got in terms of RAM and CPU
because that also plays a factor if you choose ZFS over ButterFS.
I think you're going to probably figure out by now that if it's on the lower end of the spectrum,
you might just want to consider ButterFS.
I think you ought to test it like Wes is saying.
I think you may be a little too worried about sending your MVME to an early grave.
I have a lot of old SSDs and MVMEs that are even the crappy kind and they're still running.
So I think the death of MVMEs due to cache writing has been slightly exaggerated.
Maybe I'm wrong on that.
People out there have had a different experience.
Do let me know.
But I would say go with Wes's recommendation.
Test ButterFS.
Play around with caching there.
Keep it really simple in that regard because you're going to have to come back to this in a year or two
when something dies and replace it.
And the simpler it is, the easier it's going to be to get up and going again.
It does seem like the LVM route would definitely work.
Some folks seem to not like the LVM route because it's maybe less flexible or just more you got to learn.
So that seems like if you're already comfortable with LVM, yeah, maybe just stick with that.
Totally could do.
Totally, totally could do.
All right, moving right along.
But thank you guys for boosting in.
We got some really great ones this week, like some really great ones.
So we appreciate everybody.
Batvin321 boosted in with a set of LeetSats.
Respect should be earned.
He says, I'm also planning on going to Ohio Linux Fest.
I should bring my retro FireWire DigiDesign 002 rackmount audio interface.
Maybe as old as me.
It's so big I need to record on the back of my car for a tailgate recording.
This is in reference to last week.
We had a listener who's going to do some recording for us.
I wanted to mention, we have the Columbus Club on Matrix.
And this is where people can organize for Ohio Linux Fest.
And we'll have a link to that in the show notes.
GeneBean also boosted in with a set of LeetSats.
Respect should be earned.
What I'm hearing from this review of the Thaleo is that this would be a great way for me to remove some thumb twiddling from my Gen 2 builds.
GeneBean also sent in a boost saying that they'd provide us with some geocaching resources, and they did.
Nice. Thanks, GeneBean.
So I think we've made the business decision to order a Thaleo.
They're on sale right now, and they just, I believe, updated them with the 13th Gen Intel's.
So I think that's going to happen.
It's a big step. I'm still sitting with it.
But I think it's going to be our replacement OBS machine.
That's so exciting.
My logic being that one of these three machines, I predict, will die in the next two months.
I'm betting it's the OBS machine.
So I'd like to get replacement hardware in so I can start the transition before it dies.
See what I did there? Before it dies.
Weird.
Yeah.
That's odd.
Wait, wait, wait.
I'm saying before it's an emergency.
Okay. Wow. I'm not used to this.
Or, you know what, we'll order it, it'll sit around in the box for a few weeks, and then it'll die and we'll get it set up.
It still might be an emergency.
Now, my understanding was that someone on the business insisted that you had to run NixOS on there, right?
That was the only condition.
Chris, I have a question whether you have an update on the Thaleo from last week.
Did you ever figure out what went wrong with that thing?
Yes, we had a problem where it powered off on us randomly.
And then, Brent, I'm not kidding you, we were sitting here after the show working on post-show stuff,
and I went upstairs and it powered up.
Come on.
From off all the way to on.
It's those solar storms we've been having.
Yeah, I don't know if the case was loose or what.
I was going to toy with it, and then I ended up getting sick.
I got a stomach bug, so I wanted to ship it back and get it back to them so they can take a look at it.
We'll figure it out.
I still think you broke the button.
I did love that button.
I pushed a lot of buttons.
Tebulas boosted in with 250 cents.
Went to the Folsom Cash and struck out.
We'll try again, but we'll bring gloves in a trash bag.
Nice place, but it needs a little bit of pickup.
Struck out.
So does that mean they didn't find it, or does it mean somebody else already found it and hasn't said anything?
Well, that question, I believe, is probably hard to answer if you don't know where the cash is.
So we might have to...
Maybe listener Jeff can go out there and check it out.
Where's the way?
It was Folsom.
Oh, Folsom.
Yeah, it was near Jeff.
No, I bet it's...
No, Folsom was found.
It was Folsom was already found.
I don't think so.
I disagree completely.
I think we need a tracker.
All right.
All right.
Okay.
All right.
Okay.
Acerbic also boosted in with 1007 cents.
Boost!
Starting to get into geocaching with my kids and would love to be the Western Australia geocacher for JB.
Also willing to take over other caches with JB stickers.
Ah, all right.
I feel like this geocaching thing might just take off.
I mean, I'm having fun with it, but...
I wonder if they'd be willing to join us in Matrix and then we could set up a little room for people who volunteer to do this.
That's not a bad idea.
Are you saying we should have a geocache room in Matrix?
I mean, somebody may have suggested earlier and I'm coming around to it.
Cash club?
Yeah.
The geocache group?
The geocache jive?
Nope.
No good.
Geocache cat?
Nope.
Got nothing.
We should probably let the members of the group decide their group name.
Marcel boosted in with 2,222 sats.
And you know what that is, Chris.
Rho dux.
Of course you start talking about a Toronto meetup just as I move out of that area.
When's the Munich meetup?
Sorry, Marcel.
We'll have to let you know on that one.
Yeah, sorry.
Yeah.
You see Rio A also boosted in saying I'll second a Vancouver or especially a Victoria meetup.
You've started something, Brent.
I think my crew is starting to wake up.
I like it.
Uh oh.
Oh, another boost from Marcel with a row of dux.
Nicole Lovay has a good video about the Fedora Kodak issue.
He explains that RedHot could not really wait until they got sued because knowingly violating
a patent is three times the fine of unknowingly violating a patent.
So once they found out, they had to act quickly.
Sure, I'd like to have the Kodak, but I'm not paying anything for Fedora.
And like you said, most people will probably find workarounds.
I find Linux users can be very entitled sometimes.
You're right.
They could license it.
They're rich.
I think people get hung up on the should RedHat license it discussion.
I don't think that's the core thing to focus on at all on this.
I would like to know why anything really fundamentally changed.
You're telling me they didn't know that Mesa had these capabilities.
They weren't knowingly shipping Mesa before.
I mean, of course they were.
RedHat legal didn't realize and get a whiff of something.
Are we all to just sit here and think that the Fedora developers don't understand how
this works, that they're so all ignorant that they don't realize that Mesa had these capabilities?
And then the other thing that I think I wish could be done is some kind of middle ground.
You know, like the way Canonical has done it in the past where there's a checkbox where
the user can choose to install them.
Fedora came up with a way for regular old users to install the NVIDIA proprietary graphics
driver from GNOME software.
And it feels like if we can overcome that hurdle and make it possible for users to get
the proprietary NVIDIA binary driver, seems like silly old codecs that no end user is
going to get sued over realistically should be solvable and there should be tooling that
could be made.
But I don't look like that's happening.
And I think like the focus on, oh, RedHat should pay for it.
That's just kind of a silly discussion to begin with.
The question I had really around that was, is it even feasible?
Could something like that even be done for a price when you don't exactly have exact
numbers of the user base?
There's no way to really know.
So how would you even license that?
And could you just buy a bulk license like that?
I don't know.
And I don't know if we'd actually expect RedHat to ever do something like that.
I think the bigger questions come around, what are the other distributions doing and
why aren't they panicking?
I've seen some talk that openSUSE is going to make a change.
Why are the thousands of other distributions not going into some sort of panic?
And then what's really the difference?
Unless we're all just thinking maybe they didn't know Mesa had this support to begin
with.
But yeah, it's a shitty situation, I'll tell you that much.
And I mean, it's amateur hour.
Sucks that it happened to a great distribution like Fedora.
I think it's changed things for me and the way I view Fedora.
I view it as vulnerable now.
I view it as vulnerable to commercial interests that override the best interest for Fedora.
Maybe that's the compromise we have to take to have an entity behind Fedora that has the
time and dedicated resources to develop things.
But I'm still sitting with that.
It makes me appreciate more distributions like Arch and Nix that don't suffer from the
political whims of their patron.
And I don't think I'll ever view Fedora quite the same way anymore.
I still respect the project, still going to probably use it from time to time.
Something shifted for me at least.
This is really kind of an unforgivable thing just because it was user hostile and there
was no real effort put in to really solve the problem for users before they take it
away.
And there's still time, but I don't see anything happening.
That's all.
And yeah, we could talk more about should Red Hat buy things, but I think that's the
silly part of the conversation.
Well, Grunerl.
Yep, Grunerl.
Boosts in with 1000 cents.
Pew!
Greetings from Germany.
And don't forget your foreign listeners.
What do you think about the future of Lure?
Thanks for making my daily commute a happy time and enjoying it for years.
I'm wondering if this is something you boys would be interested in trying out.
So Lure, L-U-R-E, is intended to bring the Arch user repository to all distributions.
So this is how I can get my Fedora codex.
Great.
Yeah, right.
It's currently in a very alpha state.
It's built in Go, has zero dependencies after it's been built.
The only thing that Lure needs is a command for privilege avalation or escalation as such
as pseudo or something like that.
And then of course, a supported package manager in this case, current support for apt, Pacman,
APKs, DNF, yum, and zipper.
It's funny because, you know, Nyx package manager is kind of the universal thing to
go to now, but I don't know.
Brent, Wes, you guys interested in playing around with this?
You want to try it?
I think we better try.
You're right.
Like Nyx has been meeting a lot of my portable package management dreams lately, but the
AOR is great.
And so something that carries on that spirit.
I've got to try.
Brent, you want to give it a go?
I'd be super tempted.
I mean, it sounds like they're doing a Herculean effort here that we've been asking for for
years.
So why not?
Well, now I'm just curious.
Like, do we have things for production like Reaper, Sonobus?
Right?
Who knows?
Is it everything in the AUR?
All right.
We got to play with it.
Well, Neve boosted and with not quite a row of duck.
It's 2022 sets.
I want to say this year has been exciting in the hardware space.
Far more than software.
As such, I, with my own money, picked up an ARC GPU, which I found on my doorstep this
morning.
Ah, congrats.
Of course, I just overheard Chris talking about the OBS machine failing and would like
to donate this brand new GPU that's still in the box to JB.
What?
I'm willing to pay the shipping.
Just tell me where to send it.
What?
Have we said recently that we have the best listeners?
I don't know if we can accept that.
What if we borrowed it for a bit?
Oh, yeah.
Okay.
And then when we can find one, we'll order it and then we send it back to you, Neve,
so you can have it back.
Because, I mean, I would really love to try one for the show.
I'd love to use one in an OBS build.
I have been getting very mixed reports on how well it's working for people.
So it's definitely now like I cutely want to try it out.
So I will email you back, Neve.
How about I borrow it from you?
And that is very generous.
Thank you.
Neve is watching live right now, too.
So that is really great.
Because, yeah, I was looking at the arcs.
I'm like, I missed my window.
Dang it.
And would you throw it in the new Thaleo then, Chris?
Yeah, totally, dude.
Yeah, for sure.
Make OBS great again.
Mitch from Podverse boosted with 5,000 sats.
B-O-O-S-T.
Just with a go podcasting.
I had a little opportunity to chat with Mitch this week because, as you both saw, Pocketcast
announced that they have gone open source.
Indeed.
And so I was chatting with our buddy Mitch because Podverse is a podcasting 2.0 client
that's GPL.
And it's available for Android, iOS, and the web.
And it's the embedded player we're now using on the new Jupyter Broadcasting website.
And I just was curious Mitch's take on it.
And Mitch saw a huge spike in traffic for Podverse on the day Pocketcast announced they
went open source.
Interesting.
That is fascinating.
That's great, right?
And I think it's in part because Podcast has been talking about Podverse, but also I think
it's people are opening up the idea of an open source podcast app is a great idea.
Why do I need a proprietary company to play an MP3 file again?
Yeah, right?
And also you think about it's an open independent media ecosystem, like the only one that exists.
Yeah, right?
It's like the only one that exists.
And why pair that with a commercial closed app?
Gosh, like the idea of like, oh, no, no, you know, my podcast provider, they lost the licensing
with Jupyter Broadcasting, so I can't listen to love anymore.
The whole back catalog.
Yeah.
We're fighting over Coderadio.
Yeah.
That's great.
So it was great to catch up with Mitch.
I think we're going to have a lot to chat with him about on Office Hours and a future
episode coming up soon.
Michael B. boosted in with 3000 sats.
Hey, Chris and team.
I would love to hear your thoughts on the streaming sats while listening features in
the new apps.
Is it a sustainable source of value or do you see a higher amount with boost?
Thanks for the great show, Michael.
This is a really great question, and I really appreciate that Michael's even kind of asking
this question because what he's really trying to get at is what's the best way for me to
return value to the podcast while listening.
Right.
My take on this is always whatever system works best for you.
If the set it and forget it with sat streaming is a better method for you.
I like that because it gives me a bit of signal when you're listening because, you know, I
see it on my dashboard that, you know, Michael B. just sent in X amount of sats, but there's
no message with it.
So I also really like the boost because they have a message with it.
And I feel like the baller boosts and all the different boosts are a great way to invest
in a particular episode production.
They're also just a really motivator for the team.
It's exciting the sort of real time connection that per episode connection like, oh, they
were listening to that thing that we said.
It makes a huge difference to that button is right there in the app.
Right.
And then we have our members and our members are like our our investors on our board that
are always investing in the ongoing production of every episode for a sustained period of
time.
And it is so much stress to us.
It's yeah, it unpluggedcore.com.
Either system, you know, might work better for different people depending on what they
got going on every day and in their life and whatnot, how they like to manage that kind
of stuff.
So today we don't see like a big source of revenue from the strat from the sat streaming.
We get a higher overall one, I would suppose from the boost.
But that's not really why we do this.
So I don't generally have a preference in there.
But I really appreciate that you're thinking about that because, you know, it is a small
independent boutique business.
It's not something that is too big to fail.
If the ad market were to turn sour for a sustained period of time, things would get pretty lean
around here.
But it's nice to know that we have some of these real baseline essentials taken care
of.
So Mars X-Ray boosted in with 1024 sats.
First time booster.
Just wanted to say keep up the great work on the podcast.
Long live Linux.
Or at least some representation of Linux.
Yours open source Lee Mars X-Ray.
Love seeing the first time boosters.
That's so great.
And then our last boost of the day came from a great username from Thought Criminal with
one thousand nine hundred ninety nine sats.
Boost community supported independent media on open source.
Yeah, yeah.
It was a cool idea a few months ago and now it's even easier than visiting a sponsor or
sending an email.
Thanks for tuning me in on the way forward.
I'm in.
That is so great.
Thought Criminal.
Thank you.
Also, I just want to say a big thank you out there to everybody who boosted in.
Not all of them get on the show.
We did a big batch this week because the content was just top notch.
A lot of those got us talking.
A lot of thought provoking discussion there.
So that's the bar.
And so we really appreciate the support.
We read all of them.
If you didn't make it on the show, doesn't mean it wasn't a great boost.
It just might mean we got tight on time or we were going for a particular theme like we
did with ButterFest this week.
But we appreciate and read all of them.
Thank you, everybody.
A couple of shout outs.
A thousand stats from Opie on the live show topics.
I'll follow up on that.
Thank you for live shows and production.
Five thousand stats from Ninja Mort, who wanted to give a shout out to Easel App and also
tell us to keep up the great work.
We got 1492 stats.
I feel like that's a particular number from Ruark.
Oh, they boosted in their earned stats while listening to us on Fountain.
Very particular indeed.
Interesting.
A thousand stats from RastakastaVersa, who was the first to report a QA issue.
We had in last week's episode.
Thanks, Rasta.
Appreciate that.
And we got a hundred stats from NowScienceNews, who is hoping that power prices will eventually
come down so they can get into self-hosting.
We hear you.
But check out things like the Odroid H3 NowScienceNews because that thing's sipping like five watts
and I would bet for 90 percent of home use cases, especially when you consider it has
quick sync for video decoding, I bet it would solve 90 percent of people's use cases.
Chris' low power colo.
There you go.
Set it up here.
Sell it to you in sacks.
If you'd like to send a boost into the show, newpodcastapps.com.
You can also just boost with Podverse.
I got a note from a listener.
I said, you know, I tried out Breeze.
I don't know.
I want to stick with AntennaPod.
So what I do is I just load up the Podverse website and boost from there.
Oh, that's a nice way to do it.
Pull up the old show and boost from there.
Very convenient.
Yeah.
Totes cool.
We will have lots of links and resources for the diffusion stuff that we talked about,
for some of the AI voice stuff we talked about, all kinds of things in there.
So do check out linuxunplug.com.
Slash 481.
481.
Or go to the new website.
Give it a go.
Jupiterbroadcasting.com.
You know, go kick the tires and then catch office hours this week because we'll be talking
about that new website.
Won't we, Brent?
Yes, we will.
We might even have a special guest.
Oh, there you go.
We do this show on Sundays and we do office hours on Tuesdays, both of which are noon
at Pacific time and 3 p.m. on the East Coast time, which is where Brent is at now.
It's true.
Weird.
You got to try all the time zones.
See which one you like best.
Brent Coast time?
Yeah, it's the Brent Coast.
See you next week.
Same bad time, same bad station.
And that does wrap us up this week.
If you'd like to see how the sausage was made, you can head over to Jupiter.Tube or you can
become a member where we curate a custom made file just for you.
We'd love to have you there.
It's a lot of fun and you get to play around with some of our tools when we talk about
it.
But if you can't make it, we understand.
That's how it goes for most people.
No hard feelings at all.
You can always chat with us after the fact in our Matrix room.
You can get details at Jupiterbroadcasting.com slash Matrix.
And of course, there's a slash mumble for all of our mumble details.
Thanks so much for joining us on this week's episode of the Unplugged program.
And I hope we'll see you right back here next Sunday.
Still some pictures coming in.
Oh, wow.
These are so fun.
There's the most recent one is of you.
Oh, yeah.
I love this one MiniMech did of a tux drinking a beer.
That's great.
That is really good MiniMech.
Sonic the Hedgehog in there.
Penguin on the beach.
This looks like a JFK going down the street, but it's a car full of tuxes.
You guys got my drift with this one.
All right.
Oh, boy.
Here's one of me.
It's kind of close.
I like that it's sort of a reverse SMB7.
Like they almost got it.
Yeah, it's got a podcast mic.
It's got a computer screen.
What's on that whiteboard?
I want to know.
Yeah.
Yeah, I don't know.
And it's got me in a shirt.
That's a shirt style I would actually wear.
Where are the suspenders?
Right.
It does need and these podcast setups are actually pretty good.
I like the, you know, this is funny how some of these actually really are.
God, Wes, you make the best ones.
Jeez.
It's worth going in the chat just to see these.
Wes Payne, you're an AI digital director artist guy over there.
I'm very impressed.
Trying for like Batcave here.
That was inspired by Mars X-ray.
You know, that's just a fun name.
But it just took super complicated machine learning, AI models, and a little docker compose
to bring out Wes Payne's creative side.
Yeah, that's right.
Pencil and paper?
Heck no.
