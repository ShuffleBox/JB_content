Coming up on today's show we have Jeff Geerling. You may know him as GeerlingGuy in Ansible Galaxy.
He's also on a bunch of work recently with the Raspberry Pi. Chris loses his mind a little bit
when Jeff tells him how he hooked up 16, yes, 16 drives to a Raspberry Pi. I'm Alex.
I'm Chris and this is Self-Hosted 41. Alex, we have a lot to talk about today and we also have
a special guest. We do indeed. Yes, we have GeerlingGuy, Jeff Geerling, the Raspberry Pi, Ansible Maestro,
all the sorts of superlatives. My new YouTube habit. I love what he's putting out. Yeah, I thought you
might like him. Yeah, I do. I want to say thanks to A Cloud Guru for sponsoring this episode. They are
the leader in learning for the cloud, Linux and other modern tech skills. Get hundreds of courses,
thousands of hands-on labs. Get certified, get hired, get learningacloudguru.com. The interview
really will be the bulk of the show today because there's so many great things we get into. But
before we start, I kind of wanted to chat with you about Nabu Kasa buying ESPHome. How'd you feel
about it? I mean, when I first heard the news, I was like, oh, I wasn't quite sure how to feel. And
then some more details trickled out about how the original creator, Otto, was, you know, basically
burning out. And I think overall, it's a great way to save an open source project that is
one of my personal favorite ways to configure, you know, ESP boards. It's a clear value
for the Home Assistant community. And this was, you're right, I had my first read of this was sort
of like, I'm not so sure because they're a small team with a lot to do. But when you read between
the lines, it seems pretty clear that Otto was about to hit the nope out button. And the project
would have been left without its leader and lead developer. This is kind of nice because this gives
the project room to grow. It'll bring in some new contributors. Otto is taken care of. He's able to
participate if he likes, but you know, he's going to focus on life for a bit. He's shutting down
the Patreon account. He doesn't have to worry about the management side of things. And it continues
to be a free software project. And if anything, I would expect it will be even tighter integrated
into Home Assistant now. We're seeing some of that already. Frank, one of the main developers
for Home Assistant has already made some significant improvements to the VS Code plugins
for how that interfaces with ESP Home. So there's some autocomplete stuff coming and things like
that. But let's just back up a little bit and explain what ESP Home is. So the way I got started
with it was I was programming these ESP8266 single-board computers, if you like. They're kind
of in the same space as an Arduino, more than a Raspberry Pi. So they don't run a full OS. They
actually run a pre-compiled firmware. And that used to require writing an Arduino sketch and
uploading it to the board and all the stuff that comes with the Arduino IDE and Universe and that
kind of thing. And what ESP Home does, and it is pure magic in my opinion, is you define the
firmware as a YAML file. You add a couple of modules here with a couple of lines to enable
Wi-Fi and then another couple of lines to enable logging and then another couple of lines to enable
the Home Assistant API, for example. And then you flash that binary that is generated from the YAML
file onto the ESP8266 without having to write a single line of C code or whatever the Arduino
equivalent would be. And it just makes it so approachable.
Yeah, and there's so many devices that run off this type of firmware out there.
And you can really see long-term the value that Home Assistant, if Home Assistant can make this
even simpler. Imagine a future, if you would, Alex, where Home Assistant could even auto-detect
devices and guide the user through generating the firmwares and maybe even has a way to deploy it
with some DNS magic or something, depending on the device. But they could really make this
a whole inclusive package at some point. Absolutely, they could, because with this
acquisition, Nabu Casa now owns the copyright to Otto's code and therefore the ESP Home
organization on GitHub and Docker as well. Yeah, and esphome.io is a great resource.
So if you want to learn a little bit more, go check out esphome.io. And of course,
we'll have a link in the notes, which, as always, you can find at selfhosted.show.
linode.com slash SSH. linode.com slash SSH gives you a $100 60-day credit towards a new account
at Linode. And of course, it supports the show. Linode is our cloud hosting provider.
Anything we want to try out or anything we put in production, we put it up on Linode.
We get emails into the show. We try stuff out on Linode. It's really quick to get going.
But also it's because it's fast. We know it's just going to get done really quick.
And sometimes you just want to prototype something as fast as possible. Now we host
all of our major infrastructure for Jupiter broadcasting 3.0 on Linode, of course. But
even the stuff that never makes it public, that never is listener facing, we run on Linode as
well. They're super fast. They have native SSD storage, 40 gigabit network, totally easy to
use cloud manager, really simple to take snapshots and get the idea of the last time your computer,
I should say Linode, was backed up. You can really simplify your infrastructure
while also reaping the benefits of great performance at a great price. Linode costs 30
to 50% less than AWS or Google Cloud or Azure. And it really works well if you want to just blend a
little bit of on premises and cloud as well. That's how I use it for Nextcloud. I have a cloud
component to my Nextcloud setup on Linode. And then the big bulk of the storage, like the archival
stuff, it's all here locally on my LAN. It works fantastic that way. And with 11 data centers
worldwide, you're going to find just the right spot to deploy. And you'll rest easy knowing
that Linode's rocking fast and has great monitoring tools that can alert you to problems
before you even notice them. Of course, these things are really important, but performance
matters as well. And Linode has you covered there too. Cloud Spectator recently did a study of the
different cloud providers, like all of them. DO, Amazon, Google, looked at Azure, all of them,
put them in there and saw who was the fastest. And one of the things that really makes Linode stand
out is their dedicated CPU rigs have AMD epic processors that are just cranking faster than
the other providers. And Linode's disk storage is super fast. So you can feed those processors
faster than the other providers. And what Cloud Spectator's survey shows is that not only does
Linode have the best CPU and disk performance, but it has the best continuous performance as well,
which really matters when you have large jobs that need processing or you're getting a lot of
traffic. You need that sustained performance. I mean, Linode started in 2003 as one of the
first companies in cloud computing. So they really know what they're doing. They're independently
owned and founded on a love for Linux, open source technologies, and the community that
surrounds them. So just go try what I'm talking about. I've told you about the object storage
before. I've told you about the cloud firewall before. There's a lot to check out with Linode
and what they've chosen to do, they do really well. So go spend that $100. Linode.com slash SSH.
Go see what I've been talking about and support the show. Linode.com slash SSH.
Well, I'm delighted to welcome to the show somebody whose work I've been following for
many years as an Ansible user. We have Jeff Geerling on the show today. Welcome, Jeff.
Thanks for having me. Thank you for being here. And more recently, of course, a YouTube
extraordinaire content creator. Yeah, that's how I came to know you. Yeah. So you've been doing a
lot of videos lately on the Raspberry Pi 4 compute module. I thought we'd talk to you a little bit
about that. But before we get to that side of the discussion, I wanted to sort of talk to you a
little bit about what I knew you for first, which was Ansible. So you have a really rather excellent
101 getting started course. Before Jeff Geerling existed and created this, you know,
de facto guide for people getting started with Ansible, how did you get involved with the project?
I started off by having a few servers than many servers and then dozens of servers. And once I
went from many to dozens, I realized I had to switch to some sort of configuration management
system. And at the time, Ansible was pretty much brand new. That was 2012, 2013, when I was making
that transition from shell scripts and runbooks to something more formal. So I tried out Chef,
but I'm not a Ruby developer. And I didn't really like it. It felt too much like programming to me
and learning Ruby when I did PHP and Node.js and things like that. So I got into Ansible at that
time. And at the time, it was so simple that you could pick everything up in a day. And it was
focused really on just Linux administration, not all the other things that it does today.
But the documentation was great, but there wasn't a ton of examples out there. So
I just started blogging about my experiences. And then I realized that there wasn't a book for it.
So I put my blog post together into a 50-page sampler thing and stuck it onto Leanpub,
which was also pretty new at the time, and started self-publishing this little ebook.
And my goal was to maybe sell 100 copies or 200 copies. And I hope some people learn Ansible. And
lo and behold, a couple of years later, since it was one of the first books on Ansible,
it became one of the most purchased books. And to this point, I don't remember how many tens of
thousands of books I've sold, but lots of thousands of books have been sold. It was the number one
bestseller for infrastructure automation for a number of periods on Amazon and has been in the
top five, top 10 books on Leanpub for years now, too. Congratulations. Yeah, thanks. I don't doubt
it. Every time you search for anything related to a specific role or something like that for
Ansible, you're looking, there's a Jeff Geerling role in there in Ansible Galaxy. So some of our
listeners will be familiar with Ansible, but some won't. So what's your quick kind of elevator
picture of what Ansible is and does? There's an XKCD about whether or not you should automate
something. And I think that that's a good illustration of what Ansible is. Once you reach
the point where you're doing something, maybe to a group of computers or to network switches or to
servers, or even I use it to manage my own computer, if you're doing a repetitive task
that can be automated, Ansible can automate that, almost anything in the world that has to do with
technology. So that's what it does. And it's very simple. That's the big selling point for it
compared to other tools is it uses YAML configuration, which is very approachable,
very easy to learn. And that's why I liked it over the other solutions at the time, Chef and
Puppet that I was looking at. People back in 2012-13 time were just moaning about how YAML was
so complicated with its white space. And I never quite understood the hate, to be honest with you,
because people say, oh, I'd much rather write JSON. I'm like, are you mad? YAML's way easier
to work with. Yeah. I think a lot of people maybe don't, they aren't used to having a code editor
do formatting for them and things like that. It's much more common nowadays, especially in
the infrastructure space than it was 10 years ago. And I think that's the biggest difference
nowadays. YAML, people complain about it mostly because they see people do things that you
shouldn't do in YAML. But back then it was more the syntax and the formatting. They're like,
I could put in anything in JSON or God forbid XML, but YAML is going to complain about it.
And I think nowadays we're past the formatting stage and we're into what could be a next
generation format for configuration that's even better than YAML. Because it does have
shortcomings, but it's, in my opinion, it's a thousand times better than JSON, XML and
SOAP and all the other protocols we used to have to know to be able to configure things.
Couldn't agree more. Yeah. So I think, speaking of things that people shouldn't do,
turning Ansible into a programming language is probably up there, right? I mean,
you can do some pretty crazy stuff in Ansible. And my day job is related to OpenShift at Red Hat.
And a lot of the OpenShift installer stuff for version three, the last major version,
there was some pretty crazy hacky stuff going on in those Ansible playbooks and stuff like that.
But what's the most crazy thing that you've seen with Ansible?
I think it's the abuse of the when condition in tasks. When your when condition is longer
than the rest of your Ansible task for a given piece of automation, I think that's where you've
failed. At that point in Ansible, you can write modules in Python. You can actually,
there are ways to write modules in other languages too, but typically you'd write it in Python.
And if you're going to use complex logic to determine whether to do something or how to do
something, that should be in Python. At that point, you're getting into advanced Ansible usage that
requires you to have some of that programming knowledge. Programming in YAML is a terrible,
terrible idea. Never do it. Every time I have gone further than an if-else type condition,
I've regretted it and the maintenance is a nightmare.
And then there's always the Ginger 2 stuff that people do, the crazy templating,
for loops, all that kind of stuff. So anyway, should we talk about Ansible 3 for a minute?
There's been a big release in the last few weeks of Ansible 3.0, which brings a lot of changes to
the way in which modules are delivered to users. What do you make of all that change?
It's been an interesting transition and I think it's ongoing and will be ongoing for another
period of time, six months to a year probably, mostly because Ansible 2.9, which is the previous
major version of what you would get when you installed Ansible using PIP or a package manager
or something like that. Ansible 2.9 will still be supported for a while, mostly because I think
there's just a lot of people who the transition to the new version of Ansible does introduce some
changes that could impact people's workflows a little bit. The good thing about the transition
is that all my existing playbooks, and I have a ton of playbooks that do a ton of different things,
they all work fine if I just upgrade Ansible using PIP, which is the Python package manager.
There are other ways to install Ansible that might not work with Ansible 3 the same way anymore,
so you have to watch out for that. And that's why I always recommend using PIP to install it,
because it's a Python program and PIP is the preferred way. But the big, big change is that
collections of modules used to all be maintained in one giant code base. And there were various
reasons that was not very sustainable. There were something like 4,000 or 5,000 different plugins
and modules. And the core team of developers who managed the releases and things, it was just a lot
to coordinate. So the main goal was to move all of that content out into smaller collections that
could be maintained by people with more knowledge of just the modules in that collection. There's
no reason why, let's say, an F5 network load balancing module should be under the same
maintenance umbrella as an email script thing. All these different modules were lumped together
from network vendors and storage vendors and cloud vendors and Linux and Windows.
So now it's all broken out, but the challenge has been making it all come together back into
what we install if we do a PIP install Ansible. And the nice thing is it all works, but the
downside is there are a few little bumps, especially if you have specialized use cases.
But another cool side effect is you could install Ansible without all that stuff and just add in
the few things you need. So if you just do Linux administration, you can install Ansible plus the
Linux modules and not install Windows, not install networking, not install cloud. So it does offer
some flexibility, but I think there's going to be some growing pains over the next year.
We're seeing that trend quite a lot in technology at the moment. Docker being an example with Podman
coming along to break that out into being less of a monolith type deployment model. So I think
it's a good thing personally. And, you know, the work that's gone in has clearly been very well
thought out. Are there any particularly good resources that you'd recommend people visit to
get their head around what the major changes are? The documentation is the best place to know what's
going on. Not only is there a guide for upgrading Ansible in the release notes, and if you are
involved in using Ansible, I would highly recommend subscribing to the Ansible project mailing list
on Google groups. But the guides and the documentation are by far the best. They encapsulate
everything that I could ever think of that could affect someone's workflow. And also I did update
my book recently. So if you are interested in learning Ansible and you don't know it yet,
Ansible for DevOps has a major second revision. I've actually revised it 25 times now. But a major
revision happened to incorporate some of the information about collections especially. And I'm
still working on fully revising the book to be up to date with Ansible 3. It all works. It's just
there are some things that could be optimized a little more. Datadog.com slash self-hosted. Analyze
code level performance across your entire environment and troubleshoot issues faster with
Datadog. Datadog has a continuous profiler that automatically collects profiles from your production
of beautiful dashboards. Get a unified picture of your environment by correlating code performance
metrics with your other monitoring data with real-time dashboards. You got to see these
dashboards. Go to datadog.com slash self-hosted to get a free trial and to see these beautiful
dashboards. And you'll get a free t-shirt when you sign up a trial and create a dashboard with
tightly integrated APM, tracing, log management, and continuous profiler products in one single
form. Datadog enables you to pinpoint the root cause of issues faster than ever. Are you seeing
the value here when you can visualize everything at once down to the application level, server stuff,
even website performance? It's all in Datadog and you can get smart alerts as well. Try Datadog's
products for free for 14 days by visiting datadog.com slash self-hosted for a limited time.
If you start a free trial and create one dashboard, you'll get a free Datadog t-shirt. And who doesn't
love free swag? So that's datadog.com slash self-hosted. So Jeff, I've been watching on
your YouTube channel, you've been doing the impossible with Raspberry Pi's. I'm talking
like I think one of your setups was like 10 SATA disks. 16 hard drives. How is this possible? How
is this madness accomplished? Is it all with using the new Pi compute module? Yes, and the funny
thing is the Raspberry Pi 4, the one that's been out since I think 2019, that was the Pi day release
back then. The Raspberry Pi 4 actually has the same processor and capabilities, but the big
difference the compute module has is it exposes the internal PCI Express lane. And that's the
big game changer. With the Pi 4, you could hack it. You could de-solder a chip on it, the VL805
chip that controls USB3. You could de-solder that, wire up some jumpers and get PCI through it. And
a couple of people actually did that. The first time that I started working with the compute
module, I was looking at their work because PCI Express support is rudimentary right now on
Raspberry Pi OS. And they were kind of like the groundbreaking people that got that going.
But the compute module 4 includes a standard PCI Express slot on the IO board that you can buy with
it. And the cool thing is that a lot of people are building boards around it that have different
PCI form factors. So M.2 slots for things like LTE modems or for storage with NVMe drives or SATA
drives that are either in M.2 form factor or using a SATA controller. And you can plug in
hard drives and things like that. So a really cool thing happened. Somebody from Broadcom
actually contacted me after they saw some of the work I was doing and said, hey, we want to see if
we can get a hardware RAID controller, an enterprise storage controller. These things cost
like a thousand bucks. We want to see if we can get that working on a Pi and we can't get a Pi.
They work at Broadcom, but they had trouble sourcing a Raspberry Pi because the compute
module 4 has been in such high demand since the launch. So they shipped me the card, they shipped
me a storage controller and had me work with a couple of storage engineers and we got it working.
So at that point I had eight drives on the Pi, but then I found that I could also plug in eight
more drives with the card I had. So I did a live stream and got all 16 hard drives plugged into
the Pi and in one giant RAID array. Wow. How was performance? Yeah. How is it?
Because, right? I mean, that's always the thing about the Pi is everybody says the Pi 4 is great,
except for the IO really limits it now. But this seems like that changes that a little bit.
It changes it a little bit. It doesn't fix all the problems. That's for sure. The big problem is that
it's X1, a by one lane. So it's PCI Express Gen 2 by one and the maximum throughput you can get with
that is five gigabits per second. But that's theoretical. So the maximum real world throughput
that I've gotten, I've tested 10 gig ethernet, I've tested the storage controller, I've tested
all kinds of different crazy things so far. And the maximum real world throughput is about 3.2
gigabits, a little over 400 megabytes per second. So I threw this hardware RAID storage controller
on it. It could do like 10 gigabytes per second, but I can only put through 400 megabytes per second.
So it's not going to give you magically access to all of the wonderful things you could throw into
like a modern Threadripper PC. But it does give us a lot more options than with the Pi 4 where you
just have USB 3.0, which has its own limitations. I mean, the fact that you could have redundant
storage is an upgrade beyond the fact that it's slightly faster too. But do you think this kind of
is maybe an indication of where the Pi is going to go? Is this compute module a hint of what we might
see maybe in the Pi 5? I hope so. Another thing to keep in mind is there are a lot of Pi competitors
and it's which one is going to be the Pi killer. Nothing's going to kill the Raspberry Pi just
because the Raspberry Pi has a community and a force behind it that is unparalleled in all the
other kind of makerspace single board computing realm. And don't you think that's kind of the
advantage of using the compute module in another board versus getting an SBC that just has all this
stuff? It's like you're getting the Raspberry Pi ecosystem with some of these cool new toys. Yeah,
yeah. On the flip side, though, there are some boards like the, what is it, the Rockchip RX?
I forget what the specific chip is. Rockchip Pro. Yeah, it has a by four lane. So you get more
bandwidth and more lanes so that you can do more with it and have more IO speed. There's still
limitations just based on the fact that the CPU is not super fast. And even if you give it, you
know, let's say we get 10 gigabits or 20 gigabits of throughput, the CPU is going to be limited in
other ways on these cheaper ARM SBCs like the Raspberry Pi. For instance, today I'm doing some
testing for a 2.5 gigabit NAS that I'm building with a Pi to see if it can compete with an out
of the box NAS from QNAP or Synology or something like that. And without overclocking the CPU,
I can only pump through 1.7 gigabits of network traffic because the way the CPU is architected,
all packets go on one core on the CPU. It's a four core CPU, so it could support more,
but the way the network throughput works on the Pi, it's stuck on one core and it maxes out. So
you have to overclock it to get more speed. I think, you know, there are two things I really
want to see in the next Pi. One is maybe more PCI bandwidth. The other is just a faster CPU.
And we've seen what's possible. Apple with their M series, even the A series, just blows away the
competition in terms of performance per watt and, you know, single threaded performance for any kind
of mobile device. So I think that the ARM SBCs have a bright future. And that's I'm hoping that
IO speed and CPU speed, which is becoming the bottleneck for a lot of my projects. Those are
the two things I really hope to see improved. I wonder where you come up with some of these
ideas, man. Your head must be an interesting place. If you want to come over to my house sometime,
I will show you the pile. I have so many projects that I really, really want to work on.
And I don't think I'll get to them in the next few months, unfortunately.
Are you near me? Are you in Raleigh?
No, I'm in St. Louis, Missouri, but, you know, fly over here after the coronavirus is over.
Oh, maybe one day we'll do another road trip, hey, Chris?
Yeah, for sure. I don't think that's a maybe. Nothing about that's a maybe.
So if we were to come visit, what kind of stuff would we see you self-hosting in your place?
Right now, the major thing that I'm hosting is PiedRamble.com. This has been a project since
2014. I started doing it. It was to see if I could host a Drupal site specifically,
because I am involved in the Drupal open source community. If I could host Drupal in my house
long term, and that site has had 99.997 or eight uptime since 2014, running on Raspberry
Pi's. Now, I cheated in 2016. I switched to use Cloudflare as a front end, but the cache
is only 30 minutes. So if I do have a major outage, it will go down after 30 minutes.
I don't think that's cheating. That's just good engineering.
Yeah, well, I was getting tired of if my ISP goes down for two minutes, I would get a
notification. I was going to say, how have you managed to have ISP uptime that high at home?
That was the most impressive part. Well, I've switched too. In St. Louis,
we have Spectrum, but... Yeah, me too. It sucks.
Yeah, it's difficult because the ISPs, they have a monopoly basically. And another fun thing that
I'm going to be trying, I actually just got last week, a Starlink.
Awesome. And I'm going to be
testing it out. My ultimate goal is to have, either through the router, I have an ASUS router,
either through that or maybe through a Raspberry Pi. I'm also testing a router build using a
Raspberry Pi compute module. Of course.
Having a redundant link that will automatically fail over and possibly do link aggregation,
but for now, I just care about the redundancy. Just because I do work from home, I do streaming,
I do video uploads, and I need a lot of bandwidth and I need reliability. And I do want to host more
besides just the PyDramble site. I want to host my personal site here at some point. I want to
host some other things that are more high impact and could survive an outage of one of the two
network links, which Starlink could give me. I don't think we've seen many people discussing
hosting services on Starlink either. I'd be curious to see what they allow, what can get
through. Have you heard much?
It's a mixed story there. So they don't give you a consistent IP address. And they also don't,
they don't pass through traffic in a way that you can host directly from home. So I'd have to use
some sort of proxy. And I can have one of the VPSs I have at DigitalOcean or something like that,
pass through the traffic for me.
Sure. So give us an idea of what other, so I heard you have a, sounded like you're running Drupal on
a Raspberry Pi server. Any x86 boxes in that mix we'd see?
I do have one x86 server that mostly what it's doing is allowing me to RDP into it and do Windows
things when I need to. It's running Windows 10 Pro and I use it for a lot of network testing
because it has a Mellanox card inside of it so I can get 10 gig network tests done on it.
Especially if it's a long test that's going to take a few hours, I don't want to do it on my
main workstation, which is a laptop, because then it's stuck wherever I have it running.
Yeah, I know that one. Like, why did I start that job on the laptop? Dang it.
Exactly. And then you have to come back downstairs later and find it. And then the other things that
I do, I have a couple of Pis that run around the clock doing just little tasks around the house,
checking on things, keeping track of temperature and like myself,
and like my sump pump, checking the level of the pit, and just logging that data.
The other thing that I have running right now, and this is part of the motivation for all this
Pi experimentation, is I have a 2011 Mac Mini. Super old. The OS is not even supported on it,
I can't upgrade it anymore. It's still my primary network storage device, which is terrible.
Like I've set up all these different NASes and things and I still am using this Mac Mini,
which has USB two. So my external 12 terabyte single hard drive, not a RAID,
my single hard drive is running at USB two speeds. I'm doing file copies with, you know,
20 gigs, 40 gigs at 30 megabytes per second. So this would be a bad time to ask you how
many terabytes. One of the questions we tend to ask all of our guests is how many
terabytes do you have on your LAN? And we had Wendell on a few months ago and I think he had
a petabyte, so maybe you won't quite match that. But how many do you have, Jeff?
No, no. Online right now I have about 24 terabytes, but in the house I have about
60 or so. There's a lot of terabytes of hard drives that are sitting on my desk over there
that are being tested and not in use because when you're testing you don't, you know,
you don't want to have production data on a hard drive you're running benchmarks against.
Ready to go in that NAS you were talking about.
So yes. Yeah. And the other thing that I mentioned on, I don't remember if it was a
video or a live stream, but my goal is at some point in the next year, if I can get a storage
vendor to work with me, I would love to build a petabyte Pi. Have one Raspberry Pi controlling
a petabyte of storage. I think that would be something fun. It would be a 400 megabytes per
second. It'd be such a waste, but it'd be so cool to see that.
Petabyte Pi project rolls off the tongue too. I like it. It's bop, bop, bop.
Exactly.
Is a petabyte a thousand or a hundred terabytes? I can never remember.
A thousand.
Oh my goodness. How would you even do that? Like that? Wow. Yeah.
You got to get at least like a hundred hard drives. So it would be, it would not be super fun
to do the project. I mean, it'd be super fun, but the hardware, I would probably have to build a
rack or something and figure out a place maybe in my, my wood workshop or something to try to,
try to fit that.
Cause if you've got a 3d printer, you could, you could probably rustle something up with one of
those. There you go. How did I know? How did I know that would be your suggestion, Alex?
Well, see, this is why I'm going to say subscribe to your channel, Jeff,
cause there's just some great videos over there and maybe one day I'll see that project on there.
I hope so. That would be fun.
Well, Jeff, before we get out of here,
I was wondering if there's any way you'd like to send people, you know,
your channel or Twitter or something like that.
Everything is linked from my personal website, jeffgeerling.com.
I started my personal site back in 2001 or two or something like that. And I like to have
my data in my site. So I typically post things preferentially there and, you know, I don't,
I can't do video hosting and things like that. I could, and I actually did at one point,
but I realized that YouTube does it way better than I ever could with streaming and all that
kind of stuff. So I like to take ownership of that. So jeffgeerling.com is where I throw
everything primarily, and then you can go to the other sites from there.
We'll have a link in our show notes too. Thanks for joining us, Jeff.
Yeah. Thanks so much for having me.
And a big thank you from me because you've saved my bacon. I can't count the number of
times with the roles on Ansible Galaxy. So huge, huge, past Alex, thanks current Jeff.
Well, now I'm even more excited about the Raspberry Pi. Thanks to Jeff for coming on.
Of course, like we said, we have links to his channel and everything in the show notes.
And I want to mention, you can find our sponsor, Cloud Guru on social media. It's just slash
the Cloud Guru at YouTube, Twitter, Facebook, like all of the social media platforms. It's
super, super easy.
And a big thank you to our members over at selfhosted.show slash SRE. Our site reliability
engineers support the show. You guys get a limited ad feed and a little bit of extra
post show every week.
Oh yeah. I haven't told you what I want to talk about yet. That's coming up for the members.
No, no. It's going to be a surprise to me too. And you can go to selfhosted.show slash
contact. That's the place to go to get in touch with us. I'm on Twitter at ironic badger.
Yeah, I'm there too at Chris LAS and the show is at self hosted show.
And don't forget the network at Jupiter signal. Thanks for listening everyone. That was self
hosted dot show slash 41.
