One of the cornerstones of our collective worlds as self-hosters is storage.
Hard drives, let's face it, are evil.
So today, we have the CTO of UnRAID, John Panazzo, joining us.
UnRAID was my gateway to Linux back in 2012, and it's got an absolutely incredible community behind it,
whilst also being one of the easiest ways to store and own your data.
John takes us through the excitement of discovering Docker,
what it was like to be featured online as Tech Tips, and the future of UnRAID itself.
First, though, a quick bit of housekeeping.
Last episode, we mentioned a group buy for a DIY open-source open hardware energy monitor for about $20.
You know, the one based around the Raspberry Pi.
We'll be doing a larger roundup of energy monitoring options in the next episode, that'll be number 26,
but I wanted to let you know that the group buy looks like it's going to be going ahead.
We've definitely got enough orders for the US and the EU, that includes the UK,
and for our friends down under, unfortunately, we're not quite there yet.
So, if you are interested, please register using the Google Form link in the show notes.
This also applies if you emailed us or posted on Twitter.
The form is what we'll be using now, as the response was so much larger than anticipated,
and it was spread across, I don't know, like five or six different places.
So please, if you are in doubt, put your name in the form and we'll record you as being interested.
We'll leave the form open until the end of August and then be in touch for the next steps in September.
Let's get you to our interview with Unraid's Jon Panotso.
Jon, welcome to Self Hosted. It's good to have you here.
Thanks. It's good to be here.
So, I know we have tons of questions for you and just full disclosure,
Alex is quite familiar with Unraid and I'm the noob.
So, I'll be playing the noob, as always, it seems, these days on this episode.
So, let's just start with people who aren't familiar with what is Unraid
and who would you say it's for?
So, Unraid is a server operating system that was built by Lime Tech back in 2005
and it's predominantly for personal home media enthusiasts,
people that want to build their own home media server
to store all their personal digital media along most other content.
And we've been basically building it out over the last several years.
So, originally, it started off as just a NAS platform, pure storage play.
And then with Unraid 6, we kind of completely modernized the OS and expanded its capabilities.
So, what used to be known as a NAS OS is now a full blown server platform.
And to us, the server platform really makes sense because storage is one aspect.
The next aspect is running applications on that server
and the third is running virtual machines.
So, we pretty much have expanded it to be the full gamut of what a traditional server can do.
I noticed your pricing structure is essentially
tiered around the amount of attached storage.
Do your customers tend to be either on the lower end or on the very extreme high end
or is there a good in between?
You'd be surprised. You know, obviously, there's a lot more people out there
with six or less devices than there are with people that have 25.
That's just logical.
But we actually have a pretty good spread.
And there are plenty of folks out there that just buy the top tier
knowing that eventually I'm going to have that many storage devices.
So, yeah, you'd be surprised how many people opt for Plus and Pro over Basic.
I'm kind of curious how the forest fire that has been 2020 has affected Unraid.
Has there been a notable change in business?
And are you guys eyeballing maybe long term something like a subscription model?
So, I can definitely tell you that with everything going on with coronavirus and whatnot,
believe it or not, that's not hurt us at all.
I think if anything, not that I'm happy that this has happened,
but it has definitely helped business growth only because there's more people at home now.
And what do you do as an IT person that's at home
or somebody who's a tech enthusiast at home?
You tinker.
And very likely those people are going to somehow or another come across Unraid.
So, we've not been negatively impacted.
And we don't have brick and mortar offices.
We're completely remote team with people all over the world.
So, if anything, it's kind of helped out because we've been able to hire some more people this
year and help some people out in some bad situations.
So, it's been great.
I think 2020 is going to be a banner year for us.
That's really great news.
I'm not sure I fully appreciate the implications of being a nerd stuck at home
means I tinker more.
I mean, it's definitely true.
Definitely true.
Hey, I know I do.
Yeah, no, it's totally true.
It's a thing.
So, yeah, I mean, it's always a tricky balance, isn't it?
Building a sustainable business model on one-time license purchases versus say the
Netflix model of, or more accurately, I suppose, the Adobe model of purchasing software over time.
And particularly with Unraid, given that the lifespan of a license purchase could be
a decade or two, you know, I pay my 60 bucks once and then that's it for,
you know, Limetech season doesn't see another dime of that.
And just to reiterate Chris's question, I was wondering if there were any plans for
subscriptions moving forward.
Yes, I can't get into all the details on how that's going to work, but we have very
much been looking into building other options that you can use with Unraid.
So, there's two ways to look at that question.
The one is, are we going to launch some kind of subscription service?
And the second is, how does that affect the current licensing model?
And so, we are working on options for both of those.
So, one model would be something that you can pay to extend the value of Unraid.
So, you still have your registration key or some type of license that validates your ownership
of the product, but then we offer services that complement the product that are optional
to purchase.
The other is an online license key.
And this is something that we've wanted to do for some time.
When Unraid was started, when this whole business was started back in 05, you know,
Tom Mortensen, our CEO, he built this as kind of a pet project and it was nothing more than
beer money.
It was, hey, there's a problem, I can solve that problem.
There's not a lot of people other than me that are looking or interested to solve that
problem, so I'll do it and I'll release it.
And literally, he just went to avsforum.com, created a post in there, said, hey, I'm a
guy, I made something, check it out.
And just from that, the whole business kind of exploded.
Now, for a very long time, it was still just a beer money business and Tom was the only
main employee, the only employee at all.
But then it started to grow and it got to the point where he wanted to do something
major and it happened to coincide with timing for me.
That's how I joined the company and I reached out to Tom and we started having conversations
about what could we do to really blow this thing up.
And years later, here we are and we're looking at sales, we're looking at how licensing works
and you hit the nail on the head.
From a business model standpoint, it's untenable to not have any customer rebuys or repurchase
or anything like that, but we've made it work.
We've made it work and we've grown doing it.
Our monthly sales revenue is over 10X what it was several years ago.
So we're doing great, but we know that there's a shelf life out there for how long that kind
of model will last.
So we are working on both of those options to give people another way to contribute back
to Unraid and also get some more value out of it.
That's a great story.
I love that origin.
I'm kind of curious right now, do you see one of the big drivers of new business people
discovering Unraid applications that they want to run on their LAN or is it storage?
The reason that I'm asking that is I wonder how cloud storage plays in this, say somebody
like Backblaze who can come along and offer reasonable rates for storage and Wasabi and
others, does that apply a certain kind of market pressure to you or is there an offset
by people hosting applications like Plex?
I don't think that any cloud storage has any pressure on us at all.
I mean, people were saying, oh, Netflix is going to kill Unraid and it's not.
Like there's the people out there that want an Unraid server, they don't care about any
of those outside factors.
And there's a lot of folks out there that, you know, cloud's great.
I have nothing against cloud.
I think it's a great technology for the right use cases.
But there are plenty of use cases that cloud is not the right technology.
And I'll tell you right now, when your power goes out or your internet goes out for any
extended period of time, especially if your internet goes out for any extended period
of time, you'll learn how quickly you miss DVDs or Blu-rays or any method of playing
media content that doesn't require an internet connection.
That's true.
Very true.
I've gone to a lot of lengths to solve that problem.
And also you can't beat, honestly, you just can't beat the cost difference between a lot
of local storage versus the same amount in the cloud.
Of course not.
I mean, we just went through a pricing model recently.
We were kind of just looking at options for what we could do with cloud tech.
And I'm like, well, what would it take to run an Unraid server in the cloud?
And when I just did, I mean, granted, this is still a research project undergoing, but
like with Amazon, oh my God, I almost choked at how much money it would have cost to just
run an instance in the cloud.
Because it's not like, oh, well, my compute use is just low and I'm only going to have
to spin that VM up when I need to access an application.
No, if you're going to run it in the cloud, you've got to run it in the cloud.
It has to be always on, always available, ready at the fingertip.
And so that's a minimum amount of compute resource that you have to dedicate budget
towards.
And then when you look at storage costs in Amazon, I mean, don't get me wrong, if you're
running a website or a business off the cloud, Amazon's great.
But when you're as a consumer and you're thinking about, well, I need a media server or I need
a home server, personal server, and I could run that in the cloud or I could run it on
prem, what's the difference in cost?
You look at the hosting model and you're like, in less than a year, I can pay for this and
build it in my house.
It's those transit costs.
That's how they get you.
Yeah, it's bandwidth and storage.
That's the real killer.
The CPU, the compute resources and all that stuff, that does add up, but it's fixed.
You know it's predictable.
It's fixed.
It's not going to grow.
It's not going to change.
It's pretty much going to remain the same.
Your storage is always going to go up and your bandwidth is always going to go up.
So it's a matter of time before the price model just doesn't make sense.
I agree totally.
I made that same calculation myself a couple of years ago when I emigrated and built a
$2,500 server.
You think, okay, well, that's a lot of Netflix, but at the same time, I've got full control
over what's on this box in my basement and I always will.
So that's the rationale I go through.
There's more to it than just that too.
Alright, let's talk Google for a minute.
So I'm a big Android guy.
My wife's an Apple person and I'm an Android person, so you can imagine the fun technology
conversations we have at home.
The best part about that is whenever she asks me for help, I'd be like, well, I don't know.
I don't use Apple.
So that's the one time I can play dumb as a tech person and be like, I think you might
have to call Apple.
But one of the things that I have noticed, and this applies to both of those platforms,
definitely with my Android phone.
I guess maybe I have to verify with Apple, but with Android for sure, when you take pictures
on an Android device and they go to Google's cloud, you think, oh, that's great, right?
And I bought this really nice phone that's got this really nice camera.
It's taking these really nice high fidelity pictures.
Yet after a while, once it's no longer cached on your phone and you go back to look at that
picture again, it's not quite as crisp, not quite as clear.
And it's because they apply compression and they lower the image quality.
That really, honestly, the first time I noticed that, it really pissed me off.
Because as a customer, I feel cheated.
I feel like I bought a device that was capable of taking really high quality pictures.
And you gave me a service that complements that device to store those pictures online,
which I think is great.
But then without notifying me and without, and whether you notice me or not, it doesn't
really matter.
You degraded the quality of those pictures and I don't like that.
So having the local storage where you can protect the original quality and fidelity
of the content that you're capturing and creating, it's one thing if it's a movie or a TV show
or whatever, something that I download from the internet, that's one thing.
But when it's my kids' pictures and I go look at it years later and it's all pixelated
because Google applied some compression to it, and that's even worse when it's years
down the road and the camera that I originally used was already low quality and now you're
compressing it even further.
It just makes for not a good experience.
So having local storage to protect your stuff, I think that's actually going to become more
and more important.
You only get one chance at those photographs.
Yes, very, very important stuff.
So all right, let's talk a little bit about the future.
We're high up in the version six release cycle of Unraid now.
It's your 15th birthday soon.
Is version seven on the horizon?
Can't get into any details about what seven might look like.
I'll tell you right now that we've had maybe a handful of conversations speculating on,
well, what could seven be?
What could go in there?
We're not yet actively developing version seven.
There's still plenty of life left in the six tree.
Six nine's about to go stable.
It's currently available for public testing.
It's in beta.
And we already have a 6.10 roadmap that's being worked on.
But beyond the six series, I can't really comment on what seven would be.
But I can tell you that I definitely have things in my mind that I want.
And eventually, I think we're going to get there.
I think we're going to get there.
I wish I could.
I really wish you could hear it in my voice.
That's a pretty good tease.
I really want to talk about what I'd love to have happen.
But it's just too early to get into those details.
And I don't want to get beat up over it.
That's cool, man.
That's no problem.
So what are you excited about in 6.8 or 6.9 next?
6.9 is the next main release.
And then after that, we have 6.10.
So 6.9 is going to be awesome.
Multi-pool support has been something that we've been working on for a while now.
And 6.9 is going to bring it to bear.
And I just actually, so this was perfect timing because Tom's like, hey,
we're going to add this new feature.
It's going to be multiple cache pools.
And we're going to roll it out in 6.9.
And right around the time that he started talking about doing that,
my cache pool was actually filling up my personal system at home.
And I'm like, you know, this is a great time to test out this new feature.
So this last week, actually, I went through and created a new cache pool,
put brand new SSDs in, got it formatted.
And then I stopped all my services, stopped Docker, stopped VM Manager,
and copied the bulk of my cache, my original cache, onto the new pool.
And then I did a new config operation so that I could make the new pool,
my default cache pool, and just replace my old pool.
John, as an UnRAID newbie, can I ask you, what is a cache pool?
So UnRAID operates with two main storage pools in mind.
The first is the array and the second is the cache.
So the array, the idea is that's where you put your hard drives.
So you have at least one, but you can have up to two parity disks.
And then the remainder can be just standard data disks.
And they can be of different sizes, speeds, brands, protocols.
Brands, protocols, that's one of the big hallmarks of UnRAID.
And then that's where you put all of your long-term storage data, right?
And that's where all your media content goes.
Everything that you want to store long-term goes there.
But the downside is that hard drives can be slow.
You might not be able to fully saturate network performance
using right operations to the array.
So we created something called the cache.
And the cache is nothing more than another grouping of devices
that manages storage a little bit differently than the array.
So the array, we have up to two dedicated parity disks and the rest are data.
And because of those dedicated parity disks,
that means there's no striping happening across the data disks in the array
that has a performance impact.
Whereas the cache pool, we actually currently use ButterFS.
We can talk about a new file system option there in a minute.
And ButterFS allows you to group many different devices,
also of different size, species, speeds, brands, protocols.
But it does it in a RAID 1 formation.
Now, for anybody that hears RAID 1, they usually have a very fixed image
in their head of what that means.
But in ButterFS world, you can have more than two devices in a RAID 1.
All it means is that every time a bit gets written to that disk pool,
it's going to make sure that bit gets written
to two different devices that are in the pool.
That's all.
Did you hear that, Chris?
ButterFS?
The ButterFS part?
Yeah, Chris is all in on ButterFS these days.
I do like me some butter these days.
ButterFS is great.
There's still some outlying issues with ButterFS that are sometimes a struggle.
And it just feels like the project that never ends.
But I still like it a lot.
I just don't trust RAID 5 and 6 totally yet.
But RAID 1 and 10 are great.
And so for operating a cache pool, which, again, the purpose of the cache pool
is to act as a cache, which for those that I would imagine most people that are listening
know what that is.
But if they don't, it's just a temporary repository for data.
And that's faster than your long-term storage repository.
So when you write data to a share in unRAID, if the share is cache enabled,
then the data actually gets written to the cache pool first,
and then it gets moved to the array on a schedule that you define.
So right now, it's by default at 3.40 AM.
So the cache is great because it can make real-time write operations
appear to be a lot faster than what the array is capable of.
Use the fast storage to receive the data and then write it in the background
as time permits.
Exactly.
Yeah, I think that that new pooling or multiple pools opens up some interesting
possibilities for different tiers of storage.
So the next logical question from here is, what about multiple arrays and stuff like that?
Because I mean, you want an SSD array, for example, backed by an SSD cache,
and then you want a spinning array backed by an SSD cache.
Like, you could have different, do you see where I'm going?
You could do different things with that, I mean.
Absolutely.
I will say that SSDs in the array are possible,
but they add additional challenges based on how the devices do discard or trim operations.
So it's a more complicated problem to solve.
Now, one thing that I do want to test at some point in the future,
I just, you know, there's so many ideas of what you can do with onRate.
But one really cool one that I want to mess around with at some point is building an array
where the parity disks are NVMe, but the data disks are all SATA-based SSD.
And the reason for this is that what happens when a write hits onRate is that the system
has to first decide which disk it's going to go to, right, where that write's going to go.
Because again, unlike traditional RAID, we don't stripe data.
Every disk is formatted with its own file system.
It operates independently of the other disks in the system.
The only time they work in concert is when you are rebuilding a disk using parity.
However, every time a disk gets a write, so does parity, right?
So parity becomes a bottleneck.
So let's say I'm writing three different files at the same time, and they're each going to a different disk.
Well, disk one, two, and three are each independently receiving a write.
But then at the same time, those three writes are also hitting the parity disk all at the same time.
But if you have a parity disk that has far more IO, far more IOPS available to it than your data disks,
then maybe you can kind of overcome that bottleneck limitation and get some really
fast write speeds direct to the array.
That is fascinating.
I want to play around with that idea.
It's one of those things where it's going to cost some money and take some time to really go through the testing on it.
But I think that could be a really cool way to do it.
Absolutely fascinating.
Thank you, John.
I was wondering if that was possible, because for the longest time, that inherent, you know, having to make two writes at once,
performance imitation has been something that, you know, we've talked about in the NRAID community for years as being a bottleneck.
So it'd be interesting to solve that.
So that leads me on to another, I guess it's an elephant in the room whenever you're talking about storage.
It's kind of the juggernaut hiding in the corner.
What about ZFS?
So I love the European way, the Z.
I'm going to start using that.
Oh, I'm sorry, darling.
Would you like ZFS?
Is that better?
No, no, no.
ZFS is it.
ZFS it is.
ZFS it up.
So ZFS, I like ZFS.
So let's just go right through it.
So have you seen the recent article that was this year from Linus Torvalds about ZFS on Linux?
I'm assuming you had to have.
Yeah.
Okay.
So Linus has got some pretty out there opinions on ZFS and why.
No, that's not like Linus.
Yeah.
It's like, no, he's got legitimate concerns as to what would happen if they just straight up merged ZFS into Linux.
And all it would take is an email from Larry Ellison or any of the legal team at Oracle to make it happen.
But they don't, and there's a reason they don't.
So it's a licensing issue.
At the end of the day, the reason ZFS is not a part of Linux has nothing to do with technology.
It has everything to do with licensing.
And we think we might have a way to work around that issue.
We know that there are other Linux distros that have already adopted it, and they're doing so at a risk.
And because they have and nothing's happened yet, that gives us confidence.
But all I can say is that ZFS has been something that we've been eyeing for a while.
And the reason part of the reason that multiple pools were put in is that it seemed like a pretty good feature to put in maybe before that.
Yeah, absolutely.
I can just imagine Unraid as the hypervisor using Zvols underneath.
That would be so great.
The other thing you have to remember with ZFS, and this goes back to why we originally chose ButterFS,
ButterFS was the perfect complement to Unraid.
Perfect, because from a user experience standpoint in terms of how somebody goes about building an array,
building their server, and then assigning all those storage devices,
the rules about what you can do there, they work the same.
That's the best part about ButterFS and Unraid is they both let you use any kind of device you want.
You can mix and match. You can use different sizes. It doesn't matter.
And the best part is when you want to expand, you can just add another device, just like Unraid.
All of that goes away with ZFS. I almost said Z.
All of that goes away with ZFS because now you have to play by the ZFS rules.
And I understand those rules, and they make sense.
But to an average Unraid user, that might be frustrating.
Let's say we did it as default.
Let's just say, for example, that our cache pool was based on ZFS as default.
You created a two-device RAID 1 ZFS setup, and now you want to expand it.
How easy is that compared to ButterFS?
It's not terrible. With a two-device pool, it's not terrible.
But imagine it's four or six, and now you have to add another four or six devices into a new Z pool
in order to expand the existing. That's a huge cost.
And sometimes it's not even realistic because the user doesn't have enough SATA ports available
to add that much storage to the server they're dealing with.
Let's face facts. ZFS was not built for home users. It was built for the enterprise.
We're trying to kind of bend that enterprise tool to be valuable to consumers.
And I'm totally on board with it because I think there are some very cool things that you can do with ZFS.
And I know there's plenty of people out there that use FreeNAS, for example, which is entirely based on using ZFS.
So I'm on board with bringing it in-house and using it.
It's going to take a little time for us to get it fully implemented.
But it's something that we are actively working on.
I actually think that's a pretty fair answer. I think Alex and I both really agree with you.
It is truly an enterprise file system, and if you have an enterprise budget, it's very manageable.
If you're a high-end home user, and you can make it work, I'm doing it right now,
but I went out and got a super microchassis to make it happen.
And that's the reality. I mean, the majority of our customers, they're not doing that.
They're taking an old PC and they're repurposing it for the use as a server.
Honestly, that's what I used to do when I was building PCs as a young'un.
When I was first getting into technology, what was my first PC? It's a gaming PC, like most tech people, right?
But then that gaming PC gets a little old, and you realize, well, I can't really upgrade it anymore.
Time to build a new one. So you take the old one, and you make it your server.
It's a good value. So John, along those lines, I guess my question is, you must see a lot of different builds,
just being inside the company and seeing different stuff online.
Does one really stand out to you as a pretty amazing Unraid build?
Oh, come on. If you've not seen any of the Linus videos from Linus Tech Tips, come on.
I thought that might be your answer.
If I don't point my finger at at least nine of those builds, then yeah.
I mean, those are the crazy â€“ I remember that the craziest one had to be the seven gamers one.
Not the nine, not the eight, but the seven.
And the reason the seven was so crazy was because Linus calls me up.
He calls me, and he says, hey, I've got seven of these AMD Nano GPUs coming.
As soon as he says AMD, my hairs on the back of my neck rise because I cannot stand AMD GPUs for one reason,
and that's because VM pass-through with those is a royal pain.
I know that there's a lot of Linux people that hate Nvidia for how they handle open source, and I understand that.
I totally get it. But when it comes down to what works and what doesn't,
I've rarely had problems getting Nvidia GPUs to pass through. I always have problems with AMD.
So he's like, I got these brand new, never before seen AMD GPUs.
Oh, and by the way, I'm going to rip all of the coolers off these GPUs,
and I'm going to have a cooler manufacturer make me a custom block, custom water cooling block,
that's going to be one block that's going to slide into this system and cool all seven of those cards at the same time.
Can I go under the hood for a second?
Because I know that this is something that you don't touch on a lot, but it's based on Slackware, right?
That's our distribution. Yeah.
Do you have any measurements on this?
But as far as you know, are you perhaps the most widely spread Slackware Linux distribution in existence?
It probably wouldn't surprise me. I don't know.
I don't know for a fact, but I mean, let's face facts.
When you think about Linux distributions,
the top names that come to mind are probably, you know, Ubuntu, Fedora, Arch, you know, that group.
Slackware is like the very last one that I think people think about because it's not really built for everyday Linux users.
It's built for guys that are building platforms.
It's built for people that want to really tinker or really want to rip the whole thing apart.
Like what you can do with a Slackware distribution in terms of from a developer's perspective
is so much more fine tuned than what you do with traditional distros.
Like, think about how small unrate is as a release.
I couldn't do that with Ubuntu.
I mean, if I could, by the time I'd get there, I'd say,
well, I could have done it a lot quicker using a different platform.
So, yeah, we're probably the largest, I would think we're probably the largest Slackware distribution out there.
I thought that might be the case, which is just something I don't think a lot of people have given a nod to or consideration
because it's one of the originals, so it's pretty great to see it in widespread use out there.
Absolutely. I mean, we love Patrick, but I can never pronounce his last name.
So, Patrick V. We're just going to say Patrick V.
Yes.
You know, we have great respect for the work that he's done and, you know, it's been a great platform.
And the funny thing about Slackware is that like, because this conversation comes up about Slackware once in a blue moon,
came up a lot years ago.
We really haven't heard anything about it since.
But the reality is that Slackware, Arch, it really does not, for us as a company, it does not matter.
Like, Linux is not about the distribution, it's about the kernel.
It's about what can the kernel do?
And all a distribution is, is a way to wrap up what the kernel can do into a more manageable way.
And when it comes to us, you know, we've always gone through discussions where we talk about,
well, should we switch?
Should we move to a different platform?
And we might at some point, we might.
But the reality is, is that one of the big value props that we have is the fact that Unraid runs as an appliance.
It really is an appliance built OS.
It's not Windows, right?
Windows is a platform, right?
Windows is, hey, you load Windows, and then you load a bunch of other things into Windows, and now it's an operating system.
Now it has everything that it needs.
We're an appliance.
Everything that you need is in the stick, all in the stick.
Your capabilities as a hypervisor, there.
It's built in.
And what's great about Slackware is that we were able to kind of pull out all the nonsense that we didn't need in the kernel,
everything we didn't need in the OS, and really get it down to a very minimalistic build.
And I think that honestly is one of my favorite things about Unraid is how minimalistic the OS really is.
You hit the nail on the head.
It was a few years ago, I think sort of 2013, 14 sort of period that I think you and I first crossed paths.
This was when Docker was being added for the very first time to Unraid.
And around about that sort of time, we were running custom VMs to run media apps.
And it was just this whole layer of abstraction and complexity, which now with containers is just not a problem.
So the base OS just doesn't matter anymore.
And I'm a strong believer of that as long as you can run a container, you can run whatever OS you want.
That's exactly right.
And I mean, the funny thing is, is that so when we were working on six,
the reason that VMs were initially looked at was not because of something that Tom wanted originally.
It was because of what people wanted, what our customers wanted, what our users were using.
And so what we found was that the big calling card to Unraid in the five days were plugins.
That was the cat's pajamas right there.
We had a plugin and that guy Faze in our community,
he created all these different plugins and it just extended the value of Unraid.
You didn't have a feature that you wanted, you'd add a plugin.
That's where Slackware's weakness was exposed, though, because in order to run these plugins,
you'd have to be able to download these packages and install them that were built for Slackware.
And you'd find that there were plenty of packages out there that just weren't built.
It's funny that Plex actually had a build that they made that somebody didn't have to hack through.
They made and they supported for Unraid, which tells you how big we must have been for their community.
And so, yeah, we saw all these people using plugins and Tom's like, you know, this is just not manageable.
So our choices are move to a platform where it is or find a way to make it work on what we have.
And VMs were the first foray into that.
And I think you were involved in that a little bit, Alex, where Tom reached out to you and you were creating some VM templates and things like that.
But then as we were going down that road, there was a couple different things that we discovered.
The first was that we were originally using Xen as our hypervisor.
And the reason that I like Xen so much is I actually come from the Citrix world prior to Limetech.
And that was Citrix's big thing was Xen and Xen Server.
And I thought, wow, this is great.
It's a similar platform.
Let's try it.
You know, I like the way that the whole project was structured.
But we had a lot of problems with Xen.
And specifically with GPU pass through, we had a lot of problems with Xen.
And we're like, wow, this is going to solve all of our GPU pass through problems.
But then the question became, well, wait a minute.
Do I really need a 10 gig or even a one gig size V disk to run Plex?
Like, does that seem like a good trade off?
And then the user has to manage that.
Like they can't just automate like Plex isn't going to just auto update like you have to manage that VM.
You have to manage the OS in that VM.
And it just there was so much additional stuff that came with VMs that didn't come with containers.
And I remember a guy in our community by the name of Naz, that's his handle in our forum,
had once posted a feature question.
He just real short or just, hey, there's this new thing, Docker.
I think it looks pretty cool.
You guys should check it out.
And so Eric, our CTO and myself, we started looking at it.
I'm like, the first week I'm looking at Docker, I'm just I'm so confused.
I'm looking at it.
I'm like, this thing sounds great, but it also is so confusing.
And then we just built it.
So Eric and Eric went into the dungeon and built a release of Unray that supported Docker.
And Eric's like, I'm about to show you how great this is.
Here's what I want you to type.
Docker run space, blah, blah, blah, blah.
I gave me a command to run and I hit enter.
And I'm like, OK, now what?
And he goes, that's it.
You're running Plex.
Yep.
I'm like, what?
And I type in the IP and sure shit Plex is loading.
It's running.
It's doing its thing.
And I'm like, wow, that's crazy.
How did you do that?
And then that's where everything fell into like this is just this big.
Ion cat or whatever.
When the thing goes like it's like the movie Limitless or whatever.
All of a sudden you understand everything.
Everything falls into place.
It's like the moment Doc Brown hits his head on the toilet and thinks of the flux capacity.
Exactly.
And so I remember calling Tom and I think I honestly think it might have been in the middle of the night.
It might have been like really late at night.
I'm like, Tom.
And he's like, John, what's up?
And I'm like, this thing, you got to see it.
So we got him the bill and he's like, OK, now what?
Command run and he's he gets it up and running and he's like, OK, now that was pretty cool.
Yeah.
And we all had this eye opening moment of we got to do this.
And so the funny thing about it, too, is that we the first iteration of building a Docker management interface was nothing compared to what it is today.
It was it was honestly it was pretty piss poor, but it did the job.
It worked, but it required users to add these template repos and people would have to build their apps on GitHub and then link these repos and all.
And just putting out like the first I think the first beta releases that we had with this in there, the community just took it and ran with it.
And that's how we have the community app store.
That's how we have the new Docker manager that that's way more polished than what the old one was.
It's just crazy how fast everything clicked into place after we put it out there.
So I mean, Docker is a Docker is awesome.
I think my Doc Brown moment was when I set everything up and I really, you know, I had a good configuration.
I tore the container down and then stood up a new version of the container and it just resumed and the data was completely separate from the application.
And that was the moment I went, aha, I get it.
This solves a problem I fought forever in I.T.
So I love that story.
It's sort of like the Docker origin story in Unraid.
I kind of want to tease out of you anything you can give us about this soon dot unraid dot net, which says the team has been working hard on something.
We're calling my servers to be released soon.
What are you talking about?
I have no idea what you're talking about.
Are you talking about the little did you know?
Now, hold on.
Did you actually find the Easter egg or did somebody just tell you?
Let's let's start with that.
I may have informants.
Would you be legit?
The color scheme looks on point.
It's SSL signed.
It's legit.
So if you're interested in getting involved in being able to test some new things that you want to get ahead of the rest of the community on, that's where to sign up for it.
All I can say is that we have some pretty big plans to roll out some pretty nice services to complement the OS.
We talked about this a little earlier, and we are looking to get people in line that want to start testing that for us a little bit more rigorously.
We've been personally testing it for over a year now, and we're pretty confident with what we've built.
Obviously, as soon as you expand it beyond, you know, the size of a room, it's the people are going to find chinks in the armor.
So it's it's a it's a beta testing program sign up.
That's that's the core of it.
That sounds like a good thing.
But John, where else should we send people?
You mentioned there's a community area, it sounds like our forums are where everybody goes, both new users, existing users and people that are thinking about becoming users.
And the biggest thing that I can guide people about on rate is, OK, first go on YouTube and watch Space Invader One's videos.
If you haven't, Ed is just an amazing guy.
He's going around on rate and going so much deeper than we ever would as a company to explain all the nuances to how to configure all the most advanced things.
So if you have any questions about on rate OS, if you want someone that's going to walk you through it, give you a nice presentation on it, I highly recommend checking that out.
The other thing I obviously recommend checking out is Linus Tech Tips.
Linus Sebastian is a big friend of the show or a big friend of the company, and we lean on him pretty heavily to help kind of push the limits of what we can do with the software.
Or I should say, he pushes us.
And the other thing that I would recommend is that if people are wondering, well, I want to build an on rate server, I'm not sure what hardware to use, the forums.
Our forums are like, we get emails pretty often about, well, which hardware should I use?
And the reality is that we're not a hardware company, we're a software company.
So our hardware requirements are pretty basic.
You've got to have a 64-bit processor.
I'd recommend at least four gigs of RAM and a decent USB flash stick.
But then if you want to do VMs, your processor's got to support virtualization, it's got to support passthrough.
And there's ways to look that up easier with Intel than with AMD.
But, you know, if you're wondering, well, am I going to run into problems?
Or if I use this hardware, are there any limitations?
Just post in our forum, there's a good chance somebody's already used it.
That's a good resource because it is such a varied thing.
You need a community to lean on.
Well, John, thanks for coming on.
Do keep us in the loop on future developments and stuff so we can keep our audience informed and send us little nudges here and there as things develop.
Because I think what we'll be following, I'm kind of scratching my head.
I think I have a couple of excuses to try out Unraid.
I might give it a go here soon and report back on the show.
If you get tired of rolling your own and you want to just have a packaged OS that you don't have to tinker and you don't have to manage,
you can just mess with the apps and the VMs and the storage and that's it, we're for you.
We're 100% for you.
That's the elevator pitch right there.
Just kidding.
Well, I hope you enjoyed that chat with John as much as I did.
As ever, you can find more about the show at selfhosted.show.
We're on Twitter at selfhostedshow.
Chris is at Chris LAS on Twitter.
Self Hosted 25.
