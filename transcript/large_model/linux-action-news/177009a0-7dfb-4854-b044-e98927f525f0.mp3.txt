Hello, and welcome to Linux Action News, our weekly take on Linux and the open source world.
This is episode 105, recorded on May 12, 2019. I'm Chris.
And I'm Joe.
Hello, Joe. I'm fresh back from Boston and Red Hat Summit, and I want to say Happy Mother's
Day to you. I know it's an important day, and we have not one, not two, but a bunch
of major stories to break down this week.
Well, it might be Mother's Day for you, but it isn't for me, so I don't care. What I care
much more about is Red Hat Enterprise Linux 8 having been released.
Joe, every day for you is Mother's Day. And indeed, it was a big release. I was there
at Red Hat Summit, so I got like all of the excitement in the room, because this isn't
something that happens all the time. It's been a few, about five years since the last
Enterprise version of Red Hat came out, and a lot has changed. The cloud has really become
a thing, and Red Hat's trying to position this release as the operating system that's
been redesigned for the, quote, hybrid cloud era.
I must say, reading through this press release from them, it really is buzzword bingo. But
you were there on the ground in Boston, cutting through some of those buzzwords. So what were
the kind of standout features for you?
You're right. There was a lot of buzz stuff to cut through, as always with these big enterprise
releases. But there's a couple of key features. They've got AppStream now, which is something
we've seen that showed up in Fedora in the most recent releases, where you can subscribe
to different versions of the repositories for software. So you can have RHEL 8, but
you could ship a very modern version of PHP even many years down the road. That's a major
feature.
But something else that Red Hat is launching is what they're calling UBI, the Universal
Base Image, which is really, truly an Alpine competitor. Now, if you want to build a containerized
environment, you can base it on this UBI, which is a real true RHEL environment. I got
clarification specifically on this point. It's not repackaged CentOS or Fedora. It is
true Red Hat enterprise in this base image. And if you run it on a RHEL stack, they'll
completely support it. But you could run it on any container environment. Then you combine
that with the new release of OpenShift 4, which is all about Kubernetes and building
your own serverless environment. They're trying to answer the on-premises, the cloud environment,
the Kubernetes workflow, and the container workflow, all in one release of RHEL.
And legitimately, they got there. It wouldn't be that odd for an enterprise software company
to try to convince everyone to just keep doing it the way they've always done things, to
keep things the same, stable. Really, Joe, the main message they wanted us to take away
is they've modernized RHEL to answer a lot of modern workflows for whatever particular
workflow that might be. And it seems like from my estimation, they've pulled it off.
And to what extent could you feel the hand of big blue in the room then?
To a large degree, it was pretty much not present. However, you could feel it in the
focusing of the message around hybrid cloud. Both Red Hat and IBM really want you to strongly
buy into the idea that the next generation of cloud workloads is just on the horizon.
The way that Ginny, the CEO of IBM, described it was, chapter two of cloud workloads is
just about to begin. And these are the real hard jobs. This was during one of the keynotes
up on stage. And she says, one of the real hard jobs that's about to come is the things
that weren't easy to move to the cloud, where you'll need to have something that's a bit
on premises and something that's across multiple different cloud providers. And that's the
workload that they're going to try to address. And she thinks, and I would imagine IBM and
Red Hat are all in agreement along these lines. They're all in alignment here. She thinks
that this is probably 80% of the workload left to go. And in that messaging and in communicating
that strategy, you could really kind of feel the hand of IBM. But outside of that, when
it came to architecture decisions, technology decisions, the way they package all this up,
that felt like classic, independent Red Hat.
Are you trying to tell me then we're talking about Cloud 2.0 then? Is that the name that's
going to be given to hybrid cloud?
I wouldn't be surprised if they came up with something like that. If they call it that,
I think you should get credit. But they really do want you to believe the story that the
cloud is yet to even really kind of kick off yet. And that they're not late. They're getting
in on the good part of it. That's the message that they really were trying to drive home.
And that's sort of completely detached from these RHEL releases. But it was pretty great
to be at a Red Hat summit when a RHEL is getting released. That doesn't happen every year.
If that's really true, and there really is 80% left of the market for them to expand,
and that with this hybrid cloud approach, they can get a big chunk of that, then suddenly
all those billions that IBM paid for Red Hat looks like chump change, doesn't it?
Oh, sure, yeah. They really tried to stress that point. They commissioned a study by IDC
to really drive this home. And there was some unbelievable number. It was just remarkable
that 5% of the worldwide economy flows through Red Hat enterprise systems. $10 trillion worth
of global business revenues in 2019 will flow through a RHEL system.
Well, we talk about IBM having bought Red Hat, but there are a lot of formalities to
go through first. And this week, a major step was taken. It was approved by the Department
of Justice. So it looks very much like that acquisition is going to complete in the second
half of this year.
Well, a busy week indeed. While I'm in Boston, Google IO and Microsoft Build were going on.
And there were a few announcements that caught our attention from Microsoft this week.
Yeah, one huge one was that they announced Windows subsystem for Linux 2, which unlike
the first subsystem actually uses a Linux kernel. So Microsoft are going to ship a Linux
kernel as part of Windows.
Right, they're building an in-house kernel from the latest LTS branch from kernel.org.
So the initial versions of WSL2 will ship with Linux kernel 4.19. Improvements or modifications
or changes that they make to that kernel, they are committing right here in their blog
post to upstream back up to the main kernel.org developers. And they will have their fully
configured version of the kernel available up on GitHub for anybody to take a look at.
It's really the addition of a new tiny lightweight VM that uses a plan nine based file server
and the Linux kernel to create a total Linux environment on Windows where all system calls
for the applications are supported, which was the major limitation of WSL before.
And along with these changes in the way they're handling files now and the support for extended
for means incredible file system performance improvements on Windows as well. Windows 10
with a Linux kernel with extended for file system support from Explorer, all shipped
and blessed by Microsoft. That's big news.
It is big news. And those performance improvements are very important here because that was always
the bottleneck. Anything that involved disk IO essentially was really slow on the first
iteration of the subsystem. But now it's almost like native performance. There's almost no
overhead there. And so this has become incredibly attractive to people who need to have Linux,
but also need to run Windows for various reasons.
A lot of things are staying the same too. I think that's a big goal of Microsoft's here
is you can still run multiple different Windows with different Linux distros in them. The
VM doesn't take a long time to start up. It's not like a traditional VM where it boots up
and it loads a fake hardware environment and then it creates some sort of weird remote
desktop connection. It's much quicker. It boots in about two seconds and it's designed
more as like a hyper VM than a real full fledged VM. But what that gives you is the full Linux
kernel, which means you can do things like run 32 bit applications, even on a 64 bit
Windows environment. You can use a fuse file system. There's a lot of advantages to having
full Linux kernel capabilities, obviously. And you can run multiple versions of them
at once, just like you could with WSL one.
There's a very interesting presentation from Build that was recorded and is up on YouTube
that goes into a lot of the details about this. And one thing that jumped out at me
was about that VM. Even if you're running multiple different distros, there's only one
Linux kernel. They all just share the same kernel. And so it means the overall overhead
is much lower than using traditional VMs.
And because this isn't like some VM they've created from whole cloth, it's what they're
using on Windows Server. It's what they're using on Azure. It means Canonical is capable
of providing actual official support now for that version of Ubuntu on WSL two, because
it's the same version that they provide support on Azure. Canonical has announced in collaboration
with Microsoft, they are certifying Ubuntu on the Windows subsystem for Linux, including
Docker containers, Kubernetes, and Snaps.
You don't have the bell in this show, but it's almost worth ringing it for that. Snaps
on Windows. It's a huge thing for Canonical.
That does seem like a really big deal. It could be a really easy way to get Plex running
for home users on Windows 10, but there's all kinds of possibilities for developers
and system administrators if you can run some of those same Linux Snaps on the subsystem.
And why couldn't you? It seems completely possible. It's interesting that Canonical
is right here at the very beginning of this thing, and we're going to officially support
that too.
Well, they were there at the beginning of the first subsystem, weren't they? They were
the first distro available. That's what it launched with. So it's not a huge surprise
to see them continue in that collaboration. But there's one big question I have about
this, right? Why didn't they just do this in the first place? Why did they spend all
that money on working out ways to interface with the NT kernel and translate those system
calls when they could have just done this in the first place?
I just can't help but think they maybe had a meeting where they were trying to solve
some of the problems that were caused by that. And someone just probably piped up with, you
could just have a Linux kernel in a VM maybe.
And that must be it. That's got to be it. In that video you cite earlier, they do up
on the screen, they show like all of the issues people have submitted that frankly just come
down to differences between the way NT does things and the way Linux does things. And
none of them are necessarily better or worse. It's just differences and applications have
expectations. And so I think really they did exactly what you suggest. They must have.
They must have sat around and said, how are we going to solve all of these issues the
developers are submitting? Because here's what's happening is we have actual application
developers that are lifelong Windows users that now need to create a Linux application
and they want to do some of that development better or for worse on the subsystem.
How can we give them a complete tool to do that? Well, the real answer there is to give
them the full kernel, right? Give them the full Monty. You got it. And so they must have
just as a matter of process of elimination come down to this. But I think what's fascinating
about it is this news in combination with their other big news out of build that affects
a lot of us traditional Linux users.
Yeah, you're talking about the Windows terminal, which is an actual proper terminal that behaves
like it should with tabs and all of the other good stuff that we're used to on Linux. Now
you're going to be able to have that on Windows and it's open source as well. But that is
MIT licensed, as you'd expect, permissive license from Microsoft. And I think that may
be the answer to the question of why they didn't do the kernel thing before was because
any changes they make, they'll have to GPL. And as much as Microsoft has pivoted and yes,
they do contribute to the kernel. They don't like having GPL stuff within Windows.
Yeah, well, that's true. They don't. They seem to try to avoid that. But they're not
just open sourcing the new Windows terminal, but also the Windows console, which hosts
the command line infrastructure in Windows and provides the traditional like command
prompt interface. That's not going away. That's going to run alongside the new fancy terminal
that everybody's going to be talking about. The new the new hotness that is GPU accelerated
because of course you need your terminal to be GPU accelerated. Of course it needs to
use DirectX for text rendering. You got to have that so that way you get the best possible
emojis. I kid, but they actually have something pretty good looking here. The text flies.
It does seem to make a difference in the rendering, so you know, give them that. And the configuration
mechanism is pretty neat. You're going to be able to create a multiple profiles for
each shell or application or tool you want to use. You can just go right into it. So
if you have maybe a traditional PowerShell prompt that you need to use for some applications
and for some things you want to go right to Ubuntu, you can do that. Or maybe you want
to just jump right to an SSH connection. You can have different profiles that just bring
you right in there. That's a great idea, and there's a lot of other nice to have things
in here for Windows users that. Honestly, in a big way, this kind of feels like Microsoft
doing a big catch up because the command.exe prompt has been horrible for years. I spend
a week on Windows 10 like two years ago or something like that, and one of the first
things I had to do was replace the terminal. You just gotta get a new terminal and Microsoft
says they explored extending and enhancing existing projects, but in the end decided
they'd have to change them too much and it would be better to do their own open source
project. Now in the summer of 2019, previews will be released on the Microsoft Store for
early adopters, but it is all up on GitHub. You can actually go grab the source and build
it today. People are doing that and submitting issues, and there's quite a bit of documentation
to help you along. I'll say this, Joe, having watched the videos and read through the documentation
as far as commercial platforms go, like your Mac OS and Windows platforms, I would bet
you after they're done here, they probably have the nicest commercial platform terminal
now built in by default. I don't think they're matching what's on most Linux distros and
maybe I'll miss that GPU acceleration, but as far as the commercial platforms go, I think
they've got it.
I haven't really used the terminal much on other platforms, but I know the one on Windows
is just terrible compared to Linux. The Mac one seems pretty limited as well, so I can
see why they wanted to have a full featured one that actually matches some of the features
of the ones that you can get on Linux. I've already seen people pretty excited about this,
people who are forced to use Windows for their day job. They're really looking forward to
having a proper terminal to use.
I agree. I think about all the listeners. I look at the stats sometimes. We got a fair
amount of Windows listeners. I think about them, I think this is going to make their
day jobs or their lives a little bit easier. If they choose or have to run Windows, whatever
it may be, this makes it better. It's bringing more Linux to more people.
Well, it comes back to that same debate that surfaced when WSL was first announced. Is
this really bringing more people to Linux or is it bringing people away from Linux to
Windows and having people not need to dual boot, they can just have it all in Windows.
That's what Microsoft wants.
Oh yeah, I won't lie. It definitely touched on those buttons for a brief moment when I
said, oh crap, crap, crap, crap, crap, crap. But you know, Joe, you just can't stop the
slow but ever consuming progress of that Linux train. Even those simple machines that were
just going to be a web browser on a laptop eventually sub come to that Linux monster.
Yeah, you mentioned Google IO earlier and something that came out of it was just kind
of a throwaway comment really that all new Chromebooks released this year are going to
be able to run Linux applications.
Not a huge surprise. I mean, that's sort of what you would expect as they introduce new
features to the platform hardware that's released after those new features get support for it.
It just seems like that would make sense. But it is nice to see that. And it's getting
easier than ever. You can just launch now using the application search launcher thing.
Just type in terminal and this will launch a terminal VM that starts up a Debian nine
box in the background. But as we've covered in the past, it's now getting easier and easier
to run full fledged applications. And Google is adding support to the file manager to get
access to those Linux files from the file browser. So it's getting pretty integrated
now.
Oh, yeah. And the one slight surprise is that even the ARM Chromebooks are going to be supported
here. And I suppose that's something we should have mentioned with the WSL too, that that
is also going to be built for ARM 64. So ARM isn't being left behind with this.
Well it strikes me as no coincidence that both Microsoft and Google are trying to make
it very easy for you to get a full fledged Linux environment on your mobile system. It
seems like they're clearly trying to go after what I call those Sputnik customers. Those
customers that Dell recognized many years ago now when they launched the first Sputnik
laptop aimed at quote unquote developers with Ubuntu pre-installed. They recognized that
developers wanted to use an environment that they were deploying on in production for development.
And now you see Microsoft and Google trying to backfill that need on their platforms that
were never designed for this. And while it's great to have it, it sort of rings hollow
to me. It's like trying to go back and fix something after the fact. Trying to fix the
barn door after the cows have already left kind of a thing.
I can see why you think that, but because they've got such a dominant market position,
I don't think that that is necessarily the case. I think that it will actually service
that niche and will keep people away from Linux, proper desktop Linux.
I suppose that's definitely possible. It still seems in that scenario, worst case, people
are still getting some rudimentary Linux knowledge and experience. And that knowledge and experience
would be directly applicable if they were to move to a more full-featured real Linux
system down the road for whatever reason. It could encourage them to go in that direction.
Whereas in the past, market and general momentum might have been towards Windows or even macOS.
Now with all these Linux environments, maybe that changes that momentum.
Maybe. But you know, something I've been thinking about is Apple in all of this. Where is their
developer story? Where's their Linux developer story? It seems to be non-existent to me.
I mean, I don't pay close enough attention. Maybe there's some things they do, but you
cannot for a second imagine that you'll be able to build and run Linux binaries on a
Mac system. And they just seem to be being left behind here because I suppose they don't
really care about that market. They care much more about iPhones and services.
Yeah, they want to enable you to develop for their own ecosystem. That's what it is.
But is that short-sighted of them?
I don't know. I guess time will tell. Right now it doesn't seem to be.
Yeah, but you've got to be thinking five years plus ahead, haven't you? And you know, that's
what Microsoft and Google are doing here by realizing that Linux is the future.
Yeah, and they did release Swift for Linux, which kind of seemed to be like an indication
that they kind of got that. That all of these mobile apps have to connect back to server-side
services and that's got to be running on somebody's platform. And perhaps they're just perfectly
happy letting that be a Wild West. But it seems to me, you're right, they would want
some kind of control knowing them. But so far, I got to say, I can't really fault them.
They seem to be doing all right.
Yeah, but while you're at the top is when you need to be thinking about when you might
not be at the top.
Yeah, I completely agree. That's good advice. You ought to write that up and send it over
to Tim Cook. Maybe send him just this time code out there, audience. Tweet Tim Cook this
time code. He needs to hear from Joe.
Android's on top and they have a big problem with security updates. I mean, that's like
the go-to horse that everybody loves to whip no matter how dead it is about nobody getting
Android updates. Google's figured out a really, really clever solution. They're just going
to sneak them on your phone.
Yeah, they're calling it Project Mainline and this is part of Android Q. And their idea
is pretty simple really. It's just expanding on Project Treble in terms of making it more
modular and being able to update those modules via the Play Store and Play Services rather
than relying on the OEMs to actually deliver the updates that Google puts out there.
Well, this is exactly what I expected when Google announced the Google Play API however
many years ago. It just seemed like a great backdoor way to push down features to phones
that weren't getting updated by OEMs fast enough. Everybody knows the story. There's
a huge long delay between when Google issues a security update and a phone manufacturer
like Samsung or LG actually sends that update out to its end users. And it's becoming more
and more of an issue as we discover more things faster and it's a bad look.
So the new feature Project Mainline like Joe talked about is going to send some security
updates directly to Android phones through the Play Store. Now there will be 12 different
quote unquote modules Google is capable of updating. It's minor stuff. It's things like
GPS stuff, media components, things that the Play API would have access to. But they are
expanding upon that as they modularize the Android base.
But this unfortunately is not going to solve all the problems because there are some updates
that do need a full OS upgrade. And so we're back to that old problem. But it is going
to help significantly by the sounds of things.
Yeah, if they could just solve a few zero days here and there, even just a few a year,
it seems like it's a worthwhile effort. And it does remind us that they have quite a bit
of leverage over a phone that has those G apps and those Google Play APIs installed.
Quite a bit of leverage, more like complete control.
Just like attackers could have had, depending on your environment setup, if you are running
Alpine Linux Docker images. Now don't worry, it's not as bad as it sounds, but it was possible.
I almost didn't include this because to me, this is a bit of a non-story. But then I saw
enough kind of debate about it and people disagreeing with my viewpoint that I thought
we should talk about this. I think you take this a bit more seriously than I do.
Yeah, generally. However, this one isn't making me call for red alert. So some Alpine Docker
images shipped with root account and no password, depending on the configurations that the end
users applied. This is all according to Cisco's Talos Research Division who discovered the
bug and they tested each version of Alpine they could get their hands on.
The vulnerable images of Alpine Linux Docker containers were available via the official
Docker Hub since 2015, but it's been a while since any of those actual affected versions
are in production. The vulnerability appears to be the result of a regression introduced
in December of 2015 due to the nature of the issues systems deployed using the affected
versions of Alpine Linux container that utilized PAM or another mechanism like that took advantage
of the system shadow file that the user set up themselves after the fact were vulnerable
to a null password for the root user. No password, zero password, have at it.
Right, but that is less of a vulnerability and more of a, I don't know, a default setting
that can be changed that isn't ideal out of the box. It's not like an actual vulnerability
where the user can't just easily just do password and put a password there.
Right, I mean it, again, it really isn't like a big deal and it was really environment specific.
If you have the shadow package installed in your Docker container and you run a service
as a non-root user, an attacker who then compromised your system via a completely unrelated
security vulnerability, so they have to chain multiple vulnerabilities, or a user that had
shell access, so you gave them legitimate shell access, could elevate their privileges
to root within that container. That's the extent of the vulnerability and you had to
install like the Linux PAM package or the shadow package yourself after the fact and
it hasn't been an issue for at least a little bit now since we, as we record this.
But doesn't this come down to the misuse of Alpine? Isn't Alpine designed to run micro
services rather than a full stack and it's people who are running a full stack but not
really knowing what they're doing enough to put a root password in there that is causing
this problem?
Fair enough. I think it's, to me too, the other thing that's interesting about it is
that this came out the week that Red Hat announced the universal base image, which is straight
up an Alpine competitor. It's a larger competitor in terms of file size, but it's very compelling
because you could run a rel container that is supported by Red Hat if you run it on their
stack or on any system you want, but you'd still get application compatibility with rel
and it's pegged to rel8's packages. I mean, that's a pretty competitive base image to
come up against Alpine when they have this news. Like the timing just kind of stinks
a little bit.
Yeah, but isn't Alpine servicing a different need here?
I think so. I think especially when you're talking thousands or many, many thousands
of containers, then some of these differences are pretty pronounced. But I just thought,
I just thought the timing still was, I don't know, just very convenient for Red Hat.
Is that some conspiracy bacon you're frying up there?
No, I won't go that far. I won't go that far. It's just the way things work out. I don't
think Red Hat would do that, but it is convenient.
Well something that's definitely convenient is the blockchain. You've got to use it for
everything, right? And it's going to be a huge success.
Yeah. I'm going to distribute podcasts. I'm going to do my accounting on the blockchain,
grocery shopping, everything, unless it's all a bunch of hype, Joe. Maybe it's all hype.
Well, I do like to end often with a blockchain story.
Yeah, you do.
They've generally been positive, but Gartner has poured quite a lot of cold water over
the whole thing by saying that 90% of blockchain supply chain initiatives are basically going
nowhere.
90% is a pretty striking number. But then again, if so many of them are just hype crap,
that doesn't seem unreasonable. And I think it's a bit of a chicken and egg problem. They've
identified two issues in this report that I can kind of see. Number one, without a vibrant
market for commercial blockchain applications, the majority of companies don't really even
grok how to evaluate or assess how they could make it useful for them. And they can't really
visualize the entire landscape to see what the different options are. The second issue
is a lot of the current offerings are really just solutions that are remixes of conventional
open source technologies that people could just use for free. On top of that, it adds
a lot of complexity and confusion because then there's a lot of one off variations between
the different implementations depending on what version they forked from and all the
kind of complexities that you can imagine.
And so it makes it harder for companies to really identify the appropriate types of blockchain
for the appropriate use cases. And then you look at the numbers. Now, granted, these are
from 2017 and 2018. But Gardner did a survey of supply chain technology users who thought
that maybe they could do some nice technology upgrades, you know, in the market to spend
some money. 19% of respondents ranked blockchain as a very important technology for their businesses.
And only 9% had even bothered investing in it. So less than 20% think it's worth their
time and less than 10% have even spent a dime on it.
I think another big problem here is that companies that are big enough to take advantage of blockchain
technology are almost too big to move quickly enough to adopt it.
If I were to put on my futurist hat here, I'd say something as fundamental as this too
is going to take a very, very, very long time to be adopted, probably longer than SQL databases
and Excel spreadsheets and access databases took to be adopted by businesses. Something
like this can take a lot longer. And I think you're going to see a lot of failed attempts
this this survey here that Gardner did. They are unimpressed. I'm unimpressed with the
survey to be honest with you. First of all, 2017. That's quite a while ago. Second of
all, they're asking companies to look forward to stuff that they can't even conceptualize
what can happen to them in the next six months. Let's be honest. And I don't think we really
have seen the breakthrough use cases yet. We're starting to see some of them. But some
areas of business just take decades to change. Look at shipping and banking. Those are areas
of business that can take 20 years to adopt new technology. Us humans, man, we're not
so good at this.
Yeah, but I think the change will come because there are some clear advantages in certain
areas for the use of blockchain. And I think these companies will eventually realize that.
But I just think it's going to take a bit longer than I had initially thought. Because
I don't know, Gardner, you say you're not impressed with this. They're usually pretty
spot on with these things.
Yeah, you're right. I mean, Gardner has been pretty solid. I think it's just these things
are pretty hard to map. We'll see. Long term, Joe, I'm betting on Dogecoin. I know it's
a long shot, but it's going to make a comeback.
I think I've still got some of those somewhere. But long term, it's all going to be about
blockchain. And it's all going to be running on Linux.
Of course. At the top of the show, the most important news this week is there's a new
show where you can get to learn more about the crew. Come meet us all over at FridayStream.com.
It's a show where our crew from all over the world hangs out and shares stories and gives
each other a hard time. It's just a chance to get to know us a little bit better. FridayStream.com.
Yeah, streamed live on Fridays at 2pm Pacific or released kind of Monday-ish on the RSS
feeds. So yeah, check it out.
Yeah, it's Friday on a Monday. It's actually kind of fun. Gets you going. But of course,
this show comes out Monday mornings. Go to linuxactionnews.com slash subscribe for all
the ways to get new episodes.
And linuxactionnews.com slash contact for ways to get in touch with us.
And one more Plug Skis Tuesday, May 14. That's coming up real soon now. We have a command
line threat hunting study group where you'll get tips to discover if your machine has been
compromised from the command line. Meetup.com slash Jupiter Broadcasting for time and details.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
I am at Chris LAS.
I am at Joel Ressington.
Thank you for joining us and we will see you next week.
See you later.
