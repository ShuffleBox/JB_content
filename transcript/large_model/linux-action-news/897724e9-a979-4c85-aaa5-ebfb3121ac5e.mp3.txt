Hello, and welcome to Linux Action News, our weekly take on Linux and the open source world.
This is episode 94, recorded on February 24th, 2019. I'm Chris.
And I'm Joe.
Hello, Joe. Good to be connected with you. We kick things off this week with some great
news out of the KDE camp.
Yeah, they've decided to embrace matrix and add it to their instant messaging infrastructure.
They're going for something modern, but freedom respecting.
I'm really pleased to see this story. So just backing up here for a second to make it clear.
We're talking about the project and how they communicate. I mean, I'm sure we'll see this
influence trickle down into some of the KDE applications. But this is big because communication
is something the project has struggled with. Inside the KDE group, there's different camps
of messaging, you have Telegram, Discord, IRC, different IRC servers and rooms, and
a mixture of all of these, which has led to some complaints in the project about making
it hard to communicate, staying up to date on what everybody's working on, keeping everybody
pulling in the same direction.
This sort of solves that because it introduces bridges to some of these different endpoints.
But it also brings a lot of advanced communication and routing features. Matrix is really nice.
And when you combine it with something like Riot IM, which they will be, you have a lot
of the features of Slack and more. And that's why it's so great to see this because Slack
for some projects is quicker to get started with. It's got a network effect. It's free
for certain types of usage. And it's really tempting because there is for a lot of cases
a workflow improvement. And so the projects are tempted to just hit that button, start
up a Slack, boom, now we're collaborating. Deploying something like your own matrix server
and loading Riot IM on top of that depending on which way you go can be a much larger investment.
But it's open source. So it's an open source project using another open source project
to communicate, which makes both projects better. And it means this stuff isn't locked
up in some proprietary database and some company that's keeping all this stuff for profit reasons,
which they have every right to, but might not mesh with the same goals of a project
like KDE.
Well, that's exactly it. This is decentralized. It's open source. It really fits perfectly
with the KDE ethos. And as for the network effect, I don't think it's a huge issue because
the kind of people who use KDE and the Plasma desktop are the kind of people who care about
software freedom. And so I think they're more likely to use matrix than maybe users of some
other open source software that's maybe a bit more pragmatic. And am I off base there?
Do you think that KDE users tend to be more freedom loving?
I don't even know if it really matters because they certainly will be more inclined to use
matrix now because that's what the project is using. And if they as users want to get
involved with the project, they'll be using matrix. And it creates its own network effect
when a large open source project starts to use this. And this is just more good news
for matrix. That might be the bigger story here is matrix has had a really good year.
They've confirmed that they are the basis for France's secure instant messaging application,
which is huge. Again, they're using like a fork of riot IM to do this. And there was
a FOSDM talk that went into details about it, Joe. I know you probably saw that talk.
And it looks like it's full fledged, like government level implementation that will
have jobs created for contractors and for people doing implementation and IT. It looks
like it's going to have a massive effect for matrix.
Yeah. And the more people use it, the better it's going to get. And to be fair, KDE is
not abandoning the old methods of communication. As you said, there are bridges there and they
will continue to use things like IRC. But hopefully, it's going to push forward matrix
and make some people check out who have never actually done so before. And maybe we can
finally have, in the open source world, a standard way to communicate that is modern
and does support the features that we need that IRC doesn't necessarily. But that isn't
something like Telegram or Slack that is ultimately proprietary.
I remember talking to the project at a conference when they were brand new. And the big thing
they were emphasizing at, I think maybe it was OSCON or I don't remember, but it was
this connection system that they have, these bridges they could do. And it's not just to
like IRC and Telegram, it's to PBX systems and video conferencing systems. It's incredible.
And it handles all of this plumbing for open source projects or for businesses that want
to use it. So when you see government level adoption, and when you see large project scale
adoption, you begin to set a new standard, you begin to set something that is bigger
than it was before. Because as they write on the Matrix blog, we expect this will drive
a lot of effort in the maturing the end-to-end encryption and the Matrix React, iOS and Android
SDKs and applications.
They believe with France's federated network of Matrix server, you're going to see an ecosystem
of businesses around that. That could be, you're starting to see bots that get built
for Slack that get sold for a certain amount, or when businesses want to have a new HIP
friendly interface for modern businesses, they create a Slack interface to their project.
You'll start to see people think a lot more about Matrix for those kinds of things. And
I think that's a pretty necessary component. There's already some momentum there, so I
think this is just going to make it even better. It's a year of Matrix, Joe.
Well, let's hope so. But is it also the year for OnionShare?
Maybe. It wasn't that bad. We tried it out. It's kind of cool. OnionShare is an open source
tool for securely and anonymously sending and receiving files using Tor Onion Services.
Surprise, surprise. It's kind of neat because most of the work is done on the sending side.
So whoever wants to send a file, you install OnionShare. And when you run it, it starts
a local web server directly on your computer, which it then makes itself accessible on the
Tor network. And it would generate a Tor web URL that you can share to somebody. And as
long as they have the Tor browser, they pop that URL into their browser, hit enter, and
they're on my little mini web server.
Yeah, and we've tried this out. And it wasn't the fastest in the world, as you'd expect
over the Tor network. But it worked perfectly well. So no complaints there. And of course,
we're talking about OnionShare 2, which is a major new release with tons of new features.
So it's nice. It's cross platform. It's open source. It's a great way to securely send
files. They write in here about how this could be great for journalists to transfer files
around and whatnot. But the part that was, I think the nice user experience aspect of
this was when Joe downloaded the video I sent, he didn't have to install anything if he already
had a Tor browser, which I assume you probably already did, Joe.
No, I actually just grabbed it. I don't generally use Tor very much because it's so slow. And
I don't really have anything to hide. But it's easy enough. You don't have to actually
install anything. You just download the tar file, extract it, and run the binary. And
boom, just works.
Yeah, and I think there's some snaps of it, too. And there's a browser extension. There's
several ways you can get it pretty quickly if you don't have it. And then you just need
that URL. The fact that it runs a local web server is, yeah, it's a little iffy from a
security standpoint. But you just got to keep it up to date and watch the project. And it
does add that sort of ease of use aspect to it where there's no real software needed on
the other end, which is pretty nice.
And that web server doesn't last very long. As soon as the files are downloaded, it kills
that for you. So it's not like it's running all the time, although you can make it run
all the time if you want to. So you could use this to distribute files to multiple people
at once if you wanted to.
Yeah, and you can watch the transfers as they go out. So you can see what speed they're
going at and what percentage they're at. And you can track them all. And you're right.
By default, once our transfer was done, I think like three minutes after that or whatever
it was, a 90-second timeout or something, it killed the web server. And the URL was
no longer usable. It doesn't have any built-in way to share that URL. So you're going to
need Signal or Wire or Keybase or, I don't know, text message, whatever you want to use
to send that URL around.
Matrix, even.
Yeah, you could use right I am on top of Matrix to send it to your buddies. And then, yeah,
you can download several files or just one. It'll do some compression for you if you put
some uncompressed stuff in there to make it one file on the other end. It does that automatically.
And version 2 is a lot more secure because it generates much longer addresses. And it's
much harder to guess what those are. And if people do try and brute force it, then after
20 goes, it just shuts it down. So it's pretty much unbrute forcible. So maybe secure is
the wrong word. It's all about privacy, isn't it? It's about being anonymous and essentially
hiding the fact that you're sending stuff to people.
Well, if you think about it in a journalism context or perhaps in another country in an
activism context or even here in the States, you could see why privacy could really matter.
That's why I think one of the major new features of version 2 that's pretty slick and really
matters like in that journalism context is it can do essentially private Dropbox mode.
A secure drop, not like Dropbox, the file sync, but like in the journalism context,
like a private secure drop. When you use Onionshare to receive files, you turn it into like a
Tor hidden Dropbox. Think of it like a lightweight version of secure drop that anyone can just
run on their own laptop or on a server instance somewhere on your own desktop without really
having to set anything up.
You just run this app, you get a URL that people can send files to and you start receiving
mode and it'll just sit there waiting to receive a file. Now, obviously there's some security
implications with that, but in certain contexts, that's massively valuable. Imagine if Glenn
Greenwald had this when Edward Snowden was trying to work with him to exchange files.
This would have been a game changer for them.
Yeah, and if you're running it on the desktop, then you need to have that desktop running
all the time, but you can run it headless on a server if you want to, which again could
be very handy for people like Glenn Greenwald.
Well, enough with the dark web. Let's go back over to, I don't know, maybe the commercial
web. At least there's a lot of money to be made in the land of databases or I suppose
potential money.
Well, there's a lot of VC funding. We know that much. Redis Labs have raised $60 million
in VC funding.
Yeah, they raised $146 million now in total, Joe. That's a lot of money. So if you're listening
and not familiar with Redis, you might be wondering why is it worth $146 million potentially?
Well, it's an open source project for essentially an in-memory key store, which is a way to
say a database that's in RAM and really fast and optimized for certain types of database
structures. And those types have worked really great in cloud applications, mobile applications,
when you're trying to pull in a lot of data for a lot of users very fast. And on top of
that, now they're nearly 10 years old. On top of that, they've built Redis Labs, and
they have the Redis Enterprise offerings, which is their commercial product, which has certain
features that make it nice for managing Redis at a certain large scale.
But although the core of Redis is open source, some of the modules that they have for it
aren't. And we talked about this towards the end of last year. They changed the license
to Apache, but added something called the commons clause, which essentially meant that
it was still open source in effect, but you couldn't use it to make money. And then the
community said, well, hang on, that means it's not open source anymore.
Which was a clear move to try to prevent Amazon from, as they saw it, taking their code, running
away with it, and making a super, super profitable product off of their backs and not giving
anything back to them. And this was their move to prevent that in the future.
But this week, they've decided to clarify that license, and they've changed it to what
they're calling the Redis source available license, which to be fair, is a much more
descriptive and much less confusing name.
That's probably the biggest change here, is this name. Instead of calling it Apache 2
modified common clause, which was confusing to everybody, it's just the Redis source available
license now. That's kind of standard terminology for this type of stuff. It's something we've
seen before in this business model, and I think it's a good clarification to be made.
The question you have to ask yourself, though, is to what end? They're taking this in this
strange direction as a company. There's quotes in here, which we'll have linked in the show
notes that you can go read.
Or if you just follow them on Twitter, they clearly see themselves as a victim of large
commercial providers like Amazon who are stealing from them. They write on their website, some
cloud providers have repeatedly taken advantage of successful open source projects without
significant contributions to their communities. They go on to write, they repackage software
that was not developed by them into competitive proprietary service offerings and use their
business leverage to recap substantial revenues from these open source projects. Their new
license was designed to help prevent this, but they treat it as if this is some new battle
that they're fighting. In fact, they declare the open source model no longer functional,
and it must be rethought, they say. Open source is fundamentally flawed in the age of cloud
computing.
And that's scary stuff. MongoDB's kind of said something similar. That's provocative,
but it's also lessons we've learned in the 90s. Apache had this same problem when the
LAMP stack became popular. This isn't a new issue. We've had this problem before, and
it's something that you probably should have been aware of when you chose an open source
license to begin with.
Well, exactly. If you don't have a viable business model with open source, then don't
use open source. You can't pivot halfway through and start making things proprietary because
you're going to have a huge backlash. And I probably shouldn't be saying that don't
use open source, but I think the better way to say it is find a business model that works
with open source. And to have not seen this coming was just short-sighted of them.
And now they're trying to retroactively fix it with a license change so that way they
can go to the VCs and say, well, look, now we've got a handle on our future property.
Our value add, we've got a real handle on that now. It's licensed properly. People have
to come to us. And their business is growing. They say they've got around 8,000 customers
right now that use their hosted services. That's not Amazon scale, even a little tiny
bit, but it's something. It's generating them a nice little bit of cash and they want to
grow that. And so they're going to the VCs and they're saying, well, now that we've re-licensed,
that's all tidied up. We've got that in the can now. And the proposition seems to be in
the future, we're going to invent some stuff for the enterprise side that's so great, they'll
have to use our services. But I would very much doubt that. I would just simply think
that if they created something that added value, Amazon could just replicate it on their
own using their own development team at a much larger scale and integrate it into their
product pipeline. They've now got the base, right? There's no putting the genie back in
the bottle, if you will. The core source code's out there and now they can build value on
top of it forever. Apache fought this same issue in the 90s and Apache decided to double
down into open source and say, well, look, it gets our product out there as a standard.
Now Apache is a platform. There's a lamp stack now and it furthers open source. So there
is a net win for Apache in that direction and there's a net win by Apache becoming the
standard. And nobody's walking around with Apache money buying Teslas here and there,
but it was the right way to handle this because of the license they used. And Redis is treating
this as if open source has gone bankrupt and Amazon's running away with the source code,
as if no one's ever done that before. Yeah. So really it boils down to they should have
done the foundation route rather than making Redis Labs a commercial entity because there's
not really that much money to be made that way. If you're a foundation that doesn't have
to chase growth and revenue, you can just concentrate on making a good open source product
and the finances will just sort of work themselves out. And as you say, no one gets rich, but
it is sustainable. Yeah. Who's to say? Maybe they can pull off a competitive commercial
offering. I mean, they are the creators of the software. If anybody could compete, it
should be them. So perhaps Redis Labs will pull something out here and in a couple of
years they'll have tens of thousands of customers using their hosted solution and they'll still
be a good core open source application for us all to use. That could very well happen.
We'll see. But I do think it feels a little disingenuous to say that open source is fundamentally
flawed and that the cloud is ruining open source. The cloud is powered by open source.
Yeah. Well, we wouldn't have had the cloud without open source probably. And for it to
kill it just seems a bit of rigging the pudding to me. I think that it might kill certain
business models like Redis Labs, but I think ultimately open source will be fine.
New technology waves often do that. They disrupt one business model and new ones emerge. Just
ask the news industry. But that doesn't mean the cloud won't always be powered by open
source and Linux in some form or another. The business models around it will continue
to change as the industry changes, but that GPL cancer, that's not going anywhere. Maybe
the cloud will be powered by ARM processors soon, Joe.
Yeah, that's the question. Is this finally going to happen? How long have we been talking
about ARM in the data center and it just doesn't ever seem to fully take off. But now ARM have
announced Neoverse processors that they're at least claiming are going to disrupt the
x86 side of things. And we are finally going to get these ARM data centers that we've been
long promised.
Here they come. Yeah. ARM claims the design provides as much as 2.5 times more processing
power for certain server workloads than previous ARM architectures. And they say moreover,
it's 60% speedier when assessed by how fast it processes integers, which are a basic unit
of data. They also hype the artificial intelligence support. I don't doubt that ARM CPUs are going
to see a continued adoption of the data center, especially on the edge devices. Absolutely.
Accelerators, purpose built devices. Clearly, I think ARM is going to probably see a ton
of success there. New telco equipment. Absolutely. ARM based. I can clearly, clearly see that.
That seems obvious to me. But I'm on board with Linus on this one. Anything that's going
to be in the application stack, anything that lives in layer seven, that's going to be running
on x86 processors for a very long time.
Yeah, that's what everyone's talking about. This email thread where Linus has basically
said, nah, this is not going to happen. They're not mature enough. It can't compete with x86.
And the fundamental reason that he said is, people are developing on x86 workstations,
and they want to deploy to x86 servers, which is a very valid point. People don't want to
have to deploy to a different architecture, because you're inevitably going to find various
bugs that are on one architecture, but not on the other.
And look how slow enterprise is to adopt changes like these large scale enterprise applications.
You know, there's still systems running on Windows 7 and Windows XP, because it runs
along just fine, and that business class application needs that operating system. It's a slow moving,
very slow moving industry when it comes to software. And I think he nailed it when he
said as long as people will have to cross build for x86 and ARM at the same time, it's
just not going to be that great. Like you have to get to a point where it's the only
platform people are developing for, for the software to get really great and to be really
good server grade at that higher level where you're creating user applications.
But the thing is, we know that all developers use MacBooks, right? Even if it's in secret.
And it looks like Apple are going to switch to ARM very soon. They proved with the iPad
Pro that they can have desktop class performance with an ARM device. And so there are strong
rumors that in the next year or two, Apple will be shipping at least some machines that
are completely ARM based.
You're referring to some reporting that was out of Axios this week that was citing, quote,
developers and Intel officials that were familiar with the matter. And I guess on Intel's roadmap,
they are planning for Apple to transition to ARM by like, yeah, 2020, 2021, something
like that. That seems like it would be a pretty big mistake for that developer market that
bought a lot of MacBooks so that way they could have a system that could run their proprietary
applications or whatever it is they wanted, but then they could click a button and have
the bash terminal and have access to some of the standard Unix user land applications.
That was a huge selling point for the MacBook. And I watched conferences, I just watched
it take off like wildfire year after year. You go to several, you go to several a year
and at every event there'd be more MacBooks. We talk about it on the shows, we'd be like,
there's so many MacBooks now. And it was clear what they were doing. They were SSHing into
Linux boxes. And I think a big part of it was they could do some of that local development
right there. They could install Ruby, they could install Pearl or Python and do development
right there in a terminal and then upload it to their cloud instance or whatever it
might be. And it just seems like you lose a huge part of that value if it's not x86.
I might be wrong, but it would seem like that to me. And I think I just, I completely agree
with Linus's point and I'll link it in the show notes so that way you guys can read it.
I think it's very, it's just a compelling point. Like that's why x86 took over the server
market to begin with. When I got into IT, there were alpha processors and risks processors
and x86 processors and power PC processors. And it basically all went away except for
x86. And it in a huge part was because of Windows. Because developers were writing on
Windows on their x86 PCs. And that's why.
However, where Apple leads, the rest of the industry generally follows. And so we might
end up seeing ThinkPads with ARM processors in them. It might just become the standard.
I'm not saying that it's going to happen this year or maybe even in 2020, but within the
next five years, ARM processors could catch up and we could get enough performance, not
to mention the incredible battery life that we get as a result of that. And it might be
that they take over.
I do tend to agree. If you zoom out the timeline enough, you kind of do think it has a bigger
possibility of working out. And Apple makes their own chips in house. So they'd be a pretty
key vendor to switch over their desktop or laptop line. Maybe just be a few machines
or one machine at first. And they could just throw a few of their A series processors in
there like they do in the iPad. Just throw six of them in there.
I mean, maybe. And maybe that takes off and the PC vendors do it. And all of a sudden
you got a bunch of people that are writing software on ARM CPUs. And so the server market
makes a transition. I've always thought ARM would be successful in the data center as
we break things off into more purpose-built appliance hardware, which is a super common
trend in the data center. There's so many appliances and accelerators for different
things now. And why wouldn't you start with a pretty competitive CPU platform that has
lower power usage and produces less heat? It's just obvious. And there's just going
to be more and more of that. So maybe there'll be parity in a five to 10 year time period.
It could be before that. I saw a poppy tweeting about wanting to test snaps on ARM this week
week. So it's something that obviously is on Canonical Employees Radar, Linux on ARM.
And we've had the Raspberry Pis and hacker boards and everything. But maybe the tide
is starting to turn and we might end up in an ARM world on our workstations and servers
before we thought we would.
I'd be willing to give it a go. I have nothing necessarily against it. The Wine Project's
investing time into it. Their hangover 0.4 alpha release came out, which is a project
for running wine applications, x86 and even 64-bit wine applications on 64-bit ARM CPUs.
So they're doing not only the Windows API translation, but under the hood, they're taking
QMU and they're virtualizing x86 components to run that Windows application on a Linux
box with an ARM CPU.
So just last week we were talking about those cheap Windows laptops that are ARM based and
the struggle to get Linux running on them and how, okay, it's not quite there yet, but
it is happening. And it's great to see that the wine developers are keeping a pace with
this. It's very early days and things aren't working very well, but it's not something
that they're ignoring. And so it is great to see that you might end up being able to
play Windows games on Linux on ARM machines.
It's going to take a lot of ARM processors or they're going to have to get a lot faster
because right now, as you would imagine, there is, as they put it, a quote unquote cost due
to emulating the whole x86 or x86-64 architecture. And as their documentation states, quote,
don't expect this to be fast. So it's got some work, but I wonder if that old trucks
versus cars analogy that got applied to tablets and PCs a lot, I wonder if that might be updated
in the near future where the x86 systems are your trucks and your cars, just your daily
drivers are ARM based systems.
Yeah, or maybe a more apt analogy would be like a scooter or something. One of those
electric scooters that you can get with the apps on your phone.
Well, if it develops, Joe, you know what? If we see it developed into something, we'll
cover it right here on the show. Well, that and all of the other things that matter in
Linux and the open source world, go to linuxactionnews.com slash subscribe for all the ways to get new
episodes.
And go to linuxactionnews.com slash contact for ways to get in touch with us.
Yeah, I'd love to hear from you. If you think ARM is going to take over the data center,
go read the link for Linus's post and then go to their contact page and make your case.
Also, if you are a full stack Ruby on Rails developer, Linux Academy is hiring a full
time remote position. Go to linuxacademy.com slash careers, or we'll have a link at the
bottom of the show notes in this episode if you'd like to apply.
We're also doing another freebie study group after Linux Unplugged on March 5th. It's about
Linux system fundamentals and some history. Go to meetup.com slash Jupiter Broadcasting
for more details on when and how to participate and all that kind of stuff.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
I'm at Chris LAS.
I'm at Joe Ressington.
Thank you for joining us and we will see you next week.
See you later.
