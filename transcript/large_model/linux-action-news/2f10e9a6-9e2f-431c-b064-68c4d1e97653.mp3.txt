Hello, and welcome to Linux Action News, our weekly take on Linux and the open source world.
This is episode 63, recorded on July 22nd, 2018.
I'm Chris.
And I'm Joe.
Hello, Joe.
I'm so excited to be connected with you, and I am elated to announce that Reaper 5.93 is
now available for Linux.
What, what, what?
Wait, let's stop here for a second.
What's Reaper?
Reaper is a proprietary piece of audio software that you and Noah absolutely love, and I won't
touch with the barge pole because up to now it's been some dodgy binary downloaded from
a website somewhere.
Well, tell people how you really feel, Joe.
Yeah, that's exactly it.
Actually, in fact, I don't talk a lot about it because I felt like it could go away at
any moment, and so I didn't want to get people's hopes up, but Reaper is proprietary.
Let's make sure that's totally clear.
Joe just mentioned it.
It is proprietary, and there are free software solutions like Ardour.
It's a DAO or a digital audio workstation or a DAW, however people might pronounce that,
and it's a full featured one at that.
Reaper is really enterprise grade, and we've been using it at Jupiter Broadcasting since
January, and I think Noah's been using it for about a year-ish, more than that, and
I switched everything over.
When I edit a show and I record a show, it's all done on Reaper under Linux now, and it
was one of the last components that let me go 100% Linux.
Every show produced in the studio is recorded and has been recorded since January at least
with Reaper, but today they're making the Linux build officially available.
Now it does require GTK 3, although if you want to hack on it a bit, you actually can't
make it work with GTK 2.
I don't know why you would want to, but you can, and you need to either be on a 64-bit
x86 platform or an ARM 7 platform like a Raspberry Pi, which is pretty cool because I have definitely
been considering building a Raspberry Pi 3-based backup recorder using Reaper because why not?
So the Linux build is still considered experimental.
It works with also jack and pulse audio, as well as one of Reaper's great features, dummy
audio interfaces where you can loop audio around.
It also has an open control surface API that has a ton of user-developed extensions that
are available to control different surfaces or initiate remote recordings and all those
kinds of things, and it's a full-featured multi-track recorder.
In the Jupiter Broadcasting Studio, I have a Behringer X32 mixer, 32 channels plus 32
inputs.
This is a big mixer, and it all connects into a Reaper workstation running Kubuntu 18.04,
and Reaper is able to actualize every one of those channels.
I can record each channel independently.
I can apply different effects, and if you have more than a two-core processor, you can
do some really great mixing in Reaper in real time.
I mean, this is some serious enterprise-grade software here.
I've been using it to produce shows for seven months, like this one right now is being recorded
my end on Reaper through my mixer on Linux.
This is a big deal that they've been working on for a while that before we weren't really
supposed to be talking about.
They didn't really want to tell anybody that you could do this, and now they're making
it official.
And the big thing is it's dang near feature parity with the Mac and Windows versions.
It's just dang, it's like perfect, Joe.
It's perfect.
I'm kind of excited.
So what makes this different from Ardour then?
Why would you choose a proprietary solution over a free software one like Ardour, which
I understand is pretty much feature complete and could do all of the stuff that you've
just said?
Yeah.
And if I was making music, I definitely would be skewed towards Ardour, 100%.
But I'm recording vocals and audio, and I'm trying to split things out onto multiple tracks
in real time.
And then I want to export out individual tracks into FLAC files, and I want to have a whole
open source workflow.
Ironically, Reaper gives me that.
When it records in real time, it's always recording to a WAV file that I can grab at
any point, even if the recorder crashes.
So it's architected.
The recording mechanism is architected in a way that is conducive to podcast production.
With music, you're sitting there, you're recording a program.
Yeah, man, it sucks if your program crashes, but you can pick back up and you can keep
playing.
But with a production like this, if our programs were to crash and we were to lose our entire
conversation, you and I would seriously be like, ah, maybe we should just call it this
week.
And then we would sit there and grouse for a bit, and we would load it back up, and we
would have to rerecord the whole episode.
But with the way that Reaper is architected, it's saving to your hard drive in real time.
And you can go in there and say, you know what I want you to do, Reaper?
I want you to save to multiple hard drives at the same time, because I want to have redundancy
with these recordings, which I love.
So I can record to an SSD and a RAID in this rig that I have for Reaper, and it gives me
that peace of mind that if this application were to ever lock up and crash on me, I've
got two separate real time backups.
But I'll mention this, just speaking of stability, this instance of Reaper has been running on
this Kubuntu 1804 machine for 60 days without issue.
I have not even closed the application in 60 days.
I close the project, I create a new one, and I record, in part because I have been on the
road for almost two months, remoting into these systems.
They have to be absolutely rock solid reliable, because when I'm on the road, I can't really
troubleshoot these things.
And Reaper has been so solid.
So while Ardour is great, and it's open, and I've actually contributed to Ardour before,
and I may again, this is perfect for recording vocals, recording podcasts.
And what gets me super excited, and the reason why I'm really kind of, I've just been bursting
at the seams to talk about Reaper, is because I feel like it can move the needle on podcast
production on Linux.
This software makes Linux a great podcast production platform.
Yeah, but it's proprietary, so I don't care.
So let's move on.
Let's talk about Atari and their VCS.
They posted an update and an FAQ this week, which I think on LUP you felt quite positive
about, but I don't, I'm afraid.
I'm curious why you're concerned.
So yeah, Atari, over on their Medium page, has posted an update saying they're going
with the AMD Bristol Ridge family of APUs, and they talk about the thermal reasons and
the performance gains and losses for that.
They talk about building the different hardware and the UI elements, and building out their
Atari store, and creating technical requirements for submitting apps.
This all looks pretty positive.
We've gotten details on Atari OS, which is a customized version of the Linux kernel that
they're calling Atari OS, and even some details on how you can load your own OS inside a hypervisor
that gives you full access to the GPU and disk and things like that.
So if you want to just load straight, standard Linux on this thing, you're going to be able
to.
I read this whole thing, checking off all the boxes for me, Joe, perfectly happy with
the multiple hundreds of dollars I've now committed to my crowd funder.
I'm not concerned at all.
No, no, Joe, I'm not nervous.
Okay.
Well, eight gigabytes of RAM, up from the four that they originally said, that's got
to be a good thing.
However, it's not the hardware that I have a problem with, it's this software situation.
The fact that they are running their own hypervisor, they're writing their own hypervisor here,
which is a custom version of Linux.
If you want to boot your own version of Linux on the machine, then it's not going to have
full hardware access.
Okay, the hypervisor is going to give it pass through to the GPU and all the rest of it,
but you're not going to be able to completely put your own operating system on this thing,
which means that when their support dries up, when the company goes bust, you're not
going to get any security updates for that hypervisor bit, which is crucially important.
Well, I would completely agree with you, Joe, except for I don't believe anything they wrote
there.
When I read Atari OS Virtualizer, I quite literally translated that in my brain as KVM.
I would expect it just to be standard KVM virtual machines.
Nobody would be stupid enough to write their own, right?
I would think so, especially when it's kind of an Ubuntu derivative to begin with, which
comes with that and you're using a modern kernel.
It would literally be lunacy to try to recreate your own hypervisor.
KVM is fantastic.
It's really good.
So you would be nuts not to use that.
But they talk about the process of being in secure mode and stuff like that, which makes
me think that maybe it's going to have a secure boot that you can't turn off and it won't
boot anything apart from the implementation of this hypervisor, which you potentially
can't change.
It's still not exactly clear, is it?
There's almost more questions raised by this Q&A, FAQ, whatever you want to call it, than
are answered.
Right.
And to your earlier point about long term, like if this doesn't work out, what happens
to the hardware, this is the point of concern.
I think you've identified it here.
And I'll say this.
It seems like what they're doing is they are creating their own signed boot system.
And the way it will work is it will check the internal disk for a signed operating system,
and it will load that.
But before it checks the internal disk, it will check all of the USB subsystems to see
if there is a device attached that has a loadable system.
And in this FAQ, they say they're going to release example code based on standard upstream
Ubuntu on how to do that.
But you'll essentially have an external USB drive with a loadable Linux system on there
that will be an open spec.
And if it's detected at boot time, it'll boot that first before it even checks the internal
disk on this Atari VCS.
And they claim that when it boots that external drive, you'll have full access to the disk,
the GPU, the network, that the virtualizer will pass it all through.
That is legitimate.
That is how it works.
Because if you think about it, the kernel is the one that's doing the driver enumeration
to the virtual operating system.
Well, guess what?
News.
The kernel is also what's doing the enumeration to the actual host operating system.
So it's the same job for the kernel either way.
And it has the same plumbing either way.
And so it is actually very performant.
It works very well.
So you will have a good experience.
And on that, you could load Kodi.
You could load Plex or VLC, whatever you want to watch.
You could load that on that external experience.
And it should be pretty good.
But when you detach that drive, it then goes into this signed mode where it has to be a
signed operating system.
So that way, you can load up the quote unquote experience where you have the store, you can
buy apps and that kind of stuff.
Yeah, and by the time we've moved on to kernel six and seven, and this thing's still running
kernel four dot something, that'll be fun, won't it?
That's a good point.
I mean, after they're done, after they get this thing out, assuming they managed to ship
it, they're going to have to be good stewards of a platform.
They're going to have to deliver updates in a consistent manner.
And because they didn't base it off of something like SteamOS, because they are rolling their
own OS, they will be responsible for that.
And we just won't know how they do until it's shipped, because obviously, we just have to
wait and see.
But I hope they can nail it.
If you think about it, because they didn't build some crazy, esoteric, ARM-based platform
with some custom GPU, they should be able to do this.
It's all upstream.
So they just have to repackage all of the hard work the upstream developers have done
in a consumer-friendly way and ship it over what I assume will be an HTTP connection to
these Atari VCS boxes.
It should technically be possible.
I guess we'll wait and see.
Well, let's hope it's HTTPS rather than HTTP, but yeah.
I hope it's Telnet, Joe, and I want it to stay that way.
Well, we'll see.
I look forward to hearing about your adventures with it when it finally arrives.
I will give you a full report when I get the machine.
But in the meantime, let's talk about our mobiles.
If there was one thing that could really be a game changer, it would be the Librem 5 being
a success, and we've got a progress update from Purism.
Yeah, which is kind of a mixed bag, really.
They're making some good progress with the software, but it looks like the prototype
hardware has slipped from their original predicted date, which means presumably the final delivery
is going to slip.
They were saying January or certainly early 2019 for the final product, but that's looking
increasingly unlikely now, isn't it?
I think we've got two things to talk about here.
So first of all, yeah, the dev boards have missed their shipping window of June.
It looks like maybe they've been punted a month or so as a few things get worked out.
But one thing that is jumping out at me, and this is the second one, is there is an issue
I see developing here that also plagued the Ubuntu mobile project.
And that is that they're building everything around a different version of the system on
a chip than what they hope will ship in the final phone.
So right now they are working with iMX6 system on a chip images, but eventually they want
to actually ship the iMX8 based development boards, which have some significant improvements.
And they're hoping that they can build it around the iMX6 and then bring it up to date
to work with the iMX8.
But the issue as of right now is you have very basic main kernel support for the iMX8
board.
Early days, it's hard to get Linux fully running and what does work doesn't include the graphic
stack and things like that.
Now it could technically work out, but in the case of Ubuntu mobile, this turned out
to be a very costly calculation before they shipped it on some hardware that ended up
being not well received because of a lot of rough edges that didn't materialize until
they were on a newer version of the system on a chip.
Yeah, that is definitely a concern.
But have you actually tried out the QEMU image that they have put out there for you to test?
No, I did not try it out.
Did you give it a go?
I didn't realize they had.
Yeah, it's one of the many, many links in this update on their blog.
If you follow it, there's pretty clear instructions how to get it running.
I used boxes because that's just such an easy GUI to use.
And I tried it on a really old laptop first and it was just terrible.
So I thought, okay, I better try it on a decent laptop.
It turns out you need more than four gigabytes of RAM on your laptop to be able to actually
run this.
Oh boy.
Yeah.
So it means that I can't run it on my old test hardware to run it on some decent hardware,
but it was all right.
It wasn't perfectly smooth, but then you have to assume that that's kind of hardware acceleration
issues and stuff like that.
But you did get a glimpse at the UI and the UI is very minimal.
It's hard to describe really.
You've got just an arrow at the bottom that you click and then that brings up an overlay
of shortcuts on the left-hand side.
And there are not many of them to start with.
There's a browser and a calendar and a terminal, which is good.
Obviously the first thing I did, open the terminal, apt-get update, dist-upgrade, yeah,
that's working fine.
Install VLC.
So it's a proper Linux box, which is what we expected.
It's pure OS.
But the problem is you've got this phone screen that's in portrait mode and none of the
applications are optimized for it yet.
You can only see a little bit of the screen before you're having to scroll sideways.
And it's just very much a work in progress, which you'd kind of expect, but that's kind
of a red flag as well, isn't it?
At this stage, they should be a little bit further on now.
It's not even six months until they're planning to ship these things if they want to hit their
original date.
Okay, maybe you might say eight or nine if they slip a little bit, but I would really
have hoped to have seen it a little bit further along than this at this stage.
The clock is definitely ticking and there's more work to be done.
I mean, there is patches they're trying to submit upstream to support things like Redshift.
They're trying to work with Epiphany to render better on the screen.
But I think you bring up a good point is so many of these applications are optimized for
a widescreen aspect ratio and the phone experience is predominantly portrait.
This is going to be, I think, long-term their biggest source of pain.
Once they get the basic OS going, once they get their Wayland client working, once they
get their Gnome Shell working, they're going to have to solve this problem.
And I just, I feel like that's the rabbit hole that never truly ends.
I wish them the best, but that's where I almost have to ask myself, would you be happy with
some basic applications, Telegram or messaging, phone calls, and then you can plug it into
an HDMI port and you can just use those applications in their regular aspect ratio on a real computer?
You know, that original convergent stream?
I could make that work, Joe.
I could live with that reality.
Well, if I were them, high up my list of priorities would be making screen rotate work flawlessly.
Dio.co.co action, get a $100 credit at DigitalOcean when you sign up with a new account, Dio.co.co
action.
That's the URL to go to.
Now, you can deploy a pre-built application or maybe just like a stack, like go for the
lamp stack, or maybe you want to mess around with MongoDB, Node.js or Docker.
You can click one button and all of the essentials get deployed, like the base Linux machine
and the appropriate software sources, the appropriate software installations.
One of the best experiences I ever had on DigitalOcean was when I just deployed an Ubuntu
LTS stack with Docker because I had recently just gone through the process of building
that.
And so I was able to go through and kind of check how they did it, and it was spot on,
like perfectly done.
And that's when I really got a sense that they know what they're doing.
They work upstream with these individual projects to make sure that they're working within their
expectations.
And that's a big part.
And that makes a big, big, big difference when you're deploying this software.
They're working with the FreeBSD project.
They're working with Canonical.
They're working with the Docker project.
They're working with the Ghost project.
They're working with each individual project to make sure that what they're deploying is
how the projects would expect it and matches documentation.
It's brilliant.
And when you sign up with a $100 credit, you can deploy a super big system.
My favorite one is $0.03 an hour.
My Nextcloud and my Mumble instance, all on $0.03 an hour.
But you can get something as low as $5 a month.
Could you imagine?
$5 a month for what used to be thousands of dollars a month in a data center.
Plus they have baked-in monitoring cloud firewalls so you can block traffic at the network level
so it never has to hit your machine.
And team management, which has been amazing to work with because we have members in our
audience that want to help us build infrastructure.
We have super talented people, so I can use these team management and account tools to
work with different individuals in our community so they have full control over the machines
that they need.
And I have backups going all the time.
It's super easy to do.
That's one checkbox.
And snapshots before we make any big changes.
And monitoring to make sure we're always as fast as possible.
I combine all that together.
You'd think I spend tons and tons and tons of time a week managing this, but Digital
Ocean makes it so easy.
And then you combine that with things like block storage, data centers all over the world,
SSDs for every machine, and a super, super nice interface to manage all of it.
And you can't go wrong.
Just start by going to do.co.co action.
OK, so it's been a fairly bad week for Google because the EU have decided to fine them $5
million for antitrust violations in Android, specifically that they have been forcing manufacturers
to install the Google search app and the Chrome browser if they want to have the Play Store.
Also they've been making payments to manufacturers and mobile carriers to make them install just
the Google search app.
And I think most egregiously, they've been forcing manufacturers to not ship any other
version of Android or any other OS if they want to ship Android on any of their phones.
That for me is worth the $5 billion fine alone.
I just have to say, I am so torn about this particular situation.
I would love to hear the audience's reaction LinuxActionNews.com slash contact.
But the key bit in here, you just you mentioned it.
It's the key bit is you have to bundle Google search and Chrome as a condition to get access
to the Play Store.
I believe looking at this entire thing, this is the straw that broke the camel's back.
That really is the part where they're playing heavy handed.
And there is a bit in here that I think is fascinating for our audience and I want to
draw attention to it.
They talk about Android forks and they talk specifically about how Google has tried to
squash them and they call out Amazon's Fire OS.
So I want to pull this out and read this for the audience.
They write in 2012 and 2013, Amazon tried to license to device manufacturers its Android
fork called Fire OS.
It wanted to cooperate with manufacturers to increase its chances of commercial success
and manufacturers were interested.
But due to Google's restrictions, manufacturers could not launch Fire OS on even a single
device.
They would have lost the right to sell Android phones with key Google apps.
Nowadays, very few devices run with Fire OS, namely only those manufactured by Amazon themselves.
This is not a proportionate outcome.
So this discussion is in serious danger of getting pretty political here and I'm fairly
libertarian I think when it comes to these things.
And so I think that if people want to ship your product, the Play Store, then it's fair
enough to impose certain restrictions on them.
I think they may be a bit heavy handed to force Chrome and Google search, but where
it crosses the line is stopping manufacturers from shipping other OSes on other devices
that have got nothing to do with you.
And you know, that really is fair enough.
That's what I said at the top of this, they should be stopped from doing that.
And the interesting thing here is that they haven't been given very long at all to fix
this, have they?
No, and I kind of feel like this is a punishment for success to a degree.
Maybe this is because of the time I've recently spent in Texas, but I don't really believe
anything Google has done in the last five years has been anything other than addressing
shortcomings to compete with iOS, because iOS is a fully integrated solution.
And that sounds like a douchebag term, but it really matters.
It means the people that are creating the CPU and the GPU are talking to the people
that are creating the operating system, that are creating the drivers, that are creating
the App Store, that are then going out and making relationships with certain application
developers.
It very much is an integrated stack, and you don't see the EU going after Apple for bundling
Safari and the App Store.
It's almost a punishment for success simply because of the massive degree of success that
they have achieved here.
And Google's position there is really without stewardship, without heavy-handed management,
open source projects and platforms could become a hot mess.
And without their clever guidance, Android would be a dumpster fire.
That is such a spurious argument though.
I mean, okay, look around at the rest of the open source ecosystem.
There's quite a lot of fragmentation there, but the best stuff floats to the top and becomes
the most popular.
Yeah.
And the irony is the very Linux kernel that they have based Android around, which is GPL2
and about as free as they come.
And yet somehow Android has been a success, but yet Google manages to argue that they
are concerned about the decision.
They say that without the careful balance they have struck with Android, it would send
a troubling signal in favor of proprietary systems over open platforms.
And that if the EU does this, open source loses and closed software like iOS will win.
But Android is mostly closed source these days anyway, isn't it?
If you buy an actual phone that's blessed by Google, all the play stuff is proprietary.
Yes.
Okay.
The AOSP stuff underneath is open source, but they're trying to make it as proprietary
as possible, aren't they?
Yeah.
That's the irony of Google's argument here.
You see all the stuff that is open and free is the stuff that they try to lock down with
the Play services, the Play API, and the Play Store.
And they're trying to centralize it around Chrome and the Play Store.
But Android is not the only solution here.
You have iOS, which is pretty strong.
You have others in the wings, of course.
We recall that Google just recently invested in a competitor.
Perhaps that has something to do with this.
All of it is out there now, and you really see Google's tenuous position and their tenuous
control over the Android ecosystem.
And their argument is, the more control that we have exerted, the better it is for consumers.
And you know, I can't necessarily argue with that core premise.
Well, surprisingly enough, I agree with my beloved EU on this.
Really?
I thought you felt this was Microsoft 2.0, that they were being ridiculous here.
Well, my first reaction to this was, what?
This is just heavy-handed authoritarianism.
But then when you really look through it, and specifically that third point, which I
keep coming back to about not allowing the freedom to ship other OSes, that is where
they've really crossed the line.
If it was only forcing the bundling of Chrome and the Google search, then I'd be kind of
much lighter on Google.
But forcing manufacturers to only ship your product, or take your ball and go home with
you, that's just not on as far as I'm concerned.
Ideally, I don't disagree with you.
But from a market practice standpoint, I have to look at Android.
When I think of those first devices that shipped, the ones with the little balls that you would
move around the UI with, to what we have now, Google really did start from an idealistic
standpoint.
Every major app on the phone was really an open-source app.
And then over time, because of the realities of OEMs and what bastards they are, and carriers
and what jerks they are, Google has slowly become more closed and more dogmatic about
what they require.
And I don't really feel like it's been out of malice, I feel like it's been out of what
delivers the most consistent and competitive Android experience.
I can't believe I'm going to say this, but I think I side with Google.
I feel like this thing is overreaching, and that what Google has done over time has gotten
more pragmatic and been responding to the competitive nature that iOS brings to the
field.
And as an iOS user, the changes they have made have, over time, made me consider using
Android as my primary phone operating system more and more.
And I wish we could just remove free software and open source from the conversation altogether
and just look at it from what they offer consumers as features and a consistent experience.
Well, if you take the open source and free software aspects away, then iOS is clearly
better.
There's no doubt.
As you said, they control the whole stack.
Of course, it's going to be a better experience.
Features wise, I don't know.
It feels like it kind of goes back and forth on that front.
But yeah, from my fairly limited experience of iOS, it is way more stable and just better
all around than Android.
But it's not customizable.
It's not at all open source.
So that's why I use Android.
But there's no doubt that something Google have done recently is good.
And that is the data transfer project where they've teamed up with Microsoft, Twitter,
and Facebook to enable you to transfer your data between the services without having to
download it and re-upload it.
And it's all open source and it's potentially going to grow beyond those services, which
is good.
This is a big deal if it takes off.
If it takes off, it solves a problem that really cloud computing has failed to address
in an embarrassing way.
With traditional applications, it just seems ridiculous to even point this out, like obvious.
But with a traditional application, I could open up, say, K-Write, and I could say, Joe
smells like beans, and I could save that to a text file.
And then I could go open that up with Libre Docs or whatever, a different text editor,
Sublime Text, and I could just read the file because it's on my file system.
Like that's just how computers work.
But in cloud computing, we've really sort of just submitted ourselves to these data
silos.
Well, apparently, good guy Google is trying to push forward the data liberation front
to the next level, where you can move your data between services.
And they call out different use cases.
Say for example, you have all of your photos on Google Photos, but a new photo book services
launches and you want to move your photos over.
Google will facilitate that ability through this initiative.
Or let's say you're using a chat network, and they've changed their terms of services,
and you no longer like those terms of services, but you would like to move over your message
history and your pictures to a new service where you do agree with their terms of service.
This is supposed to facilitate that as well.
We'll have a link in the show notes.
Go over to linuxactionnews.com slash 63 for details.
But I read through the white paper for you, so that way you don't have to.
And the way this really works is pretty good.
It kind of checks out, guys, I got to say.
Everything is encrypted in transit.
Everything is encrypted at rest.
I know that's your number one concern, and they've taken care of that.
The only real blocker for different cloud services to participate is they have to build
what is essentially a connector or a translator, so that way they can take the standard REST
based API and they can translate it to their services.
But Google's going to work on this.
It started as a small skunks works project in Chicago, actually, and now it's really
developed into a full-fledged initiative that has involved Google reaching out to Microsoft
and Facebook and others and really building an industry-wide standard that may facilitate
you one day going into one social network and saying, I want to transfer all of my information
to a different network, or one service to another service.
Doesn't have to be social.
It could be anything.
It's legitimately awesome, and it could be great, especially when you start considering
things like Google Drive, Dropbox, OneDrive, and photo services, and all of these include
a facility for you to download them as well.
It's really about standardizing a interface that can talk between the services, and it's
all done with a translator on each end of each service.
So you have a limited buy-in right now, but potentially this could pick up some traction
because you're seeing some wide adoption initially.
I had this dawning realization a few years ago that open standards for data is potentially
more important than open source or free software because it's not much use having a completely
open source text editor or word processor if the resulting files can't be read anywhere
else, right?
And so it's almost better to use proprietary software that is using open standards than
free software that isn't or isn't using a widely adopted standard.
I say almost because I know there's a lot of purists or whatever, and this isn't them
saying that they're moving to open standards, but it's probably the best that we're going
to get in a sort of pragmatic view of the world.
You're not going to get Facebook and Twitter and Google and Microsoft to all of a sudden
open up their APIs and make everything completely open standards and interoperable.
But this sort of bridging software here, I think realistically is the best we're going
to get.
So that's why I think, well, be grateful for what you get at the end of the day.
I like some of the screenshots that we'll have linked in the show notes where they show
exporting Google photos over to Microsoft.
That's just, I don't know, it's just neat to see Google blogging that.
But it really does depend on each service creating what Google calls an adapter.
But the backend mechanisms, they check out.
Like I said, I read through it all, and they're using things like OAuth for the authorization,
and they're using perfect forward secrecy where each item you have has a unique key
which is generated for each transfer, and they have a framework which allows partners
to support any authorization mechanism they choose, which enables partners to leverage
their existing user account database and their existing security infrastructure for authorizing
accounts.
So Google's really trying to do this in a way that is very friendly to third party interfaces,
including even like their graphics and all of that when you're accepting all of this.
It's a good system, and it really could be a file system for the web for some of our
most popular services.
It's never, ever going to replace having control over your own data and having your own files.
But for the users out there that live online, that live on their mobile devices, that live
on Chromebooks, that live on cloud services, this may finally enable them to move data
between competing services.
And in the white paper, Google specifically calls that out and says that's something they're
trying to enable.
Somebody changes a policy and they want to move to a competing service, this is supposed
to enable that.
So we'll see.
This is over at opensource.googleblog.com, and they call it the Data Transfer Project,
an open source platform for promoting universal data portability.
Yeah, and this is clearly due to the GDPR stuff.
So it's another win for the EU, but let's not go on about that too much.
Let's end the news with Slackware turning 25.
It's the oldest actively developed Linux distribution.
And having installed it last night, yeah, you can tell.
Yeah, that is exactly my interpretation as well.
And not necessarily a bad way, like it's kind of awesome in a certain way, like I really
appreciate it.
But you really feel the ethos of Slackware, you know, it's supposed to be simple.
And that simplicity in this instance is really being the removal of barriers between you
and the Unix experience.
It's really all about that Unix experience with Slackware as close as you can get with
a Linux distro.
I mean, it all got started in July of 1993.
It was really aimed to be the most Unix-like Linux distribution.
And the team has managed 30 releases over the years, with the latest being 14.2 on June
30, 2016, which is based on the 4.14 kernel.
I love Slackware.
It has been a constant in my Linux life.
And of course, original SUSE's were based off of it.
And the name, in 1994, for an interview with Linux Journal, the then 27-year-old benevolent
dictator of Slackware said, I think I named it Slackware because I didn't want people
to take it all that seriously at first.
Which I don't know, when you think about 25 years afterwards, it just makes me like it
more even.
You're talking to someone who's running XFCE, so I don't like change for its own sake.
And I do appreciate that Slackware hasn't changed much.
It's kept very much to its original principles.
But on the other hand, it really makes you appreciate Fedora, Ubuntu, other distros
like that, and how far we've come, and how much polish has been added to the whole experience.
Yeah, either way, 25 years and still being famous for its simplicity, only Linux could
deliver that.
I love it, Joe.
I love Slackware.
Even though I'm not a daily user of it, I have so much respect for the project.
Well, a project we have a lot of respect for is Firefox, and we made an error last time,
so we need to correct that error.
We were talking about them making changes on Android, and we incorrectly said that they
were moving away from Gecko as a rendering engine to WebKit, but they're not, so we needed
to make that correction.
Yeah, it actually looks like a great initiative, and it's one that I'll be following in the
future.
And as things develop, we'll keep you posted.
Go to linuxactionnews.com slash subscribe for all the ways to get new episodes.
And go to linuxactionnews.com slash contact for ways to get in touch.
Yeah, and you can support the whole network and everything we're doing over at patreon.com
slash jupitersignal.
We'll be back next Monday with our weekly take on the latest Linux and open source news.
I'm at Chris LAS.
I'm at Joe Rissington.
Thank you for joining us, and we will see you next week.
Have a good night, sir.
