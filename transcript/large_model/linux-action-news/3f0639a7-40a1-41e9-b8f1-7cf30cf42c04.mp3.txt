Hello, and welcome to Linux Action News, our weekly take on Linux and the open source world.
This is episode 84, recorded on December 16, 2018.
I'm Chris.
And I'm Joe.
Hello, Joe.
It's good to be connected with you.
We have a good batch of stories this week.
One that, I got to say, our first story didn't think we'd be hearing maybe until Intel was
on the ropes.
But it looks like Intel could be working on open sourcing their FSP.
Yeah, now, it's easy to get excited about this, but I do think we have to temper our
expectations slightly because this is only the first talk of this.
And it's not the only proprietary component that makes an Intel system boot.
But it is a very good potential first step.
Right.
So just really quick.
The FSP, just so everybody's on the same page, that stands for the Firmware Support Package.
And you probably guessed what that does.
It initializes the CPU, the memory controller, and some of the chipset stuff.
It's a pretty important piece of an Intel motherboard.
So it would be a big contribution if it was made open source.
This information and this possibility is coming from Michael Laribel from Fronix, who was
down at an Intel event.
And some of what he saw at this event syncs up with my experience when I was on the Intel
campus just a couple of months ago.
And when I was there, I had a genuine sense, and I talked about this on Linux Unplugged,
that Intel wanted to rebuild a bridge with the open source community after the fiasco
that was Meltdown and Spectre and how some of those projects were or were not notified.
And honestly, some of those projects, like the Linux kernel developers, that are still
very frustrated with Intel for essentially making them fix their problem.
And I had a distinct sense talking to the staff and watching their presentations that
they are trying to look at ways of repairing that relationship.
Well, that's the thing, though.
Is this just paying lip service to the idea of open sourcing this stuff?
Because it's not going to happen overnight, is it?
And making positive noises to journalists like Michael is making us talk about it, right?
Yeah, yeah.
It also is a dangerous thing to play with, though, isn't it?
He told Michael in the interview that we'll likely hear more in quarter one of next year.
He indicates that they're getting customer demand for Intel to open this thing up.
If that is retroactive on stuff that's shipping today or if it's only on future Intel products
and boards, we don't know.
But it sounds like if this is going to happen, we're going to hear more about it early next
year.
Well, something you have to consider is that Intel has about 16,000 people working on software
alone, which is about twice the number of people who work at AMD in all departments.
So they do have a huge software department over Intel.
And of course, we know about Clear Linux, but that's not all they're working on over
there.
They haven't got all those people working on one distro.
They're contributing a lot to the Linux kernel, and they need to stay relevant in the software
world in order to sell their hardware.
And really, the data center is where open sourcing things like the FSP are going to
make the difference because people are taking security so seriously these days.
And you just can't really be sure at the moment that your systems, all your servers are properly
secure because it's running this proprietary code to boot them up.
You can run completely free software thereafter.
But if that processor needs this proprietary code, then you just have no idea, do you?
And so it would be nice for us to have it on our machines, on our laptops and everything
as a kind of byproduct of this.
But I think really that's where this is focused and where we're going to see it first with
the Xeons and stuff rather than the i3s and i5s and i7s.
Yeah, I could definitely see this taking off in the data center first.
That makes a lot of sense.
And kind of going along with those large data center workloads, Intel also just released
the Deep Learning Reference Stack, which they say is a highly tuned stack of Linux that's
built for the cloud and the cloud-native environments.
And you've probably guessed, it's built around clear Linux OS.
Yeah, something we've been hearing an increasing amount about, and I think it's going to be
the hot distro for next year.
Bit of a spoiler for our predictions there.
No, that's not actually one of my official predictions.
Maybe it should have been.
But yeah, this is kind of a little bit buzzword bingo, isn't it?
But fundamentally, what Intel have done here is put together a stack, as they're calling
it, of the various components needed to do this deep learning computing, which is essential
to the kind of next phase.
I suppose we're already into this phase, aren't we, of computing, that it's all about AI,
and you need to do the learning to feed that AI in order to do all of the different applications
that we need.
Self-driving cars is the one that everyone goes for.
Well, there's so many, though.
I mean, there's so many things.
It's not just self-driving cars.
Yeah.
I was really surprised by this, because this is so abstract to me.
I don't do anything with machine learning or artificial intelligence, so to me, it doesn't
seem like it's a real thing that's driving a lot of interest.
But I was just at System76's factory.
In fact, I just got back yesterday, and I had several side conversations with them.
And one of the things that's driving them building these massive Thalia workstations
is they are having new customers that want to get into machine learning that are coming
to Linux because it's the best platform to do this, sort of like a lot of 3D printers
have started selling Linux boxes.
And the thing is these customers don't really know how to set this up.
They're not normal Linux users.
They're not familiar with how to install packages or use a Docker image, even.
So the thing that Intel is trying to solve here is that particular problem.
This clear Linux OS-based stack, it comes optimized, of course, for the Intel processors.
But it's also set up and ready to work with TensorFlow and other tools that people are
familiar with, even if they're not familiar with working with Linux.
And that's the problem they're trying to solve here.
That's really the same problem System76 is trying to solve with Pop OS and their metapackaging
system where you can install things like TensorFlow or R and get going with machine learning,
which is typically very hard to set up if you're new to Linux.
The market is out there.
It's just, to me, I'm blind to it.
But I know that your buddy and mine, Wes Payne, likes to play around with the machine learning
from time to time, likes to have himself a little machine learning.
And from our chats, it sounds like Linux is really one of the best platforms to be doing
this on.
Yeah.
Well, it's all math-based, isn't it?
So, of course, he's going to be interested.
Yeah.
He is such a math geek.
Yeah.
And I mentioned self-driving cars there.
Well, Uber have been pushing that forward.
And they have now brought their Horovod project, which is distributed deep learning, to the
Linux Foundation's Deep Learning Foundation.
It's a little bit like Foundation Inception, that, isn't it?
Yeah, it is.
Foundation within Foundation.
That seems to be their thing these days, a foundation for everything.
But the LF Deep Learning Foundation has some serious players at least attached on their
website.
AT&T's on there, Red Hat, ZTE, Nokia, Intel's on there, and a bunch of others.
And it seems like just since this Uber announcement about a month ago, other projects are throwing
in now too.
Some of them which are designed for cloud providers specifically, but a lot of them
circle back to TensorFlow, including some contributions from Amazon and IBM and NVIDIA.
Well, the reason this has got some attention this week is because it was kind of officially
announced at the KubeCon and CloudNativeCon conference right there in Seattle, where you
are.
And you guys actually talked about that, didn't you?
The Kubernetes side of things on TechSnap 392 this past week.
Indeed, we did.
We tried to cover some of the top stories out of there that you need to know about if
you're just trying to stay up to date with Kubernetes.
We didn't really bother explaining what Kubernetes is.
We have an episode dedicated to that.
So instead, we just tried to keep everybody up to date.
It's sort of a newsier edition of the TechSnap program.
But this is the way the industry is going now, isn't it?
That we've got such powerful machines available, and the orchestration software is so good
that you can do this distributed deep learning and push things forward to what feels like
a kind of scary future.
But the good part about it is it's all running Linux.
That's true.
I think, and a lot of the stuff at KubeCon this week that we talked about in TechSnap
is also about just using multiple cloud providers, so that way you can distribute your risk.
And also use those same exact tools to just manage your own boxes on premises.
And to be able to go from on premises up to a cloud provider that might be two or three
different cloud providers, but you're using one set of tools to deploy all those servers
and to set up their software, set up their loads, set up the virtual machines, and manage
and maintain them from one console across multiple cloud providers and your own local
boxes.
That's a big deal.
But if you think about it, it's sort of helping avoid vendor lock-in into the cloud by becoming
this common platform.
And that's an interesting story, and that's one of the things we try to touch on.
Well, that's very much the present and future of computing, but the past of it is 32-bit
x86, which we've seen over the last couple of years, distro after distro abandoning.
But there was kind of a bridge within Linux between 64-bit and 32-bit, which it looks
like might well be going away sometime soon.
Yeah, a bit of a shame that this didn't get more traction now that I've done some reading
into this.
I never really bothered because no distro really ships with support for this.
But we're talking here about the x32 sub-architecture, and it did a neat trick.
It was a software variant of x86-64, so it would run the processor in 64-bit mode, so
you get the advantages of your CPU in 64-bit mode.
But it would use 32-bit pointers and 32-bit math.
The idea is to get the advantage of an x86-64 style system without the extra memory usage
that goes along with it.
But it came along about six years ago, and we were just a little too late at that point.
Few distributions supported it, and the number of users that actually use it seems to be
very small.
So one of the kernel developers is now proposing to eventually remove it.
And the way that process works in the Linux kernel is it gets flagged to broken or not
supported.
You've seen this if you've ever built your own kernel and gone through that menu.
You'll see these, in big brackets, broken.
They move it to broken.
The idea is you're supposed to stop using it.
It's no longer officially supported, and then it sort of phases out from there.
Just imagine if this had taken off.
You could run at least an extra Electron app with your 32 gigs of RAM.
Yeah.
Hey, that's good.
You know?
Maybe that'll keep it around.
Or we'll all be running Fuchsia, and it won't matter, Joe.
Yeah, we keep getting these teasers from Google about Fuchsia, don't we?
And this week, it's that the Fuchsia SDK has shown up in the Android open source project.
And there's also this mysterious Fuchsia device.
Yeah, it almost feels like one shoe after another getting dropped here.
In a commit posted this last week to Android's source code management system, two Fuchsia-related
repos popped up in the manifest for the Android open source project.
So if you're not familiar with that, the manifest is used to inform Google's download tools
of what repo should be included with the base AOSP.
So that's what that manifest file describes.
And that manifest file was updated to include these new repos.
So as part of that base AOSP now, you're getting these two different Fuchsia repos.
And when you install the Android emulator, it will pull those things down.
The two repos in question are still a little mysterious because they're essentially empty.
But there is a couple of clues.
One of them is platform Fuchsia SDK, which is pretty clear it's gonna be the SDK for
Fuchsia.
And it appears based on other posting, it's gonna be a huge repo.
The second repo, which is the one Joe was just talking about, is the most interesting.
That is the device Google Fuchsia repo.
And that device is a Google created device that runs Fuchsia.
And it's going to be managed by some sort of Android code base, maybe Android Studio
itself in the emulator or something like that.
In fact, it very likely could be the device that would be in the Android Studio emulator.
That emulator actually has its own repo, its own device class in AOSP.
So that could be what we're seeing here is they're preparing folks the ability to create
applications on Fuchsia using Android Studio.
Yeah, that was my read on it.
It's not an actual device.
It's this kind of virtual device in the emulator, which is a key part of development, isn't
it?
You need to have that in the emulator.
And now it's just going to be part of Android open source projects.
So that is kind of a, it seems like a small step, but it's also a giant leap at the same
time.
I don't know.
It's very much, it's like if you see a construction project of a building, right?
And once the actual building starts to go up, it's relatively quick, but there's a lot
of groundwork goes into it first.
The foundations and all the drainage and everything that's, you know, you're just looking at a
construction site that's just doing nothing seemingly.
And then bang, suddenly the building appears and that's what Google's been doing with Fuchsia.
And this is one of those important steps and it's not a big flashy display, you know, we're
not flashing it on a phone and checking it out and being able to make YouTube videos
about it and all the rest of it.
It's the plumbing, isn't it?
It's the foundational work.
Yeah.
Yeah.
And it also gives us an insight into what their strategy is going to be for developer
adoption.
And I think this is a cunning one.
They're just apparently going to bake it into the existing tools that people already have
for creating Android apps, which is also likely a clue that there's going to be some way to
move Android applications over to Fuchsia.
Well, yeah.
Why force people to change the tools they're using?
And they're almost sort of sneaking it in by the back door, aren't they?
If you're keeping up to date with the tools that you've already been using, then it's
suddenly just going to appear there.
Yeah.
I think our predictions episode is going to be a fun one this year.
I got to say.
I've been keeping a list and checking it twice and they're coming up soon for the holidays.
I'm going to have to do some in Linux Unplugged, too.
I don't know.
I feel like I'm feeling confident about my predictions this year.
Well, I'm going to give you another one and that's that we're not going to see an actual
consumer device shipping with Fuchsia in 2019.
It's too early.
There's too much foundational plumbing work left to do and I don't think that that's going
to happen this year.
But that's an unofficial prediction that I'm not putting on the record.
All right.
If it was on the record, I'd argue, what about beta builds for Pixel devices?
But that's maybe a conversation for a different show because we still have new software to
talk about.
Our cousins over at the FreeBSD project have the brand new FreeBSD 12 they've released
and there's really something in here for just about every BSD user.
This does feel like it's not like a huge flashy release, is it?
This 12.0.
It's much more of a they've improved various small bits.
It kind of almost reminds me of elementary OS where you had that ridiculously long post
for Juno where it was just so many small features that add up to something huge.
And that's kind of how this FreeBSD release feels to me.
It's not like this huge showstopping release, is it?
Yeah, it's kind of like I was saying.
There's something there for every BSD user.
If I was a BSD user, the couple of things that I like are the improvements to Beehive
so you can do NVMe device emulation and they've also now have the ability to run Beehive,
which is their kind of KVM competitor, their virtualization system.
You can run it itself within a jail, which is pretty nice.
That's a cool security feature.
And packet filter is now usable within jails and they have a great packet filter system.
So there's just a ton of stuff in here, but our buddies over at the BSD show, they did
a real good coverage on it over at BSD Now episode 276.
They did a full, as you would expect, a BSD Now style full rundown of the new release.
And come on, let's not forget the most important feature, KDE 5.12.5, which is the LTS but
not quite the latest point release, but you know, it's BSD, we'll forgive them.
Yeah, that's actually not bad.
You could get a nice modern plasma LTS desktop on free BSD.
Nothing wrong with that if Linux doesn't float your boat.
Yeah, it's not for me, I'm afraid.
Yeah, but you know, it probably makes a decent XFCE workstation there, Joe.
Yeah, I might have to check that out actually.
I don't know.
I'm happy enough with the mix, but yeah, I thought we'd better give a shout out to our
BSD cousins.
And go check out BSD Now 276 for their completely in-depth take on the new release.
And check out linuxactionnews.com slash subscribe for all the ways to get new episodes of this
here show.
And go to linuxactionnews.com slash contact for ways to get in touch with us.
And for you Linux Academy students, from December 16th through December 26th, 2018, Linux Academy
is donating $1 to St. Jude Children's Research Hospital for each learning activity that you
complete.
So you can help others while learning at the same time and also earn gems on the platform.
Yeah, great way to avoid your relatives learning some useful stuff and helping out some children.
Right, so we'll be back next Monday with our end of year review.
Looking forward to that.
I am at Chris LAS.
I'm at Joe Ressington.
Thank you for joining us and we will see you next week.
Have a great night, y'all, and have a great night, y'all, and have a great night, y'all.
Bye.
