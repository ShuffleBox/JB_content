Hello, and welcome to Linux Action News, Episode 257, recorded on September 6th, 2022.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
Linux users living the enterprise lifestyle in a Windows shop felt the sting of the Microsoft
strategy text this week when they discovered the Teams app for Linux is being discontinued.
Yeah, that stings for a lot of users because it can already be pretty tough as a Linux
user to exist in that kind of environment.
And apps like Teams can be sort of like a cold drink of water to a user stuck in a compatibility
desert.
I guess I'm just slightly surprised by this.
I'm not shocked, but I am slightly surprised since a big deal was made about Teams coming
to Linux in the first place, but when you realize that Microsoft doesn't even make a
native version of Teams for Windows, how much support can you really expect for their Linux
port?
In the announcement, Microsoft informed Linux users that they had figured out what their
next best option would be saying, quote, we found the best way to act on this is to offer
a Teams Progressive Web App, a PWA, on Linux as a new feature of our current web client,
which we'll be making available to our Linux customers in the coming months.
While that was a considerably insufficient answer to many, and the upset here has been
notable, the real story is why Microsoft is making this change.
It appears to be related to moving Teams off of Electron and onto Microsoft's edge-based
WebView2, which at least as of this recording, has no Linux or Mac OS support.
Yeah, and I think a lot of people felt, okay, well then just keep supporting the Linux version
until the WebView2 port is ready.
And I don't know a lot of Linux users that love Electron, and I don't really know if
WebView2 is significantly better because it's still web technologies, although indications
seem to be that it is at least notably better than Electron.
I think for some, just losing an application like this isn't a great answer for them, and
while they were hoping for something other than Electron, this isn't what they were asking
for.
But you know, I guess the question I have to the audience, is it such a bad pill to
swallow to use a web app if it means long-term better technology will be used?
Microsoft notes, quote, Teams PWA is an evolution of our Linux web experience.
It offers the best of the web with key functionalities of client.
Things like zero install, lightweight, and a rich set of features.
But it's still in a web browser, which is a deal breaker for some, and has led to a
sizable amount of online pushback.
Maybe this will accelerate Microsoft's Linux port of WebView2, and they do currently list
that as a major update they plan for the future.
But in the meantime, I'm afraid your web app is now a web app.
Arch users took another one in the face this week, so the rest of the Linux world doesn't
have to.
It seems a recent grub issue impacts many Arch and Arch derivative ties.
This takes a little bit of setup to understand, but it all started when some grub developers
were trying to improve support for EFI systems.
Specifically a handy dandy menu option that allows users to reboot directly into the system
firmware.
Maybe you've seen it on your system, in fact.
You've got your Linux Mint entry, you've got your Nix OS entry, and then maybe if your
system supports it, you've got a little menu entry that just reboots us right into the
BIOS interface.
Now before this most recent series of patches to grub, this firmware reboot option was only
really available if grub had detected that your system supported it at grub installation
time, not at run time, not at boot time, but whenever you happen to have installed grub.
And this meant that if your system happened to have grub installed when you were booting
via legacy boot, or maybe you'd copied things over, or you'd switched to EFI down the road,
well even if your system supported it, you weren't going to get that option.
To address that, this series of grub updates change that behavior to instead check at run
time, see if the system booted through EFI, see if it supported rebooting into the firmware,
and if it did, display the menu entry.
Okay, all good, and to do this grub relies on a command known as fw setup.
Now previously this command was only available if UEFI support was found at the installation
time like Wes had said.
As part of these recent updates and patches, grub started using this command in just more
scenarios, and as such, it made it so that, and as such, it was enabled for all installations
rather than only systems where UEFI support had been detected during install.
Unfortunately, the result of all of these different changes meant that on some arch
and arch type systems, after you did a system update, it was possible that your grub configuration
would reflect this new pattern of having fw setup available, but unless you'd intervened
and manually run grub install yourself, or if a friendly package manager out there had
done it for you, you might not actually have fw setup available, and that of course could
break your boot.
That's not good, nobody wants a broken boot, and the thing is, this was kind of tricky,
maybe nearly impossible to catch in testing, and didn't really get discovered until a larger
user base started using it in production, because this issue just simply did not impact
all grub users, it did not impact new installs, and to make things even more problematic,
a lot of arch users, especially the cutting edge arch users, aren't even using grub.
But you know, it is what it is, and thankfully the issue now has been caught, and if you
wound up with an unbootable system, first of all, thank you for taking it in the face
so we don't have to, and second of all, we have what seems to be the most popular fix
linked in our show notes.
It's been a few releases since we last highlighted a new Pipewire release, but 0357 just shipped
this week with a few fantastic features.
As an Opus fan, I was really happy to see that Pipewire can now send and receive Opus
data over Bluetooth, that's great.
But perhaps even better, or at least immediately practical, an AAC decoder was added so that
Pipewire can now also function as an A2DP AAC receiver.
That seems really useful for little gadgets you might want to build, turn a Raspberry
Pi into an A2DP receiver.
I can also imagine there's a lot of uses for that in automotive Linux.
And of course, you got the list of always good to see bug fixes every single time.
And like you said, Wes, we don't cover every Pipewire release, but they tend to be so great
that we debate doing so every time.
And this one just got put over the top with those two new features alone.
There's been a lot of improvements to tooling around Pipewire, various module improvements,
and of course, fixes going into Pipewire core.
The great thing is, the API and the ABI are compatible with previous releases of Pipewire
in the 3 series.
Some big milestones to report this week, starting with Nmap 7.93, the 25th anniversary edition
that's just been released.
Gordon Leon, founder and lead Nmap developer wrote, quote, 25 years ago, I released the
first version of Nmap in a Frac article named The Art of Port Scanning.
I never thought I'd still be at it a quarter of a century later.
But that's because I also didn't anticipate such a wonderful community of users and contributors
spanning those decades.
You've helped Nmap blossom from a fairly simple port scanner to a full featured network discovery
application trusted by millions of users every day.
So thanks for that.
And another milestone is a big happy birthday to SUSE, which turned 30 this week.
And as a gift, we're reminded just what SUSE stands for.
It's Software und Systementwicklung, or Software and Systems Development in English.
Linode.com slash LAN, go there to get $100 in 60 day credit on a new account.
It's just a great way to support the show too, because you're getting yourself something,
trying out something cool, supporting the show.
Linode is fast, reliable cloud hosting.
It's the best option out there with the best support in the business.
Real humans all the time, every day.
What else is structured like Linode?
Linode's how we run everything we've built, including our new website that builds and
is published on Linode.
Linode's S3 compatible object storage is how we run the backend for our next cloud storage
so we're not constantly worried about checking disk space and undeleted files and things
like that.
And Linode is 30 to 50% cheaper than the major hyperscalers out there that just want to adopt
you and basically make you one of their own, assimilate you into the collective.
You will become one with the Borg, but with Linode, resistance is futile.
They can be part of your multi-cloud strategy since they are 30 to 50% cheaper after all.
So go build something, go learn something, go try one of their 11 data centers around
the world.
Maybe their cloud firewall, their simple backups, or their Kubernetes support.
Go try it for yourself and support the show.
So go to Linode.com slash LAN, get that $100 in 60 day credit and kick the tires for yourself.
There's a reason they've been around for a long time on this show.
Our listeners love Linode.
I know you will too.
So go support the show and try it out.
One more time, Linode.com slash LAN.
Collide.com slash LAN.
Collide is endpoint security that uses the most powerful untapped resource in IT.
It's end users.
So if you're trying to achieve security goals for yourself or a third party audit, maybe
the new boss, whatever it is, the conventional wisdom in the past would have been to deploy
some sort of device management software, lock every device down like it's Fort Knox, employ
these policies from afar, and of course put a little performance overhead on their system,
introduce possible new points of security vulnerabilities and end users hate it.
Well, Collide does things differently.
Instead of forcing changes on the users, Collide sends them security recommendations via Slack.
Collide will automatically notify your team when their devices are insecure and give them
a step-by-step instruction on how to solve that problem.
And by reaching out to employees via a friendly Slack DM and then educating them about company
policies, Collide can help you build a culture in which everyone contributes to security
because everyone understands how and why to do it.
And for IT admins, Collide provides a single dashboard that lets you monitor the security
of your entire fleet, whether they're running on a Mac, Windows, or yeah, you bet, Linux.
You can see at a glance which employees have their disencrypted, their OS up to date, and
a password manager installed, making it easy to prove compliance to your auditors, customers,
and leadership.
So that's Collide, user-centered, cross-platform endpoint security for teams that Slack.
You can meet your compliance goals by putting users first.
Visit collide.com slash LAN to find out how, and you go to that link, you try it out, they're
going to hook you up with a goody bag, which includes a free t-shirt, which is basically
how I've built out my entire wardrobe.
And you know what?
I ain't hating that game.
Get a free t-shirt just for activating a free trial.
So go to collide.com slash LAN, that's K-O-L-I-D-E.com slash L-A-N, collide.com slash LAN.
For our last story this week, we're going underwater.
Subsea Cloud, a company proposing to put commercial data centers in deep ocean waters, has moved
closer to a physical launch.
The company plans to install a pod near Port Angeles in Washington state.
That very first pod will start with a 20-foot shipping container at around 30 feet underwater,
holding 800 servers, although eventually hoping to scale that operation to 100 such pods.
This might sound familiar because another local company tried this before.
Microsoft wrapped up a multi-year experiment in 2020.
The overarching goal of Project Natick is to evaluate the feasibility of underwater
data centers.
Phase one was just to be able to figure out can we get computers into a container and
can we deploy them in the water without it leaking and do the computers survive and how
well do they last.
Phase two was to show that we can make it in a manufacturable production scale component.
So the container behind me, it fits on a trailer, it fits on a cargo ship and it allows us to
actually build up this data center to any size that we want.
And Microsoft's tests found the underwater data center had a lower failure rate than
the identical test unit on land.
So far as we've been monitoring this and the data center that we have on land that are
using the same components, we see one-eighth the failure rate in the ocean data center
than we do on land.
Now Microsoft attributes that difference in failure rate primarily to just the very stable
temperatures and humidity conditions under the sea, but also, frankly, no humans to make
mistakes and bump things plays a factor as well.
But unlike Microsoft, Subsea Cloud does not use a pressure vessel, instead it uses a more
conventional shipping container with pressure equalized between the inside and outside.
That not only lowers costs, but it actually turns out to be more effective in dissipating
thermal load as well.
And now Subsea Cloud wants to commercialize this idea, so the company is starting small,
both in scope and depth.
That first data center pod in Port Angeles will be known as Jules Verne.
Inside Jules Verne, there's space for about 16 standard issue data center racks, accommodating
about 800 servers.
Additional capacity, if and when required, is delivered by just adding another pod.
And don't worry, they're not skimping on the connection.
The pod to shore link in this deployment provides 100 gigabits.
I can't help but kind of love this idea because as a sysadmin, as a, as a deployer, you get
to pick and choose what goes into the pod.
It's your systems.
And you get an idea of that from the Subsea CEO Maxi Reynolds, who says, quote, data center
space rental is similar to just leasing an office space.
Our leasable spaces provide our tenants network connections, stable power supply, cooling
and security systems.
And then she goes on to say, quote, we ensure the facility is capable of providing the required
IT services when being underwater.
We build, deploy and maintain the Subsea data centers.
And you just know there's not going to be very many Windows boxes down there.
Nobody wants Windows underwater.
Maybe like us, though, you're wondering what the environmental impact of an underwater
data center might be.
Well, both Microsoft and Subsea Cloud say it's a net positive.
According to Subsea, there are significant savings in electrical use, which matters because
at three percent of the global electricity supply, data centers have the same carbon
footprint as the aviation industry.
Subsea claims their data centers reduce the typical CO2 a traditional data center emits
by 40 percent.
Forty percent at scale is a massive difference.
And for one thing, that's achieved because there's no air conditioning and the entire
thing is passively cooled.
That's massive right there.
The other thing is they don't use any water.
In fact, the focus is keeping water out.
Inside the servers are also immersed in a dielectric coolant, an oil which conducts
heat but not electricity, and the Subsea pods are designed to passively disperse heat rather
than using pumps to move the oil around, which you typically would see in a land-based immersion
cooling system.
And I think what's kind of tragic and ironic about land-based data centers, you know, all
of them, is that they actually use millions of gallons of water a day.
And studies have shown that over half of that water is estimated to be potable water.
The Subsea data center uses no water.
But what happens if something goes wrong, or a customer wants to replace one of their
servers?
Well, according to Subsea, customers can schedule periodic maintenance, including server replacement,
and they say it should take between 4 to 16 hours for a team to get to the site, bring
up the required pod or pods, and then replace any equipment.
As for the lifespan of these underwater server rooms though, Subsea says the lifespan of
the actual data center pod itself, the environment containing the servers, that should be around
20 years.
But of course, in line with a typical server lifespan and deployment, each pod would likely
live on the seafloor for 3 to 5 years, as they're going to need to rotate the hardware
in and out to keep up with the times.
And Subsea says they build this with one or two failures being totally fine and they can
continue on, but yeah, they have to build it so they can pull it out.
And when they pull it out, they also have to drain it of all of that oil.
So it's a big job.
Subsea hopes that Jules Verne is going to kind of prove all of this stuff out for customers,
and maybe attract the attention of some of the big hyperscalers out there.
I think that's one of their strategies.
It seems that this is really all just a first step, with deployments in the Gulf of Mexico
and other locations already being considered, but we can't help find the entire idea of
Linux Underwater totally fascinating.
We'll keep an eye on it, see where it goes.
So don't miss any updates to this or anything going on in the world of Linux, go to linuxactionnews.com
slash subscribe for all the ways to get new episodes.
And linuxactionnews.com slash contact for ways to get in touch.
The new Jupiter Broadcasting website has launched, if you haven't checked it out, jupitabroadcasting.com,
poke at it, find what's broken, and then go submit a GitHub issue, please.
We'd appreciate the feedback.
As for this show?
Well, don't worry.
We'll be back next week with our take on the latest Linux and open source news.
Thanks for joining us.
That's all the news for this week.
