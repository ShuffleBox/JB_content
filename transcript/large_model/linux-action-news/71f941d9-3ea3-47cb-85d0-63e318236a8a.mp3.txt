Hello, and welcome to Linux Action News, episode 135, recorded on December 8th, 2019. I'm
Chris.
And I'm Joe.
Hello, Joe. Good to be connected with you. And we start this week with Ubuntu going pro,
at least on Amazon Web Services.
This is really a rolling up of existing services that Canonical offers with the convenience
of being able to pay for them through AWS, just adding it to that bill rather than having
to deal with a separate organization.
Right. It makes compliance as simple as selecting and running an image on Amazon. Because these
images have 10 years of package updates, they have kernel live patch enabled, and they've
been specifically tuned to be compliant for use in environments under compliance regimes
such as HIPAA, or the ISO standard, PCI and many others. So compliance is baked into these
images. And the patch coverage for Ubuntu's infrastructure applications like MongoDB, or
some of the things that are in universe, even the universe repository, which typically is
not covered, we'll see security patches directly from Canonical.
Yeah, that's kind of the big new thing here. Because although a lot of those packages did
get support, and security updates, now they're guaranteeing that. But also what's new is
a rolling kernel.
A rolling kernel, you say, Joe? They're transitioning the images to a rolling kernel, the existing
ones. They write on their blog, applying this model directly to 1804 today, the Linux AWS
kernel is a 4.15 based kernel. When we start to roll, they will move to the five kernel
series from their 1904 interim release. So they're branching from there. And they say
it is available for preview. And there's also a way to just nope out of this if you want.
They write on the blog, they feel like they've tested this and they have LTS level stability
with this rolling model. And so new IO scheduling, some hypervisor changes, networking changes,
all of that container tweaks, all of that's going to be landing now on an ongoing basis,
but in a tested way. And of course, I don't know about you, Joe, but I have a sense that
Canonical is really making sure this works because they don't want to upset this demographic.
Well, yeah, but if you're already using the hardware enablement stack, then you've got
a 5.0 kernel. So this is definitely well tested. I'm talking to you with a 5.0 kernel on an
1804 system right now.
And it seems that Canonical has tested this at other cloud providers before they're moving
it to AWS. But let's talk about for a moment the money aspect of all of this. This could
be a big revenue generator for Canonical, keeping in mind that Amazon's likely to take
a decent size cut. You're looking at somewhere around 23 cents an hour up to 33 cents or
more depending on your rig for these pro images. That's per hour, but it's low enough. Your
large financial institutions and your medical institutions and everything in between would
happily pay 33 cents an hour on infrastructure systems to not have to rebuild that infrastructure
for 10 years. And to get pre-checked compliance means that when they get audited, they can
point to the steps they're taking to follow compliance requirements. It's this weird thing
in compliance where part of being compliant is documenting that you are using services
and infrastructure that are compliant. And so by these very images outline that part
of their features are compliance with HIPAA and ISO and PCI, et cetera, et cetera. The
companies can now include this in their documentation of compliance. It feeds the auditing monster
and that alone is worth 33 cents an hour.
I love the smell of an IPO in the morning.
This is a really clever idea. And it would be interesting to see where these pro images
go from here. Will they make a Ubuntu pro available for on-premises installations or
for container installations or VMs on other providers? I mean, this pro thing could take
off. It could be more than just AWS.
They could go that way, yeah. It really feels like them leveling up, doesn't it? It feels
like them becoming really serious. And we've seen this over the last year or so, just all
of the little things they've done, starting with the 10 years of support. And now step
by step, they're getting into a position where they are a serious enterprise player that
is ready for an IPO. I don't want to spoil my predictions, but I'm getting it in now.
I'm predicting an IPO in 2020.
Are you carving that one out so that way I don't steal it? Amazing. That is incredible.
I'm not sure that's allowed. There's something about this approach that feels uniquely Ubuntu,
and that's really clever. And it's this low key, no big deal. Hey, you just want to use
our stuff? That's fine. Hey, you want to build your entire infrastructure and your business
around Ubuntu at the core? Hey, that's fine. Oh, yeah. Oh, yeah. We can provide support
for that. Yeah. Oh, would you like to get a support contract? Yeah, absolutely. Would
you like to turn on these pro images? It's just 33 cents more an hour. Go ahead. And
it's this perfect spot that Ubuntu has lived in for a long time that made it the ideal
candidate for laptops and VPS and containers. And I think it's what led to it just exploding
in the cloud was you didn't have to use something that was completely different from the enterprise
version or use a clone of it and kind of just support it yourself. You could use the actual
Ubuntu, the actual long term release, and then you could upgrade your support options
when you need it. And they're taking that to this approach on AWS, which is a massive
marketplace where people are running systems that are critical to their business with this
low key approach that serve them so well so far in the cloud. I think they nailed it.
And I'd love to see what they would do if they took it to infrastructure. Because honestly,
I could see businesses wanting to run something like this on their on premises, Ubuntu servers,
you can get all these things individually, but wrapping it all up in one thing that you
just turn on is that's the magic bullet.
And you have to imagine that the systems architects and the CTOs who are approving this stuff
have probably been using Ubuntu for 10 years or more on their home server and VPS is as
they progressed in their career, because it was so accessible. It's just that whole give
it away for free to get them hooked and then start charging the model.
Yeah. And probably a lot of them are using different parts of this pro offering already
if they're using Ubuntu in the enterprise, a lot of them could be already taking advantage
of live patch, or some of these other features. So when they see it all bundled up, they already
know what they're getting, and they are already consumers of it. And this just is all in one
ready to go just charge a bit more per hour package. And there's no contract, if you no
longer want it, you just turn it off, and it's done. And I think that kind of jump in
jump out kind of approach is also really appealing. No big sales contract, no, you know, supporting
it a 10 year payment thing. It's just you turn it on when you want it, you turn it off,
and those services come and go. And it's pretty clever. And it's, it's very modern. Much like
their approach to the Windows subsystem for Linux, it might make some people uncomfortable,
but this new technology, they seem to be all in on Joe.
The first clear sign of this was when they hired Hayden Barnes, who we've had on Linux
Unplugged before. He does the penguin distro. They hired him to be part of the desktop team.
And now they've got a job posting for another Ubuntu desktop software engineer, who is going
to specifically focus on the WSL stuff. They want to own WSL, it seems.
Well, they were the first distro to officially support WSL. So they did get an early start.
And they write in their post, quote, we think WSL is a fantastic way for Windows user to
experience Ubuntu on their desktop, easing their development process and allowing for
local development and testing on Windows before deploying to Ubuntu in the cloud, end quote.
IE, they see this as a clear play for developers.
Yeah, use Ubuntu for your development work on your Windows workstation, and then deploy
your applications to AWS with Ubuntu Pro.
There's a cold practicality to this, because the reality is, this is what's going to be
happening. You have so many enterprises out there with Windows on the desktop that are
in a scenario where they have it managed with group policy and active directory and inventory
management and patch management, all going back, by the way, to that compliance stuff.
And they also now have to develop for their cloud systems, which are running Linux.
So what are they going to do? Well, they're going to probably do in VMs, or they're going
to SSH in all the time. And then along comes the subsystem for Linux. Well, one way Ubuntu
keeps that lead in the cloud is by recognizing this opportunity early and jumping on it before
somebody else does.
Based on my semi casual conversations with various canonical employees, I suspect they
see Windows 10's Windows subsystem for Linux as just yet another platform that Ubuntu can
run on, just like other VMs and containers or bare metal boxes, or Amazon instances.
It's yet another platform for the Ubuntu system. And it's not really about the fact that it's
running on Windows, it's just where the developers are going to be. It's a recognition of a market
fact.
It's clearly part of a multi year strategy from Canonical that thus far seems to be working
pretty well to me.
Well speaking of multi year strategies that seem to be successful, Amazon is executing
on their multi year strategy to troll me with the name of their ARM processors by going
all the way to 64 cores and making them insanely fast. Seems like a lot of work just to get
me upset over the name Graviton.
Why are you upset over the name Graviton?
Because it's like a Star Trek thing. I'll put a link in the show notes. It's like all
of throughout Star Trek. It's Graviton waves and Graviton beams and Graviton particles.
It's so funny that Amazon is, I mean there must be some Star Trek fan in there, but these
things are legitimately incredible. And this might be a bigger deal than anything Apple's
done with the CPUs and the iPhone. As much respect as I have for their work.
Yeah, this is the second generation of this Graviton system on a chip. The first one was
kind of an experiment, whereas this time they're serious. This is seven nanometer with 30 billion
transistors and they're claiming that it's going to outperform x86 in terms of price
to performance.
So that's really key. And that's kind of why I said this could be a bigger deal than what
Apple has done with all respect because what they have pulled off with the A series of
CPUs is truly tremendous. But what Amazon is doing here is astronomical improvements
that will be in production under load 24-7 in enterprise environments like that. That
is a really big deal. So here's some other stats that are just nuts about these things.
Each core has a megabyte of cache, 64 cores in total supporting two terabytes of bandwidth,
as well as an additional 32 megabyte level three cache per core, seven times faster than
their previous instances.
But the real numbers are impressive when you're looking at a comparative Amazon instance, say
something that's based around the Xeon Platinum 8175 processor, which clocks up to 2.5 gigahertz.
This thing in many jobs, HTTPS load balancing, x264 encoding, the spec CPU benchmark, mem
cache tests, it is substantially faster, like in the 40 to 50% range faster. Amazon describes
that these new 6G instances are able to offer 40% higher performance than the existing x86
fifth generation platforms, which consumers would have traditionally been buying.
Now, could you build a faster x86 system? Yes. But when you're buying into the AWS infrastructure
and you're looking at price and cost to hourly run, 40% difference is a huge thing in that
ecosystem. It means a drastic cost savings for the company and for any customer that
switches to these instances. This is a watershed moment for ARM in production. And to be honest,
64 cores is what it took to get it there. Like I think we all expected to really make
ARM competitive, you're gonna have to up that core count, and they've done it. They are
custom building this stuff. I think it's incredible. It also creeps me out.
Why does it creep you out? Well, because now you've got Apple building
their own custom silicon, you've got Google building their own custom silicon, you've
got Amazon building their own, etc, etc. All of these near trillion dollar tech giant companies
all have their own custom CPUs, which are not necessarily compatible with each other.
Well, that's true. But Amazon are still using Intel and AMD.
Yeah, I mean, x86 still remains the bastion of a quote unquote, open platform, not open
in terms of open source and liberties and blobs. But open in the sense that x86 is an
architecture that your code would write on on a DigitalOcean box or an Amazon x86 instance
or an Azure x86 instance or an x86 box in your closet could all run that code. We are
now moving into a world where the largest, most influential tech companies are creating
their own CPUs for their own custom jobs. If we go down the world of ARM, and we start
replacing all x86 laptops and desktops, you know, just as ARM becomes more and more competitive,
which kind of just seems to be the way people want things to go, I worry that we will enter
into a world where it's so fragmented compared to what we are used to today. It just seems
like not a great direction, like not a lesson learned kind of situation.
Well, I think you're right in terms of the images and operating systems that are going
to have to be bespoke to run on each platform. But I think the applications will be just
ARM 64, right? So you're not going to have huge incompatibility for the users.
No, it's going to be probably fine on the cloud providers. They'll just work all that
out. It'll be an implementation detail. You won't even have to worry if it's some sort
of custom built Azure CPU that is super great at doing your specific task, because you'll
just write to their API. And that's the end of the day. That's all that matters. But I
wonder about the market that isn't part of the big cloud. One of the one of like the
small providers or somebody who just wants to build their own instances, or how will
open source projects deal with this? Like, are they going to make versions for all these
different ARM CPUs? Because undoubtedly, these Amazon A6 instances are going to be big. This
is a huge hit. You get faster system for less cost. All right. So the open source world's
going to have to deal with this. I mean, I don't know. Maybe I'm wrong.
Well, companies like Red Hat and Canonical will have no problem dealing with it. But
maybe you're right, the smaller distros are going to lose out here. I hadn't thought about
that. I thought about the positives of it for a change. And that is that it is going
to force Intel and AMD to innovate faster and better to compete.
I hope they can. I hope they can. I feel a lot of momentum moving towards ARM. You know,
like people are waiting for ARM MacBooks, people are waiting for ARM laptops to take
over the world. People are going to System76 and saying, build us an ARM laptop. And I'm
sitting here going, maybe we could just make x86 better. Can we all just get on AMD's platform
for a while and just ride that? Because I love the idea that if I download an ISO that's
AMD 64, it's going to run on any of my CPUs. Maybe I'll have weird Wi Fi driver issues
here or there. But the frickin CPU and motherboard, at least that works. Maybe we won't get there.
Maybe it won't matter. But looking at this, I think you're seeing remarkable, remarkable
accomplishments both from Apple, Amazon, Google, and Microsoft. But you're not seeing it really
benefit anybody else. Like it's not, you're not seeing products out in the world except
for their own products.
There's been quite a lot going on in the world of Mozilla this week. Firstly, they've released
Firefox 71, which doesn't have a huge number of new features. It's got one pretty good
one for Windows users. But unfortunately, we don't get that. It's criminal. It's criminal.
71 Joe, I remember when version one came out. I remember when the better it took forever
to just get to conversion one. Well, yeah, picture in picture video comes to Firefox
for Windows users. Now, picture in picture video sounds like one of those features. That's
a cute little toy you'd never use. And that's because you're completely wrong. It is the
best. I am now a firm, firm user, a firm, firm user, Joe, like, like not even like a
soft user, but like a firm user of picture in picture mode. It's so great. You know,
some YouTubers rambling on, you just pop it up in a picture in picture mode and go about
your day. It just goes into the corner. God, I love it so much. It's one of the actual
reasons why one, one of a handful of reasons I've quit using Firefox again, which I totally
blame on you. But it is what kept me off Firefox.
You can do it with extensions and stuff, but it would be nice if we had it natively.
You can do with extensions. Not quite as nice though, Joe. It's not as nice.
Yeah, they've also improved lock wise, the integrated password manager, and it's just
kind of a few little improvements here and there. And this is really because they're
moving to a much shorter release cadence. So I think we're going to have fewer features
per release going forward.
We'll put a link in the notes. It kind of shows Firefox 71 Linux performance isn't looking
all that great. Of course, compared up now to Brave and Vivaldi, it really isn't doing
very well. He benchmarks Chrome 78, Michael Arbel does, against Firefox 71. And on Linux,
Chrome 78 kind of dominates all the benchmarks, except for like two or three by my count.
So it's not looking super great for performance on Linux. But the story has improved overall
in the aggregate. And the overall feature set of Firefox has improved without a massive
slowdown. So that's kind of a net win too. And new services are starting to roll out
in beta now as well.
Yeah, you can finally start using Firefox Private Network, which is their VPN service
that we've been waiting for. And it's $4.99 per month, but only in the US. So I wasn't
able to try this out, unfortunately. It's unfortunately only available for Windows 10
at this stage as well. And it is cheaper than private internet access, which is about $7
or $8 a month, I think. So I think realistically, once it's generally available, it's probably
going to go up to somewhere around that kind of cost.
Right. And then there's the browser extension, which is free and available to those in the
US that just want to protect just their browser traffic. If you want to try this out, you'll
have to use a link in the show notes to join the waiting list. Because as the queue grows,
they're putting a list up. And then when they get to that list, they're opening it back
up again right now.
It's worth mentioning with the free extension that it's only the browser traffic. And you
only get 12 one hour passes per month.
Yes, that's the thing that's a little different. I'm glad you mentioned that is the 12 hour
passes per month. The browser only being protected. I think there's like a handful of VPN services
that do that now. It's not my preferred way to go. But I bet you that covers a lot of
use cases for a lot of people, webmail, banking, social, a lot of people just do it all in
the browser. So it's a really easy low hanging fruit, but it's not a complete solution.
But at $4.99 per month, that's the same price as spending up your own DigitalOcean droplet
and running a WireGuard instance. I suppose it's a lot easier to just sign up for Firefox's
one.
Yeah, that's just it. If that suggestion sounds like a ridiculous proposition, then you're
probably a decent customer for this browser extension. If you're like myself, I've already
got a VPN set up. I've already solved this problem. So I'm not the right target audience
for this. However, I think this is a net positive for Firefox users. Might as well get something
that is Mozilla branded. So you know, if you're already using Mozilla Firefox, you hear about
VPNs, most users, they don't even really fully understand what it is. You can tell them it's
a tunnel through the internet. Oh, okay. But if they even stop for half a second, well,
what the hell does that mean? What does a tunnel through the internet mean? What is
that, right? So they need something that is safe, that's brand recognizable, and can be
built right in and just turned on and turned off. So pretty likely, this is going to scratch
that itch for a lot of end users. I don't think you and I are it though.
I think that's a nice idea. But isn't the reality that everyone else is using Chrome
and it's only really people who care about open source are still using Firefox?
I think their strategy here is to change that narrative. That narrative needs to go away
and the new narrative needs to be yeah, Firefox, Chrome's great. Isn't the only people like
Firefox are people that are like really worried about their privacy? So if they could shift
that to just people that are worried about their privacy, that's a huge market. And that's
something people are going to be railing on Google, Apple, Microsoft, other tech people,
companies, whatever are going to be railing on Google on hitting on that point. And so
Mozilla gets to just sit back and enjoy the fruits of everyone else's labor while positioning
Firefox as this privacy conscious, web defending browser, and just sit back and wait for people
to look for an alternative. I think that's got to be the strategy here. So that's why
things like lockwise and Firefox protect that they really kind of get these things entrenched
in your mind as the brand is trying to really take care of you.
Yeah, which is probably why when a security researcher pointed out that Avast and AVG
extensions were effectively acting as spyware, they removed them from the Firefox store.
Yeah, that was a big deal. I think Opera did the same. So when these extensions were installed,
they would track the URL and title of every page you visit, how you got to that page,
along with per user identifiable details about your operating system and browser version
plus other metadata. And it would transmit all of that info back to Avast back end servers.
The researcher Joe mentioned had been blogging about this for a little bit finally raised
attention about this and really made a great case with visual screenshots why it was just
way more information than Avast needed. Avast did respond and say that they had to collect
all this data to detect dodgy and fraudulent websites to protect the users. But it's pretty
easy to argue that they went way too far and dipped into the spyware category.
It's interesting to note that if you have them already installed, though, they're going
to continue to work. They're not going to be disabled automatically.
Right. And what concerns me about this is as more people have moved to Linux, they have
brought with them this concern about viruses and malware. I think every week I see a question
come in asking what antivirus people should install on Linux. They're not even asking
if they should. They want to know which antivirus to install. And I could see a portion of those
users going out installing extensions like this. I really wonder if people looking for
antivirus solutions isn't just the natural result of being trained from day one of using
a desktop computer on Windows that you need to be careful and you need to use antivirus.
And so they've just associated that paradigm with desktop computing. So these kinds of
scams end up looping in more people than you'd expect.
So hopefully people will become aware of this and disable those extensions themselves, but
probably not everyone. But one last story from Mozilla is their release of DeepSpeech
0.6. This is their speech recognition system, which has become incredibly fast to the point
where it can run on a single core of a Raspberry Pi 4, which I imagine piqued your interest.
Yeah, it did. Reading through this, it's astonishing how far this has come. Remarkable. When they
launched Common Voice and also DeepSpeech, I thought to myself, well, this will be a
10 year project. It'll be cute when they finally get to where Nuance and Google are today.
Why was I wrong? Their new streaming decoder has seen remarkable performance improvements,
consistently lower latency and memory utilization. It's to the point where a Raspberry Pi single
core can do it, or on an efficient, fast desktop system, it can do it in faster than real time,
which is incredible. They've gotten this thing 73% faster in that regard. They also swapped
out some of the TensorFlow stuff for TensorFlow Lite components, and they brought the sizes
way, way down from like 98 megabytes to 3 megabytes. And their entire model size for
the English language went from 188 megabytes to 47 megabytes. It now uses 22 times less
memory and starts up over 500 times faster. And they've added support for.NET and Windows
along with Python, JavaScript and C bindings..6 is the release I was expecting five years
from now.
It is very impressive. But can you imagine if this had been in this state when Mycroft
first came around, it could have potentially actually succeeded. The possibilities of on
premises implementations of this technology are really mind boggling when you think about
how enterprises could use this to have their own private system or somebody like myself,
who just simply wants fully offline speech recognition with my automation systems. No
internet connectivity required, full voice transcription understanding of what I'm saying.
There's some projects that are getting really close, but nobody's gotten this close yet.
And I could see things like Home Assistant integrating deep speech and other components
of common voice and bringing complete private voice control to automations in workplaces
and in home. Not to mention all of the accessibility benefits this could bring, how things like
LibreOffice could take advantage of this for transcription. They have an example of a medical
professional who's working with a system that has been tuned for health lingo and he's dictating
into LibreOffice his medical notes and it recognizes the words and just does the transcription
for him.
This is a huge market for Dragon, naturally speaking. They have products that are particularly
designed around the medical industry and this could be something that LibreOffice just does
one day.
It feels like a serious step closer to project offline, off-grid, whatever your dream is.
Project off-grid, Joe. Don't mess up the branding. Geez. It really is though. You're right. Yeah.
That's my goal. That's something I've been documenting in our self-hosted podcast is
I want a completely offline system, like an internet in a box in my RV and I don't have
any kind of speech recognition that works without internet connectivity. And I just
thought, well, years from now, years from now, I'll have something.
Wouldn't it be good if it was all open source as well, like this is?
That's really neat. This could be a great contribution. I mean, faster than real time.
That's mind blowing. And you can still contribute to Common Voice if you want to help them build
their modeling. That's the other really cool thing about this is they didn't have to listen
to hundreds of thousands of Google voice recordings. They didn't have to listen to years worth
of YouTube, all of your voice chats, all of the commands you speak into a smart speaker.
They were able to get this working using open source technology and people voluntarily contributing
to Common Voice and buying data sets that are freely available and open or at least
available. And I think that's also really important to recognize because while some
others in the industry may be further ahead, they've done that through surveillance where
Mozilla has not here. And I think that's a huge accomplishment as well.
Yeah, I remember at the time I contributed my voice and also did some of the verification
of people who had done theirs. And it only took me a few minutes. But if hundreds of
thousands of people do that, then this is the result of it.
Yep, I did the same. And I think people should consider just going to Project Common Voice
and and going through the process only takes a few minutes. If you have a decent mic, you
could probably do it pretty quick.
And even if you don't, that's one thing that they were keen to have is people just on phone
mics and laptop mics with background noise, because that's what you need to train the
algorithms.
Yep, you got to cover all the edge cases. And they're thinking about that. So deep speech
has really come a long way. And it's great to see version 0.6. Put that on the list of
one of my favorite projects this year that just went from zero to hero in like no time
and in such a complex thing to machine learning is real, Joe.
Yeah, it's good to see them spending some of their money on something that's going to
benefit so many people.
Yeah, really, it's one of those projects that maybe Mozilla is best suited for. Well, whatever
happens, we'll let you know next time there's a big development. Just go to linuxactionnews.com
slash subscribe for all the ways to get new episodes.
And you can go to linuxactionnews.com slash contact for ways to get in touch with us.
We'll be back next week with our weekly take on the latest Linux and open source news.
I'm at Chris LAS.
I'm at Joe Rissington.
Thank you for joining us. And we will see you next week.
Take care, bye-bye.
