Hello, and welcome to Linux Action News, episode 172 recorded on January 17th, 2021.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
And we start with Plasma's bright future.
The currently in development 5.21, due for release sometime in early February, features
some exciting improvements both in the UI and under the hood.
Yeah, we wanted to give you an idea of what will be landing in distributions released
around that time.
And picking up on the UI side, there will be updates to the breeze theme that look really
sharp, but also an overhaul to the kickoff menu, the default launcher menu that brings
a two panel look to it.
We'll have a link in the show notes so you can see the screenshots for that.
And then a feature that I'm really excited to see besides dynamic audio indicators is
an update to K-Runner, which is Plasma's built in application launcher with K-Runner anything
in Plasma from launching an application to rebooting a computer to command anything can
be done in K-Runner.
And one of the things they're adding is the ability to pin applications to your K-Runner
menu, which is just so nice because that's probably the primary way I interact with the
Plasma desktop is through K-Runner.
But there's some nice under the hood stuff, too.
Oh, great.
One more thing to customize.
No, no, I kid.
I also use K-Runner all the time.
Under the hood, though, Plasma 5.21 will officially be the first version that integrates with
system D at startup.
I know it's kind of surprising it took this long.
GNOME's been doing that for a while now on many distributions.
What you might notice as a user is a much faster start time.
And that's pretty nice when it's your main desktop.
Under the hood, some of the stuff was important because it avoids process race conditions
during startup, better session cleanup and some fancy integration with things like C
groups that just wasn't possible before.
Yeah, that's interesting.
But even if you're not a system D fan, you're going to love the updates that are going into
K-Win.
The compositor now provides an option for you to choose two different modes, smooth
animation or a lower latency experience.
I can't wait to play with that.
But also the work brings support for mixed refresh rate display setups on Wayland.
In fact, a significant chunk of work around Wayland is going into this K-Win update, which
is going to have ramifications upstream.
It really does seem like there's a lot of great work going on in K-Win right now.
And isn't that just a classically plasma option?
And they even say it in the GitLab where they write that we have to choose between latency
and stable animations.
And given that we cannot make such decisions for the user, a new option has been introduced
to set the desired latency level.
By default, you get medium, but then you can choose to get more stable and smooth animations.
Or if you just want speed, set it to reduce latency.
Wow, you're right.
This is quintessential plasma versus gnome difference.
The gnome shell desktop would just be like, yeah, we're doing low latency.
Or nope, we're doing super smooth animations.
It's not user configurable.
It's just baked in.
And they could argue for consistency.
It's nice to see it.
There seems to be a acceleration of Wayland development too for K-Win.
We had Nate Graham on Linux Unplugged 385 recently.
And he does the This Week in KDE blog post where he kind of chronicles all of the just
super great stuff going on in the plasma desktop right now.
And one of the things he noted was the project as a whole really wanted to do a lot with
Wayland in 2020.
But it was when Fedora 34 announced that the plasma spin would become official and that
the plasma spin would be switching to Wayland by default, it really kind of rallied the
developers to really start cranking on that.
And it's a good example of how a distribution plays a role in this ecosystem, a distribution
like Fedora in this case, which is known for shipping kind of cutting edge open source
free software to their users.
Well that reputation means that when that news hit the developers, they knew they needed
to get started.
They needed to get that code upstream.
They needed to get it in K-Win.
And it kind of gave them a real goal to rally around.
And it's a nice insight into how the ecosystem works, I think.
And it's also great for us end users and awesome to see the K-Win support there.
Even right now in 5.20, it's pretty good.
It's daily drivable if you're on an Intel video card with a single screen, you're not
really going to have a bad time.
It's going to work pretty well for you with a few small things.
So they're not too far.
It does start to fall down when you go multi monitor right now.
And it looks like that's where some of this work has gone in specifically to solve that.
And of course, I'm going to be playing around with that lower latency.
I'm going to have to set it to like lowest latency possible and see if I notice a difference.
You want a fast but broken desktop.
Got it.
Oh, it cuts deep, Wes.
That cuts deep.
One feature we're not sure is going to make it into 5.21 is much improved fingerprint
support in KDE Plasma, a fingerprint manager capable of registering multiple different
fingerprints and support more widely across the desktop.
And that last part is maybe what the hang up is.
There's a nice MR over on their GitLab right now by Devin Lin, who's put together a lot
of this, a really new shiny UI, which I'm excited to see in production.
But there are some concerns from some of the developers, Nate Graham included, that Intel
support is really wide across the whole Plasma desktop.
You might encounter some password forms or similar where it's just not supported and
it is in one and not in another.
They're probably going to blame the team for that.
It's going to be funny because if they solve for that, they will essentially have a superior
implementation than Apple does with Touch ID on Mac OS because I've been on a Mac with
Touch ID and there's dialog boxes that still require your password to say, install software
or do an update that do not support the fingerprint reader.
Could you imagine if Plasma beats Apple to that?
Here's hoping.
Well, recently is a holiday treat to us all, XFCE 4.16 was released.
That release marked one year and four months of work for the team.
As you can imagine, they're pretty excited about getting this one out.
They had some big changes in the back end development too.
They migrated over to GitLab during this release.
And they also made some updates to their visual identity.
They really kind of went after the way all of the icons looked and made a more consistent,
maybe more of a long term look to them.
And they're nice and sharp.
But there's also some pretty decent under the hood improvements as well.
Oh yeah, this feels like a well polished release.
Here's an example.
Support for fractional scaling was added to the display dialog and along with that comes
highlighting the preferred mode of a display with an asterisk and adding aspect ratios
next to resolutions.
And I just like that attention to detail.
Makes it feel like a well thought out feature.
Also nice to see falling back to a working mode after a misconfiguration of the display
layout has also been made more robust.
And that's great because I really don't want to lose my whole desktop or have to unplug
and replug some cables.
Also included in 4.16, the file manager Thunar, which is one of my favorites, received a boatload
of fixes and quite a few notable features, including pause for copy move operations.
Fancy.
Support for queued file transfer, remembering view settings per directory and support for
transparency in GTK themes.
Nice.
Have you ever had a server that needed a desktop for some strange reason?
Yeah, I have.
XFCE is my go to in those kinds of situations where I want something that's fully functional,
that feels like a really usable environment, but also is extremely conscientious about
the disk space, about the resources, about really all of it, even make, you know, using
it in a remote session.
So I'm just pretty thrilled to see the team have another release.
Took them a year and a bit to get it out, and it's great to see it here.
Congratulations to them.
Next up in the show, we've got a PSA for older Intel GPU users out there.
Yeah.
Anyone that had the Haswell GT1 graphics?
Well, if you've been running a recent kernel, good chance you noticed that your GPU has
been broken for about a half a year under Linux.
It's kind of a hot mess of a situation.
Yeah, well, Intel is generally well regarded for their Linux development practices, especially
around things like integrated graphics and continuous integration and testing to make
sure that stuff actually works by the time they've shipped it upstream.
Unfortunately, while they were trying to mitigate a GPU vulnerability, kind of similar to the
Spectre vulnerabilities, we've seen another attack where there's some leaks from GPU access
that you need to go in, purge GPU state, and just introduces more performance penalties.
And this time around, it also introduced your GPU hanging when you tried to boot.
That's not good.
That's kind of the last thing you expect.
And the situation remained pretty bleak for about half a year.
But there's a patch now that has a working driver and allows you to mitigate the security
protections.
You can pass a little bit of mitigations equal off type command at boot and it will disable
the mitigations at runtime and should restore the former glory of your Haswell GT1 iGPU.
Yeah, that's another area where it's very similar to Spectre.
It is a different command line flag though.
So if you have this particular chip and you're trying to mitigate this and Spectre vulnerability
as well, that's two more things on your kernel command line.
But if all goes well, these patches should be mainlined for Linux 5.12.
And actually, ideally, the fix for this not booting your GPU bug will actually get picked
up for 5.11 still, fingers crossed.
And it seems like it's going to be backported to stable series of Linux all the way back
to 5.7.
Linode.com slash LAN.
You go there to get a $100 60-day credit towards a new account and you support our podcast.
Linode is our cloud server provider.
We've got a whole fleet of Linodes now.
We really just kind of have gone all in because they're perfect.
Not only do I love all of their features like object storage and node balancers, which help
us manage when something gets released and there's quite a bit of traffic.
And the object storage is brilliant because it's S3 compatible, which means we can work
with all kinds of different applications, but we can even mount it as a file system
and just use the storage that we need so we can have the storage and the server detached.
And that makes it so easy to manage things that are running in containers and applications
that we want to spin up and not have to worry about allocating a ton of disk to the Linode
that they're on.
And it also means we can generate public URLs for those files.
I just absolutely love Linode's object storage.
But maybe you just need something simple, like a personal website where they got machines
that start at $5 a month.
But I don't know, maybe play around when you get a $100 credit.
I mean, you could really see what Linode is capable of.
They have systems with dedicated GPUs and dedicated CPUs.
They've been in this for a long time.
They started in 2003, pretty much the first company in what is now called cloud computing
because they saw what Linux was capable of.
And then as they've grown, they've supported the community projects like Kubuntu, events
like Linux Fest Northwest, and now your humble Linux action news.
They're independently owned and they've been founded on a love for Linux.
You know I get that.
And I love that it shows through their interface.
I see the touches.
And even if you're brand new to managing a server, they've built something that's easy
enough for anyone to manage.
Get a personal site or get something for your business set up in seconds.
Just start at linode.com slash LAN.
Get that $100, 60 day credit and you support the show.
Thanks to Linode for sponsoring Linux Action News.
And thanks to everyone for going to linode.com slash LAN.
After a year in development, Wine 6.0 is here.
And this release is something of a special one because it's dedicated to the memory of
Ken Thomas' who passed away just before Christmas at the age of 51.
Ken was an incredibly brilliant developer and the mastermind behind the Mac OS support
in Wine, which boy, that is impressive.
Definitely is.
And the team says that they're going to miss his skills, his patience, and his sense of
humor.
There are some significant features in Wine 6.0, which include core modules built as PE
executables.
More on that in a moment.
A new experimental direct 3D render that has Vulkan support, as well as direct show support
and a new text console mode and a lot more.
At this point, I think we might be taking Wine for granted a little bit.
I mean, it took 15 years to get to version 1.0 and really actually get Windows applications
and games really running on Linux and then eventually Mac OS as well.
And these days, there's almost 28,000 different applications, games, basically anything you
can run on Windows.
There's a shot.
It'll work in Wine.
And that's just awesome.
Yeah, some of even our production tools for audio editing, we've used Wine versions on
occasion and they actually work.
I noted in there that one of the things that 6.0 brings is PE executables.
So this really comes into games that are checking for DLLs on the Windows disk for some kind
of shenanigans, copy protection schemes that check for DLLs like kernel 32 and NTDLL.
And they expect them to match a certain way.
And if they don't, that's one of the things that can flag copy protection.
And I guess this built in PE format for some of these things will make this check pass.
And there's three states that it can possibly find out.
It can find out that it's on a fake system.
It can find out it's in the middle of an update and it can find out that somebody has replaced
the files.
And I guess it works better within those contexts.
That was what I was able to grok, which seems like it's going to be great for gamers that
have gotten the ban or something like that because copy protection was triggered.
We've all heard those stories.
Yeah, this is just adding more sadness, I guess.
They've done a lot of interesting work sort of making PE executables work nicely, including
some stuff where if you don't have a Windows API available, you can actually have a Linux
style DLL linked file.
And those two can talk so you can use leverage Unix APIs from your otherwise Windows focused
code.
That's neat.
And I think it just means that from the game or applications perspective, it all just looks
the same.
Like what's actually in memory should be the same as the file and disk because they're
no longer stored in different wrapping formats.
Yeah.
And also, I mean, just beyond that kind of copy protection stuff, which thankfully has
never bit me, there's other improvements in here that are going to mean that your wine
applications just launched from disk faster.
Those of you who like to play some of the Blizzard games like Diablo or some of the
others, there was an issue that prevented some of them from working.
That has now been fixed.
And then I was just trying out Destiny 2.
So it's very exciting to see that has been fixed in here.
There was a launch crash issue.
However, in my testing with Wine 6.0 released this morning, I still was getting the crashes
they said were fixed.
So I may have something else going on.
Speaking of slightly disappointing things, support for the obsolete 32 bit power PC architecture
was removed.
Hey, so long.
But there's some good news in the same vein.
There's now initial support for ARM64 on macOS for the shiny new Apple silicon.
Wow, that just took about a minute.
How about that?
Also, display settings are now being retrieved through XRender 1.4 if it's available.
And it means that wine is going to be smarter about multiple display orientations as well.
So those applications will behave a little bit more like native applications.
After last year's news about the future of the CentOS project, we saw a flurry of activity
and speculation about various potential future rebuilds.
One of the more prominent from Cloud Linux was called Project Linux.
We didn't know much about it then and details are still scarce.
But there have been some updates, including its new name, Alma Linux.
Here's kind of what we do know at this point.
The company Cloud Linux has about 10 years experience building their derivative of CentOS.
They already have been doing this for their customers.
And they claim now that they're going to release a version of that as a binary one to one compatible
fork of RHEL 8 and future releases.
They promise to provide an uninterrupted way to convert existing CentOS servers with absolutely
zero downtime or need to reinstall anything.
The company says that you'll be able to port an entire CentOS server fleet with a single
command, no reinstallation and no reboots required.
The name WESK is the Latin word for soul, by the way.
But you did some digging into this and it seems like the biggest advantage they have
is that they are leveraging that existing infrastructure they had for a product that
they've been making that is really kind of targeted at VPSs.
Is that right?
Well, for folks who run those, you know, the folks running VPS providers, you've got a
whole bunch of web servers running on the same host.
You've got a particular set of problems and that's where Cloud Linux come in, right?
They've got their own customized kernel, they've got some customized software that's targeted
at exactly the space to make sure you can host, for instance, a whole bunch of websites
where one person who's overloaded website or just poorly performing won't affect all
the other guests.
And yeah, that's that's pretty important.
It is interesting, though, because there's no real direct comparison.
I mean, they might leverage some of their work with Alma Linux for Cloud Linux, but
if you're not in that space, that's not going to be the operating system for you.
So this is, in some ways, entirely separate and just a new community effort as a way for
Cloud Linux to give back.
That is pretty great.
But it is interesting that and I think they don't come directly at this, but their CEO
does sort of acknowledge that they don't have a one to one path from what will be Alma Linux
to their commercial product.
It's not like they don't have an upsell upgrade path.
And some people may see that as a really good thing.
I worry a little bit about what it means for making it a sustainable effort for them, because
you could say, oh, well, we already have the build infrastructure, we're already doing
it for our product, so it doesn't take a lot of work.
But I kind of call BS on that because it's sort of like Jupiter Broadcasting saying,
yeah, we've got servers to encode our shows and it would be zero cost for us to just encode
everybody else's podcast in the world that wants them.
There's clearly a cost on that.
There's an infrastructure cost, there's a staff cost, there's a real time commitment.
And they're even promising to support it with over a million dollars per year.
Now, who knows how long that will last.
They also say that, you know, they will help out a lot, especially with their expertise
in doing RHEL rebuilds already.
But ideally, intentionally, it will be owned and governed by the community, at least to
quote them.
Well, that's interesting.
And the governance aspect is something we're not really clear on yet, but they do seem
like they want to have a lot of community involvement there.
Their intentions seem really good at this point.
And this is what's going to make for the differentiation between these different CentOS quote unquote
replacements, if you will, because I still maintain that stream is going to work for
a lot of people.
But you'll have different clones come up and how they are monetized and sustainable and
how they are governed are going to be some of their key differentiators that make them
appealing or unappealing to people for different use cases.
Absolutely.
And actually, in an interview, Igor Slatsky, the CEO and founder, sort of said that, you
know, I think the quote was around, well, nothing can really stop us except if no one
uses our Alma Linux, you know, it's really up to the community.
Will there be communities that form and actually are the soul of these efforts?
And I think it's interesting that there are some different sectors, for instance, you
know, cloud Linux, their expertise is all about the web hosting version of things.
Whereas I think for Rocky Linux and some of the other folks, there's a large contingent
of high performance computing and scientific efforts, people coming from those communities.
Makes me wonder how this all shakes out and if there'll be any little differences between
their approaches.
Yeah.
In the meantime, their website is up.
We'll have that linked in the show notes.
And right now the team is just working their butts off.
They're trying to get this thing up and going.
They, you know, they know there's a window of opportunity here to kind of grab the lead.
And they've got a pretty good backstory to make them seem credible.
And they're targeting for an end of January, early February first beta release.
Also hopefully coming soon will be Podman 3.0 and it's got one feature I know you've
been waiting for.
Oh boy, me and millions of other users.
Now if you're not familiar with Podman, it's a demonless container engine for managing
OCI compliant containers on your Linux box akin to Docker.
But it has been missing a Docker feature that a lot of the self-hosted community really
wants to see before they switch over.
And that's Docker Compose support, the command line utility that orchestrates multiple Docker
containers for local deployments was missing with Podman.
And now with version 3.0, the team has been working hard to get Docker Compose support
into Podman.
That's, I mean, that's huge for me.
Game changer for me.
And I know that you loaded the fresh code, gave the new build to try and saw how good
or bad the support was.
How did it go?
Surprisingly well.
I think the biggest drawback I noticed right out of the way was that there were no logs.
You know, if you do an interactive Docker Compose up, normally you get to see all the
logs for the containers you're running.
Not so with the integration so far along, but you can just do a Podman logs, TACF, and
then the name of the container just like normal and they're still there.
They're just not shown through the interface of Docker Compose just yet.
The other thing is there are a few missing features like renaming a container that's
not yet available.
So if you've done a, if you've started containers and then hit control C and stopped and try
to bring them up again without doing a full Docker Compose down, you'll also run into
some problems there.
But none of those are really deal breakers because most of the time, once you've figured
out what you're doing with Docker Compose, you do it in the background anyway and you
just start all your services up.
You mentioned at the top there that it's a Daemonless solution and that's been a big
deal for Podman because it was really simple and clean and it sort of replaced where you
might have previously done Docker run, you would do Podman run.
And I think it's kind of been sort of a backend solution up to now, you know, it might be
leveraged by things like Kubernetes or OpenShift or other systems that sit on top and want
to run containers, but not re-implement everything themselves.
Well in version 2.0, they added the Podman system service, which included this whole
new REST API.
Actually it's two REST APIs.
There's a native Podman focused one and they added one that implemented basically the Docker
REST API.
And so that's how all of this works.
There's a new service that you start just with systemd and then it's got a socket that
looks just like the Docker socket.
Docker Compose just thinks it's talking to Docker, it's using the same REST API calls.
Podman handles it all under the hood.
That's pretty brilliant.
And the beauty of open source software when you need to implement compatibility like that.
I guess like there's a caveat also that you could add to this is it's not currently implemented.
Swarm support isn't currently implemented.
So if you use swarm functionality with Docker, you're not going to have a good time with
Podman.
Obviously not an area that I'm concerned about in the slightest for me.
I mean I'm really going to use this more like on our server and on my laptop.
That's where this is going to be a big game changer for me.
Not that I have any real issues with Docker, but I will say as somebody who kind of stays
really current with Linux, I have definitely had releases where there has been no Docker
support officially for a bit and I've had to wait around until the distribution was
supported by upstream.
Well yeah, I think there was a lot of disappointment with how long it took for Docker to get support
for cgroups v2 and that just really wasn't an issue with Podman.
I think for now though we'll still see Podman as sort of the, you know, a tool in the tool
built of Linux users in the know, especially as they slowly add more porcelain on top here.
And I think Docker still got the name recognition and the cross-platform support.
So say you're a developer on a Mac laptop, I don't know that Podman is going to have
a great option for you unless you want to run your own Linux VM, whereas Docker takes
care of that plums at all so that you can kind of forget there's even Linux involved.
Datadog.com slash Linux action news.
Datadog is the powerful unified monitoring and analytics platform that gives you comprehensive
visibility into your cloud, a hybrid setup and multi-cloud environments.
Quickly analyze the performance of your Linux servers in real time with a customizable dashboard
and it makes it a breeze to troubleshoot issues.
Maybe your Linux box or an application has problems, zero in in seconds with a unified
view of your metrics, your traces and your logs all in one place.
You got to go to datadog.com slash Linux action news just to see the visuals of what I'm talking
about.
This kind of stuff is really what utilizes the power of having multiple systems and with
the clipboard you can streamline performance outages and investigations by capturing relevant
views of your infrastructure and applications all in a single heads up display right there
on the dashboard and they have turnkey integrations for over 400 technologies.
You could even use Datadog to monitor key Linux metrics right alongside the rest of
your entire stack so you get the complete picture, get full visibility into health and
performance of your entire infrastructure.
So start your Datadog trial today by visiting datadog.com slash Linux action news.
If you're having problems communicating with your team, Datadog gives you the metrics and
the visuals to communicate.
It was started by its founders because the dev team was having a hard time talking to
the sysadmin team and from there they have built a brilliant product.
So start your free trial, create one dashboard and you'll get a free Datadog t-shirt.
That's datadog.com slash Linux action news and a big thank you to Datadog for sponsoring
Linux action news and thanks to everybody who uses our sponsors offers, takes advantages
of those offers and helps out the show and gets the free swag.
Datadog.com slash Linux action news.
Some unfortunate news for Chromium users this week as Google has announced they'll be limiting
access from Chromium to some of their quote unquote private APIs.
Yeah, this is pretty dramatic and drastic really.
If you're like me and you use the Chromium browser package from your distribution and
you rely on regular old Google Chrome syncing, well, you're either going to need to move
to Google Chrome or switch to Firefox or another browser because Google is limiting that access.
Just the straight up Chromium browser or other browsers that are derived on it.
I guess they didn't realize this was something you could do according to their blog and then
when they were conducting an audit realized it was possible and decided for security reasons
they should shut it down, not to get you to move to Google Chrome proper, of course not.
Of course not.
This is kind of an upsetting reminder though that Chromium, I think we think about it a
little differently than maybe Google does and that while it has a great built in Wenderer,
all kinds of nice technology on it, things like missing click to call or Chrome sync,
those are features you think about having in a modern browser and you just sort of think
with Chrome or at least I think we like to tell ourselves with Chrome that all the stuff
we use for the most part, besides like actual Google integration is the open source, is
part of it, having an open source heritage, but not really.
You know it's bad when I'm looking at Edge going, man, Microsoft just add sync support.
That might be my go to blink based browser now.
There is some, I guess, bit of a silver lining.
If you use the sync service and you do switch to Chrome, your data will be there and if
you don't switch to Chrome, but want your data, it'll be available in their takeout
section and they'll continue to leave everything locally.
It's not like they're going to wipe your profile data when they disable this feature, but nobody
ever likes to see this stuff get removed, especially when the explanation is as dodgy
as, oh, we didn't know it was possible.
Give me a break.
Well, speaking of breaks, Hector Martin and his team over at Asahi Linux caught a nice
break this week with the release of macOS Big Sur 11.2 beta 2, which comes with full
custom kernel support.
Yeah, Hector Martin and his team are the group working, one of many groups working on getting
Linux running on the Apple M1 platform.
And this is huge.
This is essentially blessed support from Apple to load your own kernel.
And when Hector and I chatted for Linux Unplugged recently, I think it might've been off air,
but he speculated with me that he may be able to get Linux booting on this thing by the
end of January if Apple made this change in time.
And here it is, they've made the change.
So things are trending in the right direction.
What once seemed like an impossible task at least has a starting line now.
It's kind of fascinating to watch because clearly Apple didn't have to do this.
They explicitly don't do this on iOS, right?
And as we see with these, you know, M1 chips and future macOS lines, there's some convergence
happening there.
So I really could have seen them porting things over and just said, no, it runs our sign stuff.
It's secure.
You don't get to touch it.
They're actually including the technology, not helping with drivers or anything else,
of course, but letting us run Linux on there.
And wow, that's nice to see.
Yeah, it's interesting too, because they're not using like some custom UEFI implementation,
but they're actually using the iBoot stuff that they do in fact use on iOS devices.
So they very much are choosing to do this.
It's hard to really know for sure if that is some kind of nod saying, yeah, go ahead.
Or if it's more like we're building this in for folks like Microsoft.
But either way, it leaves the door open for Linux.
So it's nice to see them go after it.
Good luck, Hector and Asahi Linux.
Well that does bring us to the end of this week's episode.
Check out linuxactionnews.com slash subscribe for all the ways to get new episodes and linuxactionnews.com
slash contact for ways to get in touch.
If you have some time Monday evening and want to hang out, join the new Coder happy hour.
It starts at 5 p.m. Pacific, 8 p.m. Eastern.
And you never know when friends like Wes Payne will be stopping by.
But for us, we'll be back next Monday with our weekly take on the latest Linux in open
source news.
Thanks for joining us and we will see you next week.
