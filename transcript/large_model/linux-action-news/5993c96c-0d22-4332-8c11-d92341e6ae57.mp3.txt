Hello, and welcome to Linux Action News, episode 246, recorded on June 22, 2022.
I'm Chris.
And I'm Wes.
Hello, Wes.
I'm on location in Bozeman, Montana, so apologies for any odd sounds, but let's do the news.
This week, Akamai Security Research lifted the public embargo on Ponchon, a new peer-to-peer
botnet they're warning customers about, and that's been breaching Linux servers since
March.
Written in Go and fully taking advantage of Golang's excellent concurrency to maximize
its effectiveness at spreading and executing malware, Ponchon relies on memory-mapped files
to avoid detection via its on-disk presence, while also reportedly stopping any of its
crypto mining processes when it detects someone looking for it.
Sneaky.
While the botnet performs crypto mining, there is also this god mode built in.
It's a control panel of sorts, it lets you make it do all kinds of things.
It's built right into the binary, but you can't just access it.
You have to have a private key.
And only after the malware requests that private key, and you provide it, then the validation
occurs and you get access to its quote unquote, god mode.
You know, this is a little bit amusing.
You hear a lot of folks raving about Golang because it's easy to distribute as a small
binary.
It has excellent concurrency.
It's got a great web server built right into the standard library.
Turns out that also makes great malware.
Now when you go to try to find this malware, turns out it's continuously looking for both
top and htop.
So pro tip, use one of the more obscure picks for top programs we've had on Linux Unplugged
and maybe you won't get caught.
Anyway, if it does find you snooping, the malware terminates the mining processes so
that you just don't see anything wrong on your system.
Goes a little bit further though, it does need to remain persistent, so Panchan copies
itself into a file named slash bin slash systemd-worker and even goes so far as to create a systemd
service to try to appear as a legitimate part of systemd.
So looking for a systemd-worker process is one of the few ways you might actually be
able to detect this thing.
I think that's essentially like the authors of this malware figured, hey, you know, systemd
is complicated.
If people see a systemd-worker process, they'll think it's legit.
Put it over there.
I guess so.
According to the researchers, the malware actually also performs SSH dictionary attacks
as well.
So when it gets onto a Linux box, instead of just trying to brute force onto other systems
on the LAN, like most botnets do, this malware reads the ID RSA file and your known host
files to harvest existing credentials and existing known good hosts and then move laterally
across the network onto those boxes.
But if that doesn't work, well, this thing can also do good old fashioned password brute
forcing.
Malware can also randomize IP addresses and attempt a dictionary attack using a predetermined
user and password list.
Now we definitely don't cover most of these and there are many, but when we do see one
with some legs, we want to bring it to your attention.
Right now, most of the victims are located in Asia, followed by a good set in Europe
with particular exploitation of university and educational networks.
However, concerning for some of us out there, and most notably myself, Akamai has noted
that VPSs tend to be a target as well.
As we mentioned before, a quick way to check is to look out for that systemd-worker process,
but you can also look out for processes listening on TCP port 1919 or sending outgoing traffic
on 3380 or 3387.
Firefox's slow startup times on the latest Ubuntu release continue to be a source of
frustration for users weeks after the latest release.
In fact, OMG Ubuntu recently tweeted that it takes 19 seconds on their system for Firefox
to start.
And it seems the root of the issue is Ubuntu now ships Firefox as a SNAP package, which
as of now introduces quite a bit of launch overhead.
Well, this week we did get an update from Canonical's Oliver Smith about their latest
efforts to improve Firefox's SNAP performance and some other outstanding issues with the
sandboxed version of one of our favorite web browsers.
Their focus it seems is wider though than just launch times, with a lot of work going
into ensuring GPU-based rendering will work in more situations, and making sure that when
it can't, it'll fall back to CPU-based rendering.
Chris, you may also like this little tidbit, there's some work going into solving rendering
issues on the Raspberry Pi as well.
That is really nice to see.
It's nice to see all of that, especially the GPU rendering stuff and fixing it when it
doesn't quite work right.
That's absolutely a win.
But what I read from this is, sorry guys, there's not a lot we can do about the startup
times.
It seems like they are addressing one of the big factors in the first launch time, which
is really a killer on Firefox.
The Ubuntu developers are working with Mozilla to change Firefox so it behaves like it does
on Windows, where only one locale would be loaded at the launch time based on the system's
local settings.
I think that just makes sense.
But that's a one-time launch issue.
That's not like a daily cold boot launch problem that I think is really frustrating for Ubuntu
users long term.
And in my opinion, that's really the one that seems to be like the most public and giving
Snap a bad reputation.
But I suspect it's just kind of inherently the way Snaps are built.
And there's only so much the developers can do.
So they're looking at optimizing all of the other layers of this Firefox Snap to try to
eek as much performance from there, because there's not a ton they can do about the initial
launch time.
This just might not be a completely solvable problem, but they're gonna give it their best.
So my advice would be, set your expectations accordingly.
Last month, in a surprise announcement, we learned that long-time Qt developer Lars Knoll
would be leaving the Qt company.
But not only is he leaving the CTO position, he's also leaving the post of long-time Qt
chief maintainer for the open source project.
Long-time is right, Lars has been heavily involved with the Qt toolkit for 25 years.
He started with KDE and Qt in the late 90s, and then became a prominent troll tech employee
in 2000.
After a round of voting by the Qt developers, Volker Hillsmeyer has been selected as the
new Qt chief maintainer.
In fact, Lars himself announced the new maintainer just a few days ago, writing, quote, Volker,
I would like to wish you good luck with leading the project.
I know that the Qt project is going to be in very good hands with you.
Volker serves as the director of R&D for graphics and UI at the Qt company, and has been with
the Qt company for the past three and a half years.
Well back from 2000 to 2011, he worked for troll tech and Nokia in various roles working
on the Qt toolkit.
This week marked 38 years since the inaugural release of the X Window system at MIT.
It was way back when, on June 19th, 1984, that Bob Scheifler first announced the X Window
system, X1.
When X was introduced, for a little context, its performance was, quote, about twice that
of W, which was the prior Windows system made at Stanford.
Crucially, X also marked the first Windows system that was both vendor and hardware independent,
something we kind of take for granted these days.
If like us, you want to get your deep, nerdy nostalgia on, we'll have the original release
announcement in the show notes.
Linode.com slash LAN.
Go there to get $100 in 60 day credit on a new account, and you go there to show some
support for this here show.
Let Linode know you heard about it here.
They've been hard at work for over 18 years, nearly 19 years, creating the best experience
to run applications on Linux.
I've tried a lot of hosting platforms out there.
Nobody gets the mix and the ratios right like Linode does.
If you'd like to build yourself something from the ground up or click a one deploy type
button and get an application up on a server, Linode will span that whole range for newbies
or pros.
In fact, I don't know if I've ever mentioned it in a read, but they offer a one click deployment
of PyHole.
And when you start thinking about maybe like a tail scale mesh network or a VPN setup or
something like a trustable DNS that you could use on your mobile device, PyHole up on a
Linode makes a lot of sense.
And of course, you could do things like we do where you build something up from the ground
up using Nix OS and basically take that Linode down to the metal.
So that whole range, they manage to strike a balance and make it accessible to you.
And of course, I appreciate while I'm on the road, I'm not worried about my Linodes.
They have some really sane monitoring just set up by default.
I got an alert about our Jupiter tube box that runs on Linode.
It's like your bandwidth usage is way up and that's fine.
But it was nice to get that threshold and just check on everything and make sure there
wasn't anything odd happening.
I love those same defaults and the real easy way I can back things up and take snapshots
before we make any major changes.
And of course, they have a bunch of back end services that make Linode great too.
Like S3 compatible object storage, VLAN support, a powerful DNS manager, Kubernetes and Terraform
and Ansible support as well.
After you've been using Linode for a minute, you're going to really appreciate that all
these things come together in a really nice kind of, I almost hate to say it, but low
key way.
Like if you never want to interact with their slick suite API, you don't have to.
But if you start using the service and you want to take things to the next level, you
totally can.
And the pricing is fantastic, 30% to 50% cheaper than those hyperscalers that want to lock
into their crazy platforms.
So go try it for the best customer support, super fast networking, crazy fast rigs, 11
data centers around the world, and a Linux culture that runs deep.
The only thing that could make it better is that $100.
So go to linode.com slash lan.
Get that $100 credit, try it out, kick the tires, build something, learn something, and
support the show, linode.com slash lan.
At the Open Source Summit North America event this week, Linus Torvalds sat down with Dirk
Hondl for one of their famous fireside chats.
So my name is Dirk Hondl.
I'm the Chief Open Source Officer for the Cardano Foundation, which I joined a couple
of months ago.
I'm focused on building stronger open source communities and ecosystems around our blockchain
technologies.
This guy does...
Yeah, I'm Linus, and the reason we do these fireside chats is I do software.
I don't do public talking, and this makes it much easier for me.
This conversation ranges from a few new topics to some classics, but maybe Linus' best take
on those classics yet.
One of those is a refresh on his never-break-userspace stance.
So I don't like the notion that people talk about APIs because, let's face it, some people
then look at documentation and say, this is the API.
This is what we documented.
If you don't do what we documented, it's on you, right?
And I feel that's a complete cop-out, and it's just bad policy.
Documentation is worthless compared to reality, and I say that as a software engineer who
never writes documentation.
Part of this is my own personal biases, obviously, but my rule has always been it's not that
we can't break the API.
I tell my sub-maintainers and developers all the time that you can change anything, but
you can't break people's loads.
You can't break what people do.
And if they take advantage of a bug in the kernel, that bug is not a bug, it's a feature.
And we will maintain that feature forever unless there are, like, really pressing concerns
and usually the only really pressing concern is security, where we will go to insane lengths
to actually keep bug-for-bug compatibility, because as a user, which I also am, the most
annoying thing I can imagine is doing a software upgrade and things stop working, right?
And I can't affect the fact that every single package around me may have different policies,
but when it comes to the kernel, I've been very hard-nosed about the policy that kernel
does not do that.
If you upgrade the kernel, you should feel safe in knowing that whatever you used to
do will still continue to work.
And if it doesn't, you're supposed to scream at us, right?
You're not supposed to say, oh, I upgraded the kernel and now I need to change what I
used to do.
No.
You should feel like it's a bug report if something breaks, and we've been pretty successful
with that and I feel very strongly about it.
I wish, since most of you are not kernel developers, I wish that you would push for this kind of
policy on your project, because it makes it so much better for all your users.
And in the end, we're all in this for the technology, and we are in this because we
enjoy programming, hopefully.
But in the end, it's really the users that matter.
A project with no users is not a project.
It's just you playing with your own code.
But then we get down to business.
And Dirk asks, where is Rust for the kernel, and why is it taking so long?
The kernel has gotten a bit more careful over the years, let's put it that way.
We were more freewheeling 30 years ago.
It was more of a Wild West where somebody came up with a great idea and sent a patch
and it would just get merged because, hey, why not?
And we can't really afford to do that.
And a lot of people actually think we're somewhat too risk averse.
So when it comes to Rust, it's been discussed for multiple years by now.
It's getting to the point where real soon now, we will actually have it merged in the
kernel.
Maybe next release.
Before the Rust people get all excited.
You know who you are.
To me, it's a trial run.
It's a way of making, A, we want to have the memory safety.
So there are real technical reasons why Rust is a good idea in the kernel.
But at the same time, it's one of those things.
We tried C++ 25 plus years ago, and we tried it for two weeks, and then we stopped trying
it.
And it seems a fear that's been building in the community gets some voice on stage.
Sure, Rust is neat and all, but is it really that great of an idea to introduce a language
into the kernel that most developers don't understand?
I think that introducing Rust, I have seen the worries about it meaning that people don't
understand Rust, and that's okay.
People don't understand the VM subsystem, even when it's written in C. So the language
is usually not the biggest hindrance to understanding.
We will have maintainers for the Rust parts exactly the same way we have maintainers for
the VM parts.
And that's not really, it's a small technical change, not a fundamental one.
Security and trust were also clearly on Dirk's mind during the chat, and he asked Linus how
the kernel team can reasonably keep the entire stack secure.
The only way to make security work, because bugs will happen.
If they don't happen in hardware, they will happen in software, and if they don't happen
in your software, they will happen in somebody else's software.
So just accept bugs, including the security ones, and the only way to try to do security
right is by having layers of security.
I like Linus's point there that you kind of have to plan on bugs, either in your software
or someone else's code.
But he also does a little bit of a reality check and admits we're probably never going
to be 100% secure.
You'll never get there.
Anybody who thinks you can get 100% secure is living in some dream world that is just
not this reality.
Serious security talk aside, one of our favorite moments was Linus just having a bit of a laugh
for being better known as the creator of Git, at least in some circles.
Linux is kind of my baby, and I've been doing it for 30 years plus, and it's what I do.
My oldest daughter, when she went off to college and did computer science, I didn't push her.
She emailed me back a few weeks later and was laughing at the fact that I was known
for Git at the computer science department, even though I only did Git for six months.
I mean, I'll take credit for it, but Git, it's not my baby.
It was a side project that I just had to start to actually do Linux development.
Linux will always be all of our babies, but it is true.
I have heard him introduced as the creator of Git before I've heard him introduced as
the creator of Linux before.
We'll have the link to the complete talk in the show notes.
I should say though, right now it's not publicly available, but I imagine that will change
in time.
And of course, I recommend you go to linuxactionnews.com subscribe for all the ways to get new episodes
as we release them.
And linuxactionnews.com contact for ways to keep in touch.
Help us stay independent and support all of the shows plus get them ad free including
Linux action news by going to Jupiter.party.
It is the Jupiter party membership.
We'll be back next week with our take on the latest Linux and open source news.
Thanks for joining us.
And that's all the news for this week.
