Hello, and welcome to Linux Action News, episode 207, recorded on September 19th, 2021.
I'm Chris.
And I'm Wes.
Hello, Wes.
Let's do the news.
We've been focused on the server and the enterprise the last few episodes.
So this week, we wanted to start with the good old Linux desktop and some good news
for HDR monitor users out there.
Red Hat is hiring specifically for a full time position to work on the Linux desktop
graphic stack and focus on HDR display support.
The job posting reads, quote, the Red Hat workstation engineering team is looking for
an experienced senior software engineer to work on the desktop, compositor and GPU support
for high dynamic range formats and displays for Linux.
The post also specifically mentions GNOME when talking about job responsibilities, saying
he will contribute to feature enhancements, bug fixes and major subsystems like Linux
kernel, Wayland and GNOME, all in support of implementation of HDR on Linux.
While they do talk about working upstream in general, no other desktop environment is
specifically mentioned.
That does make me a touch nervous there, Wes, because it well, it seems like a full stack
job, right?
Like it seems like you got to do the lower level driver stuff.
You have to do the Wayland stuff and you have to do the toolkit and desktop environment stuff
all has to support HDR and the full color range you need for HDR.
And so I would think the plasma is going to need similar work to enable this in the plasma
desktop and the cute developers love to do similar work to enable this in Qt.
So it does leave me wondering how plasma can kind of keep up and offer a similar functionality.
So there is some parity between the two major desktops.
And maybe if anyone has an understanding of some work or anything that is already ongoing
to support this, let me know at our contact page at linuxactionnews.com slash contact.
But you did do some digging into the state of HDR and Qt.
Yeah, well, a few years ago, 2019, Krita was looking at adding HDR support, which makes
sense, right?
And at the time, they found that Qt could really only support up to an eight bit color
space.
They wanted something more like 10 bit or 16 bit for like full HDR support.
They were able to get there basically by hacking up Qt a bit and changing things and making
more of it color space aware.
But sadly, at the time, there was really only HDR support from Windows.
So that's where this work was done.
I don't really know what the state is on Linux today.
Yeah, but I think the silver lining here, and it's a pretty nice silver lining.
Even if not all of that work is usable outside of GNOME and GTK, a lot of it is going to
be work that will be and it's all going to be upstream.
So everyone can benefit because there will be some lower level components that are improved
for this.
And the stuff that may or may not be done to GTK and GNOME is all going to be out in
the public.
It'll be there for the documentation for everyone to see.
So there will be benefits universally.
This is it's a 100 percent a good move.
And I'm I'm grateful that Red Hat still does some of this very heavy lifting, even though
they don't directly sell a desktop product outside of a few rail desktop installations.
And I guess those clients are important enough or whatever it is.
I am just so grateful that Red Hat does this.
I'm not trying to take away from that, but I am always looking out for my my favorite
desktop.
It's just a difficult world where we have a lot of competing interests in Linux and
there are a lot of upsides, right?
Because Plasma is very distinct from GNOME, but there are some downsides, too.
If you're interested in helping out with this work, well, you'll need to be highly
proficient in C, of course.
And Red Hat says you'll need to be familiar with contributing to the development of a
major desktop Linux distribution, their words.
And then as examples of that, you've got Fedora, Ubuntu or Google Chrome OS.
You can work remotely or in a Red Hat office up to you, but you do have to work in a country
where Red Hat is registered to do business.
Well, sticking with the desktop for a bit longer, Canonical has announced that they
are shipping Firefox as a snap in future versions of Ubuntu.
This is apparently the work and result of cooperation between the desktop team at Canonical,
the snap team at Canonical and developers over at Mozilla.
And it seems to be the first step towards a dab to snap transition that will take place
during the 20204 development cycle.
It's not clear exactly what happened behind the scenes in the Firefox 92 release notes,
though Mozilla say that Canonical is now building the official Firefox snap.
At the same time, Ubuntu has said Mozilla is in charge of publishing the snap.
I'm hoping that mostly just means they've got well-connected CI systems.
Either way, it does sound like Mozilla and Canonical have spent some considerable time
together to make sure this goes well, including making sure that things like Firefox user
profiles are brought over to the snap version when they make the transition.
Yeah, OK, that's good, and I'm glad they thought of that.
And so to be clear here, if you're a Firefox user on Ubuntu, this is going to impact users
of the Ubuntu desktop installing 2110 or upgrading to 2110 and then the full transition is targeting
2204.
On the upside, if you're a fan of these kinds of things, it does appear this snap is using
strict confinement.
That is good to see, but I am struck by the fact that if you rewound this story a couple
of years, I think this announcement would have been met with outrage online.
And I've seen a little, but I see not much.
I mean, it's very little compared to what I think it would have been.
And I wonder maybe if in 2021 people are just used to the concept of universal sandbox apps.
Is it becoming normal?
I mean, I'm not sure what I attribute this rather mediocre, mild reaction to.
Yeah, I mean, part of it might be normalization.
It's already packaged up as a flat pack, say, and Canonical have been moving more and more
things to a snap, including other browsers like Chromium, right?
But it also might be just that there's less usage of Firefox in general, sad as that is
to say.
But really, to my mind, I'm just not that upset either.
I mean, it's a little strange because Firefox is kind of the default browser on a lot of
these, you know, open source operating systems these days.
And thinking of it being in a non-traditional package is a bit strange.
But I think you're right, for a browser, for something that changes all the time, it kind
of makes sense to be packaged this way.
I mean, heck, Mozilla even distributes a tarball you can just download and run, which is how
I've been trying out the latest versions anyway.
Yeah.
And you make a good point.
It has been a flat pack.
And truthfully, I don't mind having my browser a little extra sandbox.
That seems like a good thing.
And I think you're right.
If people really care, they'll just grab the tar.
The type of people who would care could just grab the tarball.
That's fine.
If you've got questions or thoughts and Ubuntu is still collecting feedback as well, that's
all happening over on the Ubuntu discourse where they've got an FAQ and they've posted
some of their rationale for going through this.
We will, of course, have that linked in the show notes.
Rather impressively, there are already some new developments in the effort to port Linux
to Apple's M1 platform.
Alissa Rosenzweig spoke this week at the VirtualX.org Developers Conference about that ongoing work
and the reverse engineering challenges involved.
Hello, and welcome to this magical talk in the magical world of Toronto, Canada.
It's not really that magical.
We have construction, though.
And this is the talk on the occult of Apple GPU.
I'm Alissa Rosenzweig, your resident witch, and we'll be going on a magical adventure.
Listening to the talk from XDC, you really learn to appreciate just how complicated the
entire task of getting just the M1 GPU stack up and working on Linux really is.
One of the most difficult obstacles so far has been dealing with the graphics co-processors.
So first, I would like to talk about the DCP, which is responsible for the display side.
The DCP is the acronym based on our best guess, based on the behavior of it.
It stands for diabolical cluster puck.
Wait, that can't be right.
This is the display co-processor.
It manages the display controller.
It is not the display controller.
That's a key distinction.
It is a co-processor that has its own co-processor.
It's co-processors all the way down.
There are seven megabytes of firmware on this thing.
Linux or Mac OS does not talk to the display controller itself.
Those registers are just not even in the device tree.
There's this massive pile of firmware with its own pile of firmware that does all of
the display controller interaction.
We just have an API to deal with in the kernel space.
Yeah, I don't know either.
Like, what is happening here?
Co-processors all the way down.
But you know, honestly, the display side really is making great progress.
And the AGX Gellium 3D driver is getting into good shape now.
She also noted that at some point soon, a Vulkan driver will become important as well.
But for the moment, that's a challenge for the future.
However, I think we should all keep our expectations in check.
We're going to get this up and going, it looks like.
I mean, I'm starting to bet on that now.
But I think it's going to be a complicated answer.
Like there's going to be some perhaps gaps in OpenGL support, at least historic OpenGL
support.
Apple has the luxury of being able to look at the same exact sets of features and just
saying, you know what, we don't need those.
We're getting rid of them in hardware.
And basically anything that's deprecated in OpenGL, you're not going to find hardware
support for.
I mean, the M1, huge amounts of the geometry pipeline are done in shaders, which is fast
enough in practice.
The net result is that well-written applications on Linux will run just as fast as their metal
counterparts.
But there will be a lot of hoops to jump through if we ever want to become conformant and support
all the random ancient legacy things and want to pass all the piglets.
In the Q&A portion of the talk, the question of how firmware will be distributed on the
M1 came up.
Something we've worried about could be legally tricky.
It's apparently seemingly straightforward, at least in one regard.
And one last question, Patrick Jacobson asks, is the DCP firmware redistributable or do
you need something like a download script like we have for FaceTime HD webcam drivers?
So this is a very interesting question.
I wish I touched on this earlier.
It's not redistributable, but that doesn't actually matter for our case because Linux
never touches this firmware.
It's on an internal system partition.
So it's on the internal storage, but not on the operating system partition.
It's loaded by the bootloader, presumably it's signature checked by the bootloader,
and then the firmware is locked.
So the operating system, be it Mac OS or Linux, just does not touch this firmware.
This is unfortunate to us because it means we can't modify the firmware to be less ridiculous.
We could not replace it with an open source version even if we wanted to.
However, it neatly avoids all of the legal questions because from Linux's perspective,
there's no firmware being used at all.
And this is one of the great ironies of Asahi Linux to me, is that with the exception of
the Wi-Fi, everything will work on Linux Libre.
And this is very much not a Libre chip.
Now, I'm still seeing it argued online that maybe this work is just a waste of time.
But personally, I feel like that ship has sailed and is a moot point and we should kind
of move on.
But I think if we think about this beyond just getting Linux on this Apple hardware,
which is no doubt going to extend the life of this hardware and also be a boon for developers.
But another result of this is we are getting a deep look at the Apple M1 platform and we're
getting insights into the hardware that Apple doesn't typically share.
The DCP runs the RTKit operating system.
This is the real-time kit.
It is Apple's secret real-time operating system that is running on every piece of firmware
or not every, with the exception of the SecureNClub, which has its own SecureNClub operating system.
It's running on essentially all of the coprocessors on Apple devices.
It's also running on things like the AirPods.
It's a fairly large operating system, not by Linux or Mac OS standards, but by the sorts
of things you'd run on a firmware with real-time constraints.
I mean, it's a whole system.
Some other recent developments in this space include the USB-C support code going out for
testing, GCC announcing plans to support the M1 in an upcoming version, and just today
Alyssa announced she got internal storage working.
Yeah, in fact, while we are recording this very episode, she is live streaming her development
of Linux for the M1, running Linux on the M1, all from the internal disk.
It's looking really good.
When you look at the areas the entire Asahi Linux team is tackling and the speed at which
they are doing it and how it's all going upstream or will be going upstream, it's just so damn
impressive.
It's truly amazing, impressive work being done right now, and the team is just killing
it.
And just a note of congrats to the LVFS project, who just recently served up 2 million firmware
downloads in the past month.
In just one month alone, firmware troublemaker and LVFS project lead Richard Hughes wrote
on Twitter, we hit 2 million firmware downloads in the last 30 days for the first time.
There are now over 3,000 firmware files available on LVFS, with over 100 vendors using 50 different
protocols.
It's been a huge amount of work, but it feels pretty awesome.
It really has been a huge amount of work.
LVFS launched 6 years ago, way back in March of 2015.
Over time, more and more vendors began adopting LVFS for distributing those important firmware
updates, and then in 2019, LVFS joined the Linux Foundation.
You can hear our coverage in Linux Action News 189 for that.
Indeed.
You know, I think for a while, we've been of the opinion that part of what has made
LVFS so successful is their sort of practical approach of adopting standards and not doing
things their own way for no reason.
And a good example of that is them using the same.cab files that Windows uses to distribute
the firmware files.
In a big way, the vendors didn't have to do anything different to package up their updates
to play nice with LVFS and FlopD, so kind of made it more approachable and easier to
adopt.
Yeah, I think that's definitely a factor.
And I think something else that helped with adoption is, although it was really truly
created to solve a problem for the desktop, LVFS and FlopD, the software itself, work
great on phones, tablets, IoT devices, and headless servers, which has been huge.
It has proven to be a very flexible, flexible tool.
It's great.
You've also got things like industry trends helping, like UEFI in general, which kind
of created some standards for all these updates.
And of course, key support from vendors like Dell early on, proving out the concept.
The future seems bright though.
Intel just recently announced they're working on rebootless firmware updates for UEFI systems.
Could really see how a project like LVFS would be interested.
Linode.com slash LAN.
Go there to get $100 in 60-day credit on a new account and go there to support the show.
This episode of Litx Action News is made possible by Linode's sponsorship and by you taking
advantage of our sponsors.
Linode started in 2003 as one of the very first companies in cloud computing.
And now 18 years later, well, they are the largest independent cloud provider in the
world with 11 data centers around the world.
And you know that checks my boxes, but Linode has really remained focused since the very
beginning, making cloud computing simple, affordable, and accessible.
And if you haven't tried it out yet because you think it might be complicated or maybe
it's going to be too, I don't know, server-y, well, don't worry.
You can take advantage of our $100 offer and deploy one of Linode's many ready to go systems.
Like Nextcloud, for example.
If you just go to Linode.com slash LAN, you create an account, you get that $100, and
then you can deploy a Nextcloud instance in seconds.
Or maybe you want to build a discourse community.
Well, they've got a click for that as well.
Or maybe it's time to replace Zoom with something like Chitsi.
You can do that with a one-click deployment on the note as well.
Just get started by going to Linode.com slash LAN and see why we use them for everything.
From development tools to game servers, Linode makes it easy to get started in just a few
clicks.
And then once you're there, you'll find they also have an easy to use powerful cloud
dashboard and S3 compatible object storage that we absolutely love.
They have bare metal servers, if your workload demands that.
Cloud firewalls, DDoS protection, VLAN support, a powerful DNS manager, and even Kubernetes
support if that's how you roll.
It's all in there.
Plus they are their own ISP.
So their networking is just wicked fast.
And they've invested in the best hardware.
There's really so much I could go on about Linode.
And their pricing is 30 to 50% cheaper than other major cloud providers.
And if you ever run into any trouble getting something set up or something goes sideways,
Linode comes with amazing 24 seven customer support by phone or by ticket.
And they have hundreds of guides, tutorials, and they're constantly investing in new
content to help people get things set up.
They really have a deep support for the community.
They made our Jupiter colony reunion road trip possible.
And they invest in content creators that create educational material to help people get started
on Linux.
There's so much to check out.
You just got to go do it for yourself and take advantage of that $100.
Go to linode.com slash land, get that hundred dollars, create a new account and you support
the show.
That's linode.com slash land.
This episode of Linux action news is also made possible by Ting.
And if you're sick of overpaying for cell service, go see why I switched to Ting back
in 2013 and take 25 bucks off by going to the linux.ting.com.
Ting is an MVNO or I guess you could call them a mobile virtual network operator.
But what that means is Ting mobile customers get access to the big carrier networks, but
with way better customer service and pricing.
Ting mobile offers nationwide coverage, a great mix of plans, fast data on LTE and 5G
networks.
And Ting's plans are simple and straightforward.
That's why I've stuck with them since 2013.
They're a mobile operator that's smarter and they have plans that start at $10 and stop
at $55.
I think their set 12 plan could be a great plan for a family and everyone gets access
to Ting's award winning customer service.
And of course, that nationwide LTE and 5G where it's available.
It's really simple to switch to Ting.
Pretty much any phone is going to work because of the networks they support.
But you just get started by going to linux.ting.com.
Check your current phone, go create an account, pick a plan that's right for you.
Ting figures it out and sends you a SIM card.
You pop that in your phone, you get activated in minutes.
And if you ever have any troubles, you contact their great customer service and they get
you sorted out.
So go over to linux.ting.com.
Get that $25 discount and switch to a much better mobile operator.
It's the next generation of Ting mobile.
It's here.
Go see how much you could save and take $25 off of that.
Linux.ting.com.
Black Lotus Labs, the threat research group at Lumen Technologies, formerly SentryLink,
revealed on Thursday that it had discovered new malware that uses the Windows subsystem
for Linux to avoid being detected.
They seem to identify several malicious files that were written primarily in Python and
compiled in the Linux binary ELF format specifically for Debian.
These files acted as loaders running a payload that was either embedded within a sample or
retrieved from a remote server and then injected into a running process using standard Windows
API calls.
I think many of us speculated that this could happen, but now we've got a documented case
of it actually happening, in fact, happening two different ways.
One was a pure Python version.
There was another variant that used Python plus PowerShell.
Once installed, the malware would attempt to kill any antivirus programs it could find
and then spawn a reverse shell.
I think really a big part of the challenge here is that most of the endpoint client security
like antivirus programs and whatnot are just simply not designed to analyze ELF files,
at least on their Windows versions.
Yeah, I guess they'll have to learn.
I just hope this doesn't mean that more enterprises will start locking down access to WSL by
default.
I mean, some places took them forever to even enable the thing.
I know.
I could really see IT departments doing that.
It's just sort of an easy way to solve this problem and then only turning it on for people
who really, really beg to have access to it.
You hate to see that happening, but then again, when you see things like the Linux kernel
adding file servers into itself, well, maybe it's not such a bad idea to lock that thing
down.
It sure didn't take long, but there is already an important security fix inbound for Samsung's
new KSMBD in-kernel file server.
Yeah, this weekend security vulnerability is an issue handling dot dot that basically
leads to files outside of the SMB3 share being accessible to clients.
And oh yeah, there are also three more patches currently undergoing review and testing looking
at buffer overflows.
I hope this is an indication people are taking a real close look at this thing and maybe
it gets a few more eyeballs on it before it ships.
But either way, we'll keep tabs on what happens and keep you informed on that and every other
story in the world of Linux and open source.
So go to linuxactionnews.com slash subscribe for all the ways to get new episodes and linuxactionnews.com
slash contact for ways to get in touch.
And if you haven't subscribed to extras, go to extras dot show slash subscribe and get
subscribe because we have some exclusive content from the road trip coming up soon.
As for us, we'll be back next Monday with our weekly take on the latest links and open
source news.
Thanks for joining us.
And that's all the news for this week.
