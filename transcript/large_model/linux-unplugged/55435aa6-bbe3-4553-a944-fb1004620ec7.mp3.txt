Breaking news from Sholo, Arizona, 18 years in the making. Wes, you're on the scene now.
What are you learning?
Well, Chris, developing at this hour, Linux users can now rest easy. The ancient, convoluted
SCO versus IBM legal mess that sought to determine who owns Unix, and perhaps who has a claim
over our beloved Linux, may be about to end, with IBM agreeing to pay 14.5 million dollars.
If this goes through, after all that's happened, it seems like a heck of a deal. At least compared
to what they paid for Red Hat.
Hello friends and welcome back to your weekly Linux talk show. My name is Chris.
My name is Wes.
Hello Wes, and say hi to Brent too.
Hello hello.
Hello Brent. This episode is brought to you by Cloud Guru, the leader in learning for
Cloud Linux and other modern tech skills. Hundreds of courses, thousands of hands-on
labs. Get certified, get hired, get learning at acloudguru.com.
Coming up on the show today, sometimes things just don't go as planned. Today, we'll talk
about a backdoor we had to build into the studio that we set up after our Wirecard server
went down. It's a remote rescue, and one of our favorite open source tools is going to
save the day. And it is a special edition of the show because we're recording early,
off air, in between storms here in Sholo, Arizona. We decided to do it a day early this
week, so that way Wes could go camping, and so that way I can make the final push into
Tuxin, Arizona, also known as Tucson, where hopefully, hopefully I'll get my RV slides
finally fixed. My living room has been broken since May, and my kitchen slides and going
out. It's a long story. So today I'm in Sholo at the Bison Golf Club is where I've been
parked. It's really nice here.
Have you seen any bison?
No, but I have seen golfers about the size of a bison. No, unfortunately, it's stormy.
I'm kind of like this strange signal vortex zone to some of my devices are working. Some
of my devices aren't, even when they're on the same carrier. I'll have two AT&T devices
right next to each other. One's working, one isn't. Verizon just comes and goes. There's
no Sprint service here at all. The only kind of working one right now is T-Mobile, but
it's dropping packets. So really kind of rough. It seems like overall older devices are connecting
more, but at least I'm I'm in Arizona in precious, precious shade where it is not crazy hot.
I'm like up in the northeastern area, I guess you could say. And it actually is a reasonable
like 80 degrees here. But you know, when the show goes on, and Wes, you're about to go
camping.
Indeed. Don't worry, though. It's not as easy. I'm having some difficulties too. Originally,
I was planning this camping trip to go up in the North Cascades, an area I know you
love a lot, Chris.
It's a beautiful area. It's one of my favorite spots to go.
Unfortunately, it's basically on fire. So we've pivoted at the last minute. I'll cancel
all of our bookings got some new bookings over in the Mount Rainier area. I'm definitely
looking forward to some time away out in nature. But it is a struggle.
Mount Rainier is not a bad way to go. And then Brian, you just got back from being out
in nature. In fact, you are at the world's highest elevation koa.
Yeah, I since leaving you I just couldn't help but have that desire to go back to a
way. So everybody loves an RV campground. You got to get a fix.
Well, Heather and I found a pretty cool one that was just an hour away. And it turned
out to be the tallest. Well, I guess highest altitude at 10,000 feet, which is I thought
was gonna be really great until I couldn't sleep at night because I was gasping for air
all night.
Oh, really?
So, well, I'm not used to the Colorado Heights yet, I guess.
Lowland Brent. Good to know.
Yeah, you need like an adjustment period when you go up to 10,000 feet. If you go because
Denver is what? 5,200?
Yeah, Colorado Springs, like 60, 62 or something like that.
Right. So then you go from 6,200 up to 10,000 feet. You need to stop like at the 8,000 feet
and hang out for like a day or two.
Yeah, no one told me this and everyone else seemed to be fine with it. But apparently
I am just sensitive.
You're just hooked on that oxygen sucker.
Yeah. Just spend years smoking and then your lung capacity is normalized to be reduced
and you're fine, you know?
Oh, that's the ticket. Anyways, we had a campfire, which I never thought, but also suffers from
like lack of air. So that's a little harder to get going than normal. But it was a great
fun experience. I would totally recommend it. It was in a place called Cripple Creek,
if anyone's looking for it.
Great. I have kind of learned a little bit about the difficulty in moving high volumes
of air just when it comes to vehicle cooling, like when you're climbing passes and stuff,
the vehicle has to work harder to move air across the radiator and that kind of stuff.
So it's a serious deal. Maybe next time you can go up for a couple of days and adjust
or something. But I'm glad you were able to make it back down the mountain to join us.
We have a little bit of community news to get into. Not a ton, but one of our favorite
tools out there, Ventoy, has a nice little update starting with version 1.0.36. It has
a web based user interface. Hmm.
Yeah, Ventoy is already pretty darn amazing, especially if like us, you want to try the
latest and greatest distros as soon as they come out. Or maybe you're just a distro hopper
by trade and you love having a thumb drive of Clonezilla and rescue disks, but you don't
want to have to keep overriding that disk all the time. Ventoy is the tool for you.
You just plug it in, you run their little script on it, and you've got it going. But
you have to be a little more comfortable with the command line. And that's where this new
web GUI comes in.
Yeah, a web UI. At first I was like, why? Because they already have a standard graphical,
they have a command line. But then I thought, you know, actually, I could see this being
useful on a headless system. Maybe you want to be able to produce these Ventoy installs.
Like for example, our studio server, which is down at the moment, we'll get to that more
in a moment. I store all the ISO images we use centrally on there. So you could see maybe
kicking off a process like this from the NAS that already has all your ISO images too.
And then you copy them over to the new Ventoy creation.
Something that saves me a trip to the garage I will take.
It looks like they're just including that new Ventoy script. You just run ventoyweb.sh,
fires up a web server on local port 24680. And then you just point your web browser over
to it. Easy peasy. Something we'll play with probably when I get back. But I wanted to
mention in the meantime, there has been a new website launched by the GNOME project
designed to highlight GNOME apps. It features a curated overview all built in the GNOME
philosophy. So applications that really sort of embrace the GNOME design. It looks like
a pretty good list.
Yeah, Sophie Harold announced today that apps.gnome.org is coming online. They hope that with apps
for GNOME, it will increase participation in the different apps and projects, lower
the barrier for getting involved with the GNOME project. And it's just one place to
host up to date information on GNOME applications and some stuff that might not fit over at
Flat Hub.
To be honest, when I saw this, my first reaction was like, well, why is the GNOME project making
a competitor to Flat Hub? Like, do we need two application directories? But as I dug
through the site, I realized they're actually adding something new here. They feature a
lot of apps I've never even really seen before. And it kind of builds the case that they have
an ecosystem and then they point to their wider ecosystem, the circle as they call it.
And then what they are doing, which I appreciate is when they have an app that they listed
is available on Flat Hub, they are linking to that Flat Hub page.
That's great because that's probably how I'm going to install it anyway.
One of my questions is how are people going to find the website if they haven't found
the apps yet?
I guess maybe because they're just browsing around the GNOME website. I don't know.
Maybe something that in future documentation, you know, they'll have be a handy link there
of a place to get started. But you're right. That's probably an open question.
The magic of SEO. Maybe that's how.
Linode.com slash unplugged. Go there to get one hundred dollars in credit, 60 days on
a new account and you go there to support the show. It lets them know you heard about
it here and our show is worth Linode's time. And that also helps us, you know, keep going.
That really is a year into being independent. That really is a note I like to hit right
now.
And I think Linode is a perfect partner for us to work with. I can easily and enthusiastically
recommend them. We use them through and through for so much stuff. Our daily production now
is weaved into Linode and it's obvious you get 11 data centers to choose from. They have
super fast rigs, very fast network connections. They are their own ISP and all of that is
backed by the best customer support in the business. And when that matters, man, does
that matter? Like makes all the difference. I mean, when your system is down, good customer
support. Well, that's going to make it or break it, isn't it? And at every step of the
way since Linode started in 2003, they've asked themselves how they can use Linux to
accomplish their next task. That love and dedication is baked into the product. And
if you're a longtime Linux user, you're going to notice that kind of stuff. As long timers
can tell, you know, you can sniff it out when somebody really knows the product or when
they're just using it to make a buck. I just recently set up a box for some backup services
in case our studio server went down, which it is down right now. I'll tell you more about
that in a little bit. And it was just invaluable. I turned the box off. I didn't leave it running.
As soon as I realized the studio server was down, I logged in my Linode dashboard, turned
it on and got the essentials back up and going again. I also use Linode to prototype ideas
for the show or services before we launch them. And you'd be surprised what you can
get done with a $5 a month Linode. And their prices is 30 to 50% cheaper than major cloud
providers out there. So it's totally worth your time to look at it with $100, you're
going to really be able to kick the tires. I mean, that's real money. So head over to
Linode.com slash unplugged, get that $100 for your new account and try this stuff out
go build something, try out an open source project you've always wanted to play with,
or maybe learn something. And I think you'll be impressed with the entire thing that eventually
you're going to put something into production. There are a lot of ways to host something,
but there's no company like Linode out there doing it independent since 2003 investing
in community events and projects and supporting your favorite Linux podcast. Go see why we
choose Linode every single time we deploy something Linode.com slash unplugged.
When I woke up this morning, I had a bad feeling about today. Now there's a lot going on. I'm
still not packed for my camping trip. But the thing that really told me something or
maybe a few things were off was this voicemail.
Good morning, Mr. Payne. We made it to Arizona. We are actually just a little bit outside
of Flagstaff. I think we're in a town called Show Low. Anyways, all the reason why that
matters is because I have horrible cell service here. So I'm not actually positive, but I
I think WireGuard is down at the studio. I'm wondering if you could check from your landline
connection because it could just be that I'm having carrier issues here, but I suspect
WireGuard's down and well, that's going to be a problem for the show we have later today.
So good morning and let me know what you see.
And from what I heard, WireGuard was indeed down. Indeed, the whole server seems to be
down at this point. So from what we can piece together and it's still, you know, rough at
this point is it seems that maybe about five days ago, just as we finished the last batch
of productions that use the studio because we record some stuff like self-hosted and
LAN just direct person to person. We don't go through the studio, but all the live shows,
they all go through the studio. And it seems like the day after we finished doing our last
batch of live shows, the power went out at the studio for a little bit. No idea why at
this point, but any system that wasn't on a UPS seems to have rebooted all around the
same time. And we don't have a complete picture at this time, but it appears that the studio
server did not come back online for some reason. And so as a result of a bunch of other things
also being down WireGuard, which also runs on that same server is down for us, which
is how we manage the live stream, which is how we manage the mixer and all of that when
we're on the road. How we manage everything. Yeah. And we knew the server was on shaky
ground. So, you know, we put some thought into a plan B. It just turns out we ended
up needing to put that plan B into production in a way we didn't expect. Of course, fake
news had to die just after we'd used it last. We discovered it earlier. I mean, I could
have just gone up to the studio and at least investigated, but we didn't realize till we
needed it again, a.k.a. this morning when we were already out of time. And I think that's
kind of showing the limitations of our centralized VPN model. It's kind of a classic setup, right?
We've got one box that's running the VPN. It's sort of the ingress point for the entire
studio network. Most of the time that works pretty darn well. Honestly, it's worked pretty
darn well for this whole trip. And we do have a few alternate back doors, but honestly,
they all come with a fair bit of downside. Yeah, a couple of our go to easy ones. If
I've really been liking Rust Desk, I've only recently on this trip realized that it seems
that the T-Mobile network actually blocks the Rust Desk connection. I don't know why,
but Rust Desk is like a great open source team viewer alternative. That's been killer.
And then sometimes we'll just use something simple like an SSH jump host. And our favorite
little maneuver there is to configure a system D service that keeps that connection alive.
So if that SSH connection drops or the box reboots, system D actually reconnects back
up to our Leno jump host. And that is a quick and easy way in. But you know, I can't really
manage everything with those options. It also means you need a little bit of infrastructure
on your side, right? You got to remember the commands to get through the jump host or otherwise
you're manually SSHing through a few different things. That's not great when you're trying
to connect on the one device, which is probably an iPad for some reason that you have available
to get back into the studio. Yeah, that actually did happen this time. I have devices that
just aren't working, but the iPad was one of them that does have a built in connection
and is working, but it's kind of useless for that stuff. You know, okay, great. Well,
I can do nothing with that connection. I can't even tether. So it was it was definitely one
of those moments where I felt very limited by the set of circumstances because if I could
fire up WireGuard on that tablet, I could at least manage the mixer. The funny part
here too, right is that we don't actually I mean, it'd be nice for fake news to be online
for a variety of reasons, but we don't actually need it for what we're trying to get done
today. And that's where we want more connectivity. I want to be able to just jump from whether
it's on my laptop, whether I'm just on my phone, I want a backdoor into the studio.
What comes to mind for us is a tool we played with way back in Episode 329, Nebula. The
last time we talked about Nebula on the show, it really clicked with people. There's some
topics that really take hold of a chunk of the audience and Nebula was definitely one
of them. Kelvin wrote into the show, he said he never looked back since we first talked
about it.
Yeah, Kelvin writes, I use it to put all my extended family's computers on the same network.
So if and when they have any issues, I can do something. Back when I heard about Nebula
the first time you covered it in 2019. I gave it a try and never looked back. I mostly use
it for support, but occasionally we copy files back and forth like photos shot in raw or
duplicity backups. Performance wise, I doubt I pushed any boundaries, but no interactions
feel slow beyond the initial connection. I don't think there were any usable phone apps
back when I first installed it, but they do exist now. It's been rock solid ever since.
That said, there are some issues you might run into. Not sure if it has built in system
D integration yet, but writing a system D unit file was simple enough. I also had one
oopsie moment when the certificate I generated expired before I could update it. Those issues
aside, Nebula single handedly enabled me switching a whole house load to Linux because they could
always bother me and I could help remotely.
I mean, the simplicity of having everything on one virtual LAN, even just for friends
and family is powerful. It's just so straightforward. It's really simple. But then you imagine
tying in multiple data centers together or multiple facilities like maybe the RV, the
studio and a machine at Wes's house and you could really start to see how Nebula can be
powerful and it has some built in firewall stuff inside Nebula as well.
Yeah, that's one of the things that really stood out to me was you could have multiple
use cases. And I mean, Chris, you've got a whole mobile house that you might want to
have access to whenever you want. I've got machines over here. We've got a whole bunch
of studio machines and things running on the node. And it can just be complicated, right?
We haven't integrated all of those things into a cohesive network right now, especially
not with WireGuard because, well, we need a lot of different tunnels set up. There are
some WireGuard mesh solutions, but Nebula, it was designed with that exact use case in
mind.
Yeah. And one of the other things I think you and I both really like about Nebula is
it brings together a lot of existing concepts and technologies, you know, existing encryption
standards, security groups, certificates, tunneling. It brings each one of those individual
pieces together in a way that hasn't really been packaged up before. And then they just
make it really simple to distribute it. Like on most systems, it's just a go binary you
can run. I mean, you can take it further than that if you want. But they've built something
that's really pretty powerful and it kind of results in something that is greater than
its individual parts. And Nebula providing a simple way to do mesh networking is fantastic.
And it has this facility called a lighthouse. And I'm not sure if we're still using that.
So could you kind of explain our setup, Wes, since I know you did a little bit of hacking
around on it this morning to get things back up and get us back in the studio?
Yeah, the lighthouse. Well, it's quite an evocative name, isn't it? And it is there
sort of acting as the beacon connecting all of these nodes. Things get tricky, especially
when you have a lot of network address translation or NAT involved. And so ideally, you use these
lighthouses on a few boxes that you can have some control over the firewall setup and ideally
have a publicly exposed IP address. So what do we use for that? Well, of course, Linode.
And actually, we had a backup lighthouse going on fake NAS, although that's not working right
now. The nice part is you can have multiple lighthouses. And that just makes your network
more robust. So you could also you know, if you wanted to have you already had a separate
cloud provider, maybe you've got something at a family or a friend member's house. Those
are all nice options. You just need them to have some static IPs. You can configure to
say, Hey, look, this is where it lives. I know if I'm trying to talk to this node on
the network, I can bootstrap myself by first talking to that lighthouse node. That will
help me punch through all of the NAT and get established connections that are peer to peer
to actually go SSH into, say, our recording machine at the studio.
So let's talk a little bit more about the groups aspect of net build. Because if I recall,
you've set up some studio machine groups. There's like a Chris machines group, I imagine
there's probably a West machines group. So that way, I don't go around fooling around
with your stuff. Yeah, that's a really handy functionality that's just built right in.
It's quite modern. It seems to be inspired by a lot of say, like, AWS is I am policies
modern ways that you can control access and in cloud environments, or just in diverse
networks. Because if you think about it, it's great to have all of your machines on one
flat network. But you might really not want all of your machines talking to everyone else.
Nebula, you can build that right in when you're setting up a new machine, you're generating
their key pairs, getting the search all set up setting up the config, you can actually
bake it in with the cryptography to say, this new host, they are a part of these groups
and then other members on the Nebula network in their configurations, they can decide which
hosts in which groups they want to allow. So we can have rules that say, anyone in the
recording group can SSH to all the machines in the studio that you might need while trying
to record a show. Or I could say like, Hey, I want to be able to stream certain things
from my house when I'm on the road. But well, Chris never needs to do that. So my machines
won't let you in. But they'll always let say, my Android phone in.
I like that a lot. And that's a that is an example of something that enterprise could
use for differentiating different server groups. If they were, say, connecting multiple data
centers together. I'm always kind of looking at it from that angle. Joe P wrote into the
show, he's really mastered nebulous, as we talked about it last, and he shared some tricks,
some tips, and some cons that he's run into.
Yeah, Joe P writes, my main concern with it is what feels like the snail's pace of development
since nebula has become a defined networking project. There's incidents and pull requests
piling up that get pretty much no attention. The second issue is that the documentation
isn't at all good. The third issue is it's slower than something like wired guard.
Okay, let's pause there and address these here. I think the issue about it not getting
a lot of fixes and the development being slow. I've noticed that a little bit myself, but
that also feels like what happens when a project kind of becomes a mature project, part of
something like the defined networking project, don't you think Wes?
Yeah, you know, it is new, they were able to start up a new company to sort of shepherd
nebula development. But you're right, the most recent release was in May, and that is
a little while and there are a lot of issues. Now, I haven't really gone through myself
and sort of triage and assessed how many of these are issues in expected functionality
and how many of these are things that would be nice to have. There's also just some stuff
in there with people with really tricky net situations that nebula tries really hard to
bust through, but you can't beat every single firewall or carrier grade net out there, unfortunately.
Yeah. And to your point, they did do a release back in May. I mean, that's not so bad. And
then there's the performance part, you know, Joe P points out that it's slower than wire
guard. And I just think there's no denying that wire but wire guards a performance beast.
I mean, that's one of its key things. Nebula is solving a different problem there, but
I've never really had any issues with the performance.
Yeah. And performance is one of those tricky things, right? What's good enough for one
use case or one person or one company won't be in others. Now, Slack for their part, I
mean, they were using this for pretty much all the back end communication between their
hosts, you know, web apps pulling from databases, things like that. And, you know, Chris, you
mentioned the orange ones right up. He's got some tips in there, too. It sounds like Slack
is seeing pretty good performance, but you may need to do some tuning to make sure Nebula
works for you.
Okay, so with all of that out of the way, Brent, he does have some ways that he uses
it that he wanted to let us know about.
He continues. All of the VPSs I have deployed have Nebula on them. I have all of my traffic
for salt running over Nebula. All of my VPSs and other servers and even workstations all
have salt minions running on them. I tell them to connect to the salt master via its
Nebula IP. All of his Synology NAS devices run Nebula on them. Well, I'm not using this
for data replication purposes yet. That will probably be a future use case just to provide
an additional location to have backup data.
I like that. I like using Nebula as a way to move backups around. And again, you can
see how the groups and the firewall features could make it so that perhaps maybe some systems
you can send to and they can't necessarily send to you. There could be some security
there.
Exactly.
He also included a few tips for us.
Yeah, he writes, use more than one lighthouse for Nebula. I use three lighthouses in three
different geographical locations with three different providers. At a minimum, I would
set up two lighthouses though, if only to make maintenance be non disruptive. And number
two, when you create your certificates, don't just choose a short name for a given machine.
For instance, choose something like hostname.nebula instead of just hostname. In this case, it
lets you take advantage of the DNS functionality that Nebula lighthouses can provide and avoids
conflict with things like dot local name resolution.
That might also come in handy if you choose to expand your network at some point. And
last thing you want is to run into those darn name collisions.
The third tip he has here, I think might be the most important one for our situation.
He writes, don't just rely on Nebula. I also use WireGuard where I can.
Boy, doesn't that ring true today? And you could say the reverse too. Don't just rely
on Nebula, have a WireGuard backup. Have both.
I mean, I think between WireGuard, Nebula, SSH, we've got to be covered, right?
I hope so. And RustDesk too. That's part of it as well. John the nice guy has been playing
around with Nebula. We'll have a link to a Raspberry Pi write up that he did with Nebula
using like a bash script. And it really kind of has me thinking about how we're going to
fix this when I get back. And I think in part what we should do, Wes, is we should remove
WireGuard from Fake NAS. So that way when Fake NAS is having a problem or whatever the
future NAS is going to be, because we're going to replace Fake NAS in the fall or maybe sooner,
we should have a separate device that is responsible for remote connectivity, like a Raspberry
Pi device.
Of course you would suggest a Raspberry Pi. But that particular out of the way. Yeah,
I definitely think you're right. You know, we don't need everything centralized on one
machine. I think we ended up in the situation just partly because, well, we had the machine
going, it was ready to go and it has good connectivity into the studio already. Plus,
that's kind of where we've been running most of our back end server workload containers
that do stuff at the studio. And we were playing with subspace and WireGuard. But as we've
talked about on recent shows, we don't really need all that connectivity. We're not, you
know, we are not hiring and firing new people who need access to the studio all the time.
So I think you're right. A simpler, redundant setup could get us a long way. Redundant.
Now that is, I think, going to be the key piece. So if anyone out there in the audience
has a way to do a hot pie failover for WireGuard and Nebula, let us know. I feel like that's
going to be particularly tricky because you're trying to get two devices that can respond
to a VPN connection request and we'd like to have two pies running simultaneously. And
if the primary one were offline for some reason, the secondary one would take over. I'm not
really sure how we would pull this off, but I'm going to start noodling that on the drive
around, you know, to Tucson and back home again. So if you've got any ideas, Linux unplugged
dot com slash contact and let me know who it is, a mess in here. Let me tell you now
that Brent's gone, nobody's doing the dishes. I cleaned up the fridge. That's true. That's
true. We did. You should actually be really impressed, Brent. We we really cleaned out
the fridge because we wanted to reduce weight on the slide. So it's like a bare bones fridge.
But now stuff flies around more than we're going down the road. So you open the fridge
and stuff come shooting out. It's bad. It's bad. But that's we'll clean about looking
that up another time. What I wanted to let you know about in the housekeeping is Gardner
Bryant has released a video of his time at System 76, and it's a little taste of what
we saw. So we're going to put a link to that in the show notes. Also, Leno did an interview
with me. We'll put a link to that in the show notes. We talked about Jupiter broadcasting.
We talked about going independent, hitting the one year mark and being in Denver. So
check that out. They were both pretty great. We'd also love to have you write in, give
us show ideas, feedback, all that kind of stuff at Linux unplugged dot com slash contact.
And if you like a more real time, ongoing conversation, Jupiter broadcasting dot com
slash telegram, get our telegram group. And then there's the like really high touch.
That's the mumble room. Not only does it run during our show, but it's every single Sunday
they're going in there with the virtual lug, having themselves a Linux beat up that you
can attend. And I know it seems like, oh, it's Sunday, noon, Pacific. What am I going
to get stuff to do? Trust me, we are social creatures. Even those of us who are introverts,
this stuff is actually really good for us. So go get the mumble info Linux unplugged
dot com slash mumble and go hang out with some like minded Linux geeks. And then last
but not least, we do have show art stickers up at Jupiter garage dot com. Now, if you'd
like to get a sticker for a device or a laptop, you know, I don't know what you got. Maybe
you want to put it on a sword. Maybe you're a ninja. I don't know. But I got stickers
for you at Jupiter garage dot com in various sizes.
Well now that it looks a little more ship shape in here, I think we've got time for
a pick. It's been a minute, though. That's why we've got something special this week.
Enter a fast Spotify client with a native GUI, no electron involved. And yes, Chris,
it's built in rust.
This is good to see. Get rid of that electron. Get it out of here. I know we harp on electron
a lot and it's become cliche, but I just want to make this point that while I have been
in this cellular vortex of hell, waiting for electron apps to load their UI components
when they check in with the server and stuff has been miserable. Electron is worse on a
slow Internet connection. So not only do I have all the bloat on my machine, but then
I have like this Web app that's like connecting to a remote server and getting elements that
just take forever to load. So looks great. A multiplatform Spotify client written in
rust. No electron. Heck, yes. It's got limited Linux testing so far. So go give it a try
and let the developer know how it's working. We'll have a link in the show notes for that.
Hey, guys, what's the name of the app again? Psst. That's P SST for you listeners out there.
Right. It's always easy just to go to Linux unplugged dot com slash four to one. I want
to say thank you to a cloud guru. You can find them on social media pretty much anywhere
that's a social media site. Just go to slash a cloud guru like the Twitters or the YouTubes
just slash the cloud guru. It's real easy. If you do that Twitter thing, you can follow
this here show at Linux unplugged. I'm over there at Chris Elias. What about you, Brent?
Are you on the Twitter? I am. That's at Brent Gervais, Wes. And I'm at Wes Payne. Who knew?
You guys should have said something. I would have been following you ages ago. The whole
networks over there to add Jupiter signal. That's great for news announcements and stuff
like this. I have no idea where I'm going to be next week, but we're going to do it
live Tuesday at noon Pacific three p.m. Eastern. See you next week. Same bad time. Same bad
station. Ah, yes. And if you work in the tech industry or you aspire to work in the tech
industry, don't miss Linux action news. Keep up with what's going on in the world of Linux
and open source. Every Monday with Wes and I, we break it all down. Everything that matters
in the most concise, clear package possible. Linux action news dot com. And then keep the
Linux rolling with Linux Tuesdays. Join us live or subscribe at Linux unplugged dot com
slash subscribe links to everything we talked about today, how to contact us, our mumble
server, our matrix server and a whole lot more is all over that website. Remember what
it was? Yeah, that's right. Linux unplugged dot com. Thanks so much for joining us. See
you back here next Tuesday.
Oh, it just started raining. Oh, really? We just missed the store. Wow. Nicely done,
guys. Sorry, there's there will be a little bit of rain noise in the post show, but talk
about just hitting the window. We did it. You guys with our podcasting powers combined.
It's almost like we're experts. Yeah. Wow. We literally started recording the instant
it stopped raining and we finished the instant it started again. And that's good because
it's going to be raining for a few hours now. I actually kind of like the sound. It's very
soothing under your voice. If it was just me, we could just you could just listen. But
because it's the three of us when I'm not talking, my my track is cut. And so it just
comes and goes. It's really weird. If only I had a rainmaker in my recording booth.
