1
00:00:00,000 --> 00:00:07,000
This is Koda Radio, episode 352, for April 8th, 2019.

2
00:00:31,000 --> 00:00:43,000
Hello there, and welcome to Koda Radio, Jupiter Broadcasting's weekly talk show that takes a pragmatic look at the art and business of software development and related technologies.

3
00:00:43,000 --> 00:00:49,000
My name is Wes, and while this week I'm not joined by Mike, unfortunately he had a bit of a conflict.

4
00:00:49,000 --> 00:00:53,000
Luckily, I've got someone totally inappropriate here to join me.

5
00:00:53,000 --> 00:00:57,000
He just happened to be wandering around the studio, the one, the only, Mr. Chris Fisher.

6
00:00:57,000 --> 00:01:04,000
Hello, Wes. Yeah, I'm no Mike. I'm no Mike. I really got thrown in the lion's den on this one because I thought, hey, it'd be fun. I'll come back.

7
00:01:04,000 --> 00:01:09,000
We'll have a 3B. We're trying to come up with an appropriate term when the three of us do a show together.

8
00:01:09,000 --> 00:01:14,000
And then I ended up kind of like having to like just sort of be the co-host.

9
00:01:14,000 --> 00:01:19,000
Yeah. So thank you for stepping in. We could have just canceled the show. But this way, you know, we had a great live stream audience.

10
00:01:19,000 --> 00:01:25,000
You can always join us live. We do this show live every single week. So there's no reason not to join us.

11
00:01:25,000 --> 00:01:30,000
I will say, I think in part because we have such a good live stream this week. It's one of the reasons why we're like, let's just do it.

12
00:01:30,000 --> 00:01:37,000
Let's just you and I do it. And also, it gives me a chance to embarrass you on the air and say, happy early birthday to you, Mr. Payne.

13
00:01:37,000 --> 00:01:42,000
Thank you. I know it's a big one coming up. So I just wanted to say happy birthday.

14
00:01:42,000 --> 00:01:48,000
I appreciate that. Yeah. You know, I'm going to be spending part of that day podcasting. So it's kind of great.

15
00:01:48,000 --> 00:01:54,000
Hey, wait a minute. That's right. We're going to be doing a show actually on your birthday. I could have saved it for that.

16
00:01:54,000 --> 00:02:02,000
Dang it, Wes. I think I had next time. Well, yeah. So Mike did have something come up and he couldn't be here today.

17
00:02:02,000 --> 00:02:08,000
He was actually like it was literally one of those last minute things and it involves, you know, family stuff.

18
00:02:08,000 --> 00:02:13,000
So we like totally understand. And, you know, we kind of embrace that on Coder Radio, right? The whole pragmatic aspect.

19
00:02:13,000 --> 00:02:19,000
Sometimes stuff comes up. Yeah, man. And I just want to say like you and Mike together have been killing it.

20
00:02:19,000 --> 00:02:25,000
So maybe it's kind of a good thing. Now, I'm not going to mess up your flow that you guys got going. You know, you guys got a good thing going now.

21
00:02:25,000 --> 00:02:31,000
I come in here. I don't want to mess it up. So now this way, it's something different because Mike wasn't going to make it anyway.

22
00:02:31,000 --> 00:02:35,000
Right. This is a weird one off standalone Coder Radio improvisation.

23
00:02:35,000 --> 00:02:39,000
Yeah, man. You know, it's on the study much to 400 to which just really is mind blowing.

24
00:02:39,000 --> 00:02:46,000
And it's it sounds old, but it's not quite as old as software that cities like San Francisco are running.

25
00:02:46,000 --> 00:02:54,000
And I have had a little run in with something like this back in my contracting days. This is an article, an article.

26
00:02:54,000 --> 00:02:58,000
What is what is an article, Wes? You know, I don't know, but I'm about to find out.

27
00:02:58,000 --> 00:03:03,000
I think it's an article about agriculture, an article. Well, that's not what you've prepared for.

28
00:03:03,000 --> 00:03:08,000
It's but it is from Bloomberg, from Bloomberg. And they have an article that's America.

29
00:03:08,000 --> 00:03:14,000
Cities are running on software from the 80s. And this isn't going to surprise anybody.

30
00:03:14,000 --> 00:03:19,000
I know that going into this, but this I just thought this is an interesting anecdote.

31
00:03:19,000 --> 00:03:28,000
San San Francisco, the the town on the coast, you know, near the heart of Silicon Valley is still pricing its real estate like it's the 1980s.

32
00:03:28,000 --> 00:03:36,000
It uses software that is DOS based. It runs on 386 and 486 as they have to maintain.

33
00:03:36,000 --> 00:03:40,000
And this is a common thing. We all know this. This is everywhere.

34
00:03:40,000 --> 00:03:45,000
This software never dies. And I just had a quick story that I wanted to share with you.

35
00:03:45,000 --> 00:03:49,000
Have you ever worked anywhere where you've come across something that's just like an ancient system?

36
00:03:49,000 --> 00:03:53,000
Oh, yeah. Yeah, absolutely. I worked for in a print shop for a while.

37
00:03:53,000 --> 00:03:57,000
And there was there was some monstrosities there. Let me tell you, like, like DOS.

38
00:03:57,000 --> 00:04:06,000
Oh, yeah. DOS and just weird ancient devices that were barely compatible had been hacked together through like six layers of conversions and would only work with Windows 98 loaded up in the right way.

39
00:04:06,000 --> 00:04:11,000
Yeah. Yeah. It does feel like certain industries are more susceptible to this problem.

40
00:04:11,000 --> 00:04:18,000
Print being one of them, like any industry that has like really large machinery that needs to be controlled.

41
00:04:18,000 --> 00:04:27,000
And it's like that machinery is locked to or that like the technology that is paired with that machinery is locked to like whatever the development cycle of that machinery was.

42
00:04:27,000 --> 00:04:31,000
So if they started it back 10 years ago, it takes a machine that's 10 years old to run it.

43
00:04:31,000 --> 00:04:40,000
And it's it makes me think, too, that there's there's a difference in how we approach this. Like, you might have a machine that you don't need to update for 30 years, but you can't do that with computers.

44
00:04:40,000 --> 00:04:47,000
I don't know where the where the boundary between like simple machine, you know, static part to complicated operating system is.

45
00:04:47,000 --> 00:04:52,000
But there is a line there. And once you're above it, you just have to update.

46
00:04:52,000 --> 00:04:56,000
There's like a there's like a weird lifecycle where you're running a mainstream operating system.

47
00:04:56,000 --> 00:05:00,000
So it's critical that you stay up to date and you stay patched for security reasons.

48
00:05:00,000 --> 00:05:06,000
But you go you go 15, 20 years out of when that operating system was mainstream.

49
00:05:06,000 --> 00:05:11,000
And in a weird way, you're kind of almost secure again, not in the sense.

50
00:05:11,000 --> 00:05:16,000
I mean, you're not secure in the sense that all of the exploits for that operating system are well documented,

51
00:05:16,000 --> 00:05:21,000
but you are secure in the sense that nobody's writing exploits anymore and going after that operating system.

52
00:05:21,000 --> 00:05:25,000
So I had this really interesting experience. I got called in to fix this.

53
00:05:25,000 --> 00:05:29,000
This this is probably eight years ago now, but it was even old back then.

54
00:05:29,000 --> 00:05:36,000
I got called in to fix this attendance machine that the attendance office, you know, you know, used for children.

55
00:05:36,000 --> 00:05:40,000
Oh, OK. So this is a track attendance in classroom. Yeah. You know, the teacher calls attendance.

56
00:05:40,000 --> 00:05:47,000
Right. And they fill out like a spreadsheet on their like clipboard or whatever and they turn it in or whatever or they do it by the computer on whatever.

57
00:05:47,000 --> 00:05:50,000
And my school was kind of an early pioneer because I'm an old man now.

58
00:05:50,000 --> 00:05:55,000
But my school used a website, a Web page. The teachers would go to a Web page and check in all the students.

59
00:05:55,000 --> 00:06:00,000
And then the ones that weren't there would get sent to the attendance office.

60
00:06:00,000 --> 00:06:05,000
And then the attendance office would manually enter them into this DOS machine.

61
00:06:05,000 --> 00:06:11,000
It was a big tower PC. You remember when like tower machines were like three or four or five feet tall?

62
00:06:11,000 --> 00:06:17,000
Yeah. Those were the days. Yeah. Multiple floppy drives. Big old big old power supplies for days.

63
00:06:17,000 --> 00:06:28,000
ISA slots. No PCI. I mean, we're talking really, really old. And I go in there because it's not dialing anymore.

64
00:06:28,000 --> 00:06:32,000
And they need this thing to call the parents to let the parents know that their kids didn't make it to school that day.

65
00:06:32,000 --> 00:06:38,000
This is the system that would leave like, you know, something on my parents answering machine, which the answering machine is a whole nother set of technology.

66
00:06:38,000 --> 00:06:48,000
But I go in there and I'm looking at it and the software after I seriously have to take like a half hour to like refamiliarize myself with using DOS and DOS screens.

67
00:06:48,000 --> 00:06:52,000
And I discovered the software is not properly communicating with the modem.

68
00:06:52,000 --> 00:06:57,000
And it's one of these proprietary modems that's got like 15 phone jacks. Oh, wow.

69
00:06:57,000 --> 00:07:01,000
It's like this big. Of course, because it's making all these connections, sending these automated messages.

70
00:07:01,000 --> 00:07:06,000
It's got well, I forget what they're called, but it's got this big plug that comes into it that then has all of the connectors hanging off of it.

71
00:07:06,000 --> 00:07:09,000
You know what I'm talking about? Oh, yeah. I don't know if that's called either, but yeah.

72
00:07:09,000 --> 00:07:17,000
And so I open up the side of the case and it's got dust bunnies that, you know, would rival the greatest dust bunnies.

73
00:07:17,000 --> 00:07:28,000
I mean, just it it was gray. The whole machine was gray inside and it was all of the ISA slots had been completely the weren't used were completely filled with dust.

74
00:07:28,000 --> 00:07:35,000
It was just disgusting. But what had happened is this monster of a modem that had all of this components on it.

75
00:07:35,000 --> 00:07:42,000
And like it was like a double stack sandwich card had over time just the weight of it had pulled itself out of the ISA slot.

76
00:07:42,000 --> 00:07:46,000
Oh, yeah. I've seen that before. So I slid it back in, but it was a loose slot.

77
00:07:46,000 --> 00:07:52,000
So the car just would like slip right back out. It just didn't it no longer had enough friction to get itself in the slot.

78
00:07:52,000 --> 00:07:57,000
I did like a test bump like bump the side of the case popped right out. Jesus is the stupidest thing.

79
00:07:57,000 --> 00:08:02,000
And so I'm I'm and because it had taken me a while to familiarize myself with the system and figure it all out.

80
00:08:02,000 --> 00:08:09,000
I wouldn't have gotten lunch at Burger King because, you know, I was being a fatty and I'm sitting there eating my fries, which are pretty decent.

81
00:08:09,000 --> 00:08:13,000
And yeah, you need no excuses for Burger King. All right. That's totally acceptable. Thank you.

82
00:08:13,000 --> 00:08:19,000
And also, by the way, a national doordash partner. Not that I not that I know.

83
00:08:19,000 --> 00:08:31,000
So I take my fry box, which I just finished my fries and I look at it and I look at the case and I go, you know, this fry box is about the height from the bottom of the case to the where the ISA card needs to be supported.

84
00:08:31,000 --> 00:08:40,000
And so I took my empty, dirty, greasy, salty fry box and I put it inside this PC case and I propped the modem card up.

85
00:08:40,000 --> 00:08:46,000
That is gross, but probably effective. Worked for years as far as I know. Worked for years after that.

86
00:08:46,000 --> 00:08:50,000
Whoever has to find that the next time like it slips or the box is just degraded.

87
00:08:50,000 --> 00:08:58,000
The next IT guy that comes in and opens this thing up like now he's going to be telling the story about the time he opened up a case and saw a fry box in there.

88
00:08:58,000 --> 00:09:03,000
I mean, probably since it's like fast food, it just won't do great ever. So it's a permanent. That's what I figured.

89
00:09:03,000 --> 00:09:07,000
You know, it's like you never have a problem with that kind of stuff. It lasts forever.

90
00:09:07,000 --> 00:09:18,000
So it doesn't surprise me when I see that, you know, cities like San Francisco, I'm sure Seattle, same thing, government facilities, people buy this stuff and they want it to be like property.

91
00:09:18,000 --> 00:09:23,000
They want to make a one time large investment and then have it pay off for years.

92
00:09:23,000 --> 00:09:31,000
This is not really the way technology works, though, is it? Yeah. And it seems like we're still trying to figure out what that right cycle time is right because you still replace things like your washer dryer.

93
00:09:31,000 --> 00:09:36,000
But maybe now you have to do that because the digital screen broke, not because the actual washing mechanism broke.

94
00:09:36,000 --> 00:09:39,000
Yeah. So what have you been playing around with recently?

95
00:09:39,000 --> 00:09:42,000
I know you've been upped all kinds of things over there on that ThinkPad of yours.

96
00:09:42,000 --> 00:09:52,000
And you said something to me earlier that I thought would be a great possibility for the audience to like set up a test environment to operate out of a while where they really wanted just extreme performance.

97
00:09:52,000 --> 00:10:02,000
Yeah. OK. Well, so, you know, temp fs slash temp on your system, you can sort of just like use RAM as a file system and store stuff there.

98
00:10:02,000 --> 00:10:05,000
It's like a small space that sort of you reboot and it's gone. It clears out.

99
00:10:05,000 --> 00:10:12,000
So it's like that. But instead, use this technology that the Linux kernel has for emulating persistent memory.

100
00:10:12,000 --> 00:10:21,000
And persistent memory is exactly what it sounds like. Right. It's it's a special type of new memory that maybe maybe this week we saw some things coming out of Intel's Optane stuff.

101
00:10:21,000 --> 00:10:29,000
That possibly you could really buy. So Intel is going to make a hardware version of persistent RAM essentially RAM that doesn't clear.

102
00:10:29,000 --> 00:10:35,000
Yeah. And it's really just I mean, it's on that fuzzy boundary right between like RAM and and these like crazy NVME drives and that sort of thing.

103
00:10:35,000 --> 00:10:43,000
And so it's just like this really fast access RAM. But is that can be persistent with some new technologies they've been developing now to partly.

104
00:10:43,000 --> 00:10:47,000
And I mean, partly it's just interesting. And then they were incentivized to do this.

105
00:10:47,000 --> 00:10:53,000
They've added stuff to the Linux kernel so that you can emulate this. So application developers could start using the same APIs that would be used down the road.

106
00:10:53,000 --> 00:10:57,000
Well, they're you know, I mean, there's a lot of people contributing.

107
00:10:57,000 --> 00:11:02,000
Interesting. And so this emulates this persistent RAM, even if you reboot the system.

108
00:11:02,000 --> 00:11:09,000
So, yeah, if you shut down the system, if your RAM gets cleared, if you don't really have persistent RAM, then, you know, there's no magic here.

109
00:11:09,000 --> 00:11:17,000
But basically you add a little parameter to your kernel command line in grub or you can use Kexec if you're if you're going that route.

110
00:11:17,000 --> 00:11:22,000
Is that the route you went? Well, it's just nice. Yeah. I will talk more about that.

111
00:11:22,000 --> 00:11:27,000
Wes loves Kexec. I really do. So you just OK, you're in your grub menu.

112
00:11:27,000 --> 00:11:36,000
You just add a little parameter that's like memmap equals and then you tell it like how many gigabytes you want to allocate from your RAM and then at what offset address.

113
00:11:36,000 --> 00:11:46,000
And there's some stuff I can find some links for the show notes where there's some commands you can run and look at your D message output to determine memory regions that are safe to be just like allocated this way.

114
00:11:46,000 --> 00:11:51,000
Do you know what makes them safe by chance? I think they're just not already reserved by the kernel for other.

115
00:11:51,000 --> 00:12:01,000
Nothing else has claimed it. Yeah, exactly. You know, so after the kernels or as the kernel is setting up using different parts of memory, this stuff is just sitting there and hasn't been allocated to any application or cash or whatever.

116
00:12:01,000 --> 00:12:07,000
So it's allocating RAM to you, much like it would allocate RAM to an application. Yeah. So so basically it shows up as a new block device.

117
00:12:07,000 --> 00:12:13,000
You just get like slash dev slash PMM zero. And it's just it's whatever size you just want to eat of your RAM. Yeah, exactly.

118
00:12:13,000 --> 00:12:19,000
So how big did you make your right now? Do I have a 12 gig chunk and these think that's have 32 gigs.

119
00:12:19,000 --> 00:12:24,000
So that's I mean, you know, that's still plenty for my day to day usage in my real OS.

120
00:12:24,000 --> 00:12:33,000
So are you booting Kubuntu and then Kexecing into an Ubuntu 1904 environment living out of persistent RAM now?

121
00:12:33,000 --> 00:12:40,000
Yes, I am. I know that sounds absurd, but it's easier. Like once you get the Kexec command down, you do have to make a couple changes.

122
00:12:40,000 --> 00:12:48,000
I basically just copied the ISO from the beta of disco dingo, copy that after I formatted the partition.

123
00:12:48,000 --> 00:12:56,000
So stick XFS on there, copy over all the ISO stuff once you've actually I mean from the squash fs file system in the ISO, but whatever.

124
00:12:56,000 --> 00:12:58,000
Got that set up. You got to do a couple of modifications.

125
00:12:58,000 --> 00:13:09,000
The first thing you're going to need to do, unless you have a kernel that has the PMM module loaded, is update your init ram fs so that it includes it, because otherwise you're not going to be able to find your root file system.

126
00:13:09,000 --> 00:13:17,000
So do that. And then maybe depending on your system, maybe you need to mess with the graphics drivers, which would probably be the same in how it's set up on your main on your host system anyway.

127
00:13:17,000 --> 00:13:21,000
Right. Unless you're maybe using any GPU. That's interesting. Right. So that's where it could get complicated.

128
00:13:21,000 --> 00:13:26,000
So you might have to do a little futzing there. And then I usually just set up that, you know, fs tab.

129
00:13:26,000 --> 00:13:34,000
You can go look under, you know, slash proc slash mounts and look at everything that's mounted and go copy the UID or it'll probably just show up as the same PMM device.

130
00:13:34,000 --> 00:13:38,000
If you just want to be lazy about it, add that to the fs tab, save that stuff.

131
00:13:38,000 --> 00:13:47,000
And then for the Kexec part, now you could do Kexec is probably just the easiest because you can then you have the new kernel right there and you update your init ram fs.

132
00:13:47,000 --> 00:13:50,000
You get a new one of those. You stick those Kexec loads of them in memory.

133
00:13:50,000 --> 00:13:57,000
And then the key part that you got to not forget, which I did more than once, you also need that same mem map kernel parameter for the new kernel.

134
00:13:57,000 --> 00:14:01,000
Otherwise, you know, it won't allocate and the PMM device won't appear.

135
00:14:01,000 --> 00:14:03,000
That definitely seems like that's a critical part.

136
00:14:03,000 --> 00:14:10,000
But if you do all of that, you get all those steps, right? And it's not that I mean, it sounds a little complicated on air, but once you've done it once, it's pretty simple.

137
00:14:10,000 --> 00:14:16,000
You can do Kexec and just have it do it right there. It jumps to the address of the new kernel.

138
00:14:16,000 --> 00:14:21,000
But system D actually has support for this. So you can do system CTL Kexec.

139
00:14:21,000 --> 00:14:26,000
And why that's nice is it'll do all this stuff. It waits till the very last part of when it would reboot, right?

140
00:14:26,000 --> 00:14:32,000
So it's unmounted file systems, all that nice stuff, stopped all your services cleanly and then it jumps to the new kernel.

141
00:14:32,000 --> 00:14:38,000
And so the practical reason why you're doing this, other than it sounds completely badass and it's got to be fast as hell,

142
00:14:38,000 --> 00:14:48,000
is you are able to stand up another work environment and try out a separate workflow, try out a whole different set of utilities, bang around with the audio subsystem,

143
00:14:48,000 --> 00:14:52,000
build software, and you're not even touching your main install.

144
00:14:52,000 --> 00:15:00,000
So it's like it's kind of the best of both worlds because it's it's way better than a virtual machine, way better than a virtual machine like performance wise.

145
00:15:00,000 --> 00:15:07,000
But you're still totally isolated and you're using that extra RAM that you're probably not using on your day to day use for the machine.

146
00:15:07,000 --> 00:15:12,000
So does anything break? Is there any real downside to doing this other than you got to eat some RAM?

147
00:15:12,000 --> 00:15:17,000
No, I mean, most things seem to work and it is just just really very snappy.

148
00:15:17,000 --> 00:15:25,000
So I do keep that in mind, like when I'm doing a distro review, I might play around with it a lot in this mode, but I will try to boot it off a real disk just to see what happens.

149
00:15:25,000 --> 00:15:33,000
But it's it is really nice. And so it's made this new this new 1904 release feel even snappier, which has been great.

150
00:15:33,000 --> 00:15:39,000
So are you what kernel is being used, though? Like what is when you Kexec your kernel swapping, right?

151
00:15:39,000 --> 00:15:41,000
Like that's a kernel you're switching.

152
00:15:41,000 --> 00:15:47,000
Yeah, so Kexec is a Linux kernel technology technique, a set of user space tools to go along with it.

153
00:15:47,000 --> 00:15:50,000
And it's actually how like crash dumps work in Linux, too.

154
00:15:50,000 --> 00:15:57,000
There's a special like crash reporting kernel that you jump to if there's a if the kernel has like a fault and then it can like save out all the crash data.

155
00:15:57,000 --> 00:16:04,000
And so the basic idea is you just load the take a kernel loaded in memory just like your bootloader would do.

156
00:16:04,000 --> 00:16:09,000
And then Kexec tells the kernel and then the kernel just jumps and starts running the new kernel right from that.

157
00:16:09,000 --> 00:16:13,000
Whatever offset it loaded in memory.

158
00:16:13,000 --> 00:16:19,000
And there is some ways I've seen various people on weird bootloader forums talking about.

159
00:16:19,000 --> 00:16:25,000
You can like maybe do grub for DOS and get it to do other operating systems.

160
00:16:25,000 --> 00:16:34,000
I know there's a lot of concerns about like Kexec when they were first working out how you if I would work with secure boot enforcing mode, like having to disable Kexec or that sort of thing.

161
00:16:34,000 --> 00:16:41,000
So can I ask you what I still don't quite understand, like if you restart, what restores the state of the old environment?

162
00:16:41,000 --> 00:16:44,000
Like how does the 1904 install not get wiped out?

163
00:16:44,000 --> 00:16:49,000
As long as you don't power off the system, usually a reboot and it might depend on your machine. Give it a give it a try.

164
00:16:49,000 --> 00:16:56,000
That's the only way to find out. But on most of the machines I've tested it on, a reboot is not long enough and it doesn't really totally power down.

165
00:16:56,000 --> 00:17:03,000
So the RAM stays like it doesn't. And for these purposes, you know, I might not keep my master's thesis on there or something.

166
00:17:03,000 --> 00:17:07,000
Right. But but we're just messing around in a test environment.

167
00:17:07,000 --> 00:17:11,000
I was just asking because for me, it would be tempting as hell to make that my my production.

168
00:17:11,000 --> 00:17:15,000
You do got to remember, don't shut down your computer because that's boy.

169
00:17:15,000 --> 00:17:21,000
I mean, I'm pretty good about saving out and, you know, saving something that would like sink off into the cloud or whatever to another machine at least.

170
00:17:21,000 --> 00:17:24,000
So I wouldn't probably lose data. I'm not so worried about that.

171
00:17:24,000 --> 00:17:34,000
It's more like I would think like application changes and stuff that maybe I if I didn't have if I installed several applications and then and then were to reboot or shut down and come back.

172
00:17:34,000 --> 00:17:39,000
And it'd be nice if I could have it like as it's shutting down right out to like an image file.

173
00:17:39,000 --> 00:17:43,000
And then when it boots back up, restore that image file. You almost like a like almost like hibernate.

174
00:17:43,000 --> 00:17:49,000
That would be nice. I wonder what the best way to do that. I was also thinking I could maybe set up like an overlay effects or something.

175
00:17:49,000 --> 00:17:53,000
You could still certainly mount your home partition just for data stuff, too, of course.

176
00:17:53,000 --> 00:17:57,000
Yeah, I am tempted. Like it wouldn't be bad to just make this sort of a more permanent.

177
00:17:57,000 --> 00:18:01,000
I mean, it's just got to be so phenomenally fast. Yeah, it's really it feels very nice.

178
00:18:01,000 --> 00:18:05,000
A couple of times I've run my operating system out of RAM and it's such a treat.

179
00:18:05,000 --> 00:18:10,000
It's like that was one of my favorite things of Knoppix. I don't remember the old day, like one of the original live CDs.

180
00:18:10,000 --> 00:18:14,000
Oh, yeah, absolutely. You can have it just load right in the RAM. That was fun.

181
00:18:14,000 --> 00:18:21,000
This stuff's kind of obscure, but it's nice. Like I've done it other ways, too, but like complicated, you know, where you break in the in it.

182
00:18:21,000 --> 00:18:29,000
Ramifest or update it with your own custom script so that it sets up a temp fess and copies all the stuff from the real partition into RAM and then continues booting that sort of stuff.

183
00:18:29,000 --> 00:18:35,000
So it's nice when you do it this way, because the PMEM stuff just makes it appear right as a block device and all the other, you know, regular.

184
00:18:35,000 --> 00:18:38,000
It's just a regular device to the rest of the scripts and system.

185
00:18:38,000 --> 00:18:47,000
So zooming out and, you know, accounting for just approachability, how approachable is this?

186
00:18:47,000 --> 00:18:58,000
Like using Kexec and all this, because I think this is an interesting example of how this is an area where Linux kind of does something that Windows and Mac OS can't.

187
00:18:58,000 --> 00:19:03,000
And it gives you a lot of flexibility. And these are not necessarily hidden tools.

188
00:19:03,000 --> 00:19:11,000
Like, so how difficult was it to come across this? And do you think if somebody was interested in doing something like this with that, could they figure this out in an afternoon?

189
00:19:11,000 --> 00:19:21,000
Yes, I think so. The documentation is a bit scattered, but once you get the right kernel command line and it's really not it's not that complicated.

190
00:19:21,000 --> 00:19:32,000
But once you find that and get the right region of memory and sometimes you just have to try and your kernel just won't boot properly if you mess it up or ignore your request and you just won't have any PMEM device show up.

191
00:19:32,000 --> 00:19:34,000
Like your system doesn't crash or something?

192
00:19:34,000 --> 00:19:37,000
No, it won't crash like while it's running, or at least not in my experience.

193
00:19:37,000 --> 00:19:41,000
Seems to try to avoid those situations, which is nice.

194
00:19:41,000 --> 00:19:45,000
So I think as long as you get that working from there, you should be fine.

195
00:19:45,000 --> 00:19:56,000
One optimization you can do that we didn't talk about is called DAX, which is sounds like Jedzia DAX, I realize, but it's totally different and is actually a method to avoid unnecessary caching, right?

196
00:19:56,000 --> 00:20:02,000
So there's the whole page cache mechanism and all the optimizations that the kernel is doing for files that are on disk.

197
00:20:02,000 --> 00:20:08,000
But our files are already in memory. They're not going to get any faster by caching them in a different place in memory.

198
00:20:08,000 --> 00:20:11,000
So DAX is an optional thing you can do.

199
00:20:11,000 --> 00:20:16,000
And right now, I think the only major one file systems that support are EXT4 and XFS.

200
00:20:16,000 --> 00:20:22,000
So if you do if you format those and then mount them with the DAX option, you can get direct access and not pay that penalty.

201
00:20:22,000 --> 00:20:23,000
So it's even faster.

202
00:20:23,000 --> 00:20:27,000
I didn't even think to ask you, did you did you use ZFS?

203
00:20:27,000 --> 00:20:29,000
You didn't, right? Did you just use XF4?

204
00:20:29,000 --> 00:20:30,000
I used XFS.

205
00:20:30,000 --> 00:20:32,000
Oh, OK. All right. Very good.

206
00:20:32,000 --> 00:20:38,000
Which actually was the one time that it was like I ran into the problem where I kind of allocated more disk from RAM than I needed.

207
00:20:38,000 --> 00:20:41,000
So far, 12 has been more than enough.

208
00:20:41,000 --> 00:20:47,000
And so I wanted to shrink it and I was like, oh, wait, I formatted this XFS.

209
00:20:47,000 --> 00:20:49,000
Something you and I have never talked about before.

210
00:20:49,000 --> 00:20:53,000
And I'm I'm curious to know where you where you land on this.

211
00:20:53,000 --> 00:21:00,000
So before I tell you my opinion, would you say you are?

212
00:21:00,000 --> 00:21:07,000
What would you guess would be when like really reliable self-driving cars are going to be mainstream?

213
00:21:07,000 --> 00:21:10,000
What would be your guess for when they go mainstream on that?

214
00:21:10,000 --> 00:21:15,000
What's the I'm running a little like what's the what are the acceptance criteria around mainstream?

215
00:21:15,000 --> 00:21:22,000
You know, most most most all cars on the market when you buy them are offering self-driving of some type.

216
00:21:22,000 --> 00:21:25,000
Jane average citizen goes out to buy a car. It's a self-driving car.

217
00:21:25,000 --> 00:21:36,000
Yeah. You know, like a lot of times in the car industry, really high end features start at the very top and then they kind of trickle down like backup cameras, parking sensors, you know,

218
00:21:36,000 --> 00:21:41,000
launch systems and all these things that, you know, like are coming down to launch.

219
00:21:41,000 --> 00:21:45,000
That's what my car has a lot. I mean, they do. It's just a funny it is a funny thing.

220
00:21:45,000 --> 00:21:51,000
And it's you go into you go into launch mode and you got to you know, it's a certain incantation to get it to do it.

221
00:21:51,000 --> 00:21:55,000
And I think self-driving could that's probably how it would trickle down at first. Right. It was it would come.

222
00:21:55,000 --> 00:21:59,000
It would just be a feature that sort of like how Tesla's all have it will soon like, you know,

223
00:21:59,000 --> 00:22:03,000
you go get a Honda Accord and it'll have a self-driving system.

224
00:22:03,000 --> 00:22:12,000
When do you think we get there? When do we get there? All right. It's 2019 now.

225
00:22:12,000 --> 00:22:19,000
It's an interesting state that it's in, like right now, because I'm not sure we've decided how many edge cases are acceptable.

226
00:22:19,000 --> 00:22:23,000
You know, I'm not sure we it's probably still going to work out to be safer,

227
00:22:23,000 --> 00:22:26,000
but it seems like we're additionally scared because the machines are doing it.

228
00:22:26,000 --> 00:22:30,000
Happy to let us kill each other. We just don't want the machines to kill us.

229
00:22:30,000 --> 00:22:36,000
Well, I also feel like it's so it's an awkward teenage phase.

230
00:22:36,000 --> 00:22:45,000
So right now it's in its baby phase and you got the teenage phase where it's awkward because some people will be self-driving,

231
00:22:45,000 --> 00:22:51,000
but a lot of people won't. And so this system has to account for both kinds of drivers at the same time.

232
00:22:51,000 --> 00:22:57,000
Exactly. It's more complicated than if you actually had like everyone mandated network talking to each other, optimized for that.

233
00:22:57,000 --> 00:23:00,000
Then cars can flow like data packets. Gosh, that would be nice, wouldn't it?

234
00:23:00,000 --> 00:23:02,000
You wouldn't have intersections anymore.

235
00:23:02,000 --> 00:23:08,000
It really changes the idea from that of a car to more of like a, you know, like some sort of city public system.

236
00:23:08,000 --> 00:23:11,000
Not that it would have to be, but it's an integrated whole that can work together.

237
00:23:11,000 --> 00:23:13,000
You could have a car that drops you off here at the studio.

238
00:23:13,000 --> 00:23:17,000
And then as you're leaving, you know, a car could be here in five minutes to pick you up and there's nobody in the car.

239
00:23:17,000 --> 00:23:20,000
It's just your pod. That'd be perfect. It would be kind of great.

240
00:23:20,000 --> 00:23:24,000
I could I could edit the show notes while I'm driving, while I'm headed back down to the city.

241
00:23:24,000 --> 00:23:34,000
That'd be amazing. So what do you think? Time wise, I'm going to say I'm going to go like ten years and say like twenty, twenty eight, twenty, twenty nine.

242
00:23:34,000 --> 00:23:39,000
Yeah. OK. I could see ten years. I could see it. I definitely could see it.

243
00:23:39,000 --> 00:23:50,000
I am a little more skeptical. I'm feeling like it's more like fifteen to twenty because I I drive around, you know, up here.

244
00:23:50,000 --> 00:23:54,000
That's, you know, what are we, thirty five, forty miles north of Seattle? Yeah.

245
00:23:54,000 --> 00:23:58,000
And there's so many edge cases like that.

246
00:23:58,000 --> 00:24:08,000
It's just a lot of weird driving and weird roads that I can't imagine are in anybody's database really where they've I just I have very little faith in off of the highways.

247
00:24:08,000 --> 00:24:11,000
OK, so here's here's an example that just happened to me. I was being driven by a human.

248
00:24:11,000 --> 00:24:16,000
I was I was taking a Lyft ride in the city trying to meet some friends for dinner.

249
00:24:16,000 --> 00:24:21,000
And, you know, they just tore down the viaduct. They're doing I mean, it's still in progress. They're doing all sorts of construction over this.

250
00:24:21,000 --> 00:24:25,000
How has the traffic been really bad? Actually, no, I don't not not crazy.

251
00:24:25,000 --> 00:24:28,000
No. OK. Not for like the first couple of weeks. It was actually a lot better.

252
00:24:28,000 --> 00:24:32,000
It sort of dwindled back to more normal now. But it's it's not been too bad.

253
00:24:32,000 --> 00:24:35,000
Yeah. Because it was like it was like everybody says can be doomsday.

254
00:24:35,000 --> 00:24:39,000
Now it is just about I think just recently started like they're doing other things.

255
00:24:39,000 --> 00:24:43,000
So buses that previously took a subterranean tunnel now have to be on the street.

256
00:24:43,000 --> 00:24:47,000
So there's always one more thing and more construction. Right. Yeah. Thank God. Thank God.

257
00:24:47,000 --> 00:24:51,000
You don't have to commute, dude. So there's this whole street that's just blocked off totally.

258
00:24:51,000 --> 00:24:56,000
That had been previously a popular thoroughfare down by the market, by the waterfront.

259
00:24:56,000 --> 00:25:01,000
Totally blocked off. But apparently looking at the drivers Google Maps, Google did not know that.

260
00:25:01,000 --> 00:25:06,000
And this was a human and he did a fine job. I don't mean to just, you know, talk ill of him.

261
00:25:06,000 --> 00:25:10,000
Right. But it was a confusing situation. And you would think if anything's going to be current, it's going to be Google Maps.

262
00:25:10,000 --> 00:25:14,000
Yeah. So he didn't even realize it was closed, despite there being a lot of signage about that.

263
00:25:14,000 --> 00:25:20,000
And at the end was one of those big long like Canadian tour buses that go like drive across the country.

264
00:25:20,000 --> 00:25:24,000
Yeah. And it was turning around because it didn't realize either.

265
00:25:24,000 --> 00:25:29,000
And so many Canadians down here. That was a complicated thing for him to navigate.

266
00:25:29,000 --> 00:25:33,000
And there was like a parking lot with a busy parking lot was the only area to turn around.

267
00:25:33,000 --> 00:25:38,000
So it was like a perfect storm. And we got out safely and I got to my destination only a little bit late.

268
00:25:38,000 --> 00:25:43,000
But that'd be a hard case for a computer. Yeah. Well, that's a great example of how how the hell would the computer solve that?

269
00:25:43,000 --> 00:25:49,000
Yeah. Hmm. Yeah. You know, or when remember we had that bridge collapse not too long ago.

270
00:25:49,000 --> 00:25:53,000
Oh, man. Yes. That was that was embarrassing. And, you know, I looked at this.

271
00:25:53,000 --> 00:25:56,000
I was reading this news story from Boeing Boeing.

272
00:25:56,000 --> 00:26:04,000
Cory Doctor wrote it up about small stickers on the ground that were tricking the Tesla autopilot into steering into oncoming traffic.

273
00:26:04,000 --> 00:26:09,000
See, that's terrifying. Some reflective stickers on the ground. Now, Tesla's patch the flaw.

274
00:26:09,000 --> 00:26:16,000
So they did a proper disclosure to Tesla and Tesla has. That's good. Yeah. So this is already taken care of.

275
00:26:16,000 --> 00:26:29,000
But I feel like when you start having computers doing the driving, you can start to you can start to plan how to exploit them better because you know what they're going to do.

276
00:26:29,000 --> 00:26:34,000
You know what their limits are. Like, take, for example, a hostage situation. This is just a crazy example.

277
00:26:34,000 --> 00:26:46,000
But if this is the thing you think about. Right. You say if you had two cars and one was on the side of the vehicle and one pulled in front of the self-driving vehicle and they both slowed down and they forced the vehicle to come to a complete stop.

278
00:26:46,000 --> 00:26:54,000
A human driver might be able to get out of that situation, but the computer is going to it's not going to have a lane to pull over and there's going to be a vehicle in front of it slowing it down.

279
00:26:54,000 --> 00:27:02,000
So the computer will probably just slow the car down. That's what my Volkswagen, my Volkswagen has radar and lane assist radar cruise control and lane assist.

280
00:27:02,000 --> 00:27:06,000
And that's what it does. It just come it'll it'll come all the way to a complete stop. That makes sense.

281
00:27:06,000 --> 00:27:15,000
I don't know how to handle this. We're just going to. Yeah. And you think about to like stickers or other reflective surfaces have thrown off the cameras before.

282
00:27:15,000 --> 00:27:31,000
Like when you learn how they're capturing the data and how it processes it and how it makes its decisions, then you know how to exploit it. And you could start having people cause traffic incidents in a totally new way where they're essentially exploiting the limitations of these systems.

283
00:27:31,000 --> 00:27:38,000
Yeah. That's the other part of this is I'm not sure that the software industry is mature enough really for this.

284
00:27:38,000 --> 00:27:45,000
We've just seen all these like the problems with the Boeing 737 Max. It's crazy. And that has previously been an industry with with great track records.

285
00:27:45,000 --> 00:27:55,000
And statistically, it still is despite these, of course. But the software world at large comes from a much more free willing place.

286
00:27:55,000 --> 00:28:06,000
And it takes a lot of time to build the sort of engineering style and knowledge and practices and auditing and all of those sorts of things that you need when you have people's lives on your hands.

287
00:28:06,000 --> 00:28:20,000
I might even argue that corporate culture isn't set up to sustain the jobs that you really I mean, I would feel much better if if the Tesla engineers were there for 35 years developing the software.

288
00:28:20,000 --> 00:28:25,000
What makes me nervous is when you have a lot of turnover and this industry does have a lot of turnover.

289
00:28:25,000 --> 00:28:29,000
There's a lot of opportunity. So you can't blame people for trying to get better deals.

290
00:28:29,000 --> 00:28:37,000
And it's a very competitive marketplace. And when you have turnover, you have new people that come in that don't really have as much familiarity.

291
00:28:37,000 --> 00:28:44,000
They might not have been there during the early decisions. That seems like that is a fundamental flaw in the way we are structured.

292
00:28:44,000 --> 00:28:53,000
There's not really incentives and there's just it's a fluid and very optimized for like short term profits and incentives and shareholders sorts of things.

293
00:28:53,000 --> 00:28:59,000
It's just a different thing or it seems like we're getting worse at building longer term institutions.

294
00:28:59,000 --> 00:29:08,000
That's the point I'm trying to get to. And that that is reflected in our software. So many times you will see we're going to just hit the big reset and rebuild the platform or we're going to rework it or we're going to redo it.

295
00:29:08,000 --> 00:29:14,000
I mean, you've seen Apple do it. In fact, to Microsoft's credit, they're one of the folks that very rarely does it, even when they probably should.

296
00:29:14,000 --> 00:29:24,000
Because is pretty much an unbroken line back to the 90s. But a lot of software and platforms eventually hit this point where they want to rebuild and restart.

297
00:29:24,000 --> 00:29:29,000
And we're going to build a new platform. It'll start with less features, but it'll be better, etc, etc, etc.

298
00:29:29,000 --> 00:29:35,000
Like you just can't afford to do that in this market that you lose too much when that happens.

299
00:29:35,000 --> 00:29:40,000
But it is it just seems to be the way the software development industry operates now.

300
00:29:40,000 --> 00:29:47,000
I agree with you. I feel like we are not built to create that kind of software right now.

301
00:29:47,000 --> 00:29:56,000
And we've got to work through all of that, the way people are going to exploit these things, the way it's going to have to operate while there's still regular drivers on the road that aren't automated.

302
00:29:56,000 --> 00:30:01,000
And we're going to have to build a real good solution around that human turnover factor.

303
00:30:01,000 --> 00:30:06,000
And then there's going to be all of the privacy considerations once these things are networked.

304
00:30:06,000 --> 00:30:11,000
And you're trapped inside them, you know, and they have a lot of information about about what you're doing in there.

305
00:30:11,000 --> 00:30:17,000
Yeah, I don't know. That's that's sort of strange. It'll be funny to kind of learn the different personalities of the automated driving systems.

306
00:30:17,000 --> 00:30:22,000
You know, if you're still like a human driver, how does Tesla drive versus Waymo?

307
00:30:22,000 --> 00:30:31,000
I actually I feel like I can absolutely tell when I when I am on a road with a Tesla that's an autopilot.

308
00:30:31,000 --> 00:30:39,000
I can tell by the way the car responds, like when I switch lanes and I've noticed now because I have the assisted cruise control like I can.

309
00:30:39,000 --> 00:30:43,000
So I can see when it's like backing off to like match speed and stuff.

310
00:30:43,000 --> 00:30:48,000
And you can see you can see when the cars you can tell when they're self-driving and right there.

311
00:30:48,000 --> 00:30:52,000
I could tell if I if I were to come to a stop that it would force that Tesla to come to a stop behind me like they would.

312
00:30:52,000 --> 00:30:56,000
I don't think it would just swerve over and zoom past me.

313
00:30:56,000 --> 00:31:03,000
I think it would be safe and it would match my speed. And if I if I was doing sixty five, then I was doing fifty five, then I was doing forty five.

314
00:31:03,000 --> 00:31:07,000
It would just match me all the way down to zero. See, it's probably going to be this another thing, right?

315
00:31:07,000 --> 00:31:14,000
There's going to be tiers. So government agencies or other powerful people with money could probably have that all tuned in custom styles, right?

316
00:31:14,000 --> 00:31:21,000
That could drive. Yeah. Chase driving, race driving or general city driving. Auto pursuit mode.

317
00:31:21,000 --> 00:31:26,000
It's so creepy. Launch the drones.

318
00:31:26,000 --> 00:31:33,000
Will there be different levels of certification like lane self-driving only lanes that go much faster than the regular traffic lanes?

319
00:31:33,000 --> 00:31:38,000
Right. Oh, geez, man. Because it is going to be I mean, obviously, the people with more money are going to get it first, right?

320
00:31:38,000 --> 00:31:47,000
Like you're talking about. It trickles down. Well, we should take a moment and give a shout out to the Linux Academy design team and Mr.

321
00:31:47,000 --> 00:31:51,000
Cheese Bacon on our team for cranking out some new coder graphics.

322
00:31:51,000 --> 00:31:56,000
So if you're in your podcast catcher, watch listening, see if you got the new MP3 badge.

323
00:31:56,000 --> 00:32:01,000
We got new artwork out for the show. It looks so good. It's really nice.

324
00:32:01,000 --> 00:32:06,000
It's amazing. And I mean, she's just came in here. He's hardly worked here.

325
00:32:06,000 --> 00:32:14,000
I don't know what his start date was, but it's been a few weeks and he just hit the ground running and then had to touch basically every single asset for everything the network does.

326
00:32:14,000 --> 00:32:17,000
It's crazy how many there are hundreds. It's really way more than I thought.

327
00:32:17,000 --> 00:32:23,000
It's ridiculous. Every service has its own requirements like YouTube, Twitter, Facebook, fireside.

328
00:32:23,000 --> 00:32:28,000
All of them have their own dimensions and requirements and banner sizes and avatar sizes.

329
00:32:28,000 --> 00:32:33,000
So you have to create essentially assets for everything, for every tiny little customizations and tweaks.

330
00:32:33,000 --> 00:32:39,000
And then you load them up and find out that, oh, actually, that part of their UI covers up the part we were trying to highlight.

331
00:32:39,000 --> 00:32:49,000
So we have to go back to square one and it's it really represents the redesign of the logos kicked off officially in October and it ramped up in December.

332
00:32:49,000 --> 00:32:55,000
And then it really ramped up when she's joined our team a few weeks ago to get it across the finish line and really refine it.

333
00:32:55,000 --> 00:33:05,000
And it to me, I think, is an interesting discussion topic for the show where you work on something that isn't a direct user facing feature,

334
00:33:05,000 --> 00:33:10,000
but you believe it is important for like brand identification or other other driving factors.

335
00:33:10,000 --> 00:33:15,000
And, you know, your user base is going to have a strong reaction, some of it positive, some of it negative.

336
00:33:15,000 --> 00:33:17,000
And you just know that's going to happen with something like this.

337
00:33:17,000 --> 00:33:24,000
And you put months of work into something like this and, you know, coming out of the gate, there's going to be pushback.

338
00:33:24,000 --> 00:33:32,000
And it's a it's dealing with that is a particular kind of challenge because you can have a hundred positive comments.

339
00:33:32,000 --> 00:33:37,000
And if you get one or two negative comments, that'll be what the human mind focuses on.

340
00:33:37,000 --> 00:33:43,000
And it's challenging because I think this is true for software developers and podcasters.

341
00:33:43,000 --> 00:33:46,000
There's a bit of a feedback cycle that we kind of thrive off of.

342
00:33:46,000 --> 00:33:50,000
You create something, you release something.

343
00:33:50,000 --> 00:33:57,000
You get the feedback, it sort of inspires you to keep going, create the next thing, and it's this kind of virtuous cycle.

344
00:33:57,000 --> 00:34:02,000
And, you know, you're making something, be it art, be it software.

345
00:34:02,000 --> 00:34:06,000
And you want to see what your audience, how they respond to it.

346
00:34:06,000 --> 00:34:11,000
And when they respond negatively, even one or two, that's what we focus on.

347
00:34:11,000 --> 00:34:12,000
It can be it's funny, right?

348
00:34:12,000 --> 00:34:17,000
You throw out the as much as you appreciate them, people tell you that they like it or that it's great.

349
00:34:17,000 --> 00:34:21,000
It just doesn't carry the same emotional weight as this is terrible.

350
00:34:21,000 --> 00:34:29,000
And I've tried to develop myself a thick skin over like the last 13 years because I've been taking crap on a daily basis for 13 years, 24-7.

351
00:34:29,000 --> 00:34:32,000
He posts videos on YouTube. I mean, I think you have to.

352
00:34:32,000 --> 00:34:39,000
Yeah. Oh, boy. But this is challenging for like small shop developers, large companies.

353
00:34:39,000 --> 00:34:42,000
I've seen them struggle with this and even large projects.

354
00:34:42,000 --> 00:34:49,000
Clement from the Linux Mint Project recently was posting that his entire team has been essentially demotivated

355
00:34:49,000 --> 00:34:52,000
and feels like they're kind of done burning out a little bit.

356
00:34:52,000 --> 00:34:57,000
I mean, they're not going to stop, but that's how they're feeling right now based on harsh user reaction,

357
00:34:57,000 --> 00:35:05,000
not to software changes in Linux Mint, but because of logo and website changes.

358
00:35:05,000 --> 00:35:11,000
And the user community responded so strongly to that that it really affected the developers of Linux Mint.

359
00:35:11,000 --> 00:35:14,000
And now it's impacting the actual development of software.

360
00:35:14,000 --> 00:35:18,000
So the reaction to the art change has impacted the software development.

361
00:35:18,000 --> 00:35:27,000
And Clement on the Linux Mint website writes that it causes burnout, it causes developers to leave the project.

362
00:35:27,000 --> 00:35:36,000
And he says this has been this Linux Mint 19.1 or 19.2, whatever it is, development cycle has been the most challenging development cycle for him ever.

363
00:35:36,000 --> 00:35:41,000
And that's just because of all this other stuff going on that's not related to the actual development.

364
00:35:41,000 --> 00:35:48,000
It is funny, this week's Linux Action News, you guys did a great job hitting on the importance of perception, even when it doesn't feel like it's important.

365
00:35:48,000 --> 00:35:57,000
But here too, right? When there are people upset about it, that creates trauma and emotional strain that developers have to fight through

366
00:35:57,000 --> 00:36:02,000
and are thinking about that instead of just sitting, being able to sit down, work and think about the problem at hand.

367
00:36:02,000 --> 00:36:05,000
And you can say, well, don't read the comments.

368
00:36:05,000 --> 00:36:13,000
But I think a lot of people are doing this to make a connection with people out there. And so it's also really hard to not read the comments.

369
00:36:13,000 --> 00:36:17,000
I don't do a ton of it. But then you also you do want the feedback, right?

370
00:36:17,000 --> 00:36:23,000
It's interesting because not all of them are garbage, maybe many, but there's a lot of good, genuine feedback there, too.

371
00:36:23,000 --> 00:36:31,000
Absolutely. Yeah. So my approach has been and I know this is it's one of those maybe that's easy for Chris to say kind of things.

372
00:36:31,000 --> 00:36:37,000
But my approach has been to essentially try to develop a level of detachment because the core issue,

373
00:36:37,000 --> 00:36:46,000
the reason why I think negative feedback can affect you so strongly is your creations are often a bit of you.

374
00:36:46,000 --> 00:36:50,000
They're your baby. They represent you in a way like you put something into that.

375
00:36:50,000 --> 00:36:55,000
And so when someone's criticizing your creation, they're criticizing you in a way because those are your choices, right?

376
00:36:55,000 --> 00:37:01,000
You shaped that thing and all tiny little decisions you made around that whole time, all of the thought you put into it and all of that.

377
00:37:01,000 --> 00:37:08,000
Yeah. And I think you have to develop a detachment and realize whatever whoever your audience is,

378
00:37:08,000 --> 00:37:11,000
they have a different perception of the product than you do.

379
00:37:11,000 --> 00:37:16,000
And you have to detach and then view the feedback through that filter.

380
00:37:16,000 --> 00:37:20,000
And what I do is I also try to account for the fact I've run into this so many times.

381
00:37:20,000 --> 00:37:24,000
Sometimes people are just having a bad day and I've gotten these awful, awful emails

382
00:37:24,000 --> 00:37:28,000
and I've written them back and just been like, hey, man, like, wow, that was a little intense.

383
00:37:28,000 --> 00:37:32,000
Like, let's talk about this. And then they'll write me back. Oh, I'm so sorry. I was just having a bad day.

384
00:37:32,000 --> 00:37:37,000
Interesting. I've had to try to learn to discard a lot of the really angry stuff.

385
00:37:37,000 --> 00:37:43,000
And a lot of the super over comment or a complimentary stuff and try to find the middle, the balance.

386
00:37:43,000 --> 00:37:51,000
And if I see a trend, a lot of something that sort of registers like the same general note or or something to that effect,

387
00:37:51,000 --> 00:37:56,000
like a trend or something to that effect, I will you know, I'll take that more seriously.

388
00:37:56,000 --> 00:38:03,000
And I find that it has been a very, very effective approach, but it is not.

389
00:38:03,000 --> 00:38:10,000
It is absolutely not one hundred percent. And even still like one or two comments here and there every now and then,

390
00:38:10,000 --> 00:38:14,000
if it's just the right one, we'll get through and get in my head.

391
00:38:14,000 --> 00:38:21,000
We talked about this a while ago, but we have actually even just recently experienced that on this very podcast.

392
00:38:21,000 --> 00:38:26,000
Yeah, that's a great example. You'll hear us all the time say, you know, people hate it when we talk about hardware.

393
00:38:26,000 --> 00:38:31,000
Nobody likes it. We get tons of feedback. There's nobody likes it. We talk about hardware.

394
00:38:31,000 --> 00:38:38,000
It's two people, tens of thousands of listeners, a guy on Reddit and a guy on YouTube might even be the same person for all we know.

395
00:38:38,000 --> 00:38:46,000
He's been the most vocal critic of us talking about hardware, but because they are persistent over time, we internalized it.

396
00:38:46,000 --> 00:38:52,000
And we have altered the show in pretty fundamental ways based on two people's feedback,

397
00:38:52,000 --> 00:38:55,000
even though tens of thousands of people were listening and didn't complain.

398
00:38:55,000 --> 00:38:59,000
And there is a subtle influence that, you know, it's just this sort of weird, immediate thing.

399
00:38:59,000 --> 00:39:04,000
You think about shaping the show that you're that you're working on and there's this little back pressure somewhere in the back of your mind.

400
00:39:04,000 --> 00:39:11,000
And then whose creation is it at that point? If you're not making thing that's truly yours, whose creation is it?

401
00:39:11,000 --> 00:39:16,000
You have to find that right balance. Yeah. Taking feedback, building, learning and making it your decision if you alter it.

402
00:39:16,000 --> 00:39:28,000
Right. But you can't I mean, I think we've seen too much and maybe bigger mainstream media type things that you can create something that lacks the heart when you it's just based on feedback or, you know, just pandering to fans.

403
00:39:28,000 --> 00:39:39,000
Pandering. Yeah. When you create something that panders to ratings, it can really ring hollow. And so even even myself taking shit for 13 years on a daily basis

404
00:39:39,000 --> 00:39:43,000
and developing a pretty good system to filter this mentally, it still gets in sometimes.

405
00:39:43,000 --> 00:39:52,000
And it even sometimes takes us a while to realize it's happened. And so part of dealing with negative feedback is accepting that sometimes it's still going to get to you

406
00:39:52,000 --> 00:40:00,000
and then creating a structure for yourself to get out of that and to recognize what's happened and then get above it again.

407
00:40:00,000 --> 00:40:07,000
And it's never perfect. And so part of handling good, negative, good and negative feedback is because both can influence you, I suppose.

408
00:40:07,000 --> 00:40:17,000
But negative seems to be the stronger influence is allowing yourself permission to sometimes still get something through the cracks and then get yourself out of it.

409
00:40:17,000 --> 00:40:23,000
Like you got to catch you got to catch yourself. Then I think that really kind of completes how you handle that kind of feedback.

410
00:40:23,000 --> 00:40:27,000
And I'm not trying to tell Clement how to do his job, but he's got to get that's where he's got to get right.

411
00:40:27,000 --> 00:40:31,000
That's where his whole team's got to get our team to like it happens to our team as well.

412
00:40:31,000 --> 00:40:36,000
And it's especially hard probably in the team environment because you've got, you know, multiple people with different feelings about what's what's going on

413
00:40:36,000 --> 00:40:41,000
and you have to all try to work together and there'll probably be different ideas and approaches about how to handle that.

414
00:40:41,000 --> 00:40:47,000
And different people that are getting criticism and feedback for shorter or longer periods of time, like some people. Right.

415
00:40:47,000 --> 00:40:53,000
You know, it takes years. I feel like unless you have somebody coaching you how to deal with this kind of stuff, it can take out.

416
00:40:53,000 --> 00:40:59,000
It can take years. I mean, I've been I've been working with guys and gals.

417
00:40:59,000 --> 00:41:08,000
On these shows that have been at it for four or five years even and still haven't figured out how to properly filter negative feedback.

418
00:41:08,000 --> 00:41:17,000
And I think it's because it's it's it really touches on a lot of instinctual behaviors and things we're not fully aware of, like why our creations are so important to us.

419
00:41:17,000 --> 00:41:21,000
Right. You know, it's like it's not obvious. There are complicated human psyche things.

420
00:41:21,000 --> 00:41:27,000
And we're right. You're right. And it's you know, it's taken me sitting here taking an ass beating for 13 years to figure it out.

421
00:41:27,000 --> 00:41:31,000
And so now I want to impart that a little bit because it can really save your psyche.

422
00:41:31,000 --> 00:41:43,000
So if you're looking at bad reviews somewhere or somebody sends you a nasty email or a poll request that seems super entitled, you just got to consider you got to detach yourself and look at it from their perspective.

423
00:41:43,000 --> 00:41:48,000
Yeah. Right. And it can help help if you can do that. But you just it's not always easy to practice, though.

424
00:41:48,000 --> 00:41:51,000
It's like exercise. And to be just to be aware, I think helps to start.

425
00:41:51,000 --> 00:42:02,000
Like, understand what you are feeling, why it relates and how that happens just by acknowledging that you can often then at least start to compensate for that feeling in your interactions.

426
00:42:02,000 --> 00:42:08,000
Yeah. And then allow yourself to screw it up because it's going to happen and don't beat yourself up on it.

427
00:42:08,000 --> 00:42:10,000
Doesn't mean abandon the philosophy. It just means get back to it.

428
00:42:10,000 --> 00:42:17,000
I think that's actually one of the bigger parts I like about whether you're doing programming or just working and keeping logs or journals or other things.

429
00:42:17,000 --> 00:42:21,000
I don't know if I can review something. It gives me a little bit of closure.

430
00:42:21,000 --> 00:42:23,000
You know, I can be like, OK, that that upsets me.

431
00:42:23,000 --> 00:42:27,000
Maybe I'm a little sensitive because I didn't feel that was the strongest part of the show either or whatever.

432
00:42:27,000 --> 00:42:30,000
Yeah. Why is that one upsetting me? Why is that the comment that's getting to me?

433
00:42:30,000 --> 00:42:33,000
Yeah, exactly. And then think about it. Give it time. Acknowledge it.

434
00:42:33,000 --> 00:42:37,000
But with the with with me knowing that once I've done that, I'm just going to move on.

435
00:42:37,000 --> 00:42:43,000
I've got other things to do that day. Yeah, that is what sometimes that's what it is sometimes.

436
00:42:43,000 --> 00:42:47,000
Yeah, I agree. So Chatham says we should talk more about hardware.

437
00:42:47,000 --> 00:42:53,000
Well, one of the reasons I was on the show today is because I've been waiting to hear how Mike's experiments with no right.

438
00:42:53,000 --> 00:42:57,000
He was tweeting about it, getting this all hyped. He got himself.

439
00:42:57,000 --> 00:43:03,000
It was it looked like it was a husband wife project to like the two of them were assembling this eGPU with Thunderbolt eGPU.

440
00:43:03,000 --> 00:43:07,000
I'm curious to know like what the sound of it is and all that. I want to know all the details.

441
00:43:07,000 --> 00:43:12,000
Mike, like I live vicariously through Mike's hardware purchases. I know he just gets to do it so much more than we do.

442
00:43:12,000 --> 00:43:16,000
He also I think he might have been pulling my leg. I can't tell what the HomePod stuff.

443
00:43:16,000 --> 00:43:21,000
But he might have got himself a HomePod because Apple dropped the price. Oh, were you tempted?

444
00:43:21,000 --> 00:43:26,000
I I'm I'm I'm still tempted. I don't have the right way into it. I couldn't now I don't think.

445
00:43:26,000 --> 00:43:32,000
Although are there anything that can do open source airplay stuff? Probably. That would be a fun experiment.

446
00:43:32,000 --> 00:43:35,000
If anybody knows tweet tweet Weston at Westpain at Chris L.A.S.

447
00:43:35,000 --> 00:43:39,000
I would love to build a stream like from pulse audio to airplay. And I think there was a bridge once before.

448
00:43:39,000 --> 00:43:43,000
Then the other question would be is with the HomePod accept it or does it only accept airplay to I doubt it.

449
00:43:43,000 --> 00:43:49,000
But that's a particular. You know, I mean, they do sound really nice. Yeah, yeah.

450
00:43:49,000 --> 00:43:53,000
That's the funny thing about it. I mean, I really kind of just I talk about it on the show just to kind of bust balls a little bit.

451
00:43:53,000 --> 00:43:57,000
But they really do sound pretty good. I actually have two of them up at the front of my RV.

452
00:43:57,000 --> 00:44:01,000
And that's what we just that's our RV's sound system. Now we don't even use the built in radio anymore.

453
00:44:01,000 --> 00:44:07,000
That's the funny part, too, is like I wish that I could play because I just don't need I don't want to buy have to buy the whole ecosystem.

454
00:44:07,000 --> 00:44:11,000
But I'm happy to buy a nice product that they make. I have no objection to that. Yeah.

455
00:44:11,000 --> 00:44:18,000
It would be really nice if there was something like airplay that was an open spec that's not not tied to Google.

456
00:44:18,000 --> 00:44:23,000
It's not Bluetooth, but is over your land and is low latency.

457
00:44:23,000 --> 00:44:27,000
So the thing there is like DLNA, but it just kind of sucks. Yeah.

458
00:44:27,000 --> 00:44:34,000
Yeah. The thing that's really nice about airplay is it buffers a little bit so it prevents from network issues.

459
00:44:34,000 --> 00:44:40,000
But your play pause controls and your volume controls are instant and right.

460
00:44:40,000 --> 00:44:43,000
So there's a separate channel that they're sending that stuff. Yeah. Yeah.

461
00:44:43,000 --> 00:44:51,000
And the OS compensates for the buffer in video and video in like video playback and games.

462
00:44:51,000 --> 00:44:58,000
So even though there is a buffer delay, what you see on screen syncs up with what the airplay devices are playing.

463
00:44:58,000 --> 00:45:04,000
So that well, that's what that's what the open spec needs to be able to do, like whatever. That's like the minimum.

464
00:45:04,000 --> 00:45:10,000
Now we need to have that. And then if it could have other stuff like Netflix has dropped airplay because I'm right.

465
00:45:10,000 --> 00:45:16,000
Expanded. Yeah. They said they say airplay has technical limitations and then they clarify the technical limitations are.

466
00:45:16,000 --> 00:45:20,000
It doesn't send the right tracking ID information from the device to the TV.

467
00:45:20,000 --> 00:45:25,000
So Netflix can't track and guarantee they're sending. They claim they can't track and guarantee they're sending the right type of stream.

468
00:45:25,000 --> 00:45:34,000
Is that right? Yay. Platform wars. I know that's the worst part about it feels like the era of open standards is coming to an end.

469
00:45:34,000 --> 00:45:37,000
Not everywhere. Like some actually some of the cloud stuff. There's been enough.

470
00:45:37,000 --> 00:45:44,000
It's low level that complicated that it can be shared. But at the consumer level, it's all services.

471
00:45:44,000 --> 00:45:52,000
It because because services are the new path to revenue, you're going to see the app store of the web at the kind of competition.

472
00:45:52,000 --> 00:46:00,000
Like there was a really super brief period of time when the iPhone first launched that the services were all provided by Google.

473
00:46:00,000 --> 00:46:05,000
The shopping was all provided by Amazon and the hardware and OS were provided by Apple.

474
00:46:05,000 --> 00:46:08,000
Yeah, that's right. And then they all became competitors and that all.

475
00:46:08,000 --> 00:46:13,000
You know, Google's still on there. But, you know, it's all like it's they all are competing now.

476
00:46:13,000 --> 00:46:19,000
Like, you know, Echo does things that the HomePod can't do. And Google Assistant has things like they all have exclusive agreements.

477
00:46:19,000 --> 00:46:24,000
Like there's this whole cross section of features that matrix you have to look at to even figure out which one's the right one.

478
00:46:24,000 --> 00:46:27,000
It doesn't seem like a lot of that is really serving the consumer.

479
00:46:27,000 --> 00:46:32,000
No, and now it's going to be even more of that now that they're all getting into media and video.

480
00:46:32,000 --> 00:46:38,000
Yeah, the Disney stuff, Apple. It's crazy. And Amazon's going so all in on on Amazon Prime Video.

481
00:46:38,000 --> 00:46:42,000
And I mean, they've got to be spending a fortune on Grand Tour alone.

482
00:46:42,000 --> 00:46:48,000
It's funny. I have Amazon Prime Video, but I don't watch it that much just because like the particular TV I have,

483
00:46:48,000 --> 00:46:53,000
their app just as awful. And they don't support Chromecast, which is my other primary streaming platform.

484
00:46:53,000 --> 00:46:57,000
They have the worst apps, all these apps. Really, Netflix is the only one that has a good app.

485
00:46:57,000 --> 00:47:02,000
But the problem with Netflix is it auto plays video and I can't stand it. It gives me anxiety.

486
00:47:02,000 --> 00:47:07,000
Yeah, right. And you can't control your, especially as a broadcaster, your computer's just going to make noise randomly.

487
00:47:07,000 --> 00:47:12,000
No, and sometimes they're like this. Sometimes they're like full fledged trailers, like if Netflix owns the property.

488
00:47:12,000 --> 00:47:20,000
But if it's like, you know, another licensed film, they'll just have like some really shitty like royalty free music playing.

489
00:47:20,000 --> 00:47:23,000
They also manage to pick some of the worst clips sometimes.

490
00:47:23,000 --> 00:47:32,000
Yeah, I feel like that's another aspect of this that we're really going to struggle with is different platforms will have different apps that have different services.

491
00:47:32,000 --> 00:47:36,000
It's really going to be not what we wanted at all.

492
00:47:36,000 --> 00:47:40,000
Thankfully, I mean, we're not going to play that game. It's easy to find all of our stuff, right?

493
00:47:40,000 --> 00:47:47,000
Just coder dot show or jupiter broadcasting dot com, which I would like to say thanks to cheese is looking so show shiny.

494
00:47:47,000 --> 00:47:54,000
Sure is. New dark theme, new logos are up there. Got a new easy link to get in the IRC room, which I can't believe we didn't have up there before.

495
00:47:54,000 --> 00:47:59,000
No, it's great. A new life page looks really good, too. It's all it's all real looking sharp.

496
00:47:59,000 --> 00:48:04,000
Yeah, you can go there and if you want to watch us live, you know, that's the easiest way to do it on Mondays.

497
00:48:04,000 --> 00:48:10,000
Wes, you got to you got to you got to take some credit, though. You did a lot of the work, too. You did a lot of the website work, too.

498
00:48:10,000 --> 00:48:15,000
I mean, there's there was a lot of WordPress to be fought. So we needed many valiant soldiers.

499
00:48:15,000 --> 00:48:19,000
So thank you. I just wanted to get that on air. Thank you, too. That's a nice thing. It's a team effort over here.

500
00:48:19,000 --> 00:48:26,000
Yeah. Yeah, it is. Yeah. So JBLive.TV for the live stream calendar, of course, that's still there.

501
00:48:26,000 --> 00:48:36,000
And it's always a page, though. Just go to the go to the calendar. We tied it up the front page, made it a little faster by taking someone like those embedded widgets off and stuff.

502
00:48:36,000 --> 00:48:41,000
And it means you got to go to the calendar page. But the main page loads faster. So, yeah.

503
00:48:41,000 --> 00:48:46,000
And you know what? We will. We do this every week. Like you said, Mondays, noon-ish Pacific time, if that's your time zone.

504
00:48:46,000 --> 00:48:51,000
Otherwise, that calendar can help you. And, you know, I have a feeling there's going to be Mike back.

505
00:48:51,000 --> 00:48:57,000
So I'm going to grill him on all those things we wanted to hear about. Thank you for stepping in today, though, Chris. This has been a lot of fun.

506
00:48:57,000 --> 00:49:02,000
Yeah, no, no problem. And I hope everything's great with Mike. I hope it's all taken care of.

507
00:49:02,000 --> 00:49:06,000
He'll probably have a story to tell. And you know what? I'll just listen. I'll get to listen to the GPU stuff.

508
00:49:06,000 --> 00:49:10,000
So I'll still be able to live vicariously through Mike. So it still works out for me, too. Thanks for having me.

509
00:49:10,000 --> 00:49:17,000
Yeah, absolutely. And, you know, if you want more of Chris, he and Joe just celebrated episode 100 of Linux Action News.

510
00:49:17,000 --> 00:49:22,000
And it's a great one. So go check that out. LinuxActionNews.com. Thank you, sir. Thank you.

511
00:49:22,000 --> 00:49:28,000
Go check out Wes. I'm TechSnap. TechSnap.Systems. With him and Jim Salter from Ars Technica doing a great show.

512
00:49:28,000 --> 00:49:34,000
That's right. You can also find us both on Twitter. I'm at Wes Payne and he's at Chris LAS.

513
00:49:34,000 --> 00:50:02,000
Thank you for joining us and we'll see you next week.

