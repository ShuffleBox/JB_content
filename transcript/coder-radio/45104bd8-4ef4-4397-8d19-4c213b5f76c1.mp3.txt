This is KOTOR Radio, episode 399 for February 1st, 2021.
Well, hello there. Come on in to Jupiter Broadcasting's weekly talk show, taking a pragmatic look at the art and business of software development and the world of technology.
This episode is brought to you by a Cloud Guru. A Cloud Guru now includes Cloud Playground, Azure, AWS, Google Sandboxes. They don't care. It's all on their credit card, not yours, so you don't have to care.
Get certified, get hired, get learning. A CloudGuru.com. My name is Chris, and joining me is our Doge specialist. It's Mr. Wes Payne. Hello, Wes.
I'm telling you to buy, buy, buy. Wait, no, sell, sell, sell.
Wes, of course, is a accredited financial advisor. I know he's not. And actually, no, he's sitting in for Mr. Dominic today, who is under the weather.
I don't think it's too serious, but we didn't want to overdo it. And so Wes, like a gentleman, offered to step up.
And as a result, we're making it a Doge special, you know, because I don't know if you know Wes, but I made it big today on the stock market.
Oh, did you? Well, you know, I got in early a few days ago on this AMC stock.
You do love a good movie. I do. And I'd love a good movie theater to be able to go back to one day.
So I am happy to say you have tuned in to the right show because my genius will come through to you now via podcast osmosis because I have made, get ready for this.
Are you ready? $13.69. Wow. What are you going to do? I mean, that's like one popcorn at a future AMC.
Not quite. Not quite. Not quite even. Not even quite one popcorn, actually. Wow.
But, you know, I mean, I'm feeling pretty good. It's better than nothing.
It was, you know, really Daniel Fore's fault because he was tweeting about how he figures he's just going to put what he would have spent on movies into a little stock action.
So there you go. That's all we're going to talk about, though. We're not going to talk about stocks today.
It's just I wanted you to be able to listen confidently, knowing that one of the co-hosts on the show is a big roller who you clearly would want to aspire.
And if you've got any hot tips, you know where to send them. Yeah.
Yeah, of course. Yeah. And me and sitting here in my robe.
Also, this is just a bit of a pre-show game killer.
So we've been hanging out on the live stream on Koda Radio, usually about a half hour before we start recording, and I've been recently trying out different game streaming services just to see what it's like to play them and get my hands kind of actually on them and get some experience.
And it seems that Google has announced they are shutting down the internal gaming studios they had for Stadia.
They had two going, two game studios going internally, creating different games, one in Montreal, one in L.A.
And I think my favorite part and the most telling about this whole story, neither had released any games yet.
Can you imagine the amount of money this represents, these two teams like this?
I mean, how many meetings they likely had? Right.
You're spinning this whole up, you know, hiring people, you're finding support staff, you're getting organized, you're starting work on projects.
Well, and you know, they do OKRs, too.
So, you know, they're setting up their quarterly goals, making sure that they meet their key performance indicators, and they may even be filling out their OKRs in like their manager meeting.
And then just one day, done, just all done.
And it makes you wonder, where is Google going with this?
And I see this one thread over and over again.
And this, I think, is where I wanted to go with this with you.
Google has screwed their brand because no one thinks they're going to stick with anything now.
And now that conception about Google has struck them right where it hurts when they're trying to launch a new services initiative.
You know, it's all about services.
And Stadia was a Google service like nobody can do.
We're going to make games linkable on the Web.
And it's really not getting their attention.
It's really not getting their focus.
The new Chromecast, the new Google TV came out without Stadia support.
How has that even happened?
It still doesn't have it.
Now you see them spinning down this game studio here.
And you have to think people see that like you and I and go, oh, this only reaffirms the belief that Google just eventually kills everything.
And I'm not going to go set up and spend a bunch of money on Stadia where you have to buy the games at full price when I know they're just going to shut this down.
Best case scenario for Stadia users is that one day Google gives them store play credits.
It's kind of a classic example to where from all accounts, like the technology behind it is really neat.
They've done some some good engineering work to make this all happen.
I mean, I know for a while like Cyberpunk was running, maybe not currently, but at least at the start for a while, it was like the best place to play Cyberpunk.
And there's a lot of Linux powered tech in there that I love.
But they just don't seem to have the organizational support or structure inside.
They didn't start out as saying we're going to use this to like help power other companies who are making games or, you know, run the servers for like, hey, you want to have a new online multiplayer game.
Stadia is ready to go. We'll get you integrated like this will work.
They were also doing this like first party. We're making games. We're going to compete.
And there's just there's no way that the current incarnation of Google has the organizational buy off or staying power inside to make that happen.
Yeah, that's why I made the point of the Google TV device coming out, because it seems like something like that, a product that's pretty, pretty high, high profile product.
It doesn't launch and lack support for your game streaming service unless management just really couldn't care less.
But I also think the other aspect of this is it only reaffirms that that brand association that Google eventually kills everything.
And that seems like long term, it's going to hurt adoption for Google.
And I think even beyond the kills everything, it's sort of, you know, I get the idea of Google is a big company or even Alphabet, you could say, and that you're going to spin up things, not all of which work, not all of what you keep.
But I think what the Stadia thing is so telling about is that they are not able to give enough runway to even see it's going to get killed before it's even had a chance to be successful on any meaningful timescales.
I mean, we know Google has a ton of money for the invested more than they'd like in this.
But if you're going to kill it and it hasn't even been like three years or you haven't even tried publishing an internal game, doesn't make me think that you have the actual capability to make any long bets.
The other one I've been experimenting with on the pre show has been GeForce Now streaming and you see them making deals with Steam.
You can think your Steam library over to GeForce Now.
If you become a member, a paying member, you get free access to cyberpunk.
It seems just like they're willing to make more deals.
They're willing to kind of come more to where the gamers are at and try to meet them on the library compatibility front.
It's a different tech.
But anyways, thought it was worth discussing with you just because it doesn't really touch the main show, but it does touch the pre show.
And you would think Google could have done a really good job of that if they just were happy enough being in the background, being in the business to business role of enabling game technologies, leveraging their experience in like cloud and data center technologies.
If they'd just done that and had less giant goals of being a game company, this might have been better from the start.
Yeah, they really you're right.
They really went all in with the studios.
They really thought they were going to be a modern game company.
It's kind of adorable.
Oh, good.
Not unless you put ads on it.
That's the only way you stay focused.
You know that Thomas wrote in.
We had a couple of emails this week about testing, and I kind of wanted to just summarize a lot of them with a couple.
Thomas wrote, he said, I have a different take on testing.
Hey, guys, I'm pretty new to the show.
I started listening with the reboot.
I love hearing the coder focused radio.
I had to write in to provide a different opinion on testing.
I work at a web based company with around 200 engineers.
My team of three engineers work on Ruby on Rails as a code base.
We use our spec to write the units and with some integration level tests that we run through our CI system for every branch.
Part of our review process is to get the green CI check before merging, as one would expect.
We have thousands of small unit tests for our service classes, helper methods, models and most controllers.
We've started using view components so that most of our front end code can be tested.
I find these invaluable as part of the development process.
Every PR is a combination of code and tests that go along with it.
These tests take about 10 to 12 minutes to run in CI.
And without testing, I find the code that's written to be far less flexible in a dynamic language like, say, Python or Ruby.
I couldn't imagine putting anything into production without some level of testing.
Now, this was in a conversation that I think you and Mike have had, too, when you were on the show.
And that is sort of Mike's kind of resistance to traditional unit testing where you're writing tons and tons of tests.
I think he's a fan of high level testing and kind of a balance there combined with QA.
But we do get a few people like Anabu who writes in that says, if you use it in a certain way, you combine it with your CI system.
You kind of integrate it with your process.
And it depends on the language you're using, but it can actually be extremely beneficial.
Westpain, can you believe we are in this debate?
Like, I'm actually surprised that we've somehow found ourselves in the middle of, is testing worth it?
Because it just seems like, yes, of course, it just depends.
I mean, that's what we're having a hard time really nailing down, is that depends part.
Yes, it's always the devil in the details.
I think by and large, modern, you know, quote, unquote, best practices, which can be a problematic term in and of itself.
But I think by and large, most software engineers these days think that tests are a good idea.
Now, what kind of tests, how many, how much do you care about things like code coverage?
That's where you get into some nitty gritty details.
I also think there's different types of projects, and this might be part of where Mike's perspective is coming from,
is, you know, he's doing a lot of development for folks or making new products.
And I think especially like when you're just spinning up a new service, a brand new API,
it can be a little harder to do maybe a more traditional test first development
when you don't really want to write your test before you've nailed down your design
because you haven't figured out what those contracts are yet.
Versus say you're working in an enterprise shop on a big team,
you're handed a already groomed JIRA card that sort of lays out what your acceptance criteria are.
You've got a good idea of the bug you're fixing or the feature you're adding
and how to tell if that's right and you're on the right track.
That makes it pretty easy to be like, all right, I'm going to start writing some tests to prove this bug exists,
or I'm going to write some tests to make sure that the API input, you know, for this input, the output is what I need.
But if you're experimenting and trying to figure out what's the right way to actually make something new work,
maybe the testing is not your primary focus at the start.
Yeah, that makes total sense.
And I think also from Mike's point, you know, UI testing is just hard.
I think some of the stuff like a more data focused, a more functional pipeline sort of view,
like some of the tools that exist in the React ecosystem can make that easier.
But at the end of the day, when you're relying on a web browser, it's complicated.
Yeah, and I take your point, too.
Like it really also part of that it depends disclaimer is it depends on your team and what your team is doing.
So I'm curious for you in hashtag day job, how does testing kind of manifest itself?
Is it something you have much interfacing with?
Is it something you are? Are you writing unit tests? Are you doing any of this testing?
Is it something teams of people are responsible for?
How does it work in the organization that you work for?
Yeah, sure. You know, currently I'm on a pretty small development team.
We don't have a dedicated QA team or anything like that,
but there is a customer support part of the organization that sometimes acts that way.
Sure.
But no, tests are pretty much expected.
Now, I think there's a common thing in the industry that half the time you know that when you send a piece of code out,
you know, a merge request, a pull request in for review, the reviewer is probably not looking at your tests.
It's really a lot in a review process to get on all the state in your head of both the code changes itself
and then did they cover all these cases in their tests.
But tests are at least expected.
You want to see that you've made some changes in the test directory that you've actually tried to test some of these things.
Personally, you know, we had some on that first feedback item mentioned unit tests and some integration tests.
This can vary a lot too.
Sort of depends on your style.
There's different thoughts on this personally, especially because I'm making a lot of APIs right now.
I kind of go from the outside in.
I try to do as much integration and sort of edge to edge testing that I can to make sure that I've got tested what the customer is going to do.
Because the last thing I want is for a customer to run into a bug when I could have caught that just by sending a request with some weird Unicode characters or something in it.
And then unit tests are still very important, but the kind of way I see it is like how do you verify correctness on the outside?
You know, a black box test.
Those are nice to have, especially because you can often then reuse those as, you know, plug them into your CI system or just run it manually and use it to verify stuff in staging or maybe even production.
Where unit tests I think are really helpful is in verifying correctness and breaking those down.
So that if you have some failure at the edge in your integration tests, if you have unit tests, that can actually help you go and isolate like, OK, well, now why did that break?
Which of my assumptions is no longer valid?
But where that gets tricky is you don't necessarily want, I think this is some of what Mike was complaining about.
I know I've had folks, you know, friends or coworkers, especially coming from maybe Java places where you're just writing tests that are duplicating.
You're basically writing a second time exactly what you wrote the first time and saying, I expect exactly this to happen.
You're basically just testing all of the implementation details.
That's a pain anytime you have to go maintain it, update it, and it doesn't necessarily test that it's actually the correct output.
I love getting insights like that because I've had very little hands on experience with development teams of various sizes like you have.
Like I've had a couple of practical client jobs where I was part of the development team as part of being infrastructure.
But you get you have a lot more hands on experience and a lot more current.
So that's one of the great things about having you on from time to time, Wes.
Before we go over looking at it, it's stuff that gives us insights into how things work.
Slack has done a postmortem of the outage that they had on, I think it was the 4th of January.
And they wanted to narrow down right away when they had an outage, what was causing it.
So the first thing they did was roll back recent changes they'd made.
I think that makes a lot of sense.
It does, although, you know, that's already, I think, a sign of some organizational maturity.
It's not every organization that can immediately identify what those are or has the ability to quickly roll them back.
Yeah, and just roll them right back. Yeah, exactly.
But they said that it didn't really solve the issue. We'll get to that, what that was.
They started bringing people in from like their infrastructure teams to figure what was going on and debug the situation and why they had a lack of usual dashboards and alerts and performance information.
They still had access to various internal consoles and status pages and some command line tools and logging infrastructure.
And the back end metric collection and saving was still happening so they could like go query them directly.
But of course, that doesn't work nearly as well as just looking at a dashboard with pre-built queries.
So it seemed like the infrastructure was generally up, but there was just signs of widespread network degradation.
So they escalated up to AWS and they talk about it here like they also notice it started happening when they start to have patterns of mini peaks, as they call them, at the top of each hour and half hour as reminders.
And other automation triggers send messages on Slack. They see a noticeable increase in traffic.
Oh, of course. Right. And that's what started like when this network issue was happening and then this this kind of natural peak, it all kind of started rolling downhill from there.
The snowball effect. It did turn out that AWS was having network issues.
But the thing that's funny about this story is they had a couple of systems that tried to automatically scale up infrastructure or to save money, scale down infrastructure.
And that bit them a couple of times because at one point they were scaling up a ton of infrastructure, but that infrastructure wasn't getting properly provisioned because of another outage.
And at another point, the one that I was chuckling about before the show, they had engineers in that were directly querying the metrics database so they could try to get, you know, some information of what's going on since they don't have the dashboard.
And their sessions kept getting dropped. They'd be in the middle of like doing a query and their session would get dropped.
Well, the system, a different system, which was lacking proper CPU utilization information and acted like CPU usage was down, started deep provisioning systems.
So while one system was trying to provision and couldn't keep up with the load, another system was going behind and deep provisioning other boxes, just dropping connections.
Oh, wow.
Yeah. Yeah. So you could see how the system can kind of just get a little way with itself.
But they, you know, they have the right tools to rein it all in.
That's what I took away from this is they repaired this flaw in their provisioning service and they can basically run their system under capacity until they need that capacity and then spin that stuff up.
And it generally works for them. But when the AWS network was degraded and the systems couldn't talk appropriately, they had weird results.
And it's a fascinating read if you're into that kind of stuff and, you know, want to think about these complicated systems and how to build them correctly.
I think that's just it. It's a good reminder that in the cloud era, we take some of this stuff for free, but a lot of the stuff we depend on is just horribly complicated.
And a lot of it is new, like we are constantly evolving software architectures and updates and evolving how your integrations with your backend cloud works.
So as you adopt new features, as you change things or also in the cloud era, as Amazon changes things under the hood behind the scenes, there's just an exponential growth of places where things can change and go wrong.
I think it's interesting in here, too. They talk about just because of that, you know, they've had that experience.
They talk about how they built in a panic mode, which balances request across all instances and sort of like this failsafe balancing mode.
And they also have a circuit breaker mode that kind of breaks things out of a loop and gets gets them back up and running the way they want.
That's all explained in there. But so they built themselves little escape hatches that they could pull the lever on if they had to, because this infrastructure is, like you were just saying, so damn complicated.
And there's so many areas where things can go wrong. They needed a circuit breaker and a panic mode.
Yes. And I like that they acknowledge here that monitoring is one of our most critical services.
It's how we know whether our user facing services are actually working or not.
And that's sort of the I think it's like the flip side of testing.
You know, it's the same answering the same question of like, how do you know that all this code you're running is actually doing anything?
Business?
Yeah. How do you know your business is actually up and running and providing like the services?
And like what you were saying, too, earlier, it's like you want to know this stuff before your customers do.
In this case, AWS, it took them a little bit to clue into what was going on.
You know, Slack started noticing it like it took a little bit. It would have been nice if AWS could have been a little bit quicker on that one.
I wonder if they'll be posting their postmortem.
It's always weird to now, you know, in these days, it used to be that maybe you could just you had to go learn how the hardware works or suddenly you're debugging kernels and stuff.
But often on AWS these days or whatever cloud, you don't have that option.
At some point, you just hit the limits of what you can see and you have to go and hope that AWS will answer your support ticket and give you more info.
Although in some cases, I'm sure that happens because, you know, they pay some big bucks for their hosting.
Yeah, that's very true.
Linode.com slash coder. This is our hosting and you want to talk about support.
Ain't nobody got support like Linode.
If you've got a five dollar a month rig or if you're like a slack size company, you're talking to a real human being.
It's the same kind of support for every customer.
That means that if you got a small business like I do and you run your services on Linode like I do, I have confidence that if anything ever goes a little sideways,
I'm going to get really good human level support over the phone or however I want to do it.
Not only have I heard story after stories from people that listen to this show, but it's a commitment that Linode makes.
And it's a commitment they made to me in the conversation that I had with them before they became a sponsor.
It's something they take really seriously.
They started in 2003 as one of the first companies in cloud computing, three years before AWS.
So they really have this dialed in now and they've got 11 data centers around the world.
So you pick the region that works best for you and your clients or customers.
It's something we kind of strategically do some of our back end stuff.
We actually deploy in Linode's California data center because it's like Wes and I interacting with stuff.
But the stuff that the audience is going to interact with will deploy maybe on the East Coast.
So it's friendly for our friends across the pond to, you know,
we'll kind of like think about what user group do we think is going to be using this and we can deploy in that area.
And every machine is just crazy fast, super fast SSDs, 40 gigabit connections into the hypervisor, screaming fast Linux boxes.
I mean, Linode is really dedicated to offering the best virtualized cloud computing.
If it runs on Linux, it runs on Linode.
I recently set up a Rust gaming server.
No, no, not rust the language, the game.
And Linode makes this ridiculously easy.
They have a couple other ones on there, too, like a handful like CS goes on there.
But Ark is on there and rust and you get all the options for your rust server to set your whatever kind of parameters you might want.
And then it deploys it on Debian and it's up and running and it gives you the IP.
And they've got an article that walks you through how to connect the rust client to your custom server and you're off and running.
So if you want to run something like a rust server or you want to run the back end,
self-hosted communications infrastructure for your business, Linode can do it.
They can do it all.
And you can get a $100 credit when you go to Linode.com slash coder.
That's some serious money to play around with our object storage or build a really powerful box or maybe create yourself a VPN.
Go to Linode.com slash coder.
Get that $100 60 day credit and you support the show.
Linode.com slash coder.
Do you remember when Mike and I and you would talk about bots a lot?
We used to talk about bots a lot.
All the time.
Well, Microsoft hasn't stopped talking about bots.
And in December, they received a patent from the U.S. Trademark and Patent Office that outlines a process to create a conversational chatbot of a specific person using their social data.
The patent says the chatbot could potentially be inspired by friends or family members who are deceased, which is actually like a direct plotline episode from a big Black Mirror episode from Netflix.
But according to this new patent from Microsoft, images, voice data, social media posts, emails, written letters,
they all could be used to create or modify a specific index and a theme of a specific person's personality.
From there, engineers use that index to train a chatbot to converse like that person with you, even if they are already dead.
Oh, yeah. Goes on to say the application could also don the likeness of your dead loved one in a 2D or 3D model and utilize their voice while talking to you.
Oh, boy.
I mean, yeah, deep, deep fake version of yourself.
You know, you and I have joked about how I'd love to be able to download my brain into a computer and have it just do the computer stuff like you don't need it to be a full rich version of myself.
It just needs to be like the decision making analytical version who could respond to emails, messages, manage a calendar and make the decisions I would make.
If my personality could be used as a template, it wouldn't actually be my essence.
The index of my personality, if that could be used to influence something that's running on my machine, maybe it's an open source, self-hosted personality bot or maybe it's some horrible thing from Amazon.
But something that runs on your computer that uses your personality as a baseline to then make decisions, I think would actually be super useful.
Right. You could say sort of like, Chris Bot, send pleasantries to all of my family members.
Right. And it just goes on Amazon, does the ordering, interfaces with their API.
There'd be certain decisions or actions where you'd want it to consult with the real you first.
Maybe tuning that would be hard, but there are a lot of stuff that I just have to do that's sort of mechanical in nature.
But and if you trained it, if this thing worked properly, it would be managing your inbound electronic communications.
So you could have the only thing that notifies you is Chris Bot because, you know, Chris Bot has made the decision that this needs to be surfaced to the actual human to make a decision.
And so I interact with Chris Bot and then they respond back to the message or whatever.
That would probably help, too, if you started using it, you know, before you're dead.
You get in the good feedback cycle messages where it's like not able to actually figure it out.
You know, that goes to you and then it's still learning from whatever your eventual response is.
Do you think this is a marketing hype BS?
I mean, this is coming from a patent, right?
This isn't a press release. This is a patent.
And they may just be patenting something that they've got kind of a rough idea about.
But I've always speculated this actually does seem possible.
I think it makes sense. I mean, you know, Microsoft's big into the old AI space, machine learning, training stuff.
I know I saw what they have. They got some deal to have access to GPT-3, for instance.
So it makes sense that they have teams of people thinking about this.
I bet you the dead aspect is just that it's strategic in patent applications to try to be as general as possible.
If it's possible, this could impact that.
Let's include it in an application on the after onset. That all gets okayed.
Arizona State University School of the Future Innovation Society's professor, the clinical assistant said,
that's quite the title, wow, quote, technically we can recreate anyone online given enough data.
I suppose the question is, I can certainly see it useful in the assistant part.
Is there a market for fake dead loved ones?
Maybe. Maybe. But it doesn't. I don't know if it seems healthy to me.
No.
I don't know that I would want that.
The rough, without really any spoilers, plotline of the Black Mirror episode is one of the couples is lost in a relationship.
It's a new kind of peak relationship and one of them is lost and a friend comes along and signs them up for this service that does this online indexing.
And then she starts a chatbot session with him and it's a chat and she can upgrade to voice and all that kind of stuff.
And you can imagine where it goes from there.
It's weird in a sense because if it's capable, we're going to have to ask ourselves if this is something we really want to enable.
Because, yeah, you're right. It's going to make it hard to move on.
The whole thing is really strange, especially when you combine deep faking voice and video.
Now, do you think you could get into some weird legal quandaries, too, of what if your AI bot gets input like when they're figuring out your will?
Can the AI bot object when your family, your sister you no longer talk to wants to claim rights to that chair she always wanted?
Imagine this, too. Imagine your AI bot being used to prove that you've lost your mental faculties or something because the AI bot scan will be the baseline.
And then there'll be other scans it could do later.
It'll be like, oh, yeah, sorry, Mr. Fisher. Yeah, you clearly have dementia or something.
We have to get you off the air.
You're now the backup, the hardware backup for the bot.
Right. Yeah. And the bot has an active role in determining the state of my health or something.
I don't know. I think we could potentially be going down a route where people eventually got access to deep fakes.
People could get access to bots that could index people online and synthesize some of this.
The other part that's upsetting is, as like so many things and as usual, probably going to get this technology before we've sorted out anything about data ownership or permissions or any of that.
Yeah. Well, I mean, it happened to Jordy, right?
In the future, he creates a holographic engineer, Leah Broms, and there was no protection on her likeness and the personality was off a little bit.
The AI simulated personality was off because the profile at the time she was indexed didn't include that she was married.
You remember, you know what I'm talking about. This stuff happened.
Yeah, it did include that she was real into Jordy.
That didn't seem to be an accurate detail.
That's right.
Okay, so the register wins for the best hoopla title of the week.
You know, we always try to cover a little bit of development hoopla for you guys just so we always get a little bit of conversation about what's going on in the world.
And this one from the register really nails it.
Quote, Pearl clutching hijackers appear to have seized control of thirty three year old programming languages dot com domain.
And they're referring to pearl dot com.
That's why the pearl clutching in there is extra clever and appears a few days ago.
Pearl dot com was hijacked.
A warning went up on pearl dot org's infrastructure weblog overnight, notifying users that pearl dot com had now directed to a parking site and advise against visiting there as there were some signals that it may be related to sites that have distributed malware in the past.
Now, we want to make it clear here. Pearl dot org was just fine.
But apparently what happened is just like a classic move.
Somebody came in and hijacked a domain that expired or was a compromised domain register account, possibly.
Don't know for sure yet, but it doesn't look like something significant, like a server wasn't taken out or something like that.
It just looks like some DNA shenanigans.
Apparently it's maybe still going on.
I just get a blank page that tries to load a whole bunch of JavaScript.
I can't tell what it does.
So I just let it run.
Maybe don't go to pearl dot com right now.
It looks like the domain expired on January 26th, but then was extended like somebody renewed it until January 26th, 2031.
So whoever has it now, they're going to have it for a while.
And, you know, that sucks because people are trying to learn about Pearl that, yes, they are still out there.
They may not know to go to the dot org.
This may actually screw a few people who are just trying to learn how all this works.
You hate to see it.
Perhaps one interesting tidbit here is I guess we've learned that the register is built on Pearl.
And I don't think I'm surprised.
I didn't realize that.
That is a nice little nugget right there.
I just want to say thank you very much to our QA team, codercua.co if you'd like to become a member.
You get access to the quarterly report.
There are two of them now.
You support the show and you get a limited ad feed, still full production, just limited ads.
And we really wanted to say thank you.
Just want to take a moment here in the show specifically and say I really appreciate everybody who went over there and signed up at codercua.co.
Thank you to our members.
You the best.
Well, before we get out of here, Wes, I wanted to just say thank you very much for coming on the show and filling in for Mr. Dominic when he's under the weather.
Thanks for having me.
I've been meaning to get you on.
But, you know, now you're doing Linux Action News.
Of course, you're still doing Linux Unplugged.
So it just seems like because you're doing a show on Sunday and you're doing a show on Tuesday, it doesn't really seem fair to ask you to do a show on Monday.
But then when Mike was out, we had an excuse to do it.
Well, we'll just have to find another time that works, too, because that way we might get the Coder three-way going.
Classic Coder three-way.
The classic, yeah.
Right.
Right.
And then, you know, you can hang out live, too.
Wes is often in the chat room, too, when we're doing the live shows.
And maybe one day we'll have a future new, like, live page that's all powered by some crazy backend service that Wes and I have concocted.
There's always discussions.
That's one of the things that's a lot of fun about podcasting with Wes is we're always kind of coming up with new ways to do the plumbing.
Like our membership system, a lot of that has been plumbed to try to make that as straightforward and as automatable and reproducible as possible.
Because any time I'm directly involved in the publishing process, there's usually a mistake.
You know, usually I typo something or I upload the wrong MP3.
That's my favorite right now.
That's how we know you haven't yet been replaced by your bot.
You're making those human mistakes.
Right.
Right.
But we are slowly replacing some of the backend stuff with bot-like activity.
But we actually just get a tremendous amount of value and mileage out of Hugin.
Is that how you say it, Wes?
Oh, Hugin, I think.
Probably just Hugin.
We say Hugin, but it's probably Hugin or something like that.
Because I think it's a Norse god or...
Yeah.
Yeah.
And this is something that we just don't really mention super often.
So I wanted to give it a mention here on the Coder Radio program because I think it could solve some problems for you guys.
It's a system for building agents that perform automated tasks for you online.
So they can read, say, a web page or an RSS feed.
In our case, they'll watch for events and then it'll take actions on your behalf.
It's like your own version of if this, then that, that you can self-host and does like way more cool stuff.
And we have been using it as a tool to kind of not only just plug different systems together,
but even just kind of surface like notifications to a Slack channel that, hey, this episode has just been posted, just even that kind of stuff.
Yeah.
They've got a lot of nice sort of built-in stuff already, like following an RSS feed and generating events.
But also it's easily extendable.
They have ways to just run like a shell script.
They've got ways to make generic like web hook calls to other APIs.
Or you can just do it totally custom and it's all written in Ruby.
So just write yourself a Ruby module and away you go.
Hey-oh, that may or may not be just what happened over here.
Yes.
I'll put a link to that in the show notes.
It's H-U-G-I-N-N.
And their slogan, which I love, is your agents are standing by.
So, yeah, go over there and check that if you need something like that on your land that you want control over that is honestly more powerful than if this and that.
It might not have some of the same integrations, but it lets you do a lot more.
Go wish Mike the best and all the health.
He's at Dumanuco on Twitter.
Wes, you're over there.
That's right. I'm at Wes Payne.
How about that?
I'm at Chris LAS.
The whole network is at Jupiter Signal.
And this here podcast is at Coder Radio Show, which you can follow for release announcements, show news, that kind of stuff.
We do this here show live.
Coder Happy Hour starts at 5 p.m. Pacific, 8 p.m. Eastern at shabbylive.tv.
You can also check Jupiter.Tube.
It's a new PeerTube instance we're working on, Jupiter.Tube.
You may find full live recorded versions of this live stream up there from time to time.
It's something Wes and I are working on right now.
That's Jupiter.Tube for that.
It's like our own YouTube in a box.
Check that out.
And links to everything we talked about today are Coder.Show slash 399.
Thanks for joining us.
See you right back here next week.
