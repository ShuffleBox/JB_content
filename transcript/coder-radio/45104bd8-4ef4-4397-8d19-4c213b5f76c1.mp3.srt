1
00:00:00,000 --> 00:00:07,000
This is KOTOR Radio, episode 399 for February 1st, 2021.

2
00:00:15,000 --> 00:00:24,000
Well, hello there. Come on in to Jupiter Broadcasting's weekly talk show, taking a pragmatic look at the art and business of software development and the world of technology.

3
00:00:24,000 --> 00:00:34,000
This episode is brought to you by a Cloud Guru. A Cloud Guru now includes Cloud Playground, Azure, AWS, Google Sandboxes. They don't care. It's all on their credit card, not yours, so you don't have to care.

4
00:00:34,000 --> 00:00:45,000
Get certified, get hired, get learning. A CloudGuru.com. My name is Chris, and joining me is our Doge specialist. It's Mr. Wes Payne. Hello, Wes.

5
00:00:45,000 --> 00:00:49,000
I'm telling you to buy, buy, buy. Wait, no, sell, sell, sell.

6
00:00:49,000 --> 00:00:58,000
Wes, of course, is a accredited financial advisor. I know he's not. And actually, no, he's sitting in for Mr. Dominic today, who is under the weather.

7
00:00:58,000 --> 00:01:06,000
I don't think it's too serious, but we didn't want to overdo it. And so Wes, like a gentleman, offered to step up.

8
00:01:06,000 --> 00:01:15,000
And as a result, we're making it a Doge special, you know, because I don't know if you know Wes, but I made it big today on the stock market.

9
00:01:15,000 --> 00:01:20,000
Oh, did you? Well, you know, I got in early a few days ago on this AMC stock.

10
00:01:20,000 --> 00:01:25,000
You do love a good movie. I do. And I'd love a good movie theater to be able to go back to one day.

11
00:01:25,000 --> 00:01:36,000
So I am happy to say you have tuned in to the right show because my genius will come through to you now via podcast osmosis because I have made, get ready for this.

12
00:01:36,000 --> 00:01:44,000
Are you ready? $13.69. Wow. What are you going to do? I mean, that's like one popcorn at a future AMC.

13
00:01:44,000 --> 00:01:52,000
Not quite. Not quite. Not quite even. Not even quite one popcorn, actually. Wow.

14
00:01:52,000 --> 00:01:55,000
But, you know, I mean, I'm feeling pretty good. It's better than nothing.

15
00:01:55,000 --> 00:02:05,000
It was, you know, really Daniel Fore's fault because he was tweeting about how he figures he's just going to put what he would have spent on movies into a little stock action.

16
00:02:05,000 --> 00:02:09,000
So there you go. That's all we're going to talk about, though. We're not going to talk about stocks today.

17
00:02:09,000 --> 00:02:18,000
It's just I wanted you to be able to listen confidently, knowing that one of the co-hosts on the show is a big roller who you clearly would want to aspire.

18
00:02:18,000 --> 00:02:23,000
And if you've got any hot tips, you know where to send them. Yeah.

19
00:02:23,000 --> 00:02:27,000
Yeah, of course. Yeah. And me and sitting here in my robe.

20
00:02:27,000 --> 00:02:31,000
Also, this is just a bit of a pre-show game killer.

21
00:02:31,000 --> 00:02:48,000
So we've been hanging out on the live stream on Koda Radio, usually about a half hour before we start recording, and I've been recently trying out different game streaming services just to see what it's like to play them and get my hands kind of actually on them and get some experience.

22
00:02:48,000 --> 00:02:55,000
And it seems that Google has announced they are shutting down the internal gaming studios they had for Stadia.

23
00:02:55,000 --> 00:03:02,000
They had two going, two game studios going internally, creating different games, one in Montreal, one in L.A.

24
00:03:02,000 --> 00:03:09,000
And I think my favorite part and the most telling about this whole story, neither had released any games yet.

25
00:03:09,000 --> 00:03:14,000
Can you imagine the amount of money this represents, these two teams like this?

26
00:03:14,000 --> 00:03:17,000
I mean, how many meetings they likely had? Right.

27
00:03:17,000 --> 00:03:24,000
You're spinning this whole up, you know, hiring people, you're finding support staff, you're getting organized, you're starting work on projects.

28
00:03:24,000 --> 00:03:26,000
Well, and you know, they do OKRs, too.

29
00:03:26,000 --> 00:03:37,000
So, you know, they're setting up their quarterly goals, making sure that they meet their key performance indicators, and they may even be filling out their OKRs in like their manager meeting.

30
00:03:37,000 --> 00:03:41,000
And then just one day, done, just all done.

31
00:03:41,000 --> 00:03:44,000
And it makes you wonder, where is Google going with this?

32
00:03:44,000 --> 00:03:47,000
And I see this one thread over and over again.

33
00:03:47,000 --> 00:03:52,000
And this, I think, is where I wanted to go with this with you.

34
00:03:52,000 --> 00:03:58,000
Google has screwed their brand because no one thinks they're going to stick with anything now.

35
00:03:58,000 --> 00:04:05,000
And now that conception about Google has struck them right where it hurts when they're trying to launch a new services initiative.

36
00:04:05,000 --> 00:04:07,000
You know, it's all about services.

37
00:04:07,000 --> 00:04:10,000
And Stadia was a Google service like nobody can do.

38
00:04:10,000 --> 00:04:12,000
We're going to make games linkable on the Web.

39
00:04:12,000 --> 00:04:15,000
And it's really not getting their attention.

40
00:04:15,000 --> 00:04:17,000
It's really not getting their focus.

41
00:04:17,000 --> 00:04:22,000
The new Chromecast, the new Google TV came out without Stadia support.

42
00:04:22,000 --> 00:04:23,000
How has that even happened?

43
00:04:23,000 --> 00:04:25,000
It still doesn't have it.

44
00:04:25,000 --> 00:04:28,000
Now you see them spinning down this game studio here.

45
00:04:28,000 --> 00:04:34,000
And you have to think people see that like you and I and go, oh, this only reaffirms the belief that Google just eventually kills everything.

46
00:04:34,000 --> 00:04:41,000
And I'm not going to go set up and spend a bunch of money on Stadia where you have to buy the games at full price when I know they're just going to shut this down.

47
00:04:41,000 --> 00:04:47,000
Best case scenario for Stadia users is that one day Google gives them store play credits.

48
00:04:47,000 --> 00:04:52,000
It's kind of a classic example to where from all accounts, like the technology behind it is really neat.

49
00:04:52,000 --> 00:04:56,000
They've done some some good engineering work to make this all happen.

50
00:04:56,000 --> 00:05:02,000
I mean, I know for a while like Cyberpunk was running, maybe not currently, but at least at the start for a while, it was like the best place to play Cyberpunk.

51
00:05:02,000 --> 00:05:05,000
And there's a lot of Linux powered tech in there that I love.

52
00:05:05,000 --> 00:05:11,000
But they just don't seem to have the organizational support or structure inside.

53
00:05:11,000 --> 00:05:20,000
They didn't start out as saying we're going to use this to like help power other companies who are making games or, you know, run the servers for like, hey, you want to have a new online multiplayer game.

54
00:05:20,000 --> 00:05:24,000
Stadia is ready to go. We'll get you integrated like this will work.

55
00:05:24,000 --> 00:05:28,000
They were also doing this like first party. We're making games. We're going to compete.

56
00:05:28,000 --> 00:05:36,000
And there's just there's no way that the current incarnation of Google has the organizational buy off or staying power inside to make that happen.

57
00:05:36,000 --> 00:05:46,000
Yeah, that's why I made the point of the Google TV device coming out, because it seems like something like that, a product that's pretty, pretty high, high profile product.

58
00:05:46,000 --> 00:05:53,000
It doesn't launch and lack support for your game streaming service unless management just really couldn't care less.

59
00:05:53,000 --> 00:06:02,000
But I also think the other aspect of this is it only reaffirms that that brand association that Google eventually kills everything.

60
00:06:02,000 --> 00:06:05,000
And that seems like long term, it's going to hurt adoption for Google.

61
00:06:05,000 --> 00:06:18,000
And I think even beyond the kills everything, it's sort of, you know, I get the idea of Google is a big company or even Alphabet, you could say, and that you're going to spin up things, not all of which work, not all of what you keep.

62
00:06:18,000 --> 00:06:29,000
But I think what the Stadia thing is so telling about is that they are not able to give enough runway to even see it's going to get killed before it's even had a chance to be successful on any meaningful timescales.

63
00:06:29,000 --> 00:06:33,000
I mean, we know Google has a ton of money for the invested more than they'd like in this.

64
00:06:33,000 --> 00:06:44,000
But if you're going to kill it and it hasn't even been like three years or you haven't even tried publishing an internal game, doesn't make me think that you have the actual capability to make any long bets.

65
00:06:44,000 --> 00:06:51,000
The other one I've been experimenting with on the pre show has been GeForce Now streaming and you see them making deals with Steam.

66
00:06:51,000 --> 00:06:55,000
You can think your Steam library over to GeForce Now.

67
00:06:55,000 --> 00:06:59,000
If you become a member, a paying member, you get free access to cyberpunk.

68
00:06:59,000 --> 00:07:02,000
It seems just like they're willing to make more deals.

69
00:07:02,000 --> 00:07:08,000
They're willing to kind of come more to where the gamers are at and try to meet them on the library compatibility front.

70
00:07:08,000 --> 00:07:09,000
It's a different tech.

71
00:07:09,000 --> 00:07:16,000
But anyways, thought it was worth discussing with you just because it doesn't really touch the main show, but it does touch the pre show.

72
00:07:16,000 --> 00:07:28,000
And you would think Google could have done a really good job of that if they just were happy enough being in the background, being in the business to business role of enabling game technologies, leveraging their experience in like cloud and data center technologies.

73
00:07:28,000 --> 00:07:34,000
If they'd just done that and had less giant goals of being a game company, this might have been better from the start.

74
00:07:34,000 --> 00:07:35,000
Yeah, they really you're right.

75
00:07:35,000 --> 00:07:37,000
They really went all in with the studios.

76
00:07:37,000 --> 00:07:41,000
They really thought they were going to be a modern game company.

77
00:07:41,000 --> 00:07:42,000
It's kind of adorable.

78
00:07:42,000 --> 00:07:44,000
Oh, good.

79
00:07:44,000 --> 00:07:45,000
Not unless you put ads on it.

80
00:07:45,000 --> 00:07:47,000
That's the only way you stay focused.

81
00:07:47,000 --> 00:07:50,000
You know that Thomas wrote in.

82
00:07:50,000 --> 00:07:55,000
We had a couple of emails this week about testing, and I kind of wanted to just summarize a lot of them with a couple.

83
00:07:55,000 --> 00:07:58,000
Thomas wrote, he said, I have a different take on testing.

84
00:07:58,000 --> 00:07:59,000
Hey, guys, I'm pretty new to the show.

85
00:07:59,000 --> 00:08:01,000
I started listening with the reboot.

86
00:08:01,000 --> 00:08:03,000
I love hearing the coder focused radio.

87
00:08:03,000 --> 00:08:06,000
I had to write in to provide a different opinion on testing.

88
00:08:06,000 --> 00:08:10,000
I work at a web based company with around 200 engineers.

89
00:08:10,000 --> 00:08:14,000
My team of three engineers work on Ruby on Rails as a code base.

90
00:08:14,000 --> 00:08:21,000
We use our spec to write the units and with some integration level tests that we run through our CI system for every branch.

91
00:08:21,000 --> 00:08:27,000
Part of our review process is to get the green CI check before merging, as one would expect.

92
00:08:27,000 --> 00:08:34,000
We have thousands of small unit tests for our service classes, helper methods, models and most controllers.

93
00:08:34,000 --> 00:08:39,000
We've started using view components so that most of our front end code can be tested.

94
00:08:39,000 --> 00:08:42,000
I find these invaluable as part of the development process.

95
00:08:42,000 --> 00:08:46,000
Every PR is a combination of code and tests that go along with it.

96
00:08:46,000 --> 00:08:49,000
These tests take about 10 to 12 minutes to run in CI.

97
00:08:49,000 --> 00:08:58,000
And without testing, I find the code that's written to be far less flexible in a dynamic language like, say, Python or Ruby.

98
00:08:58,000 --> 00:09:05,000
I couldn't imagine putting anything into production without some level of testing.

99
00:09:05,000 --> 00:09:10,000
Now, this was in a conversation that I think you and Mike have had, too, when you were on the show.

100
00:09:10,000 --> 00:09:17,000
And that is sort of Mike's kind of resistance to traditional unit testing where you're writing tons and tons of tests.

101
00:09:17,000 --> 00:09:22,000
I think he's a fan of high level testing and kind of a balance there combined with QA.

102
00:09:22,000 --> 00:09:29,000
But we do get a few people like Anabu who writes in that says, if you use it in a certain way, you combine it with your CI system.

103
00:09:29,000 --> 00:09:31,000
You kind of integrate it with your process.

104
00:09:31,000 --> 00:09:34,000
And it depends on the language you're using, but it can actually be extremely beneficial.

105
00:09:34,000 --> 00:09:37,000
Westpain, can you believe we are in this debate?

106
00:09:37,000 --> 00:09:44,000
Like, I'm actually surprised that we've somehow found ourselves in the middle of, is testing worth it?

107
00:09:44,000 --> 00:09:48,000
Because it just seems like, yes, of course, it just depends.

108
00:09:48,000 --> 00:09:52,000
I mean, that's what we're having a hard time really nailing down, is that depends part.

109
00:09:52,000 --> 00:09:55,000
Yes, it's always the devil in the details.

110
00:09:55,000 --> 00:10:01,000
I think by and large, modern, you know, quote, unquote, best practices, which can be a problematic term in and of itself.

111
00:10:01,000 --> 00:10:06,000
But I think by and large, most software engineers these days think that tests are a good idea.

112
00:10:06,000 --> 00:10:11,000
Now, what kind of tests, how many, how much do you care about things like code coverage?

113
00:10:11,000 --> 00:10:15,000
That's where you get into some nitty gritty details.

114
00:10:15,000 --> 00:10:20,000
I also think there's different types of projects, and this might be part of where Mike's perspective is coming from,

115
00:10:20,000 --> 00:10:24,000
is, you know, he's doing a lot of development for folks or making new products.

116
00:10:24,000 --> 00:10:29,000
And I think especially like when you're just spinning up a new service, a brand new API,

117
00:10:29,000 --> 00:10:33,000
it can be a little harder to do maybe a more traditional test first development

118
00:10:33,000 --> 00:10:36,000
when you don't really want to write your test before you've nailed down your design

119
00:10:36,000 --> 00:10:39,000
because you haven't figured out what those contracts are yet.

120
00:10:39,000 --> 00:10:42,000
Versus say you're working in an enterprise shop on a big team,

121
00:10:42,000 --> 00:10:47,000
you're handed a already groomed JIRA card that sort of lays out what your acceptance criteria are.

122
00:10:47,000 --> 00:10:50,000
You've got a good idea of the bug you're fixing or the feature you're adding

123
00:10:50,000 --> 00:10:54,000
and how to tell if that's right and you're on the right track.

124
00:10:54,000 --> 00:10:57,000
That makes it pretty easy to be like, all right, I'm going to start writing some tests to prove this bug exists,

125
00:10:57,000 --> 00:11:02,000
or I'm going to write some tests to make sure that the API input, you know, for this input, the output is what I need.

126
00:11:02,000 --> 00:11:08,000
But if you're experimenting and trying to figure out what's the right way to actually make something new work,

127
00:11:08,000 --> 00:11:11,000
maybe the testing is not your primary focus at the start.

128
00:11:11,000 --> 00:11:12,000
Yeah, that makes total sense.

129
00:11:12,000 --> 00:11:17,000
And I think also from Mike's point, you know, UI testing is just hard.

130
00:11:17,000 --> 00:11:21,000
I think some of the stuff like a more data focused, a more functional pipeline sort of view,

131
00:11:21,000 --> 00:11:26,000
like some of the tools that exist in the React ecosystem can make that easier.

132
00:11:26,000 --> 00:11:32,000
But at the end of the day, when you're relying on a web browser, it's complicated.

133
00:11:32,000 --> 00:11:34,000
Yeah, and I take your point, too.

134
00:11:34,000 --> 00:11:40,000
Like it really also part of that it depends disclaimer is it depends on your team and what your team is doing.

135
00:11:40,000 --> 00:11:46,000
So I'm curious for you in hashtag day job, how does testing kind of manifest itself?

136
00:11:46,000 --> 00:11:49,000
Is it something you have much interfacing with?

137
00:11:49,000 --> 00:11:53,000
Is it something you are? Are you writing unit tests? Are you doing any of this testing?

138
00:11:53,000 --> 00:11:56,000
Is it something teams of people are responsible for?

139
00:11:56,000 --> 00:11:59,000
How does it work in the organization that you work for?

140
00:11:59,000 --> 00:12:02,000
Yeah, sure. You know, currently I'm on a pretty small development team.

141
00:12:02,000 --> 00:12:04,000
We don't have a dedicated QA team or anything like that,

142
00:12:04,000 --> 00:12:10,000
but there is a customer support part of the organization that sometimes acts that way.

143
00:12:10,000 --> 00:12:11,000
Sure.

144
00:12:11,000 --> 00:12:13,000
But no, tests are pretty much expected.

145
00:12:13,000 --> 00:12:20,000
Now, I think there's a common thing in the industry that half the time you know that when you send a piece of code out,

146
00:12:20,000 --> 00:12:25,000
you know, a merge request, a pull request in for review, the reviewer is probably not looking at your tests.

147
00:12:25,000 --> 00:12:30,000
It's really a lot in a review process to get on all the state in your head of both the code changes itself

148
00:12:30,000 --> 00:12:34,000
and then did they cover all these cases in their tests.

149
00:12:34,000 --> 00:12:36,000
But tests are at least expected.

150
00:12:36,000 --> 00:12:43,000
You want to see that you've made some changes in the test directory that you've actually tried to test some of these things.

151
00:12:43,000 --> 00:12:48,000
Personally, you know, we had some on that first feedback item mentioned unit tests and some integration tests.

152
00:12:48,000 --> 00:12:50,000
This can vary a lot too.

153
00:12:50,000 --> 00:12:51,000
Sort of depends on your style.

154
00:12:51,000 --> 00:12:56,000
There's different thoughts on this personally, especially because I'm making a lot of APIs right now.

155
00:12:56,000 --> 00:12:58,000
I kind of go from the outside in.

156
00:12:58,000 --> 00:13:06,000
I try to do as much integration and sort of edge to edge testing that I can to make sure that I've got tested what the customer is going to do.

157
00:13:06,000 --> 00:13:14,000
Because the last thing I want is for a customer to run into a bug when I could have caught that just by sending a request with some weird Unicode characters or something in it.

158
00:13:14,000 --> 00:13:21,000
And then unit tests are still very important, but the kind of way I see it is like how do you verify correctness on the outside?

159
00:13:21,000 --> 00:13:23,000
You know, a black box test.

160
00:13:23,000 --> 00:13:33,000
Those are nice to have, especially because you can often then reuse those as, you know, plug them into your CI system or just run it manually and use it to verify stuff in staging or maybe even production.

161
00:13:33,000 --> 00:13:39,000
Where unit tests I think are really helpful is in verifying correctness and breaking those down.

162
00:13:39,000 --> 00:13:47,000
So that if you have some failure at the edge in your integration tests, if you have unit tests, that can actually help you go and isolate like, OK, well, now why did that break?

163
00:13:47,000 --> 00:13:51,000
Which of my assumptions is no longer valid?

164
00:13:51,000 --> 00:13:56,000
But where that gets tricky is you don't necessarily want, I think this is some of what Mike was complaining about.

165
00:13:56,000 --> 00:14:04,000
I know I've had folks, you know, friends or coworkers, especially coming from maybe Java places where you're just writing tests that are duplicating.

166
00:14:04,000 --> 00:14:11,000
You're basically writing a second time exactly what you wrote the first time and saying, I expect exactly this to happen.

167
00:14:11,000 --> 00:14:15,000
You're basically just testing all of the implementation details.

168
00:14:15,000 --> 00:14:23,000
That's a pain anytime you have to go maintain it, update it, and it doesn't necessarily test that it's actually the correct output.

169
00:14:23,000 --> 00:14:32,000
I love getting insights like that because I've had very little hands on experience with development teams of various sizes like you have.

170
00:14:32,000 --> 00:14:39,000
Like I've had a couple of practical client jobs where I was part of the development team as part of being infrastructure.

171
00:14:39,000 --> 00:14:42,000
But you get you have a lot more hands on experience and a lot more current.

172
00:14:42,000 --> 00:14:46,000
So that's one of the great things about having you on from time to time, Wes.

173
00:14:46,000 --> 00:14:50,000
Before we go over looking at it, it's stuff that gives us insights into how things work.

174
00:14:50,000 --> 00:14:57,000
Slack has done a postmortem of the outage that they had on, I think it was the 4th of January.

175
00:14:57,000 --> 00:15:02,000
And they wanted to narrow down right away when they had an outage, what was causing it.

176
00:15:02,000 --> 00:15:05,000
So the first thing they did was roll back recent changes they'd made.

177
00:15:05,000 --> 00:15:07,000
I think that makes a lot of sense.

178
00:15:07,000 --> 00:15:12,000
It does, although, you know, that's already, I think, a sign of some organizational maturity.

179
00:15:12,000 --> 00:15:18,000
It's not every organization that can immediately identify what those are or has the ability to quickly roll them back.

180
00:15:18,000 --> 00:15:21,000
Yeah, and just roll them right back. Yeah, exactly.

181
00:15:21,000 --> 00:15:26,000
But they said that it didn't really solve the issue. We'll get to that, what that was.

182
00:15:26,000 --> 00:15:35,000
They started bringing people in from like their infrastructure teams to figure what was going on and debug the situation and why they had a lack of usual dashboards and alerts and performance information.

183
00:15:35,000 --> 00:15:42,000
They still had access to various internal consoles and status pages and some command line tools and logging infrastructure.

184
00:15:42,000 --> 00:15:49,000
And the back end metric collection and saving was still happening so they could like go query them directly.

185
00:15:49,000 --> 00:15:54,000
But of course, that doesn't work nearly as well as just looking at a dashboard with pre-built queries.

186
00:15:54,000 --> 00:16:01,000
So it seemed like the infrastructure was generally up, but there was just signs of widespread network degradation.

187
00:16:01,000 --> 00:16:15,000
So they escalated up to AWS and they talk about it here like they also notice it started happening when they start to have patterns of mini peaks, as they call them, at the top of each hour and half hour as reminders.

188
00:16:15,000 --> 00:16:21,000
And other automation triggers send messages on Slack. They see a noticeable increase in traffic.

189
00:16:21,000 --> 00:16:30,000
Oh, of course. Right. And that's what started like when this network issue was happening and then this this kind of natural peak, it all kind of started rolling downhill from there.

190
00:16:30,000 --> 00:16:35,000
The snowball effect. It did turn out that AWS was having network issues.

191
00:16:35,000 --> 00:16:48,000
But the thing that's funny about this story is they had a couple of systems that tried to automatically scale up infrastructure or to save money, scale down infrastructure.

192
00:16:48,000 --> 00:16:57,000
And that bit them a couple of times because at one point they were scaling up a ton of infrastructure, but that infrastructure wasn't getting properly provisioned because of another outage.

193
00:16:57,000 --> 00:17:09,000
And at another point, the one that I was chuckling about before the show, they had engineers in that were directly querying the metrics database so they could try to get, you know, some information of what's going on since they don't have the dashboard.

194
00:17:09,000 --> 00:17:14,000
And their sessions kept getting dropped. They'd be in the middle of like doing a query and their session would get dropped.

195
00:17:14,000 --> 00:17:25,000
Well, the system, a different system, which was lacking proper CPU utilization information and acted like CPU usage was down, started deep provisioning systems.

196
00:17:25,000 --> 00:17:34,000
So while one system was trying to provision and couldn't keep up with the load, another system was going behind and deep provisioning other boxes, just dropping connections.

197
00:17:34,000 --> 00:17:36,000
Oh, wow.

198
00:17:36,000 --> 00:17:40,000
Yeah. Yeah. So you could see how the system can kind of just get a little way with itself.

199
00:17:40,000 --> 00:17:43,000
But they, you know, they have the right tools to rein it all in.

200
00:17:43,000 --> 00:17:54,000
That's what I took away from this is they repaired this flaw in their provisioning service and they can basically run their system under capacity until they need that capacity and then spin that stuff up.

201
00:17:54,000 --> 00:18:01,000
And it generally works for them. But when the AWS network was degraded and the systems couldn't talk appropriately, they had weird results.

202
00:18:01,000 --> 00:18:08,000
And it's a fascinating read if you're into that kind of stuff and, you know, want to think about these complicated systems and how to build them correctly.

203
00:18:08,000 --> 00:18:19,000
I think that's just it. It's a good reminder that in the cloud era, we take some of this stuff for free, but a lot of the stuff we depend on is just horribly complicated.

204
00:18:19,000 --> 00:18:28,000
And a lot of it is new, like we are constantly evolving software architectures and updates and evolving how your integrations with your backend cloud works.

205
00:18:28,000 --> 00:18:40,000
So as you adopt new features, as you change things or also in the cloud era, as Amazon changes things under the hood behind the scenes, there's just an exponential growth of places where things can change and go wrong.

206
00:18:40,000 --> 00:18:44,000
I think it's interesting in here, too. They talk about just because of that, you know, they've had that experience.

207
00:18:44,000 --> 00:18:52,000
They talk about how they built in a panic mode, which balances request across all instances and sort of like this failsafe balancing mode.

208
00:18:52,000 --> 00:19:00,000
And they also have a circuit breaker mode that kind of breaks things out of a loop and gets gets them back up and running the way they want.

209
00:19:00,000 --> 00:19:10,000
That's all explained in there. But so they built themselves little escape hatches that they could pull the lever on if they had to, because this infrastructure is, like you were just saying, so damn complicated.

210
00:19:10,000 --> 00:19:15,000
And there's so many areas where things can go wrong. They needed a circuit breaker and a panic mode.

211
00:19:15,000 --> 00:19:21,000
Yes. And I like that they acknowledge here that monitoring is one of our most critical services.

212
00:19:21,000 --> 00:19:25,000
It's how we know whether our user facing services are actually working or not.

213
00:19:25,000 --> 00:19:28,000
And that's sort of the I think it's like the flip side of testing.

214
00:19:28,000 --> 00:19:34,000
You know, it's the same answering the same question of like, how do you know that all this code you're running is actually doing anything?

215
00:19:34,000 --> 00:19:35,000
Business?

216
00:19:35,000 --> 00:19:41,000
Yeah. How do you know your business is actually up and running and providing like the services?

217
00:19:41,000 --> 00:19:45,000
And like what you were saying, too, earlier, it's like you want to know this stuff before your customers do.

218
00:19:45,000 --> 00:19:51,000
In this case, AWS, it took them a little bit to clue into what was going on.

219
00:19:51,000 --> 00:19:58,000
You know, Slack started noticing it like it took a little bit. It would have been nice if AWS could have been a little bit quicker on that one.

220
00:19:58,000 --> 00:20:01,000
I wonder if they'll be posting their postmortem.

221
00:20:01,000 --> 00:20:07,000
It's always weird to now, you know, in these days, it used to be that maybe you could just you had to go learn how the hardware works or suddenly you're debugging kernels and stuff.

222
00:20:07,000 --> 00:20:11,000
But often on AWS these days or whatever cloud, you don't have that option.

223
00:20:11,000 --> 00:20:19,000
At some point, you just hit the limits of what you can see and you have to go and hope that AWS will answer your support ticket and give you more info.

224
00:20:19,000 --> 00:20:24,000
Although in some cases, I'm sure that happens because, you know, they pay some big bucks for their hosting.

225
00:20:24,000 --> 00:20:25,000
Yeah, that's very true.

226
00:20:25,000 --> 00:20:31,000
Linode.com slash coder. This is our hosting and you want to talk about support.

227
00:20:31,000 --> 00:20:33,000
Ain't nobody got support like Linode.

228
00:20:33,000 --> 00:20:39,000
If you've got a five dollar a month rig or if you're like a slack size company, you're talking to a real human being.

229
00:20:39,000 --> 00:20:42,000
It's the same kind of support for every customer.

230
00:20:42,000 --> 00:20:50,000
That means that if you got a small business like I do and you run your services on Linode like I do, I have confidence that if anything ever goes a little sideways,

231
00:20:50,000 --> 00:20:57,000
I'm going to get really good human level support over the phone or however I want to do it.

232
00:20:57,000 --> 00:21:04,000
Not only have I heard story after stories from people that listen to this show, but it's a commitment that Linode makes.

233
00:21:04,000 --> 00:21:08,000
And it's a commitment they made to me in the conversation that I had with them before they became a sponsor.

234
00:21:08,000 --> 00:21:10,000
It's something they take really seriously.

235
00:21:10,000 --> 00:21:15,000
They started in 2003 as one of the first companies in cloud computing, three years before AWS.

236
00:21:15,000 --> 00:21:20,000
So they really have this dialed in now and they've got 11 data centers around the world.

237
00:21:20,000 --> 00:21:24,000
So you pick the region that works best for you and your clients or customers.

238
00:21:24,000 --> 00:21:28,000
It's something we kind of strategically do some of our back end stuff.

239
00:21:28,000 --> 00:21:34,000
We actually deploy in Linode's California data center because it's like Wes and I interacting with stuff.

240
00:21:34,000 --> 00:21:39,000
But the stuff that the audience is going to interact with will deploy maybe on the East Coast.

241
00:21:39,000 --> 00:21:42,000
So it's friendly for our friends across the pond to, you know,

242
00:21:42,000 --> 00:21:48,000
we'll kind of like think about what user group do we think is going to be using this and we can deploy in that area.

243
00:21:48,000 --> 00:21:56,000
And every machine is just crazy fast, super fast SSDs, 40 gigabit connections into the hypervisor, screaming fast Linux boxes.

244
00:21:56,000 --> 00:22:00,000
I mean, Linode is really dedicated to offering the best virtualized cloud computing.

245
00:22:00,000 --> 00:22:03,000
If it runs on Linux, it runs on Linode.

246
00:22:03,000 --> 00:22:05,000
I recently set up a Rust gaming server.

247
00:22:05,000 --> 00:22:09,000
No, no, not rust the language, the game.

248
00:22:09,000 --> 00:22:12,000
And Linode makes this ridiculously easy.

249
00:22:12,000 --> 00:22:16,000
They have a couple other ones on there, too, like a handful like CS goes on there.

250
00:22:16,000 --> 00:22:23,000
But Ark is on there and rust and you get all the options for your rust server to set your whatever kind of parameters you might want.

251
00:22:23,000 --> 00:22:26,000
And then it deploys it on Debian and it's up and running and it gives you the IP.

252
00:22:26,000 --> 00:22:32,000
And they've got an article that walks you through how to connect the rust client to your custom server and you're off and running.

253
00:22:32,000 --> 00:22:35,000
So if you want to run something like a rust server or you want to run the back end,

254
00:22:35,000 --> 00:22:39,000
self-hosted communications infrastructure for your business, Linode can do it.

255
00:22:39,000 --> 00:22:40,000
They can do it all.

256
00:22:40,000 --> 00:22:45,000
And you can get a $100 credit when you go to Linode.com slash coder.

257
00:22:45,000 --> 00:22:51,000
That's some serious money to play around with our object storage or build a really powerful box or maybe create yourself a VPN.

258
00:22:51,000 --> 00:22:53,000
Go to Linode.com slash coder.

259
00:22:53,000 --> 00:22:57,000
Get that $100 60 day credit and you support the show.

260
00:22:57,000 --> 00:22:59,000
Linode.com slash coder.

261
00:22:59,000 --> 00:23:03,000
Do you remember when Mike and I and you would talk about bots a lot?

262
00:23:03,000 --> 00:23:04,000
We used to talk about bots a lot.

263
00:23:04,000 --> 00:23:05,000
All the time.

264
00:23:05,000 --> 00:23:08,000
Well, Microsoft hasn't stopped talking about bots.

265
00:23:08,000 --> 00:23:23,000
And in December, they received a patent from the U.S. Trademark and Patent Office that outlines a process to create a conversational chatbot of a specific person using their social data.

266
00:23:23,000 --> 00:23:34,000
The patent says the chatbot could potentially be inspired by friends or family members who are deceased, which is actually like a direct plotline episode from a big Black Mirror episode from Netflix.

267
00:23:34,000 --> 00:23:44,000
But according to this new patent from Microsoft, images, voice data, social media posts, emails, written letters,

268
00:23:44,000 --> 00:23:53,000
they all could be used to create or modify a specific index and a theme of a specific person's personality.

269
00:23:53,000 --> 00:24:01,000
From there, engineers use that index to train a chatbot to converse like that person with you, even if they are already dead.

270
00:24:01,000 --> 00:24:12,000
Oh, yeah. Goes on to say the application could also don the likeness of your dead loved one in a 2D or 3D model and utilize their voice while talking to you.

271
00:24:12,000 --> 00:24:13,000
Oh, boy.

272
00:24:13,000 --> 00:24:17,000
I mean, yeah, deep, deep fake version of yourself.

273
00:24:17,000 --> 00:24:30,000
You know, you and I have joked about how I'd love to be able to download my brain into a computer and have it just do the computer stuff like you don't need it to be a full rich version of myself.

274
00:24:30,000 --> 00:24:41,000
It just needs to be like the decision making analytical version who could respond to emails, messages, manage a calendar and make the decisions I would make.

275
00:24:41,000 --> 00:24:45,000
If my personality could be used as a template, it wouldn't actually be my essence.

276
00:24:45,000 --> 00:24:58,000
The index of my personality, if that could be used to influence something that's running on my machine, maybe it's an open source, self-hosted personality bot or maybe it's some horrible thing from Amazon.

277
00:24:58,000 --> 00:25:05,000
But something that runs on your computer that uses your personality as a baseline to then make decisions, I think would actually be super useful.

278
00:25:05,000 --> 00:25:09,000
Right. You could say sort of like, Chris Bot, send pleasantries to all of my family members.

279
00:25:09,000 --> 00:25:13,000
Right. And it just goes on Amazon, does the ordering, interfaces with their API.

280
00:25:13,000 --> 00:25:18,000
There'd be certain decisions or actions where you'd want it to consult with the real you first.

281
00:25:18,000 --> 00:25:25,000
Maybe tuning that would be hard, but there are a lot of stuff that I just have to do that's sort of mechanical in nature.

282
00:25:25,000 --> 00:25:30,000
But and if you trained it, if this thing worked properly, it would be managing your inbound electronic communications.

283
00:25:30,000 --> 00:25:41,000
So you could have the only thing that notifies you is Chris Bot because, you know, Chris Bot has made the decision that this needs to be surfaced to the actual human to make a decision.

284
00:25:41,000 --> 00:25:45,000
And so I interact with Chris Bot and then they respond back to the message or whatever.

285
00:25:45,000 --> 00:25:48,000
That would probably help, too, if you started using it, you know, before you're dead.

286
00:25:48,000 --> 00:25:54,000
You get in the good feedback cycle messages where it's like not able to actually figure it out.

287
00:25:54,000 --> 00:25:58,000
You know, that goes to you and then it's still learning from whatever your eventual response is.

288
00:25:58,000 --> 00:26:01,000
Do you think this is a marketing hype BS?

289
00:26:01,000 --> 00:26:03,000
I mean, this is coming from a patent, right?

290
00:26:03,000 --> 00:26:05,000
This isn't a press release. This is a patent.

291
00:26:05,000 --> 00:26:10,000
And they may just be patenting something that they've got kind of a rough idea about.

292
00:26:10,000 --> 00:26:14,000
But I've always speculated this actually does seem possible.

293
00:26:14,000 --> 00:26:20,000
I think it makes sense. I mean, you know, Microsoft's big into the old AI space, machine learning, training stuff.

294
00:26:20,000 --> 00:26:26,000
I know I saw what they have. They got some deal to have access to GPT-3, for instance.

295
00:26:26,000 --> 00:26:30,000
So it makes sense that they have teams of people thinking about this.

296
00:26:30,000 --> 00:26:37,000
I bet you the dead aspect is just that it's strategic in patent applications to try to be as general as possible.

297
00:26:37,000 --> 00:26:40,000
If it's possible, this could impact that.

298
00:26:40,000 --> 00:26:44,000
Let's include it in an application on the after onset. That all gets okayed.

299
00:26:44,000 --> 00:26:51,000
Arizona State University School of the Future Innovation Society's professor, the clinical assistant said,

300
00:26:51,000 --> 00:26:59,000
that's quite the title, wow, quote, technically we can recreate anyone online given enough data.

301
00:26:59,000 --> 00:27:04,000
I suppose the question is, I can certainly see it useful in the assistant part.

302
00:27:04,000 --> 00:27:08,000
Is there a market for fake dead loved ones?

303
00:27:08,000 --> 00:27:13,000
Maybe. Maybe. But it doesn't. I don't know if it seems healthy to me.

304
00:27:13,000 --> 00:27:14,000
No.

305
00:27:14,000 --> 00:27:16,000
I don't know that I would want that.

306
00:27:16,000 --> 00:27:23,000
The rough, without really any spoilers, plotline of the Black Mirror episode is one of the couples is lost in a relationship.

307
00:27:23,000 --> 00:27:33,000
It's a new kind of peak relationship and one of them is lost and a friend comes along and signs them up for this service that does this online indexing.

308
00:27:33,000 --> 00:27:40,000
And then she starts a chatbot session with him and it's a chat and she can upgrade to voice and all that kind of stuff.

309
00:27:40,000 --> 00:27:42,000
And you can imagine where it goes from there.

310
00:27:42,000 --> 00:27:48,000
It's weird in a sense because if it's capable, we're going to have to ask ourselves if this is something we really want to enable.

311
00:27:48,000 --> 00:27:50,000
Because, yeah, you're right. It's going to make it hard to move on.

312
00:27:50,000 --> 00:27:55,000
The whole thing is really strange, especially when you combine deep faking voice and video.

313
00:27:55,000 --> 00:28:03,000
Now, do you think you could get into some weird legal quandaries, too, of what if your AI bot gets input like when they're figuring out your will?

314
00:28:03,000 --> 00:28:10,000
Can the AI bot object when your family, your sister you no longer talk to wants to claim rights to that chair she always wanted?

315
00:28:10,000 --> 00:28:20,000
Imagine this, too. Imagine your AI bot being used to prove that you've lost your mental faculties or something because the AI bot scan will be the baseline.

316
00:28:20,000 --> 00:28:22,000
And then there'll be other scans it could do later.

317
00:28:22,000 --> 00:28:27,000
It'll be like, oh, yeah, sorry, Mr. Fisher. Yeah, you clearly have dementia or something.

318
00:28:27,000 --> 00:28:28,000
We have to get you off the air.

319
00:28:28,000 --> 00:28:31,000
You're now the backup, the hardware backup for the bot.

320
00:28:31,000 --> 00:28:37,000
Right. Yeah. And the bot has an active role in determining the state of my health or something.

321
00:28:37,000 --> 00:28:43,000
I don't know. I think we could potentially be going down a route where people eventually got access to deep fakes.

322
00:28:43,000 --> 00:28:48,000
People could get access to bots that could index people online and synthesize some of this.

323
00:28:48,000 --> 00:29:00,000
The other part that's upsetting is, as like so many things and as usual, probably going to get this technology before we've sorted out anything about data ownership or permissions or any of that.

324
00:29:00,000 --> 00:29:02,000
Yeah. Well, I mean, it happened to Jordy, right?

325
00:29:02,000 --> 00:29:14,000
In the future, he creates a holographic engineer, Leah Broms, and there was no protection on her likeness and the personality was off a little bit.

326
00:29:14,000 --> 00:29:20,000
The AI simulated personality was off because the profile at the time she was indexed didn't include that she was married.

327
00:29:20,000 --> 00:29:22,000
You remember, you know what I'm talking about. This stuff happened.

328
00:29:22,000 --> 00:29:25,000
Yeah, it did include that she was real into Jordy.

329
00:29:25,000 --> 00:29:27,000
That didn't seem to be an accurate detail.

330
00:29:27,000 --> 00:29:28,000
That's right.

331
00:29:28,000 --> 00:29:33,000
Okay, so the register wins for the best hoopla title of the week.

332
00:29:33,000 --> 00:29:39,000
You know, we always try to cover a little bit of development hoopla for you guys just so we always get a little bit of conversation about what's going on in the world.

333
00:29:39,000 --> 00:29:42,000
And this one from the register really nails it.

334
00:29:42,000 --> 00:29:50,000
Quote, Pearl clutching hijackers appear to have seized control of thirty three year old programming languages dot com domain.

335
00:29:50,000 --> 00:29:52,000
And they're referring to pearl dot com.

336
00:29:52,000 --> 00:29:58,000
That's why the pearl clutching in there is extra clever and appears a few days ago.

337
00:29:58,000 --> 00:30:01,000
Pearl dot com was hijacked.

338
00:30:01,000 --> 00:30:15,000
A warning went up on pearl dot org's infrastructure weblog overnight, notifying users that pearl dot com had now directed to a parking site and advise against visiting there as there were some signals that it may be related to sites that have distributed malware in the past.

339
00:30:15,000 --> 00:30:20,000
Now, we want to make it clear here. Pearl dot org was just fine.

340
00:30:20,000 --> 00:30:24,000
But apparently what happened is just like a classic move.

341
00:30:24,000 --> 00:30:30,000
Somebody came in and hijacked a domain that expired or was a compromised domain register account, possibly.

342
00:30:30,000 --> 00:30:36,000
Don't know for sure yet, but it doesn't look like something significant, like a server wasn't taken out or something like that.

343
00:30:36,000 --> 00:30:38,000
It just looks like some DNA shenanigans.

344
00:30:38,000 --> 00:30:40,000
Apparently it's maybe still going on.

345
00:30:40,000 --> 00:30:44,000
I just get a blank page that tries to load a whole bunch of JavaScript.

346
00:30:44,000 --> 00:30:46,000
I can't tell what it does.

347
00:30:46,000 --> 00:30:48,000
So I just let it run.

348
00:30:48,000 --> 00:30:50,000
Maybe don't go to pearl dot com right now.

349
00:30:50,000 --> 00:31:02,000
It looks like the domain expired on January 26th, but then was extended like somebody renewed it until January 26th, 2031.

350
00:31:02,000 --> 00:31:06,000
So whoever has it now, they're going to have it for a while.

351
00:31:06,000 --> 00:31:13,000
And, you know, that sucks because people are trying to learn about Pearl that, yes, they are still out there.

352
00:31:13,000 --> 00:31:15,000
They may not know to go to the dot org.

353
00:31:15,000 --> 00:31:20,000
This may actually screw a few people who are just trying to learn how all this works.

354
00:31:20,000 --> 00:31:21,000
You hate to see it.

355
00:31:21,000 --> 00:31:27,000
Perhaps one interesting tidbit here is I guess we've learned that the register is built on Pearl.

356
00:31:27,000 --> 00:31:29,000
And I don't think I'm surprised.

357
00:31:29,000 --> 00:31:31,000
I didn't realize that.

358
00:31:31,000 --> 00:31:33,000
That is a nice little nugget right there.

359
00:31:33,000 --> 00:31:39,000
I just want to say thank you very much to our QA team, codercua.co if you'd like to become a member.

360
00:31:39,000 --> 00:31:41,000
You get access to the quarterly report.

361
00:31:41,000 --> 00:31:42,000
There are two of them now.

362
00:31:42,000 --> 00:31:48,000
You support the show and you get a limited ad feed, still full production, just limited ads.

363
00:31:48,000 --> 00:31:51,000
And we really wanted to say thank you.

364
00:31:51,000 --> 00:31:57,000
Just want to take a moment here in the show specifically and say I really appreciate everybody who went over there and signed up at codercua.co.

365
00:31:57,000 --> 00:31:59,000
Thank you to our members.

366
00:31:59,000 --> 00:32:00,000
You the best.

367
00:32:00,000 --> 00:32:08,000
Well, before we get out of here, Wes, I wanted to just say thank you very much for coming on the show and filling in for Mr. Dominic when he's under the weather.

368
00:32:08,000 --> 00:32:09,000
Thanks for having me.

369
00:32:09,000 --> 00:32:11,000
I've been meaning to get you on.

370
00:32:11,000 --> 00:32:14,000
But, you know, now you're doing Linux Action News.

371
00:32:14,000 --> 00:32:16,000
Of course, you're still doing Linux Unplugged.

372
00:32:16,000 --> 00:32:23,000
So it just seems like because you're doing a show on Sunday and you're doing a show on Tuesday, it doesn't really seem fair to ask you to do a show on Monday.

373
00:32:23,000 --> 00:32:25,000
But then when Mike was out, we had an excuse to do it.

374
00:32:25,000 --> 00:32:31,000
Well, we'll just have to find another time that works, too, because that way we might get the Coder three-way going.

375
00:32:31,000 --> 00:32:33,000
Classic Coder three-way.

376
00:32:33,000 --> 00:32:34,000
The classic, yeah.

377
00:32:34,000 --> 00:32:35,000
Right.

378
00:32:35,000 --> 00:32:36,000
Right.

379
00:32:36,000 --> 00:32:38,000
And then, you know, you can hang out live, too.

380
00:32:38,000 --> 00:32:42,000
Wes is often in the chat room, too, when we're doing the live shows.

381
00:32:42,000 --> 00:32:52,000
And maybe one day we'll have a future new, like, live page that's all powered by some crazy backend service that Wes and I have concocted.

382
00:32:52,000 --> 00:32:53,000
There's always discussions.

383
00:32:53,000 --> 00:33:00,000
That's one of the things that's a lot of fun about podcasting with Wes is we're always kind of coming up with new ways to do the plumbing.

384
00:33:00,000 --> 00:33:08,000
Like our membership system, a lot of that has been plumbed to try to make that as straightforward and as automatable and reproducible as possible.

385
00:33:08,000 --> 00:33:13,000
Because any time I'm directly involved in the publishing process, there's usually a mistake.

386
00:33:13,000 --> 00:33:17,000
You know, usually I typo something or I upload the wrong MP3.

387
00:33:17,000 --> 00:33:18,000
That's my favorite right now.

388
00:33:18,000 --> 00:33:21,000
That's how we know you haven't yet been replaced by your bot.

389
00:33:21,000 --> 00:33:23,000
You're making those human mistakes.

390
00:33:23,000 --> 00:33:24,000
Right.

391
00:33:24,000 --> 00:33:25,000
Right.

392
00:33:25,000 --> 00:33:28,000
But we are slowly replacing some of the backend stuff with bot-like activity.

393
00:33:28,000 --> 00:33:35,000
But we actually just get a tremendous amount of value and mileage out of Hugin.

394
00:33:35,000 --> 00:33:37,000
Is that how you say it, Wes?

395
00:33:37,000 --> 00:33:38,000
Oh, Hugin, I think.

396
00:33:38,000 --> 00:33:39,000
Probably just Hugin.

397
00:33:39,000 --> 00:33:42,000
We say Hugin, but it's probably Hugin or something like that.

398
00:33:42,000 --> 00:33:43,000
Because I think it's a Norse god or...

399
00:33:43,000 --> 00:33:44,000
Yeah.

400
00:33:44,000 --> 00:33:45,000
Yeah.

401
00:33:45,000 --> 00:33:48,000
And this is something that we just don't really mention super often.

402
00:33:48,000 --> 00:33:53,000
So I wanted to give it a mention here on the Coder Radio program because I think it could solve some problems for you guys.

403
00:33:53,000 --> 00:33:57,000
It's a system for building agents that perform automated tasks for you online.

404
00:33:57,000 --> 00:34:00,000
So they can read, say, a web page or an RSS feed.

405
00:34:00,000 --> 00:34:05,000
In our case, they'll watch for events and then it'll take actions on your behalf.

406
00:34:05,000 --> 00:34:13,000
It's like your own version of if this, then that, that you can self-host and does like way more cool stuff.

407
00:34:13,000 --> 00:34:21,000
And we have been using it as a tool to kind of not only just plug different systems together,

408
00:34:21,000 --> 00:34:27,000
but even just kind of surface like notifications to a Slack channel that, hey, this episode has just been posted, just even that kind of stuff.

409
00:34:27,000 --> 00:34:28,000
Yeah.

410
00:34:28,000 --> 00:34:33,000
They've got a lot of nice sort of built-in stuff already, like following an RSS feed and generating events.

411
00:34:33,000 --> 00:34:35,000
But also it's easily extendable.

412
00:34:35,000 --> 00:34:38,000
They have ways to just run like a shell script.

413
00:34:38,000 --> 00:34:41,000
They've got ways to make generic like web hook calls to other APIs.

414
00:34:41,000 --> 00:34:44,000
Or you can just do it totally custom and it's all written in Ruby.

415
00:34:44,000 --> 00:34:47,000
So just write yourself a Ruby module and away you go.

416
00:34:47,000 --> 00:34:51,000
Hey-oh, that may or may not be just what happened over here.

417
00:34:51,000 --> 00:34:52,000
Yes.

418
00:34:52,000 --> 00:34:53,000
I'll put a link to that in the show notes.

419
00:34:53,000 --> 00:34:56,000
It's H-U-G-I-N-N.

420
00:34:56,000 --> 00:35:00,000
And their slogan, which I love, is your agents are standing by.

421
00:35:00,000 --> 00:35:07,000
So, yeah, go over there and check that if you need something like that on your land that you want control over that is honestly more powerful than if this and that.

422
00:35:07,000 --> 00:35:11,000
It might not have some of the same integrations, but it lets you do a lot more.

423
00:35:11,000 --> 00:35:15,000
Go wish Mike the best and all the health.

424
00:35:15,000 --> 00:35:17,000
He's at Dumanuco on Twitter.

425
00:35:17,000 --> 00:35:18,000
Wes, you're over there.

426
00:35:18,000 --> 00:35:20,000
That's right. I'm at Wes Payne.

427
00:35:20,000 --> 00:35:21,000
How about that?

428
00:35:21,000 --> 00:35:23,000
I'm at Chris LAS.

429
00:35:23,000 --> 00:35:26,000
The whole network is at Jupiter Signal.

430
00:35:26,000 --> 00:35:36,000
And this here podcast is at Coder Radio Show, which you can follow for release announcements, show news, that kind of stuff.

431
00:35:36,000 --> 00:35:38,000
We do this here show live.

432
00:35:38,000 --> 00:35:43,000
Coder Happy Hour starts at 5 p.m. Pacific, 8 p.m. Eastern at shabbylive.tv.

433
00:35:43,000 --> 00:35:45,000
You can also check Jupiter.Tube.

434
00:35:45,000 --> 00:35:48,000
It's a new PeerTube instance we're working on, Jupiter.Tube.

435
00:35:48,000 --> 00:35:53,000
You may find full live recorded versions of this live stream up there from time to time.

436
00:35:53,000 --> 00:35:55,000
It's something Wes and I are working on right now.

437
00:35:55,000 --> 00:35:57,000
That's Jupiter.Tube for that.

438
00:35:57,000 --> 00:35:58,000
It's like our own YouTube in a box.

439
00:35:58,000 --> 00:35:59,000
Check that out.

440
00:35:59,000 --> 00:36:04,000
And links to everything we talked about today are Coder.Show slash 399.

441
00:36:04,000 --> 00:36:06,000
Thanks for joining us.

442
00:36:06,000 --> 00:36:16,000
See you right back here next week.

