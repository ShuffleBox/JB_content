I knew what happened, Alex, I rolled the Starlink dice and I came up snake eyes.
I came back to a location after being on the road for about three weeks, set up the
Starlink and went to update my service address and I got the dreaded no more capacity at your area.
And this is an area I frequent a lot.
It's like home base territory and Starlink says, sorry, no room for you.
So what happens now?
Are you out of luck until further notice?
It's weird.
I'm only like 15 miles from the other location I was at.
It's kind of working and not well.
It's like losing and dropping packets from time to time and connection.
But when it works, I'm getting like 30 megabits, which is pretty slow for Starlink.
But I did see some YouTubers reporting that Starlink seems to be testing a roaming mode
that lets you move around and maybe use it outside your service address.
So I'm hoping that happens to me soon.
And I'm just going to keep checking the website every few days.
There is a website I just found as you were talking here, satellite map dot space, and
it seems to like divide the entire country up into hexagons.
And then they've got the actual Starlink satellites flying in real time over the top of it.
And it looks like the entirety of the Pacific Northwest Redmond's right at the middle of a cell.
So I don't understand, you were on the coast and then you came back to the studio.
That's not far enough to cross a boundary even.
What's going on?
I think it's more nuanced than that website makes it look.
I think the cells are actually more divided.
I've seen another website that gives you a different view.
It's not as fancy as that one.
It shows hexagons that are basically 20, 30 mile in sizes that overlay over the Google map.
Either way, I knew I was rolling the dice because you're not supposed to move the Starlink.
When you're in a service area, they provision for capacity because these require downlink stations too.
Come on, they know exactly who's going to use this thing.
People in rural places that have no other option, or people, you know, not connected to the real world like you that lives in a bus.
Out there in the virtual world.
When I reviewed Starlink on Linux Unplugged, I didn't really mention the fact that the Ethernet cable doesn't disconnect from the dish.
It's built in.
So every single time I tear it down in the snow, in the rain, in the mud, I have to like spool this big cable that I can't detach from the dish and I have to like carry them both around soaking wet and dry them off together and load them up.
It is the worst.
At least you got a router with an Ethernet port.
You can stop complaining.
That's true.
They're taking that away.
But when SpaceX does come out with the Starlink designed for mobile use, which they have patents for, I'm all over it.
I mean, I was even tempted by the $500 a month Starlink Pro, but I'm glad I didn't pull the trigger on that.
It would be really SOL.
Yeah, it's interesting, you know, like obviously it has the power to completely change the game, but so does 5G.
Like you look at what bandwidth that's capable of and you know, the number of subscribers that a single tower can support on 5G versus LTE significantly different proposition.
It's going to be really interesting to see which technology wins out.
Obviously, you know, in rural America where, you know, it's a pretty different use case to what I'm used to in England, right, where everything's really dense and connected with cables pretty well.
But like rural America, you're in the middle of the wilderness pretty quickly in America if you're not careful.
And those places, those are the ones where Starlink will change the game for people like me that work fully remotely.
I think, well, I live near Raleigh right now because, you know, I have access to good schools, one thing for my daughter, but I also have access to a good job market.
Well, that kind of thing has gone away because I could move anywhere and get a remote job I wanted in my industry.
I'm very lucky. And then you think, well, Internet's another one because you start trying to look at buying 20, 30 acres worth of land in the middle of West Virginia and good luck getting anything above one meg DSL.
Yeah, I think it's a mix of all of them at once, at least for the nomadic use case, because you can't, I would imagine, ever really use Starlink mobilely because I don't think the way it works.
I don't think you can be, say, going down the road at 60 miles per hour.
I've seen Dwayne the Rock Johnson on a sat phone, you know, they could do they could do these things in the movies.
Maybe it could. Maybe that'd be awesome.
But I imagine for quite a while it's going to be a mix of different wireless tech, LTE, 5G, and then you park when you're stationary.
You go Starlink or if you're out like at a piece of property, you know, a farm, it's all kind of hit and miss.
There's a guy I work with who is working for a government contract and he lives on a boat off the East Coast and he just sails up and down the East Coast, depending on where the weather's nice all year.
And he's on a 4G, works great.
I had a buddy that did that, but he gave it up, I think, when the boat just started falling apart.
Well, they do do that. They're a boat.
You know, there are two good days when you own a boat.
You know that, Chris? The day you buy it and the day you sell it.
And the day you sell it. Yep.
I think that might be true for an RV too, Alex.
And I'm looking at what's coming down the road for Home Assistant, which I have deeply integrated into my RV and I'm not sure what I'm going to do.
So I had some time away from Lady Joob's. Not recently, but this is about a month and a half ago. Strictly platonic time away, I hope.
Yeah, when our buddy Brent was in town, we were staying at the studio to let Lady Joob's defrost from a stay we had in the winter wilderness.
I spent some time here at the studio and I just realized how little I've integrated Home Assistant.
It's just so much the basics.
It's like motion sensor stuff, a couple of NFC automation tag stuff, and you know, smart lights.
It's really fine. It's fine.
I'm not trying to denigrate that setup, but compared to what I've done in my primary home in Lady Joob's, it's just really night and day.
And I came to realize just how much we rely on Home Assistant. It is an integral part of operating our home now.
And I don't know how to describe that. I describe it as important as some of the machinery in the engine.
You know, it is an absolute critical part of the operation of the vehicle now.
So when I see things that are coming down the pipe that are going to break Z-Wave, man, I just don't know what I'm going to do.
So this is really for any of us out there who are on the OG Z-Wave support, like I'm talking the old Z-Wave stuff.
It seems going by the beta release notes than in a couple of releases in the 22.4.
So not the next one, but the one after.
They are going to deprecate the old Z-Wave support simply because they have to move on in Python versions and no one supports that old Z-Wave stuff.
And the dev team is recommending instead that you migrate to Z-Wave JS.
And you know, Alex, we've talked about this. I tried it and it went badly.
It's one of the few times I had to hit the escape hatch and do a full restore from backup and bail out of what I had done because my migration went so poorly.
That just about everything from automations to timers and buttons all broke. Everything broke.
How many sensors do you have? How many devices on that network?
I think it's somewhere like a hundred devices.
I don't remember how many of them are sensors because it's tricky because each sensor actually shows up as an individual device.
And there are like seven in each one of those little Z-Wave sensors.
And when you migrate, do you have to repair each device one by one?
Because I had to do that with my Zigbee thing when I changed my channel.
I think it's actually stored in my Z-Wave controller.
However, it seems like the new versions of Z-Wave JS, and I haven't done this for about six months, but it's like a bunch of missing devices show up.
Like the names don't line up.
And so I don't know exactly what went wrong when I looked at it, but it was, yes, it stored the pairings.
But it was almost irrelevant because I'd have to wipe the slate and repair it anyways to fix everything.
I'm not ready to go there when matter is probably about a year away.
And I'm going to then just start replacing all of this with matter devices.
And I was really hoping to hold out, just kind of hold out until matter arrived and then just switch over.
And it seems like I'm not going to get that opportunity because they want to move on.
They got to get a newer version of Python in their stack.
I'm playing devil's advocate a little bit here, but I mean, how do you propose that Home Assistant solve this problem?
I mean, time moves on.
Python 2 has been on the ropes for a long time now.
I mean, it's not like this is a new problem.
What's the alternative there?
I'm not really sure there is one looking at it objectively.
I think to myself, isn't there some way they could supply this as a container so it is unaffected by the base system.
But these integrations are just that they are integrated.
They don't run as separately isolated containers, but it's a shame because right now I really wish they could.
This is really going to screw me.
And there is people already online, of course.
And of course, the Internet doesn't recommend you do what the developers suggest you do.
The Internet wants everyone to go install Z-Wave JS to MQTT and go set up an MQTT broker and go learn all of that.
Which perhaps is a great idea, but it's like not what the developers are recommending.
And when something like a breaking change like this comes along and the community needs to know what to do,
having all this mixed messaging just makes things worse.
So I just that stuff drives me crazy.
And what you start seeing people say they're going to do is just not upgrade.
They're basically going to upgrade to 22.3 and then they're going to hold until something else comes along,
which, you know, it sucks because that's probably what I'm going to have to do.
I'm grateful that I have a separate Home Assistant instance here in the studio that I'll be able to keep up to date so I can follow along on development.
But in my RV where I consider it mission critical, I and I think a lot of people are just going to stop upgrading now.
Yeah, I think a lot of people get burnt out.
There was a thread on Reddit.
I think it was about a week ago complaining about the state of the Home Assistant documentation.
The complaint itself is neither here nor there for purposes of this discussion.
What I wanted to talk about was the general consensus in the comments of that thread.
The Home Assistant, despite its best efforts for now, at least, is geekware.
You know, my dad's a smart guy, but I can't imagine giving him a vanilla Raspberry Pi with nothing except Home Assistant even flashed onto it and say,
here, go automate your house.
I can't imagine that going very well.
And I look at things like the HomeKit integration that Apple are doing.
I look at the Alexa stuff.
I look at the Google Home app.
That's what you need to do.
That's the level of integration that you need to get to in order to make it more approachable and more accessible for people.
Home Assistant's biggest strength is how modular it is and how customizable it is and how geeky it is.
That's the thing I love about it the most is the fact if I want to go and tweak a specific knob three degrees to the left,
I can go and do that one specific change.
Probably similar to the reasons why I like Linux as well, you know?
Yeah, I do.
I do know what you mean.
And, you know, we're trying to compare, I think, Apple's, you know, kind of, you will like this approach that they do on Mac OS to Linux.
You know, I'm comparing Alexa to Home Assistant here.
And I don't know, like, I just think about where does the Home Assistant project go to address complaints like yours,
like the ones in this Reddit thread and complaints of my own as well, where, you know, I get fatigue.
I get fatigue maintaining my own Home Assistant instance.
Stuff just breaks for no apparent reason.
And, you know, I stay on top of updates and I do try and figure stuff out.
And I don't know, like, it's just difficult.
I don't know that Home Assistant is quite grasping the problem that faces them quite yet.
They're solving the technical problems really, really well.
But I do think on the whole, there's still a lot of work to be done on the kind of people side of the problem that they're solving,
like the education, the documentation, making things more bite-sized and more accessible to folks.
I feel like there is a period of time where it's reasonable for Home Assistant to introduce breaking changes,
to get things built right for the long term.
And when a project's new, you decide to do a few things and you got to make a few changes.
I think to their credit, it's not like Z-Wave JS came out yesterday, right?
And part of the reason is because I saw where this was going.
There was multiple options and I just wanted to hold off.
But anybody who's adopted Home Assistant in the last year just started off with Z-Wave JS, right?
They don't have to deal with this.
And so I think something we have to keep in mind is even though you and I have been using it for a few years,
I think the vast, vast, vast majority of users that Home Assistant will ever have are still yet to come, right?
They start arriving when there's hardware devices.
So we're still the early adopters that are actually helping kind of bang out some of the rough edges on this thing.
And so we are more likely to get exposed to those issues that cause fatigue that both you and I are feeling right now.
But what gives me hope is if you zoom out a couple of years and look at the Home Assistant project's trends,
the break-in changes are slowing down.
I think you'd agree there's less.
Absolutely are, yeah.
Also, they're making things more and more automatic as time goes on.
Like when you throw Home Assistant on a network for the first time, you know, just like say you're a new user and you take a look at it.
It'll often suggest four or five or six integrations automatically just by noticing what's on your network.
They've gotten really good at like saying, hey, you got an Apple TV.
Hey, you got an HP printer, you know, like, would you like to set that up?
The fundamental appeal that Home Assistant has that will always be a unique value proposition for at least these open source type systems is that it's multi-vendor.
It works with all the different third party products and cloud devices that you got on a whim and to your thing.
Somebody bought you for Christmas and it works with all of it, right?
Whereas Apple stuff, it only works with the HomeKit stuff.
The Echo stuff only works with the devices that, you know, work with the Echo and same with the Googs and all of that.
It's different in that way.
It's a finally a way to just bring it all home, bring it all on the land.
And once that starts connecting with people and there's a piece of hardware and some of these transitional things are worked out, I think it's going to be fine.
But the reality is when you're living in the in the now and this stuff still getting hashed out, it kind of sucks.
And I'm not a big fan of doing the I'm not updating thing.
That's sort of my last worst case scenario.
I'm much more of a keep my systems up to date.
Like if I'm going to run a box when I decide to deploy something, I'm committing to keep it maintained.
I don't just deploy something and not maintain it.
So that bothers me a lot.
Additionally, this is why I'm really glad I'm not running their OS because I will keep the Ubuntu base up to date, right?
Where I don't know if that's safe when I'm running their OS if I kept the OS upgrading all the time, but didn't upgrade Home Assistant Core.
I don't know if something breaks.
Possibly I could see that being an issue, especially if it's like a year before any matter devices ship or maybe even longer.
But because I've installed it myself on an Ubuntu system, I know I can keep that 2004 system up to date.
So at least that'll be secure.
Can you believe I got an opportunity to work the OS rant in there?
It's been a few episodes.
And I was almost worried that you weren't going to come up for air then.
And then I realized you were going on an OS rant.
Somehow you managed to work that angle.
Good job.
It's been a while.
Linode.com slash SSH.
Go there to get $100 in 60 day credit on a new account and you go there to support the show.
Yeah, I mean $100.
You can really go kick the tires at Linode.
It's the Geeks Cloud.
They're not going to try to lock you into some crazy esoteric hyperscaler proprietary platform where your skill set only applies to that.
Oh, I don't like that business model at all.
No, that's not Linode.
They got 11 data centers worldwide.
They've been working at this for 19 years to create a great experience to run applications on the cloud.
You can build it from the ground up yourself.
I mean really all the way down to the image.
Or you can pick one of their ready to go application stacks and get it deployed in just one or two clicks.
And the performance is great.
Anything that faces the JB audience that we've built in the last, I don't know, two and a half years.
We've built it on Linode.
And I would imagine now as being a part of Akamai, they're going to get access to Akamai's CDN.
I was quite surprised when I heard the news, but I contacted a couple of our friends that we know that work there at Linode.
And they seem pretty excited.
In fact, they're working on a new secret product, a new Linode product offering that'll be coming out soon.
That's still all in the works.
And you know another thing that's really cool is the day that announcement dropped, we actually have Linode employees on the self-hosted Discord.
And they were there answering our audience's questions about what does this mean for the future of the company?
And I think a lot of fears were kind of put to rest that day.
Yeah, they really have been part of the community for a while.
I met them the same time I met you at Texas Linux Fest, you know, years ago now.
Feels like a hundred years ago.
That was when I really realized they're actually in it because they wanted to be.
Like they were passionate about being at Texas Linux Fest and made a good impression on me.
So if you're ready to go spin something up, you want to go experiment or do a little R&D, go try it out on Linode.
Go to linode.com slash SSH.
So in the news this week, TrueNAS Scale is finally at release.
Can you believe it, Alex?
This was like announced in the summer of 2020.
It has been a very methodical development process to get us here.
And the big news with Scale is it's based on Debian 11, not FreeBSD.
Right. Yeah.
I mean, back in the old days, TrueNAS is the product formerly known as FreeNAS, of course.
In fact, there is still a variant based on FreeBSD.
That's TrueNAS Core.
This one, TrueNAS Scale, is based on Linux.
And obviously this is made possible by some of the amazing work that's been done by the ZFS on Linux project.
This TrueNAS product is still ZFS first.
It's still the primary storage file system that they recommend and kind of push in the OS.
And everything else around that is kind of orthogonal to that original premise of ZFS first.
Yeah, ZFS with Gluster.
They kind of position TrueNAS Scale as a product that works great if you want to scale out your storage across multiple systems.
And they use Helm on the back end to manage all of this with a Kubernetes system.
So you could see how when you scale that out, that back end management system scales with it.
When you're deploying a Docker container on TrueNAS Scale, it's actually being orchestrated with Helm on the back end.
I think that's fascinating.
It must have been a ton of work to get all that working right too.
They really are pitching this as a ZFS plus Gluster.
And I'm curious what you think of that.
Well, it's interesting.
I mean, I've done a lot of work with Gluster through my OpenShift stuff at work.
And all I can tell you is that with version 3 of OpenShift, we used to ship Gluster to customers.
To end customers using a tool called Hickety to do a lot of the automated volume management of persistent volume claims and stuff like that on top of the underlying Gluster storage.
All I'll say about it is we don't ship Gluster with version 4 of OpenShift because it wasn't very reliable.
Gotcha.
Based on customer feedback, you might say.
Yeah.
I mean, you got to say, like, you look at the scale that Red Hat operates at and, you know, we battle test our stuff in development.
But the real test is when you put it into production on customer sites and the reality at least for some of the incredible scale at which the OpenShift clusters that I work on operate at is it just wasn't up to the job.
Now for smaller deployments, sure, it's okay.
I'm thinking it'll be fine.
It'll get the job done for a handful of servers.
I mean, the thing with Kubernetes in particular is it can spin up hundreds of pods within a space of a minute or two, and sometimes each of those pods is making a request to the API underneath to request certain things and just things.
They're not really designed to handle that kind of scale, but I don't necessarily think that TrueNAS is kind of going after that particular market.
I mean, we look at the marketing materials and you could be forgiven for being given a bingo card and sort of crossing things off, looking at the things they've got, you know, Docker, KVM, Kubernetes, scaling, all this kind of stuff.
And I just, I look at it and wonder who it's for.
It's a serious storage appliance product, but if I'm looking for a serious storage appliance product, wouldn't I go to NetApp or Dell EMC or insert other major storage vendor here?
I don't know what niche is TrueNAS aimed at.
Is it home users like FreeNAS started out being?
Is it small, medium businesses?
I'm genuinely curious if you use TrueNAS as part of your daily workflow and you're not just a home user, let me know.
selfhosted.show slash contact.
I think this is targeted at like your Linus Media Group sized companies that have a lot of storage needs and they also want to do KVM virtualization with GPU pass-through and that kind of stuff.
Or JB, you know, we have three physical x86 servers now and you could see using this to turn all three systems into one large storage system and take advantage of running applications across them and VMs.
I mean, I'm almost talking myself into it, just actually, you know, saying it right now.
The reality is, I think small to medium business.
I think people who were maybe buying a high-end QNAP or Synology or what is that NAS software that Linus Media Group uses?
Unraid.
Unraid, we've talked about Unraid on the show, like they may be going after a little bit of Unraid's market as well here, I think.
Yeah, Unraid was where I cut my teeth in Linux, darling, you know?
Yes, I remember.
In fact, I think we both, you know, we both are actually kind of fond of Unraid, even though neither one of us have used it in quite a while.
But it definitely serves a market niche and Freenaz scale feels like it's going after that market.
But they also say, we also have a way to go even bigger.
And, you know, so maybe if your storage needs ever start really getting big, we've got other solutions here for you as well.
It's an interesting pitch for sure.
And I'll be curious to see how it plays out over the next few years.
Now, I thought I'd spin it up in the name of science slash content and see how it performs.
So I built a new backup server in January, which somehow I haven't talked about on the show yet.
Oh, criminal!
I've kind of been meaning to.
Anyway, I'll go into more detail in a future episode.
But the quick pitch is it's a local box on my LAN that just duplicates the ZFS array from my basement to my attic, right?
So it's opposite ends of the house, if a pipe bursts or something happens at one end of the house, it's okay at the other.
Obviously, I've got offsite backups in England for the rest of my backup methodology.
But this is to save me having to mail a hard drive from England instead of uploading eight, nine, ten terabytes, whatever it is.
Yeah, pipe bursts.
You don't really want to have to go through all that.
And if you got the hardware, why not?
Exactly.
So what I thought I'd do for the purposes of this segment was install TrueNow Scale on that backup box.
So I fired it up yesterday evening, installed the ISO, pretty painless.
I did it through the IP and my interface of the ASRock board I'm using.
Install was six minutes, something like that.
Really fast, painless, ZFS on route.
Great, done, booted, got an IP address straight away.
Everything was detected.
All my drives could be seen.
First thing the operating system tells me when it boots is update available.
I'm like, it was released yesterday.
I just downloaded the ISO and we're not talking small updates.
We're talking, you know, the ISO is two gig or something.
We're talking another 1.3 gigs worth of updates.
And I'm like, couldn't you have just rolled that into the ISO that you released yesterday?
That's the whole thing.
Yeah, yeah.
Maybe they froze the image a little bit ago or something.
Maybe, right?
I was like, fine, screw it.
Doesn't matter.
I'll do the update, press the button.
Then I'm presented with an error message that says cannot downgrade.
Release 22.02.0 cannot be downgraded to release 22.0.release.
And I think, man, if this is a sign of things to come, they just haven't checked the string,
you know, logic that's doing the passing of the logic about which updates the newer one there.
I'm thinking, okay, that's a fairly basic mistake to make.
But sure, fine.
We're human.
Okay, cool.
No problem.
I go to the storage tab next and I think, right, I need some storage before I can actually
even test out any of the features.
I need a ZFS pool in which to put my KVM virtual machines and my containers that I can now
run on top of TrueNAS scale because it's a proper operating system.
Just trying to trigger the BSD nerds there.
Wait, that was a totally factual statement.
What's that?
Fortunately, my ZFS pool showed up straight away.
You know, the backups pool was there.
Both drives were detected.
I click import.
It looks like it's doing something.
And on Proxmox, this process takes 20 seconds at most, 25.
That time elapses and I'm sort of, you know, watching the progress bar spin.
And then another minute goes by and I'm like, okay, this is taking a bit longer than I thought.
Another minute goes by and nothing's happening.
So then I drop to the command line, try and figure out what's going on, do a zpool import
list and it shows me all the available pools, including my backups pool.
And I'm like, okay, I'll reboot the box just in case that failed update did something silly.
I didn't do the GUI this time.
I just went straight to the command line, did a zpool import backups.
It imported the pool and I'm like, okay, cool, no problem.
Zpool list bang straight, straight away.
There it is.
Go to the UI, nothing.
So I reboot just in case there's some kind of mismatch there.
Nope, need to import the pool again.
And I'm like, oh, is it because you're doing it on the command line?
Is there some GUI command to import a pool that maybe you have to use?
Who knows?
I mean, good luck Googling anything for this thing right now because it's so brand new
and obviously the SEO behind TrueNAS is the last five years of TrueNAS core and FreeNAS before it.
And if I'm honest with you, Chris, I love the audience, but I don't love them enough to
waste more than three or four hours trying to figure this thing out.
And eventually after that time elapsed, I was like, screw this.
I'm going about the Proxmox.
I'm going to run my Ansible script and get things back up and running.
So yeah, ultimately TrueNAS scale was a massive fail for me.
I have typically struggled with these types of products and I often end up just going
back to basics and I think it's kind of unfortunate because in some ways these guys can unlock
stuff for me that I don't even know how to do.
I also feel like there's a spectrum of user that probably prefer something like this,
you know, and it works better for them as well.
And I wish I could kind of get my head in that space.
I was tempted for a brief moment to deploy it here at the studio and base our stuff on all
that because, well, you know, we were just going to build this YOLO setup.
It was like this crazy cross three system storage array.
And, you know, maybe even no redundancy, just tons of disks and stupid stuff like that.
That just has no sensible use.
And then we started thinking, well, what if we wanted to the opposite?
What if we really wanted to build this thing to be reliable?
We're like, you know, there's failover and all that kind of stuff.
And I got to say it's on my list of things to consider.
But what my preferred route would be to just build it really simple, build it basic and
probably, you know, manage it with something like Ansible.
The simpler you go, the easier it is to recover from a failure too.
Like in my pipe burst scenario, all I have to do is a ZFS send from one box to another
and I'm back to where I was.
I think it's very likely too that if you were to check back in, say, I don't know,
in episode 85 and see where TrueNAS scale is at, I bet you'd be in a totally different
state, right?
Even though they've been working on this since 2020, this is a massive reworking of the product
and it's going to be a little while before it's probably fully, fully cooked.
And I think they even consider it that, like, if you look at like their presentations on
this, they're kind of positioning it for more early adopters at this point.
There's a difference between fully cooked and not importing the basic storage pools
there.
TailScale.com slash self-hosted.
Go there to get a free personal account for up to 20 devices.
And of course you support the show.
What I love about TailScale is that it's zero config VPN.
I think it's going to blow your mind how fast you can get this thing set up and then it
just runs.
It connects all your devices directly using WireGuard's noise protocol.
So it's as tough as WireGuard, but it's a mesh network.
I was using it today to connect back to LadyJuice to check in on the Raspberry Pi because I
started getting some errors with the Uptime Kuma.
I was getting errors because I have Uptime Kuma running here in the studio and it connects
back to LadyJuice over TailScale and checks on stuff for me.
And sure enough, yep, I was having an outage, it turned out to be Starlink though.
But it was nice to know that I could go check on everything and I've created like my own
LAN that goes wherever I go and it can connect my servers, my workstations, my mobile devices
even when you're separated by firewalls or even double NAT, TailScale just works.
I'm using it on my family's computers to help provide remote support now as well.
And I just love that every device essentially gets a static IP address, at least in my world.
It's pretty nice.
I really like the fact that you can use different nodes as exit nodes as well.
So if you want to come out in a different state or a different country for some reason,
you can totally do that.
So you use the advertise exit node feature and you know, for me and my iPlayer habit,
that's very handy.
Yeah, that's a power move right there.
That really is.
And the other thing that's great is that TailScale supports your authentication system, your
identity provider.
So you can enforce multi-factor authentication, you could deauthorize employees or devices
and stuff when people move on, like you get access and control over all that as well.
So go try it out for free for up to 20 machines and support the show by going to TailScale.com
slash self-hosted.
So David asks about keeping Nextcloud going.
Hey, Chris and the Badger, I've been listening for a while now and I've just started my journey
with Nextcloud.
It seems to be a perfect fit for my home lab.
And as I progress with my journey, I can see myself getting more into the, how do I say
it, enterprise-y way of doing things, specifically I'm talking around monitoring and security.
So what are some of your must-haves when you're deploying things like Nextcloud for that kind
of stuff, like monitoring and security?
I'm sure your first answer will be everything sits behind WireGuard, but outside of that,
it can be a bit overwhelming to newcomers.
Maybe everything sits outside of TailScale, right?
You know, it's funny.
I actually would go the other way, you know, I mean, so David asks, what would you install?
My top Nextcloud tip is only load the apps you need and then double check if you really
are using them and need them.
And if you don't, unload them, all right?
So that's my top tip.
But as far as turning stuff on, if you're going to expose Nextcloud to the internet,
turn on two-factor authentication and it integrates with probably any two-factor authentication
system that you love and know.
It's really easy to do.
They've made this simple.
There's an app you can install as well as some settings and I'll put a link in the show
notes for how to get that going because I think if you just keep Nextcloud up to date,
you keep it super lean, you turn on SSL and you turn on two-factor authentication.
I think that just doing those things, you'd probably be all right.
What's your feeling about updates for Nextcloud?
I think I'm probably five versions behind at this point.
I am a version behind myself.
You know, that's tricky here at JB is we run two Nextcloud instances.
One that you guys interact with up on the node and then we run another instance here
in the studio and it is kind of a pain in the butt to keep it updated if I'm honest
because sometimes there is some work that has to be done.
So what I do is I just wind to Wes and usually get him to do it, but we do it all through
Docker Compose now and I'll do it on occasion, but I have to tell you, it slips and I don't
like that.
Not everybody has a Wes at their disposal, you know that, right?
Wes, you just do it like that.
Thankfully if you run it all through a container or some other system you're comfortable with,
I know some of our listeners use the snap.
Some of those methodologies are actually pretty easy to keep it up to date.
I'm only a version behind, I just checked on version 22, 23 is the latest, came out
in December.
It's not too bad.
Yeah.
In my head I'm like three behind, in reality I'm only one behind, but I feel that pressure.
Another important thing, David, would be to make sure that you are really cognizant about
how you actually deploy Nextcloud in the first place.
As Chris mentioned, some people use a snap, other people use a container, other people
do it by running it on the host itself.
And one of the most common ways I've seen listeners lose data is by not remembering
how they set something up six months, a year, two years ago, and then their server goes
down for some reason.
They've got a copy of the data from the sync client on their local system, but they don't
have a way to reconstruct the database and the users and everything as it was.
So use something like Docker compose, it would be my recommendation for a repeatable deployment
method.
Whatever you do, whether it's compose or whatever, make sure you write it down somewhere.
Well said.
Well said.
Plus one on that.
John writes in, looking for a simple way to get started.
He says, I hope you guys can help me here.
I'm starting to dive further into self hosting and I have a couple of Mac mini servers at
home and I was thinking about setting up the M1 box with either Docker, maybe with Portainer
or Unraid to start and learn about implementing containers for apps such as Plex Media Server,
Home Assistant, TDR, et cetera, et cetera.
I want to have a GUI as I'm not a coder apart from following how-to videos from YouTube
and using terminal commands.
What would you suggest?
Cheers, John.
Well, I think Unraid is a bloody brilliant place to start, to be honest with you.
It's a really great mix of UI, community, and documentation, and I think those three
things together make a perfect mix for newcomers.
A lot of people that are running Unraid do so because they are new to serving stuff at
home, you know, media servers, what have you.
By this point, Unraid has been around for, I want to say like 15 years.
So not only do you have that mix of noobs, for want of a better word, but you've also
got that mix of really experienced, passionate users that want other people to be as excited
about their special little thing that they found 10 years ago and has been working perfectly
for them ever since, you know?
And there's very few products on the market that do what Unraid does.
One of the things that makes it so great is the fact that you can stick any kind of hard
drive in there, you know, like a JBOD style.
There's no real kind of constraints around like there is with ZFS, for example.
You've got to do a matched pair for a VDEV, and if you exceed the VDEV, you lose data
and yada, yada, yada.
Unraid's really simple.
If you have a parity disk, it has to be the biggest disk in the array or as big as.
If that fails, you've lost your fault tolerance, and if any further drive fails, you lose the
data on that drive.
And that's really simple to understand, and I think just that simple thing hooks a lot
of people into Unraid.
But then you start looking at things like the community.
There's lots of videos from a chap called SpaceInvader1 on YouTube.
He does really great simple-to-follow tutorials where you click here, you do this, you do
that, and off you go.
As you grow, you might find the guardrails that Unraid has are a little bit restrictive,
but as a new user, that's a good thing in my opinion.
I don't know if I've heard of anybody running Unraid on a Mac Mini, especially not an M1
Mac Mini.
I also don't know if Portainer works on Mac OS.
You'd probably end up using Docker Desktop on Mac OS.
He talks about wanting a GUI, and Unraid's definitely an option, maybe FreeNAS Scale
is an option, if you want to manage some disks.
If you're just going to have like one disk and you just want to run some applications,
you know, Alex, I almost wonder if it's worth considering the whole Home Assistant stack,
because if ultimately he wants Home Assistant anyways, when you install Managed Home Assistant,
you get an app store essentially that lets you install things like Plex, and it just
does it all through Docker containers.
The only trick is you have to install it, I mean, generally like they release a Raspberry
Pi image or something like that, but it does offer a way to run a lot of these popular
open source self-hostable applications with just a few clicks, because Home Assistant
itself has a supervisor part that can manage all these containers.
Otherwise yeah, probably something like Unraid or FreeNAS, or there's also just the option
of doing something like CentOS or Ubuntu and using something like Cockpit on top of that.
I know that's getting a little more advanced, but he did say he was comfortable using terminal
commands.
So that's another choice, but let us know how the journey goes, John.
I'll do a final shameless plug for PerfectMediaServer.com if you want to just do things from the command
line.
I think that's probably the way to go.
Well, behind the scenes, we are making secret, not so secret plans for a JB East Coast meetup.
And of course, in the planning phase, what's come up is like, how the hell are we going
to pay for this?
And it got us talking, and I don't think we're going to do it for this.
But down the road, there may be a project or something like a special edition of a show
or maybe some special trip.
How would we, if we wanted to, do crowdfunding?
And we thought, well, we'd like it to be open source and self-hostable.
I went out there and did a little looking around, and it looks like a lot of those projects
have died or become abandoned over the years.
So if you know of a self-hosted crowdfunding application that's alive and well, maybe you're
using it, let us know about it, self-hosted.show slash contact.
Because if it was ever something JB did want to get into, we'd like it to kind of align
with our values.
I can't believe it's taken us until this point in the show to actually even mention this.
But I know April the 9th in Raleigh, we're going to have an East Coast JB meetup.
And rumor has it that a certain RV dwelling podcaster might be joining us there.
It's true.
Although I'm going to fly in.
I think, I'm hoping it'll be a life goal if it's like one part mini vacation with the
fam because it'll be my son's 13th birthday and spring break.
And he is a Bitcoin nut.
So we're hoping we could fly into Miami, go to the Bitcoin conference for a couple of
days, and then fly up and hang out with you and the family and then go to a meetup.
It's all in the planning phase.
But Alex, we have needed to do an East Coast JB meetup for about 15 years.
I mean, it's embarrassingly bad.
And you and the community just were like, screw it.
We're just going to get something started.
And I was talking behind the scenes thinking, you know, I'm feeling like I really need to
take a little bit of a trip.
I am really feeling burned out.
Like I need to do something.
And this Bitcoin conference came up and this meetup came up and it's like, this is almost
too perfect.
So behind the scenes, we're trying to figure it out.
Well, of course, normally you're busy planning for Linux Fest Northwest, but for obvious
reasons that's still on hiatus.
Right.
And that was actually how the conversation started, because that's usually like a nice
little way for us to connect with the community once a year.
And we're going on two years now of not having it.
It's like our big event.
And you found a great spot, too.
So it's like, God, it just all seems like it's coming together, like a nice spot and
great weather on the East Coast.
Right on Dylan's birthday spring break.
I'm like, oh, let's do it.
So we're figuring it out.
Let me paint a picture for the audience.
Right.
So prime barbecue is a Texas style barbecue joint that's just opened out just outside
of Raleigh.
It's a place called Nightdale and it looks out over this big park.
And on the other side of the park is a place called Oak City Brewing.
So what I'm thinking is two, three o'clock in the afternoon, something like that.
We'll put all the details on meetup.com closer to the time, but something like two or three
o'clock in the afternoon on the Saturday, we'll meet at the barbecue place, go get some
food, sit on the lawn, go and eat and mingle with people.
And then as the evening progresses, we can head across the brewery and go and get some
drinks.
And I've been racking my brains for the last few weeks about where we could go in town
that was kind of a COVID safe location.
And the beauty of this place is we can all congregate in this place together, but we're
outside.
Right.
And the weather in Raleigh in April is going to be lovely, of course, apart from the pollen,
maybe that might be a thing, but on the whole, I think it will be a lovely day for everybody.
And it's going to be right next to some great stuff.
Yeah.
So the thing to do would be to join our meetup.
We don't have like one set for this, but you could join the group at meetup.com slash Jupiter
broadcasting or join the discord, selfhosted.show slash discord if you have questions.
But when we get our details solidified, which we're really close to, hopefully, we'll probably
make a proper meetup post about it.
The provisional plan, like I say, is Saturday, April 9th, 2 or 3 p.m. until we all get bored
and want to go home, something like that.
If you're anywhere in the area, we don't make it out to the East Coast too often.
So come join us.
It'll be a lot of fun.
And also thank you to our members.
You know, you guys really help us keep the show on the road and you also give us the
freedom to wait until a great sponsor like Talescale comes along.
You know, like you give us leverage there to make wise choices.
You give us runways, they say in the business.
Selfhosted.show slash SRE if you'd like to join as a perk, you get more show.
You get a post show.
You can also support the entire network, just like the cost of two memberships and you support
all the shows and you get all the shows ad free plus that post show.
That network support is at Jupiter.party.
And as you all know by now, the place to go to get in touch with us is selfhosted.show
slash contact.
You can find me on the Discord at Alex KTZ and you could find me on matrix.
Come join us in the self-hosted matrix.
Our matrix server is Colony.JupiterBroadcasting.com.
I didn't mention it in the show and it's just a very quick addendum.
Big thanks to Jake, the real orange one, the orange one, whatever his handle is this week
for running our matrix party thing, set up party that we had a couple of weeks ago.
It went really well.
We had about 30 people show up.
It was a fun time on a Sunday.
Big thanks to Jake for setting that up.
And as always, thanks for listening everybody.
That was self-hosted.show slash 65.
