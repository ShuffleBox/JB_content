Coming up on today's show, I report back from a failure that led to a couple of cold nights.
Alex has been shocking and jiving and we have a pick for you pack rats. I'm Chris.
And I'm Alex and this is Cell Hosted.
What did you end up buying on Prime Day then?
You got me. I actually almost avoided it entirely, but for some reason in the evening,
maybe I'd had a glass of wine, I had a moment of weakness and I opened up the Amazon app
and they had the Fire Tablet, the new 8-inch, I guess it's quote unquote new, on sale for $50.
$50? That's nothing.
I know. And I'd already been thinking, in fact, this is probably why I opened the Amazon app,
is I'd been thinking I'm ready for a second wall-mounted always-on home assistant display.
And I don't know if I love the Fire Tablets, but I could be pretty happy at $50.
What about you? Did you get anything?
So there's two categories of Prime Day purchases, aren't there? There's the ones
that you tell your wife about and the ones that you don't. I'm only kidding, but-
No, you're not because I also just remembered, and I don't think I've told the wife yet,
I went ahead and got a SodaStream.
Oh, wow. 1980s cool. They want their SodaStream back.
I drink water in the studio all the time and I'm getting kind of bored. I've been doing it
forever. Just nothing but water during the day. And I want to spice it up a little bit.
So I picked up yet another TV. This one's from my kitchen.
Oh my, a kitchen TV, Alex? That's what tablets are for.
Well, yeah. I mean, we've been using my iPad for that for a little while, but I don't know,
like when you're cooking, there's something about just having that big display on the wall.
And so I bought a 43-inch TCL TV thinking it would be the same as the other two that I have
with the Roku built-in. I didn't even look, just bought it from Target actually, not Amazon.
It was $179. So it was really very, very cheap.
Wow.
And it comes with Android TV on it, would you believe?
Not, but not Google TV?
It says Android TV on the box.
Oh, right. But it's not Google TV, right? It's not.
No, I know what you're saying. Like it's supposed to be the same as what's on the new Chromecast,
but it's different. It's the same as what's on the Shield.
Ah, okay. That's great. How's the performance?
Performance is what you'd expect from probably a three or four-year-old processor that they've put
in there. Yeah, it's fine. It does the job. It's a very bright, punchy TV. It's not going to win
any awards, but for the price, I don't really care.
Well, here's the question. Are you going to attach any external set-top boxes to it,
or are you going to use the built-in Android?
Well, that's what I bought the Chromecast for.
Oh.
But now I don't need it.
You're right.
So now what are you going to do? You're going to keep the Android TV on there and then,
oh, you know, that Chromecast, you could always just use it as a travel device if we-
If we ever leave the house again. Yeah, maybe. I don't know what I'm going to do with it really,
but it's interesting. It's amazing what you can get for the money these days, really.
Yeah, I did see a lot of really good deals on TVs. I couldn't believe my eyes on some
of the deals during Prime Day. I'm not in a place to really just hang a TV anywhere,
so I didn't get one. But now that I think about it, you know, maybe as a business expense for
the studio, I should have thought of something because I could always use another screen in here.
Well, it's Black Friday again before you know it.
Yeah.
So coming up shortly, I'll talk to you about some of my hard drive purchases, but first-
This episode is brought to you by a cloud guru. Tech moves fast, and so does ACG.
Their courses and labs are always online and obsessively updated. Plus,
they curate all the news on AWS, Kubernetes, Linux, and more. Stay up to date at acloudguru.com.
So Alex, you also got some drives and you've been doing some shucking and jiving, I understand.
Indeed I have. I think I might classify this as a hobby now. I seem to do it really quite often.
So I bought five different chucked drives or five different USB enclosure drives,
mostly so that I could report to everybody here what the different types of drives on
the market are and the prices and that kind of stuff.
Interesting. Okay.
I bought a 10 terabyte easy store from Best Buy, which was $189. I bought that about a week ago
because I found out after my ZFS snafus a couple of weeks ago that one of the drives in the mirror
was failing smart, so it's time to replace that one quickly. The others that I bought,
I bought a pair of 10 terabyte Seagate USB 3 drives, which I think were about $179 again.
Oh no, those two were actually on Amazon warehouse deals, so I got those for like $150-ish each.
And then the final two that I purchased were actually on Prime Day because Best Buy were
matching Amazon and they did 12 terabyte drives for $169 a piece, so I got two of those as well.
And what's really interesting between all these different drives is you don't really know what's
going to be inside the box until you crack the case open. And a few years ago, I shucked about
10 or 12 10 terabyte easy stores and they were all purchased within a few weeks of each other.
And so my logic for buying more drives now is that if one or two drives are starting to go now,
the chances of others from that batch going is probably decently high.
I agree.
They've been subjected to the same environmental conditions, the same vibrations, humidity,
workloads, etc, etc. So it seems logical to start replacing those drives a couple at a time,
you know, every six months or so, or whenever Best Buy has a sale, really.
Now, those people in Europe that want to do this kind of thing,
you obviously don't have Best Buy over there, but Amazon do have some good deals.
So use camelcamelcamel.com to go and track the prices of different things on Amazon,
and then you can see what the historical highs and lows were. Bear in mind that US prices don't
include tax and European ones do. The cheapest I saw was about 200 pounds or so for every drive.
So it's a good deal for a 10 or 12 terabyte drive. So just keep an eye out. They are there.
They are a little more expensive than over here, but they do exist.
So we'll start off with the 10 terabyte Western Digital drives.
Couple of years ago, you used to get rebadged Hitachi storage 10 terabyte Helium drives,
which ran cool. They ran quiet. Everybody suspects that they were actually 7200 RPM drives that
make the cut and were kind of underclocked in firmware to 5400 and rebadged and sold
through the easy store program. Nowadays, in the 10 terabyte easy stores, they seem to be
putting in air filled drives, and that doesn't sound like a big deal, Helium versus air, except
for the fact that in my testing at the moment, and I'm burning all of these drives in right now,
and I'll talk about that more later. I'm burning these drives in at the moment, and the air filled
is running about 10 or 12 Celsius warmer than the Helium filled drives, and that's quite a lot. It's
sat right now at 52 Celsius, whilst the Helium drives right next to it are at 40. So just an
observation there. Yeah, if you don't like heat, take that for what it's worth. You know, if heat
kills hard drives, you do wonder if that would multiply to if they were really smashed together,
would there be even more extreme differences in the temperatures between the Helium and the air
filled? Yeah, I think, you know, it's, heat is gonna, it's gotta go somewhere, you know, and
hard drives don't need a huge amount of airflow, but they need some. And, you know, as long as
they're getting that gentle breeze over them, they'll generally be okay. But a lot of NAS cases
and server, you know, home server grade chassis don't have the best airflow in the world. So
you've really got to pay attention to those temperatures. Somebody was asking me on Discord,
how hot is too hot for a hard drive? And I generally try and keep things in that 40 degrees
or lower range. Often it will go up to 45 at a max, you know, on a particularly hot day. And I
generally think that's fine. But my rationale for that is if you look at the data center
environments, most of those are kept between 20 and 24 Celsius. And, you know, my basement
fluctuates a little bit either side of that, but generally speaking, just through natural convection,
it keeps pretty much at that temperature. You know, if you're aiming to keep these drives
at 45 or lower, you're probably having them in a similar kind of state to what a data center would
be. And because data centers buy so many hard drives, you've got to imagine that that's how
people engineer, these companies engineer those drives to succeed well in those temperatures.
Now, before you shuck a drive, there's a few different considerations that you've got to make.
You don't want to just run a full smart test and then burn the drive in in the enclosure with no
fan on it, because very quickly you'll see your drive temperatures going north of 60 Celsius.
Because those enclosures just aren't built for, you know, stress testing enclosures. They're
basically built for someone to just dump a few, you know, bits of drone footage on to or some
movies or something like that, and just stick it in a drawer and forget about it. They're not really
designed as performance type things, which led me on to another train of thought. I was thinking,
well, how performant are these drives? So I had my air filled 10 terabyte drive. I got a pair of
helium filled 12 terabyte drives. In the Seagate boxes were a pair of Barracuda Pros, which normally
sell for about $300 each. Whoa. So I was very pleased with that. What the heck? That's a great
score. Yeah, no SMR stuff, which is nice. They're all CMR drives. So something else you want to try
and watch out for. But the whole purpose of me burning in these drives now and stress testing
them now when they're only a few days old was actually borne out perfectly for me by the real
orange one over on the Discord. And he has a two month old hard drive, which is failing. And he's
now having to go and do an RMA with Seagate. I mean, they'll replace it. It's under warranty.
That's not the issue. The issue is when hard drive manufacturers replace drives, they almost always
send you a refurb. Yeah. So put yourself in his shoes. He's now got a two month old drive that's
a refurb. That's not great. No. And you wonder why it was sent in in the first place. And of course,
a failure in a disc like that's either going to happen early in its lifetime or on the average,
about what, five years later? It's the bathtub curve. It is indeed. The whole idea between
stress testing them now is to weed out the weaklings whilst I'm still within my Best Buy or
Amazon or Newegg or whatever retailer's return policy. So I can just send it back to them and
make it their problem, not mine. Just reshuck. Yeah. I mean, seriously, it's not the retailer's
fault that Western Digital made a faulty drive. But equally, it's not my fault. And I don't want
to commit data to it either, and then have to copy all that data off in a couple of months time.
And it's just, for me, it's about a day per terabyte to do the burn-in. Now I've written a
blog post about how I do burn-ins. I use bad blocks to do it. Yeah, it takes about a day per
terabyte. So I'm looking at 12 continuous days of burn-in here, but I think it's worth it.
That is definitely a peace of mind test. That long of a test really is going to genuinely
stress that disc. I would actually have a pretty good peace of mind after going through that.
My question to you is, maybe with the Barracudas aside, none of these really seem necessarily
server-grade discs. Is that part of why you're doing this? I don't think they are. I mean,
some of them are rebadged Hitachi UltraStar drives. Some of them are rebadged Western Digital
Red drives. It's this kind of whole situation with the white label drives that go inside the
easy stores. A couple of years ago, you used to sometimes actually get red label drives. They
didn't even used to have a separate skew for the easy store drives that went inside them,
the white labels. But now they've cottoned on to the fact that we've cottoned on to the fact that
they are shipping seconds, basically, in these boxes. They know we know that they know. Now we
all know. Yeah. I think it's kind of an unspoken, you know, just, yeah, okay, we'll sell you drives,
but you have to put a bit of effort in and take them out of the case, which is a five-minute job
per drive. As long as you've got a couple of guitar picks and a screwdriver with a Torx bit
on it, you're fine. I mean, it's really easy, so there's no fear there. But somebody was talking
to me, and this wasn't on Discord, this was at work actually, saying that they thought that these
drives were slow and that, you know, if you want rusty, spinning, slow drives, there's a Best Buy
sale on today, was what they said. And so I thought, hmm, let's go and test the performance of
the two-year-old drives I have in my basement versus the new ones we've got here. And it turns
out that actually the, I have a, I bought an eight terabyte Hitachi $270, 7,200 RPM, 256 meg
cache drive when I first got here. So it's, you know, it wasn't shucked. It was always shipped as
a naked drive. And, you know, so theoretically it's as good as it gets on the consumer side of
things. And what was interesting is that that drive, when I put it through some testing with FIO,
and I used Jim Salter's Ask Technica, how to test your hard drive performance article, I used FIO
to do this. So I got in the region of 134 megs writes to this drive, which is pretty good. And
so then I compared it to a shucked Easy Store, which runs at 5,400 RPM, and I got 116. So 134
plays 116. Now for me, the cost difference, you know, the eight terabyte drive that was shucked
was about half the price. So for 18 megabytes a second, that's fine.
Yeah. I think you could argue it's worth considering if these were disks that you were
putting in your workstation and you were working from them. Okay. Maybe I'll hear that argument,
but these are going into a RAID. The RAID has its own performance characteristics that also
change the math on all of this anyways. And at the end of the day, you're storing items on this
that you access infrequently. And when you do, you're likely accessing them over the network,
possibly even over Wi-Fi. So you have to take the entire use case picture in when you're looking at
the speed versus price argument, I think. Absolutely. Yeah. So, you know, if you're
looking to buy a new drive on Black Friday, my personal advice would be steer away from the
10 terabyte easy stores because they're now hot air drives and go for either the Seagate ones
at 10 terabytes that you can probably find on Amazon warehouse for 150, 160 bucks a piece,
or go for the 12 terabyte easy stores from Best Buy because they are helium drives and they run
nice and cool and quiet and, you know, 12 terabytes. So it's more than 10, isn't it? So...
Linode.com slash SSH. You go there, you get a $100 60-day credit towards your new account,
and you can try out our hosting provider in the cloud. Some workloads are better in the cloud,
and Linode is dedicated to offering the best virtualized cloud computing. If it runs on Linux,
it will run on Linode. They started three years before AWS. They're independently owned and
they're founded on a love for Linux and open source technologies. I started using them about
two years ago, and I roped Alex into it, and Alex discovered that Linode has pretty excellent
Terraform support. Yes, in fact, all of the self-hosted show infrastructure is running
on Linode now, and we're using Terraform to use the infrastructure as code principles to spin up
all of this infrastructure like magic, and it just works. The documentation is top-notch,
and the integration with Terraform and other DevOps tools is fantastic.
That is super slick, and it makes it really easy for us to prepare and test things for the show.
Something else that I rely on a lot for show production, and you should consider it too,
is object storage. Now, there's a lot of ways you could take advantage of object storage. If you
don't know, it's an easy way for you to store and access data without the need for a front-end
server that's producing a website or syncing files. It's perfect for data that doesn't change very
regularly, like maybe you want to store some images, or I store audio clips and video clips
up in the object storage. But additionally, you could use it to host files for a static website,
and man, would your website load fast. It's really worth checking out object storage. If you need
really easy cloud storage that you can generate public URLs for and then embed in websites,
object storage is fantastic. I love Linode. I recommend it to all of our listeners. You can
get a $100 60-day credit for a new account when you go to linode.com slash ssh. So sign up today,
you support the show, and you get that $100 60-day credit. linode.com slash ssh.
Well, it's that time of year. The leaf blowers are firing up and winter is coming.
It's getting cold. Yeah, it is. And I finally hooked up my heating again. I'm very proud of
the automations I've built for the heating system in lady tubes. I finally got them all plugged back
in because what I like to do is during the summer, why not reclaim that space? I pack away the heaters,
but I leave the smart plugs plugged in. So that way, everything's still talking to home assistant.
And then I have a series of automations that will start and stop those heaters based on
the temperature in that area, matching a condition that the sun is below the horizon.
So I have heaters in my bedroom, in the living room, kitchen area, because again, this is a
bus, right? So the living room and kitchen are essentially one area. And then the upfront driving
area has a temperature sensor. My water bay has a temperature sensor and my battery slash electrical
bay has a temperature, mostly so I can monitor if that's just getting too hot. But they all have
temperature sensors in those areas. And the way the system works is it looks at all of that,
looks at the individual rooms and it sees what the temperature is in the room. And it sees if
the sun is above the horizon or below the horizon. And if the sun is below the horizon and the
temperature is, say, below maybe it's the bedroom, so below 67 degrees, the heater comes on. And if
it's really cold, I have I have like supplemental heaters that will kick in to really kind of get
it up there because, you know, it's an RV. The walls are like maybe if I'm lucky, six inches thick,
probably more like four or five inches thick. So it's a thermal loss was a big problem.
Last year was our our best winter in an RV after five years because the the heating was finally
just right. We were really always perfectly comfortable. It'd been really nice. And it had
been just a bliss of having automations that just take care of it. You don't even think about it.
And all of that, Alex, came to a chilling end this recent week. Chilling end. Who are you going to
call? Who are you going to call? Myself. Right. And it's one of that's what's so awful. And
I actually had a bit of a down moment during all this is like, oh, this isn't working.
Dude, this is what I was saying last episode. The perils of self-hosting. Like if it breaks,
you're the one on call. I think you jinxed me. I think you jinxed me. So sure enough,
the night that I hook up the heaters, I think to myself, well, let's go make it cozy in the bedroom.
So I tell home assistant, turn on the heaters in the bedroom, you know, get it nice and cozy in
there. So, you know, I wanted my wife to walk in and go, oh, man, oh, yeah, the heaters are back.
It's so nice. And sure enough, home assistant reliably fires off the heaters. And I have a I
have an automation that when it gets to 73 degrees in the bedroom and if it holds that for three
minutes to turn off the heaters and I'm in bed, I'm getting all comfortable and I hear the heaters
click off, the automation kicked in perfectly to turn off the heaters. I fall asleep and I wake up
right around two a.m. and I'm very cold, like because it's it was the first night here in the
Pacific Northwest where it got into the mid 40s in the middle of the night. And it's so 2 a.m.
I wake up because I'm so cold. That's what woke me up. Right. So, you know, it's uncomfortable in
the room. And I'm I'm like, I wake up. I'm like, what the hell's going on? The heaters are hooked
up like this isn't supposed to be happening. So I get up and I don't want to disturb my wife. So I
go out into the living room perfectly cozy, very comfortable. Clearly that the heating automations
had been working out in the living room flawlessly. But in the bedroom, of course, not working. So I
didn't realize fully the extent of this. I thought, OK, there must have been some mistake. So I open
up home assistant. I looked at I turned my did I turn off the automation because I didn't actually
check because I just assumed I left it on. So I always do just what you want to be doing at 2 a.m.
Oh, yeah. So go to home assistant. Oh, yeah. Look at that. I had left the automation, but I could see
the last time it had been triggered was the first week of May because I haven't used the heating
since then. So I hit the little play button that fires off the automation immediately. And the
heaters kick right on. OK, OK. It's working. It's obviously working. I go back to bed temperature
slowly coming up. I wake up at 6 a.m. and the room is cold again. What I realized was very reliably
very reliably. The turn the heaters off automation works, but the turn the heaters on doesn't work.
So they turn off, but they don't ever turn on. And I didn't really get this. Of course,
it's like 6 a.m. and I hadn't slept well, but I'm dumbfounded, right? Because the turn things off
automation is essentially just the reverse of the turn things on automation. And one's working and
one isn't working. And I'm just really perplexed by this. And there was one star sized difference
between them. But I'll get to that in a moment. But let me just say at first I was actually a
little discouraged that morning. I telegrammed you. I was doing a round of Googling. And what
I was finding is the recent rapid versions of Home Assistant, God bless him, have made it so that
almost every release, something in automations kind of goes sideways for somebody out there in
the Internet because of all these use cases and edge cases. And so you just find all of this
backlog of stuff that's no longer relevant to troubleshooting anymore. All these forum posts
and everything because Home Assistant so quickly outdates it that something that was posted in
April is just really generally not very useful anymore. And the error was so generic that nearly
everything I searched for kind of just showed up, you know, automation not firing off, not triggering,
you know, the kind of basic crap you get with that. You just don't really get any help.
It's like Googling something for Windows. Unless you have the very specific error code, you just
end up in a tar pit of just useless information. Yep. So I go to work, you know, I figure
I'll think about it, but I won't I won't stress out too much about it.
And I'm chatting with my wife and she's like, so there's really no other differences between the
off and on automations, really? You got to bear in mind, like I created these more than a year ago,
right? So I don't implicitly remember them very well. So I open up the two automations,
the off automations and the on automations side by side. And what I realized is the off automations
run 24 hours a day, regardless of what the sun is doing. The idea being that if it gets above
this temperature, I don't want the heat. So I don't want the heaters on. So just I don't care
what time of day it is, turn the heaters off. But the turn on automations only trigger if the
condition of the sun is below the horizon and if that's met and if that isn't met, the automations
don't trigger. So with that realization, I kind of refined my Googling and I found a two year old
Reddit thread that actually was my problem. So I had to change the condition. Now, the conditions
are these options that prevent execution of an automation unless all of the, quote unquote,
conditions are satisfied. So one of my conditions is that the temperature is at a certain threshold
and that the sun is below the horizon. And, you know, I use the crap out of that for like all my
outdoor lights, a bunch of the lights inside the RV are set to come on 30 minutes after sunset,
and those are all working just fine. It's only the two heating automations for the bedroom.
But for some reason, kind of still unknown to me, I had to just make a change in how I was
checking the state of the sun. Stick with me for a second. The sun in Home Assistant is also
essentially a sensor. And so I went from using the built in condition of the sun, which is built
into the automation GUI wizard. You can say sun below horizon is just a built in option.
I had to take that out and I had to instead go get the state of the sun sensor. And then I had
to manually specify in just plain language when the state of the sensor is below underscore horizon.
And when going from a state of the sensor as a condition, the automation started working again,
as expected. And it seems to be maybe something in the logic of how the graphical interface builds
that automation with the sunset condition. So essentially you end up using for if you want
something to reliably work based on the sunrise and sunset in Home Assistant, you need to use the
sensor state, not the built in sun condition. It's confusing. Even the language around it is
confusing. And I still kind of have questions like, why did this only bite me now? I've had
this automation for over a year. This reddit thread is two years old. So somebody ran into
this two years ago. I don't really know when it broke. It must have broke during the summer when
I had the heaters actually disconnected and I just didn't notice that the smart plugs were
clicking on or off. I don't notice that. I'd leave them plugged in all the time. So when did it
break? I don't know. Was it some particular update? I don't know. And why do my other
automations that are using the original sun condition work fine still? And then I guess my
last question is, are they eventually going to break on me? I think we can refer to this as like
the Home Assistant half-life. You know, like they have an entropy of decay that just sort of
happens. Automations just stop working for some reason. And sometimes it's not totally logical
as to why and when it happens. Yeah. Yeah, I felt a little like less confident in the setup
all of a sudden. And then just unrelated, Alex, just a couple of days later, I did an update.
And that night, Home Assistant locked up on me. So I got the heating working for one night. And
then the next night, Home Assistant locked up on me. None of the automations ran. I couldn't
even get to the dashboard. I ended up just rebooting the entire host because it needed
to reboot for some security updates anyways. But so for the second night, so one night it works,
the next night, no heat again throughout the entire place now because Home Assistant just
locked up. It hasn't done that in forever. And I had to reboot the whole host. It's very reliable
for me. I don't have any lockups or anything like that. But I do find that sometimes automations
just stop working. And I don't notice that they stop working straight away. And I don't know
whether it's the pace of updates, like you mentioned, breaking stuff, or whether it's just
that I've introduced another change somewhere else. It maybe almost needs a testing framework
for these automations, like a CI build passing set of badges or something for each automation
somehow. I'm not sure how that would even work. But I don't want to make a change in one place
and then have it break something somewhere else. So I need a way that when I dust this dinosaur
bone over here, the tail doesn't fall off the dinosaur at the back. It's a tricky one though.
Tricky problem. I think that could be doable, Alex. I just got a supervisor add-on that checks
the Home Assistant configuration against any new version. So it takes your existing config,
it looks at the new release config defaults, and does a compare and tells you if there's going to
be any issues. And I could see something like that expanding to automations.
Yeah, particularly given all the changes they made in the latest birthday release to the YAML
structure and that kind of thing. I could see that being useful.
All things considered, I am happier today with Home Assistant than I have ever been. I continue
to be extremely enthusiastic about it. I am constantly integrating new things with it. I
went ahead and just recently integrated the studio's Amazon Echoes, which support Amazon Guard.
And now I can toggle the guard status inside Home Assistant, and all of the Echoes do not disturb
switches and other features show up as sensors and options in Home Assistant now. It's really cool.
So I just have been just bringing more and more into it. Also, I've recently learned that the
Ring API integration is pretty decent. You can bring in still images from Ring cameras into Home
Assistant. You can also bring in their motion sensors into Home Assistant. You can get a little
Lovelace card that shows you the last time they detected motion. It's all great because the way
Home Assistant works with all this stuff is at the end of the day, they're all just like sensors.
So you can just build everything around these. And it still to this day feels like this great
unifier of all these rando products that these different vendors make. And I bring it all
together in Home Assistant. Well, let me just take a moment and thank a cloud guru. You know,
a cloud guru has a system D course. Now it might be worth checking out because system D has taken
over the Linux landscape and you may know some of the basics, but there's a lot more it can do.
It's got some components that you can put together as well, which we'll mention later on in the show
that can make your life a little bit easier. So go to a cloud guru.com or use the link in our show
notes to take you directly to this course. It's a course designed to demystify the sometimes
difficult and admittedly deep topic of system D. You might be using system D today, but are you
really taking full advantage of it? There's an opportunity here to learn more. Use the link in
our show notes, 5.8 hours of content, 40 total lessons and eight hands-on labs. Link in the show
notes and thanks to a cloud guru.com. All right, it's time for some listener feedback. Pete writes
in about his OBD2 data. Yeah, he says, Hey guys, on one of the JB shows a while back, Chris explained
his usage of his OBD2 readings from his vehicle to save him some money on fuel. I was wondering if
Alex does something similar and if you have any interest in to capture this data and maybe put
it into a self-hosted solution like Grafana. So I don't know if either one of us are actively
capturing our OBD2 data from our cars, but I know we both have done things with them. Well, I was,
I was using this thing called the automatic, which you put me onto actually, Chris.
And it wasn't self-hosted. It was an entirely proprietary thing. And I used to talk to if this,
then that and log all my trips in a spreadsheet. And it was, it was kind of interesting. It didn't
really do a lot that was, you know, life shatteringly interesting. I would be really
interested in a device that went into my OBD2 port and could talk to my Grafana and InfluxDB
set up. But then you have to factor in that it needs a cellular connection as well as GPS. And
very quickly it becomes quite a complicated device. So unless you already have a LAN in your vehicle
like I do, not everyone's house is their car. Yeah. I actually mostly just use this for real
time data. It is so aggravating how much information my truck's computer inside the RV has
that is not displayed on the dashboard. I kind of get it for your average commuter car, maybe,
you know, just a couple of dummy lights and some dials fine, but in a super duty engine that's
massive, that has all these different thermal things and just like all these sensors that
they've built in the, the car computer, the truck engine computer is collecting an incredible amount
of information and doing nothing with it. And I find that so aggravating. So I did get just some
crappy one, some Bluetooth OBD2 dongle that you plug in every car manufactured in the United
States since 2012 or sold in the United States at least since 2012 has these ports. You plug it in
there and different vehicles will give you different levels of information. So you need to
pair that with a device that understands the information from your vehicle's engine. A lot of
the apps that you can get for your phone that talk to these dongles have a database of vehicles and
they can kind of do something with the information. And I put that up on either an iOS device or an
Android device as I'm going down the road, especially when I'm going over passes, and I get
all my coolant information, all of my air intake information, I get my engine performance, my turbo
boost information, I get the transmission temperature, the oil temperature, I get all the
sensor information that is never displayed to me on my dash. And I've never thought about capturing
that. But when Pete wrote in with this email, kind of made me realize this would be a fascinating
way to monitor the long term health of an engine, wouldn't it? It's taking all of this data and
graphing it and then seeing trend lines change over time. That's really the power of a good
graph, isn't it? It's just seeing that the overall trend. I mean, the humidity in my basement to
come back to a previous episode, I was able to spot different storms throughout the year and
notice the trend that in the summer it was getting too high, because I had it graphed every day. And
I think if you're able to take a decent set of readings are actually meaningful readings. I mean,
I don't know what you'd necessarily do with oil temperature, although maybe you'd see that over
six months, it creeps up by an average of three or four degrees. Who knows? Certainly an interesting
thing. And if anybody has any, any solutions in the audience, please write in self hosted dot show
slash contact. Optimus Gray writes in. He wants us to put on our consulting hats. So get your day job
hat on there. Alex says I was looking at my Docker list and I have four MariaDBs running. One is my
personal website. I have C file. I have get T and next cloud. Should I work on merging these into
one database, one's database server, or is it worth keeping four copies or more of the same
image running? What a great question. There is no right answer to this question. I don't think. No,
I agree. You asked three different people, you get three different answers. So there are two main
schools of thought, right? So my assumption is that all of these different things are using the
same database engine underneath, whether that's MySQL, Postgres, whatever, it doesn't really matter
what the database is. For a while, for a couple of years, I actually just ran one MySQL database
I actually just ran one MySQL container and then just manually went in through the MySQL command
line and created new databases, added new users, scoped them correctly and learned a little bit
about the MySQL command line. But lately I've been spinning up a lot of stuff for the show
on Linode and doing a lot of stuff for family members and friends and stuff like that and just
testing out a lot of stuff for the podcast, really. And so I don't want to have to futz
with that every time. And most containers that you spin up, most database containers,
have the option to feed in through environment variables, the username and password for that
specific database table you need to create for the app. And so lately I've moved into
creating a database instance per app. It's a bit wasteful in terms of system resources, but
I think it's, you know, in terms of simplicity, it's a lot easier to manage in terms of backups,
in terms of administration, initial setup. One database per container is my current strategy.
Yeah, it really is what you're trying to get out of your setup. Do you want simplicity
and the ability to just easily tear it down and throw things back up again,
or do you want efficiency? And you could also argue that if you only have one instance of a
database running, not only do you save system resources, but you theoretically reduce your
tech surface, right? So there's not as many vulnerabilities when there's something that shows
up in MariaDB. You have only one instance instead of four. You have one version instead of
potentially four different versions, depending on how the containers are set up. So while there is
advantage to it, I think I'm going to side with Alex here is because we kind of used to do the
same exact thing, is we had one database server, both for our cloud instances and for our local
instances. And then all of the containers and applications would use those. And it worked fine.
But we did run into a couple of instances where the application expected it was the sole
use of the database, or there were several scenarios where it became a lot more overhead
to maintain that one instance and reconfigure software on the regular. And what we ended up
doing when we kind of redid things recently is we did the same thing as Alex just suggested.
We just went ahead and did a database for each one of the applications we're running that pulls it
down. And it does mean that I have a couple of instances of the same database software running,
and I don't find that ideal. But because they're not open to the general public,
they're not even open to the general network, I don't consider the attack surface issue to be
as serious as I would have back in the day when these were entire VMs or they were entire physical
servers that were on the LAN and maybe even connected to the public internet, God forbid.
And in that scenario, I would consider the efficiency and the lower attack surface a much
higher important consideration. But when you're running it for yourself on your own LAN,
you maybe have very limited control of what can talk to it publicly. I think the risk scenario
goes down, and then the convenience and reproducibility factor becomes more important.
And I say, just let it be and run each one individually and save yourself the hassle.
The other thing is, if you want to port one service to a different system, let's say you
wanted to move Nextcloud from your LAN to a Linode instance, for example, you haven't got to then
worry about MySQL commands to export and dump databases and all that kind of stuff. You just
move the Docker app volumes and you're good to go. Jay writes in with our last email this week,
and it's a frustrating one. He has an issue where when his clients go to sleep,
they're unable to remount the NFS on his FreeNAS. He tried Samba, but it's not ideal with FreeNAS
in his opinion. And he wanted a solution to automatically remount these. We've mentioned
AutoFS in the past, but he said it's running into some deficiencies. And so I knew this has got to
be a problem that other people run into, where you have a laptop or you have a desktop, it goes
into power saving mode, you bring it back up, and now your mounts are dead. They just will not
reconnect despite all of the tools that are supposed to make them do it. I have some advice
for you, Jay, and anyone else that runs into this. This is an area where it's worth learning
a little bit of SystemD because SystemD has a facility for this that is network aware.
And then it notices that when your network connection comes back up, which is actually
what's happening when you're waking from sleep, it'll auto remount those file systems. And I have
resources in the show notes to help with that. Cloudfree.shop. This is where you go to buy stuff
that's ready to run on your LAN and never needs a cloud connection. A wide range of smart home devices
that come pre flashed with Tasmota. No cloud connection means that you run it for as long as
you want. You own it. And something that Alex and I brought up last episode and we've been informed
is on the cloudfree.shop is these little metal NFC tags that work outdoors that are kind of,
I think, the best looking to. They're on the shop for a dollar a piece. How great is that? So go to
cloudfree.shop and use the coupon code self-hosted at checkout and you'll get a dollar off each one
of the smart plugs you get, which I think they're only like 10 bucks, right? Correct. Yeah. And
they're pre flashed with Tasmota. So it's a great way to get going with Home Assistant and devices
you fully control at a great price. Cloudfree.shop. Well, it finally happened. Can you believe it?
ESXi on a Raspberry Pi. Now, are you taking it seriously? No. I thought this might be it. Yeah,
ESXi. Now, it's a fling edition, which means it's not really meant for production,
but I think they're really serious about it. And I'm going to try it out. There is some
current limitations I thought maybe people should be aware of that are kind of important,
but I think this is huge. Is it the limitation that I read where you can't actually run any VMs
on it? No. No, it's the issue is there's no local storage at the moment. Not even USB.
Not a big deal at all, that one. No, you just do it over NFS. It's fine. It's fine. Yeah,
you do it over it. But it is ESXi 7. You do have to have UEFI boot. And so there's a few extra
steps you have to go through. I'll have a link in the show notes to how to walk through all of that.
But all said and done, you can run four or five ARM VMs on this. You have about six gigs of RAM
leftover after you have VMware in the core OS. It uses somewhere in the neighborhood of just under
two gigs. But if you have an eight gigabyte edition Raspberry Pi 4, you could still run a
couple of VMs. And you get a lot of the more enterprise grade features like vMotion. But also
you could use this to just access VMFS file systems where in the past you'd have to have
a massive expensive x86 server just to mount a disk that you need to recover files from.
Now you can do it with a Raspberry Pi. Additionally, if you are learning VMware,
you say you're getting a job somewhere that is using ESXi infrastructure and you don't
understand VMware, well, you don't have a lot of options that aren't super expensive
to learn on. But now you could go get a $75 Raspberry Pi and actually run an image from them
that gives you a lot of that experience and lets you plug in with the wider VMware infrastructure.
And there's got to be some decent backup scenarios. I'm not even thinking with this.
So you're going to be limited to ARM VMs, but you imagine something like this, Alex,
and you say the Raspberry Pi 8. And now all of a sudden you could see how this could be
really great, like at the edge or on-premises virtualization to run several services on a low
power little Raspberry Pi. But you get the additional benefit of everything being in VMware
so you can manage it with your entire tool set. And I could see this going somewhere kind of cool.
It's early days, but I could see it getting pretty neat.
The cynic in me thinks the only reason VMware are doing this is because of Apple.
When I listened to a podcast, which we have a link in the show notes too, that talked about
a lot of the larger server ARM boards that are these massive ARM systems, minimum 16-core,
160 gigs of RAM minimum kind of system, like massive ARM boxes,
and go up to several terabytes of RAM and whatnot, 24 cores and 32 cores.
One of the things they were saying, though, is that, again, it's the problem of developing
software for those big data center ARM boxes. Developers need something that is approachable
that they can execute ARM code on. And the nice thing about VMware here is they're abstracting
out the details of, are you specifically supporting the Raspberry Pi's video card
and network controller? Or can you just deploy for VMware and just focus on creating really
fast ARM code and then eventually move that up to the cloud? And I think that's part of
their strategy is to give people a development environment they can run on their land,
throw in their bag to deploy on ARM in the cloud running VMware.
You know where I can see this being useful? If you're a traveling salesperson or pre-sales
engineer or something, whip out a Raspberry Pi in a sales meeting and boom. If you don't want
to use AWS for some reason, I don't know. You know that's going to be a thing,
right? People showing up with Pi's and little virtual environments. I'm not a big VMware guy
anymore, but I did, as part of an old job as a previous life, run an infrastructure on VMware.
And so I get kind of excited about this. If this was usable for say, solidly four VMs,
I could see have gone, I mean, have gone this way. I could have gone this way potentially,
instead of having four Pi's, I could have had maybe one eight gig Pi.
I view this very much as a signal of intent rather than something that's useful right now.
Yeah. Something I'm definitely going to keep an eye on and I'll probably wait for a couple of
builds because they're getting a lot of community feedback and they're rolling out releases. So I'm
going to wait for a release or two to land and then I think I'm going to try it on my eight gig Pi.
Now we found a pick for you. This one's called Archivee and it's a self-hosted knowledge
repository that allows you to safely preserve useful content that contributes to your own
personal knowledge bank. Yeah. Imagine like sucking down an entire website and all of its
assets into your own knowledge bank. That's a pretty cool idea. And I like that it ties in
with pocket. If you happen to use that, you can set it up so that anything you put in pocket,
it just sucks all down into your own personal database. I think the UI to navigate it
is a little simplistic, but it gets the job done. And it's a really super cool concept. If you are
an archivist who likes to just pull down all of the things for your research, I've definitely had
projects where we linked to stuff and then that website goes offline or the story changes. And
I really had wished I'd archived an original version. Yeah. Having that local copy of stuff's
very useful. I can't remember what the show was, but I saw another example of Netflix or was it
maybe Disney censoring? I think it was The Simpsons. So it must be Disney censoring episodes of The
Simpsons that are on Disney Plus. Whereas if you had the DVD on your shelf, they could never change
it. So it's a similar kind of mindset. It seems like the project is fairly active and the developer
intends to add integrations with Hacker News and Reddit. So if you have stories on there that you've
upvoted, you could potentially integrate that in with this and just have it go and automatically
archive that story for you, which I really like that idea. So I'm keeping my eye on this one.
You know, I'm interested because it runs out of Docker, but it also requires Elastic Search. So
there is a little bit of no batteries included setup required. So just bear that in mind.
I want to say thank you to our members. If you are interested in supporting the show and get a
limited ad feed of this here show, plus extra content, you get a post show, go to selfhosted.show
slash SRE and become one of our site reliability engineers that keeps the show going. As always,
you can find different ways to get in touch with us at selfhosted.show slash contact.
I'm on Twitter at ironicbadger. I'm there at Chris Lass and the show is at Self Hosted Show.
Thanks for listening, everyone. That was selfhosted.show slash 30.
